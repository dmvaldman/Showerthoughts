[
  {
    "year": 1995,
    "label": "A1",
    "difficulty": "1",
    "problem": "Let $S$ be a set of real numbers which is closed under\nmultiplication (that is, if $a$ and $b$ are in $S$, then so is $ab$).\nLet $T$ and $U$ be disjoint subsets of $S$ whose union is $S$. Given\nthat the product of any {\\em three} (not necessarily distinct)\nelements of $T$ is in $T$ and that the product of any three elements\nof $U$ is in $U$, show that at least one of the two subsets $T,U$ is\nclosed under multiplication.",
    "solution": "Suppose on the contrary that there exist $t_{1}, t_{2} \\in T$\nwith $t_{1}t_{2} \\in U$ and $u_{1}, u_{2} \\in U$ with $u_{1}u_{2} \\in\nT$. Then $(t_{1}t_{2})u_{1}u_{2} \\in U$ while\n$t_{1}t_{2}(u_{1}u_{2}) \\in T$, contradiction."
  },
  {
    "year": 1995,
    "label": "A2",
    "difficulty": "2",
    "problem": "For what pairs $(a,b)$ of positive real numbers does the\nimproper integral\n\\[\n\\int_{b}^{\\infty} \\left( \\sqrt{\\sqrt{x+a}-\\sqrt{x}} -\n\\sqrt{\\sqrt{x}-\\sqrt{x-b}} \\right)\\,dx\n\\]\nconverge?",
    "solution": "The integral converges iff $a=b$. The easiest proof uses\n``big-O'' notation and the fact that $(1+x)^{1/2} = 1 + x/2 +\nO(x^{2})$ for $|x|<1$. (Here $O(x^{2})$ means bounded by a constant\ntimes $x^{2}$.)\n\nSo\n\\begin{align*}\n\\sqrt{x+a}-\\sqrt{x} &= x^{1/2}(\\sqrt{1+a/x} - 1) \\\\\n&= x^{1/2}(1 + a/2x + O(x^{-2})),\n\\end{align*}\nhence\n\\[\n\\sqrt{\\sqrt{x+a} - \\sqrt{x}} = x^{1/4} (a/4x + O(x^{-2}))\n\\]\nand similarly\n\\[\n\\sqrt{\\sqrt{x} - \\sqrt{x-b}} = x^{1/4} (b/4x + O(x^{-2})).\n\\]\nHence the integral we're looking at is\n\\[\n\\int_{b}^{\\infty} x^{1/4} ((a-b)/4x + O(x^{-2}))\\,dx.\n\\]\nThe term $x^{1/4} O(x^{-2})$ is bounded by a constant times\n$x^{-7/4}$, whose integral converges. Thus we only have to decide\nwhether $x^{-3/4} (a-b)/4$ converges. But $x^{-3/4}$ has divergent\nintegral, so we get convergence if and only if $a=b$ (in which case\nthe integral telescopes anyway)."
  },
  {
    "year": 1995,
    "label": "A3",
    "difficulty": "3",
    "problem": "The number $d_{1}d_{2}\\dots d_{9}$ has nine (not\nnecessarily distinct) decimal digits. The number $e_{1}e_{2}\\dots\ne_{9}$ is such that each of the nine 9-digit numbers formed by\nreplacing just one of the digits $d_{i}$ is $d_{1}d_{2}\\dots d_{9}$\nby the corresponding digit $e_{i}$ ($1 \\leq i \\leq 9$) is divisible\nby 7. The number $f_{1}f_{2}\\dots f_{9}$ is related to\n$e_{1}e_{2}\\dots e_{9}$ is the same way: that is, each of the nine\nnumbers formed by replacing one of the $e_{i}$ by the corresponding\n$f_{i}$ is divisible by 7. Show that, for each $i$, $d_{i}-f_{i}$ is\ndivisible by 7. [For example, if $d_{1}d_{2}\\dots d_{9} = 199501996$,\nthen $e_{6}$ may be 2 or 9, since $199502996$ and $199509996$ are\nmultiples of 7.]",
    "solution": "Let $D$ and $E$ be the numbers $d_{1}\\dots d_{9}$ and $e_{1}\\dots\ne_{9}$, respectively. We are given that $(e_{i} - d_{i})10^{9-i} + D\n\\equiv 0 \\pmod 7$ and $(f_{i} - e_{i})10^{9-i} + E \\equiv 0 \\pmod 7$\nfor $i=1, \\dots, 9$. Sum the first relation over $i=1,\\dots,9$ and we\nget $E - D + 9D \\equiv 0 \\pmod 7$, or $E + D \\equiv 0 \\pmod 7$. Now\nadd the first and second relations for any particular value of $i$\nand we get $(f_{i} - d_{i})10^{9-i} + E + D \\equiv 0 \\pmod 7$. But we\nknow $E+D$ is divisible by 7, and 10 is coprime to 7, so $d_{i} -\nf_{i} \\equiv 0 \\pmod 7$."
  },
  {
    "year": 1995,
    "label": "A4",
    "difficulty": "4",
    "problem": "Suppose we have a necklace of $n$ beads. Each bead is\nlabeled with an integer and the sum of all these labels is $n-1$.\nProve that we can cut the necklace to form a string whose\nconsecutive labels $x_{1},x_{2},\\dots,x_{n}$ satisfy\n\\[\n\\sum_{i=1}^{k} x_{i} \\leq k-1 \\qquad \\mbox{for} \\quad k=1,2,\\dots,n.\n\\]",
    "solution": "Let $s_{k} = x_{1} + \\cdots + x_{k} - k(n-1)/n$, so that $s_{n} =\ns_{0} = 0$. These form a cyclic sequence that doesn't change when you\nrotate the necklace, except that the entire sequence gets translated\nby a constant. In particular, it makes sense to choose $x_{i}$ for\nwhich $s_{i}$ is maximum and make that one $x_{n}$; this way $s_{i}\n\\leq 0$ for all $i$, which gives $x_{1} + \\cdots + x_{i} \\leq\ni(n-1)/n$, but the right side may be replaced by $i-1$ since the left\nside is an integer."
  },
  {
    "year": 1995,
    "label": "A5",
    "difficulty": "5",
    "problem": "Let $x_{1},x_{2},\\dots,x_{n}$ be differentiable\n(real-valued) functions of a single variable $f$ which satisfy\n\\begin{align*}\n\\frac{dx_{1}}{dt} &= a_{11}x_{1} + a_{12}x_{2} + \\cdots +\na_{1n}x_{n} \\\\\n\\frac{dx_{2}}{dt} &= a_{21}x_{1} + a_{22}x_{2} + \\cdots +\na_{2n}x_{n} \\\\\n\\vdots && \\vdots \\\\\n\\frac{dx_{n}}{dt} &= a_{n1}x_{1} + a_{n2}x_{2} + \\cdots +\na_{nn}x_{n}\n\\end{align*}\nfor some constants $a_{ij}>0$. Suppose that for all $i$, $x_{i}(t)\n\\to 0$ as $t \\to \\infty$. Are the functions $x_{1},x_{2},\\dots,x_{n}$\nnecessarily linearly dependent?",
    "solution": "Everyone (presumably) knows that the set of solutions of a system of\nlinear first-order differential equations with constant coefficients\nis $n$-dimensional, with basis vectors of the form $f_{i}(t)\n\\vec{v}_{i}$ (i.e.\\ a function times a constant vector), where the\n$\\vec{v}_{i}$ are linearly independent. In\nparticular, our solution $\\vec{x}(t)$ can be written as $\\sum_{i=1}^{n}\nc_{i}f_{i}(t) \\vec{v}_{1}$.\n\nChoose a vector $\\vec{w}$ orthogonal to $\\vec{v}_{2}, \\dots,\n\\vec{v}_{n}$ but not to $\\vec{v}_1$. Since $\\vec{x}(t) \\to 0$ as $t\n\\to \\infty$, the same is true of $\\vec{w} \\cdot \\vec{x}$; but that is\nsimply $(\\vec{w} \\cdot \\vec{v}_{1}) c_{1} f_{1}(t)$. In other words,\nif $c_{i} \\neq 0$, then $f_{i}(t)$ must also go to 0.\n\nHowever, it is easy to exhibit a solution which does not go to 0. The\nsum of the eigenvalues of the matrix $A = (a_{ij})$, also known as the\ntrace of $A$, being the sum of the diagonal entries of $A$, is\nnonnegative, so $A$ has an eigenvalue $\\lambda$ with nonnegative real\npart, and a corresponding eigenvector $\\vec{v}$. Then $e^{\\lambda t}\n\\vec{v}$ is a solution that does not go to 0. (If $\\lambda$ is not\nreal, add this solution to its complex conjugate to get a real\nsolution, which still doesn't go to 0.)\n\nHence one of the $c_{i}$, say $c_{1}$, is zero, in which case\n$\\vec{x}(t) \\cdot \\vec{w} = 0$ for all $t$."
  },
  {
    "year": 1995,
    "label": "A6",
    "difficulty": "6",
    "problem": "Suppose that each of $n$ people writes down the numbers\n1,2,3 in random order in one column of a $3 \\times n$ matrix, with\nall orders equally likely and with the orders for different columns\nindependent of each other. Let the row sums $a,b,c$ of the resulting\nmatrix be rearranged (if necessary) so that $a \\leq b \\leq c$. Show\nthat for some $n \\geq 1995$, it is at least four times as likely that\nboth $b=a+1$ and $c=a+2$ as that $a=b=c$.",
    "solution": "View this as a random walk/Markov process with states $(i,j,k)$ the\ntriples of integers with sum 0, corresponding to the difference\nbetween the first, second and third rows with their average (twice\nthe number of columns). Adding a new column adds on a random\npermutation of the vector $(1,0,-1)$. I prefer to identify the\ntriple $(i,j,k)$ with the point $(i-j) + (j-k)\\omega +\n(k-i)\\omega^{2}$ in the plane, where $\\omega$ is a cube root of\nunity. Then adding a new column corresponds to moving to one of the\nsix neighbors of the current position in a triangular lattice.\n\nWhat we'd like to argue is that for large enough $n$, the ratio of\nthe probabilities of being in any two particular states goes to 1.\nThen in fact, we'll see that eventually, about six times as many\nmatrices have $a=b-1,b=c-1$ than $a=b=c$. This is a pain to prove,\nthough, and in fact is way more than we actually need.\n\nLet $C_{n}$ and $A_{n}$ be the probability that we are at the origin,\nor at a particular point adjacent to the origin, respectively. Then\n$C_{n+1} = A_{n}$. (In fact, $C_{n+1}$ is $1/6$ times the sum of the\nprobabilities of being at each neighbor of the origin at time $n$, but\nthese are all $A_{n}$.) So the desired result, which is that\n$C_{n}/A_{n} \\geq 2/3$ for some large $n$, is equivalent to\n$A_{n+1}/A_{n} \\geq 2/3$.\n\nSuppose on the contrary that this is not the case; then $A_{n} < c\n(2/3)^{n}$ for some constant $n$. However, if $n=6m$, the probability\nthat we chose each of the six types of moves $m$ times is already\n$(6m)!/[m!^{6} 6^{6m}]$, which by Stirling's approximation is\nasymptotic to a constant times $m^{-5/2}$. This term alone is bigger\nthan $c (2/3)^{n}$, so we must have $A_{n+1}/A_{n} \\geq 2/3$ for\nsome $n$. (In fact, we must have $A_{n+1}/A_{n} \\geq 1-\\epsilon$ for\nany $\\epsilon>0$.)"
  },
  {
    "year": 1995,
    "label": "B1",
    "difficulty": "1",
    "problem": "For a partition $\\pi$ of $\\{1, 2, 3, 4, 5, 6, 7, 8, 9\\}$,\nlet $\\pi(x)$ be the number of elements in the part containing $x$.\nProve that for any two partitions $\\pi$ and $\\pi'$, there are two\ndistinct numbers $x$ and $y$ in $\\{1, 2, 3, 4, 5, 6, 7, 8, 9\\}$\nsuch that $\\pi(x) = \\pi(y)$ and $\\pi'(x) = \\pi'(y)$. [A {\\em\npartition} of a set $S$ is a collection of disjoint subsets (parts)\nwhose union is $S$.]",
    "solution": "For a given $\\pi$, no more than three different values of $\\pi(x)$\nare possible (four would require one part each of size at least\n1,2,3,4, and that's already more than 9 elements). If no such $x, y$\nexist, each pair $(\\pi(x), \\pi'(x))$ occurs for at most 1 element of\n$x$, and\nsince there are only $3 \\times 3$ possible pairs, each must occur\nexactly once. In particular, each value of $\\pi(x)$ must occur 3\ntimes. However, clearly any given value of $\\pi(x)$ occurs $k\\pi(x)$\ntimes, where $k$ is the number of distinct partitions of that size.\nThus $\\pi(x)$ can occur 3 times only if it equals 1 or 3, but we have\nthree distinct values for which it occurs, contradiction."
  },
  {
    "year": 1995,
    "label": "B2",
    "difficulty": "2",
    "problem": "An ellipse, whose semi-axes have lengths $a$ and $b$,\nrolls without slipping on the curve $y = c \\sin \\left( \\frac{x}{a}\n\\right)$. How are $a,b,c$ related, given that the ellipse completes\none revolution when it traverses one period of the curve?",
    "solution": "For those who haven't taken enough physics, ``rolling without\nslipping'' means that the perimeter of the ellipse and the curve pass\nat the same rate, so all we're saying is that the perimeter of the\nellipse equals the length of one period of the sine curve. So set up\nthe integrals:\n\\begin{multline*}\n\\int_{0}^{2\\pi} \\sqrt{(-a \\sin \\theta)^{2} + (b \\cos \\theta)^{2}}\\,\nd\\theta\\\\\n = \\int_{0}^{2\\pi a} \\sqrt{1 + (c/a \\cos x/a)^{2}}\\,dx.\n\\end{multline*}\nLet $\\theta = x/a$ in the second integral and write 1 as $\\sin^{2}\n\\theta + \\cos^{2} \\theta$ and you get\n\\begin{multline*}\n\\int_{0}^{2\\pi} \\sqrt{a^{2} \\sin^{2} \\theta + b^{2} \\cos^{2}\n\\theta}\\,d\\theta\\\\\n = \\int_{0}^{2\\pi} \\sqrt{a^{2} \\sin^{2} \\theta +\n(a^{2} + c^{2}) \\cos^{2} \\theta}\\,d\\theta.\n\\end{multline*}\nSince the left side is increasing as a function of $b$, we have\nequality if and only if $b^{2} = a^{2} + c^{2}$."
  },
  {
    "year": 1995,
    "label": "B3",
    "difficulty": "3",
    "problem": "To each positive integer with $n^{2}$ decimal digits, we\nassociate the determinant of the matrix obtained by writing the\ndigits in order across the rows. For example, for $n=2$, to the\ninteger 8617 we associate $\\det \\left(\n \\begin{array}{cc} 8 & 6 \\\\\n1 & 7 \\end{array} \\right) = 50$. Find, as a function of $n$, the\nsum of all the determinants associated with $n^{2}$-digit\nintegers. (Leading digits are assumed to be nonzero; for example,\nfor $n=2$, there are 9000 determinants.)",
    "solution": "For $n=1$ we obviously get 45, while for $n=3$ the answer is 0\nbecause it both changes sign (because determinants are alternating)\nand remains unchanged (by symmetry) when you switch any two rows other\nthan the first one. So only $n=2$ is left. By the multilinearity of\nthe determinant, the answer is the determinant of the matrix whose\nfirst (resp. second) row is the sum of all possible first (resp.\nsecond) rows. There are 90 first rows whose sum is the vector $(450,\n405)$, and 100 second rows whose sum is $(450, 450)$. Thus the answer\nis $450\\times 450 - 450 \\times 405 = 45 \\times 450 = 20250.$"
  },
  {
    "year": 1995,
    "label": "B4",
    "difficulty": "4",
    "problem": "Evaluate\n\\[\n\\sqrt[8]{2207 - \\frac{1}{2207-\\frac{1}{2207-\\dots}}}.\n\\]\nExpress your answer in the form $\\frac{a+b\\sqrt{c}}{d}$, where\n$a,b,c,d$ are integers.",
    "solution": "The infinite continued fraction is defined as the limit of the\nsequence $L_{0} = 2207, L_{n+1} = 2207-1/L_{n}$. Notice that the\nsequence is strictly decreasing (by induction) and thus indeed has a\nlimit $L$, which satisfies $L = 2207 - 1/L$, or rewriting, $L^{2} -\n2207L + 1 = 0$. Moreover, we want the greater of the two roots.\n\nNow how to compute the eighth root of $L$? Notice that if $x$\nsatisfies the quadratic $x^{2} - ax + 1 = 0$, then we have\n\\begin{align*}\n0 &= (x^{2} - ax + 1)(x^{2} + ax + 1) \\\\\n&= x^{4} - (a^{2} - 2)x^{2} + 1.\n\\end{align*}\nClearly, then, the positive square roots of the quadratic $x^{2} -\nbx + 1$ satisfy the quadratic $x^{2} - (b^{2}+2)^{1/2}x + 1 = 0$. Thus\nwe compute that $L^{1/2}$ is the greater root of $x^{2} - 47x + 1 =\n0$, $L^{1/4}$ is the greater root of $x^{2} - 7x+ 1 =0$, and\n$L^{1/8}$ is the greater root of $x^{2} - 3x + 1 = 0$, otherwise\nknown as $(3 + \\sqrt{5})/2$."
  },
  {
    "year": 1995,
    "label": "B5",
    "difficulty": "5",
    "problem": "A game starts with four heaps of beans, containing 3,4,5\nand 6 beans. The two players move alternately. A move consists of\ntaking \\textbf{either}\n\\begin{itemize}",
    "solution": "This problem is dumb if you know the Sprague-Grundy theory of normal\nimpartial games (see Conway, Berlekamp and Guy, {\\it Winning Ways},\nfor details). I'll describe how it applies here. To each position you\nassign a {\\em nim-value} as follows. A position with no moves (in\nwhich case the person to move has just lost) takes value 0. Any other\nposition is assigned the smallest number not assigned to a valid move\nfrom that position.\n\nFor a single pile, one sees that an empty pile has value 0, a pile of\n2 has value 1, a pile of 3 has value 2, a pile of 4 has value 0, a\npile of 5 has value 1, and a pile of 6 has value 0.\n\nYou add piles just like in standard Nim: the nim-value of the\ncomposite of two games (where at every turn you pick a game and make\na move there) is the ``base 2 addition without carries'' (i.e.\\\nexclusive OR) of the nim-values of the constituents. So our starting\nposition, with piles of 3, 4, 5, 6, has nim-value $2 \\oplus 0 \\oplus\n1 \\oplus 0 = 3$.\n\nA position is a win for the player to move if and only if it has a\nnonzero value, in which case the winning strategy is to always move to\na 0 position. (This is always possible from a nonzero position and\nnever from a zero position, which is precisely the condition that\ndefines the set of winning positions.) In this case, the winning move\nis to reduce the pile of 3 down to 2, and you can easily describe the\nentire strategy if you so desire."
  },
  {
    "year": 1995,
    "label": "B6",
    "difficulty": "6",
    "problem": "For a positive real number $\\alpha$, define\n\\[\nS(\\alpha) = \\{ \\lfloor n\\alpha \\rfloor : n = 1,2,3,\\dots \\}.\n\\]\nProve that $\\{1,2,3,\\dots\\}$ cannot be expressed as the disjoint\nunion of three sets $S(\\alpha), S(\\beta)$ and $S(\\gamma)$. [As\nusual, $\\lfloor x \\rfloor$ is the greatest integer $\\leq x$.]\n\n\\end{itemize}\n\\end{document}",
    "solution": "Obviously $\\alpha, \\beta, \\gamma$ have to be greater than 1, and no\ntwo can both be rational, so without loss of generality assume that\n$\\alpha$ and $\\beta$ are irrational.\nLet $\\{x\\} = x - \\lfloor x \\rfloor$ denote the fractional part of $x$.\nThen $m \\in S(\\alpha)$ if and only if $f(m/\\alpha) \\in (1-1/\\alpha,1)\n\\cup \\{0\\}$. In particular, this means that $S(\\alpha) \\cap \\{1,\n\\dots, n\\}$ contains $\\lceil (n+1)/\\alpha \\rceil -1$ elements, and\nsimilarly. Hence for every integer $n$,\n\\[\nn = \\left\\lceil \\frac{n+1}\\alpha \\right\\rceil +\n \\left\\lceil \\frac{n+1}\\beta \\right\\rceil +\n \\left\\lceil \\frac{n+1}\\gamma \\right\\rceil -3.\n\\]\nDividing through by $n$ and taking the limit as $n \\to \\infty$ shows\nthat $1/\\alpha + 1/\\beta + 1/\\gamma = 1$. That in turn implies that\nfor all $n$,\n\\[\n\\left\\{ - \\frac{n+1}{\\alpha} \\right\\} +\n\\left\\{ - \\frac{n+1}{\\beta} \\right\\} +\n\\left\\{ - \\frac{n+1}{\\gamma} \\right\\} = 2.\n\\]\nOur desired contradiction is equivalent to showing that the left side actually\ntakes the value 1 for some $n$. Since the left side is\nan integer, it suffices to show that $\\{ -(n+1)/\\alpha\\} +\n\\{-(n+1)/\\beta\\} < 1$ for some $n$.\n\nA result in ergodic theory (the two-dimensional version of the Weil\nequidistribution theorem) states that if $1,r,s$ are linearly\nindependent over the rationals, then the set of points $(\\{nr\\},\n\\{ns\\}$ is dense (and in fact equidistributed) in the unit square. In\nparticular, our claim definitely holds unless $a/\\alpha + b/\\beta =\nc$ for some integers $a,b,c$.\n\nOn the other hand, suppose that such a relation does hold. Since\n$\\alpha$ and $\\beta$ are irrational, by the one-dimensional Weil\ntheorem, the set of points $(\\{-n/\\alpha\\}, \\{-n/\\beta\\}$ is dense in\nthe set of $(x,y)$ in the unit square such that $ax + by$ is an integer.\nIt is simple enough to show that this set meets the region $\\{(x,y)\n\\in [0,1]^{2}: x+y<1\\}$ unless $a+b$ is an integer, and that would\nimply that $1/\\alpha + 1/\\beta$, a quantity between 0 and 1, is an\ninteger. We have our desired contradiction.\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 1996,
    "label": "A1",
    "difficulty": "1",
    "problem": "Find the least number $A$ such that for any two squares of combined\narea 1, a rectangle of area $A$ exists such that the two squares can\nbe packed in the rectangle (without interior overlap). You may assume\nthat the sides of the squares are parallel to the sides of the\nrectangle.",
    "solution": "If $x$ and $y$ are the sides of two squares with combined area 1, then\n$x^2 + y^2 = 1$. Suppose without loss of generality that $x \\geq y$.\nThen the shorter side of a rectangle containing both squares without\noverlap must be at least $x$, and the longer side must be at least\n$x+y$. Hence the desired value of $A$ is the maximum of $x(x+y)$.\n\nTo find this maximum, we let $x = \\cos \\theta, y = \\sin \\theta$ with\n$\\theta \\in [0, \\pi/4]$. Then we are to maximize\n\\begin{align*}\n\\cos^2 \\theta + \\sin \\theta \\cos \\theta\n&= \\frac 12 (1 + \\cos 2\\theta + \\sin 2\\theta) \\\\\n&= \\frac 12 + \\frac{\\sqrt{2}}{2} \\cos (2\\theta - \\pi/4) \\\\\n&\\leq \\frac{1 + \\sqrt{2}}{2},\n\\end{align*}\nwith equality for $\\theta = \\pi/8$. Hence this value is the desired\nvalue of $A$."
  },
  {
    "year": 1996,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $C_1$ and $C_2$ be circles whose centers are 10 units apart, and\nwhose radii are 1 and 3. Find, with proof, the locus of all points $M$\nfor which there exists points $X$ on $C_1$ and $Y$ on $C_2$ such that\n$M$ is the midpoint of the line segment $XY$.",
    "solution": "Let $O_1$ and $O_2$ be the centers of $C_1$ and $C_2$, respectively.\n(We are assuming $C_1$ has radius 1 and $C_2$ has radius 3.)\nThen the\ndesired locus is an annulus centered at the midpoint of $O_1O_2$, with\ninner radius 1 and outer radius 2.\n\nFor a fixed point $Q$ on $C_2$, the locus of the midpoints of the\nsegments $PQ$ for $P$ lying on $C_1$ is the image of $C_1$ under a\nhomothety centered at $Q$ of radius $1/2$, which is a circle of radius\n$1/2$. As $Q$ varies, the center of this smaller circle traces out a\ncircle $C_3$ of radius $3/2$ (again by homothety). By considering the two\npositions of $Q$ on the line of centers of the circles, one sees that\n$C_3$ is centered at the midpoint of $O_1O_2$, and the locus is now\nclearly the specified annulus."
  },
  {
    "year": 1996,
    "label": "A3",
    "difficulty": "3",
    "problem": "Suppose that each of 20 students has made a choice of anywhere from 0\nto 6 courses from a total of 6 courses offered. Prove or disprove:\nthere are 5 students and 2 courses such that all 5 have chosen both\ncourses or all 5 have chosen neither course.",
    "solution": "The claim is false. There are $\\binom{6}{3} = 20$ ways to choose 3 of the\n6 courses; have each student choose a different set of 3 courses. Then\neach pair of courses is chosen by 4 students (corresponding to the\nfour ways to complete this pair to a set of 3 courses) and is not\nchosen by 4 students (corresponding to the 3-element subsets of the\nremaining 4 courses).\n\nNote: Assuming that no two students choose the same courses,\nthe above counterexample is unique (up to permuting students).\nThis may be seen as follows: Given a group of students, suppose that\nfor any pair of courses (among the six) there are at most 4 students\ntaking both, and at most 4 taking neither.  Then there are at most\n$120=(4+4)\\binom{6}{2}$ pairs $(s,p)$, where $s$ is a student, and $p$\nis a set of two courses of which $s$ is taking either both or none.\nOn the other hand, if a student $s$ is taking $k$ courses, then he/she\noccurs in $f(k)=\\binom{k}{2}+\\binom{6-k}{2}$ such pairs $(s,p)$.  As\n$f(k)$ is minimized for $k=3$, it follows that every student occurs in\nat least $6=\\binom{3}{2}+\\binom{3}{2}$ such pairs $(s,p)$.  Hence\nthere can be at most $120/6=20$ students, with equality only if each\nstudent takes 3 courses, and for each set of two courses, there are\nexactly 4 students who take both and exactly 4 who take neither.\nSince there are only 4 ways to complete a given pair of courses to a\nset of 3, and only 4 ways to choose 3 courses not containing the given\npair, the only way for there to be 20 students (under our hypotheses)\nis if all sets of 3 courses are in fact taken.  This is the desired conclusion.\n\nHowever, Robin Chapman has pointed out that the solution is not unique\nin the problem as stated, because a given selection of courses may be\nmade by more than one student. One alternate solution is to identify\nthe 6 courses with pairs of antipodal vertices of an icosahedron, and\nhave each student pick a different face and choose the three vertices\ntouching that face. In this example, each of 10 selections is made by\na pair of students."
  },
  {
    "year": 1996,
    "label": "A4",
    "difficulty": "4",
    "problem": "Let $S$ be the set of ordered triples $(a, b, c)$ of distinct elements\nof a finite set $A$. Suppose that\n\\begin{enumerate}\n\\item $(a,b,c) \\in S$ if and only if $(b,c,a) \\in S$;\n\\item $(a,b,c) \\in S$ if and only if $(c,b,a) \\notin S$;\n\\item $(a,b,c)$ and $(c,d,a)$ are both in $S$ if and only if $(b,c,d)$\nand $(d,a,b)$ are both in $S$.\n\\end{enumerate}\nProve that there exists a one-to-one function $g$ from $A$ to $R$ such\nthat $g(a) < g(b) < g(c)$ implies $(a,b,c) \\in S$. Note: $R$ is the\nset of real numbers.",
    "solution": "In fact, we will show that such a function $g$ exists with the\nproperty that $(a,b,c) \\in S$ if and only if $g(d) < g(e) < g(f)$ for\nsome cyclic permutation $(d,e,f)$ of $(a,b,c)$. We proceed by\ninduction on the number of elements in $A$. If $A =\n\\{a,b,c\\}$ and $(a,b,c) \\in S$, then choose $g$ with $g(a) < g(b) <\ng(c)$, otherwise choose $g$ with $g(a) > g(b) > g(c)$.\n\nNow let $z$ be an element of $A$ and $B = A - \\{z\\}$.\nLet $a_{1}, \\dots, a_{n}$ be the elements of $B$ labeled such that\n$g(a_{1}) < g(a_{2}) < \\cdots < g(a_{n})$. We claim that there exists\na unique $i \\in \\{1, \\dots, n\\}$ such that $(a_{i}, z, a_{i+1})\n\\in S$, where hereafter $a_{n+k} = a_{k}$.\n\nWe show existence first. Suppose no such $i$ exists; then for all\n$i,k \\in \\{1, \\dots, n\\}$, we have $(a_{i+k}, z, a_{i}) \\notin S$.\nThis holds by property 1 for $k=1$ and by induction on $k$ in\ngeneral, noting that\n\\begin{align*}\n(a_{i+k+1}, z, a_{i+k}), &(a_{i+k}, z, a_{i})  \\in S \\\\\n&\\Rightarrow (a_{i+k}, a_{i+k+1}, z), (z, a_{i}, a_{i+k}) \\in S \\\\\n&\\Rightarrow (a_{i+k+1},z,a_{i}) \\in S.\n\\end{align*}\nApplying this when $k=n$, we get $(a_{i-1}, z, a_{i}) \\in S$,\ncontradicting the fact that $(a_{i}, z, a_{i-1}) \\in S$. Hence\nexistence follows.\n\nNow we show uniqueness. Suppose $(a_{i}, z, a_{i+1}) \\in S$; then for\nany $j \\neq i-1, i, i+1$, we have $(a_{i}, a_{i+1}, a_{j}), (a_{j},\na_{j+1}, a_{i}) \\in S$ by the\nassumption on $G$. Therefore\n\\begin{align*}\n(a_{i}, z, a_{i+1}), (a_{i+1}, a_{j}, a_{i}) \\in S\n&\\Rightarrow (a_{j}, a_{i}, z) \\in S \\\\\n(a_{i}, z, a_{j}), (a_{j}, a_{j+1}, a_{i}) \\in S\n&\\Rightarrow (z, a_{j}, a_{j+1}),\n\\end{align*}\nso $(a_{j}, z, a_{j+1}) \\notin S$. The case $j =i+1$ is ruled out by\n\\[\n(a_{i}, z, a_{i+1}), (a_{i+1}, a_{i+2}, a_{i}) \\in S \\Rightarrow (z,\na_{i+1}, a_{i+2}) \\in S\n\\]\nand the case $j=i-1$ is similar.\n\nFinally, we put $g(z)$ in $(g(a_{n}), + \\infty)$ if $i = n$, and\n$(g(a_{i}), g(a_{i+1}))$ otherwise; an analysis similar to that above\nshows that $g$ has the desired property."
  },
  {
    "year": 1996,
    "label": "A5",
    "difficulty": "5",
    "problem": "If $p$ is a prime number greater than 3 and $k = \\lfloor 2p/3\n\\rfloor$, prove that the sum\n\\[\n\\binom p1 + \\binom p2 + \\cdots + \\binom pk\n\\]\nof binomial coefficients is divisible by $p^2$.",
    "solution": "(due to Lenny Ng)\nFor $1 \\leq n \\leq p-1$, $p$ divides $\\binom pn$ and\n\\begin{align*}\n\\frac{1}{p} \\binom pn &= \\frac{1}{n} \\frac{p-1}{1} \\frac{p-2}{2} \\cdots\n\\frac{p-n+1}{n-1} \\\\\n&\\equiv \\frac{(-1)^{n-1}}{n} \\mymod{p},\n\\end{align*}\nwhere the congruence $x \\equiv y \\mymod{p}$ means that $x-y$ is a\nrational number whose numerator, in reduced form, is divisible by $p$.\nHence it suffices to show that\n\\[\n\\sum_{n=1}^k \\frac{(-1)^{n-1}}{n} \\equiv 0 \\mymod{p}.\n\\]\nWe distinguish two cases based on $p \\mymod{6}$. First suppose $p =\n6r+1$, so that $k = 4r$. Then\n\\begin{align*}\n\\sum_{n=1}^{4r} \\frac{(-1)^{n-1}}{n}\n&= \\sum_{n=1}^{4r} \\frac{1}{n} - 2 \\sum_{n=1}^{2r} \\frac{1}{2n} \\\\\n&= \\sum_{n=1}^{2r} \\left( \\frac{1}{n} - \\frac{1}{n} \\right)\n+ \\sum_{n=2r+1}^{3r} \\left( \\frac{1}{n} + \\frac{1}{6r+1-n} \\right) \\\\\n&= \\sum_{n=2r+1}^{3r} \\frac{p}{n(p-n)} \\equiv 0 \\mymod{p},\n\\end{align*}\nsince $p = 6r+1$.\n\nNow suppose $p = 6r+5$, so that $k = 4r + 3$. A similar argument gives\n\\begin{align*}\n\\sum_{n=1}^{4r+3}\\ \\frac{(-1)^{n-1}}{n}\n&= \\sum_{n=1}^{4r+3} \\frac{1}{n} + 2 \\sum_{n=1}^{2r+1} \\frac{1}{2n} \\\\\n&= \\sum_{n=1}^{2r+1} \\left( \\frac{1}{n} - \\frac{1}{n} \\right)\n+ \\sum_{n=2r+2}^{3r+2} \\left( \\frac{1}{n} + \\frac{1}{6r+5-n} \\right) \\\\\n&= \\sum_{n=2r+2}^{3r+2} \\frac{p}{n(p-n)} \\equiv 0 \\mymod{p}.\n\\end{align*}"
  },
  {
    "year": 1996,
    "label": "A6",
    "difficulty": "6",
    "problem": "Let $c>0$ be a constant. Give a complete description, with proof, of\nthe set of all continuous functions $f: R \\to R$ such that $f(x) =\nf(x^2+c)$ for all $x \\in R$. Note that $R$ denotes the set of real numbers.",
    "solution": "We first consider the case $c \\leq 1/4$; we shall show in this case\n$f$ must be constant. The relation\n\\[\nf(x) = f(x^2 + c) = f((-x)^2 + c) = f(-x)\n\\]\nproves that $f$ is an even function. Let $r_1 \\leq r_2$ be the roots of\n$x^2 + c - x$, both of which are real. If $x > r_{2}$, define $x_{0} =\nx$ and $x_{n+1} = \\sqrt{x_{n} - c}$ for each positive integer $x$. By\ninduction on $n$, $r_{2} < x_{n+1} < x_{n}$ for all $n$, so the\nsequence $\\{x_{n}\\}$ tends to a limit $L$ which is a root of $x^{2} +\nc = x$ not less than $r_{2}$. Of course this means $L = r_{2}$.\nSince $f(x) = f(x_{n})$ for all $n$ and $x_{n} \\to r_{2}$, we\nconclude $f(x) = f(r_{2})$, so $f$ is constant on $x \\geq r_{2}$.\n\nIf $r_{1} < x < r_{2}$ and $x_{n}$ is defined as before, then by\ninduction, $x_{n} < x_{n+1} < r_{2}$. Note that the\nsequence can be defined because $r_{1} > c$; the latter follows by\nnoting that the polynomial $x^{2} - x + c$ is positive at $x = c$ and\nhas its minimum at $1/2 > c$, so both roots are greater than $c$. In\nany case, we deduce that $f(x)$ is also constant on $r_{1} \\leq x \\leq\nr_{2}$.\n\nFinally, suppose $x < r_{1}$. Now define $x_{0} = x, x_{n+1} =\nx_{n}^{2} + c$. Given that $x_{n} < r_{1}$, we have $x_{n+1} >\nx_{n}$. Thus if we had $x_{n} < r_{1}$ for all $n$, by the same argument as\nin the first case we deduce $x_{n} \\to r_{1}$ and so $f(x) =\nf(r_{1})$. Actually, this doesn't happen; eventually we have $x_{n} >\nr_{1}$, in which case $f(x) = f(x_{n}) = f(r_{1})$ by what we have\nalready shown. We conclude that $f$ is a constant function. (Thanks\nto Marshall Buck for catching an inaccuracy in a previous version of\nthis solution.)\n\nNow suppose $c > 1/4$. Then the sequence $x_n$ defined by $x_0 = 0$\nand $x_{n+1} = x_n^2 + c$ is strictly increasing and has no limit\npoint. Thus if we define $f$ on $[x_0, x_1]$ as any continuous\nfunction with equal values on the endpoints, and extend the definition\nfrom $[x_n, x_{n+1}]$ to $[x_{n+1}, x_{n+2}]$ by the relation $f(x) =\nf(x^2 + c)$, and extend the definition further to $x < 0$ by the\nrelation $f(x) = f(-x)$, the resulting function has the desired\nproperty. Moreover, any function with that property clearly has this form."
  },
  {
    "year": 1996,
    "label": "B1",
    "difficulty": "1",
    "problem": "Define a \\textbf{selfish} set to be a set which has its own\ncardinality (number of elements) as an element. Find, with proof, the\nnumber of subsets of $\\{1, 2, \\ldots, n\\}$ which are \\textit{minimal}\nselfish sets, that is, selfish sets none of whose proper subsets is selfish.",
    "solution": "Let $[n]$ denote the set $\\{1,2,\\ldots,n\\}$, and let $f_n$ denote the\nnumber of minimal selfish subsets of $[n]$.  Then the number of\nminimal selfish subsets of $[n]$ not containing $n$ is equal to\n$f_{n-1}$.  On the other hand, for any minimal selfish subset of $[n]$\ncontaining $n$, by subtracting 1 from each element, and then taking\naway the element $n-1$ from the set, we obtain a minimal selfish\nsubset of $[n-2]$ (since $1$ and $n$ cannot both occur in a selfish\nset).  Conversely, any minimal selfish subset of $[n-2]$ gives rise to\na minimal selfish subset of $[n]$ containing $n$ by the inverse\nprocedure.  Hence the number of minimal selfish subsets of $[n]$\ncontaining $n$ is $f_{n-2}$.  Thus we obtain $f_n=f_{n-1}+f_{n-2}$.\nSince $f_1=f_2=1$, we have $f_n=F_n$, where $F_n$ denotes the $n$th\nterm of the Fibonacci sequence."
  },
  {
    "year": 1996,
    "label": "B2",
    "difficulty": "2",
    "problem": "Show that for every positive integer $n$,\n\\[\n\\left( \\frac{2n-1}{e} \\right)^{\\frac{2n-1}{2}} < 1 \\cdot 3 \\cdot 5\n\\cdots (2n-1) < \\left( \\frac{2n+1}{e} \\right)^{\\frac{2n+1}{2}}.\n\\]",
    "solution": "By estimating the area under the graph of $\\ln x$ using upper and\nlower rectangles of width 2, we get\n\\begin{align*}\n\\int_1^{2n-1} \\ln x\\,dx &\\leq 2(\\ln(3) + \\cdots + \\ln(2n-1)) \\\\\n&\\leq \\int_3^{2n+1} \\ln x\\,dx.\n\\end{align*}\nSince $\\int \\ln x\\,dx = x \\ln x - x + C$, we have, upon exponentiating\nand taking square roots,\n%\\begin{align*}\n%\\left( \\frac{2n-1}{e} \\right)^{\\frac{2n-1}{2}}\n%< (2n-1)^{\\frac{2n-1}{2}} e^{-n+1}\n%&\\leq 1 \\cdot 3 \\cdots (2n-1) \\\\\n%&\\leq (2n+1)^{\\frac{2n+1}{2}} \\frac{e^{-n+1}}{3^{3/2}}\n%< \\left( \\frac{2n+1}{e} \\right)^{\\frac{2n+1}{2}},\n%\\end{align*}\n\\begin{align*}\n\\left( \\frac{2n-1}{e} \\right)^{\\frac{2n-1}{2}}\n&< (2n-1)^{\\frac{2n-1}{2}} e^{-n+1} \\\\\n& \\leq 1 \\cdot 3 \\cdots (2n-1) \\\\\n& \\leq (2n+1)^{\\frac{2n+1}{2}} \\frac{e^{-n+1}}{3^{3/2}} \\\\\n& < \\left( \\frac{2n+1}{e} \\right)^{\\frac{2n+1}{2}},\n\\end{align*}\nusing the fact that $1 < e < 3$."
  },
  {
    "year": 1996,
    "label": "B3",
    "difficulty": "3",
    "problem": "Given that $\\{x_1, x_2, \\ldots, x_n\\} = \\{1, 2, \\ldots, n\\}$, find,\nwith proof, the largest possible value, as a function of $n$ (with $n\n\\geq 2$), of\n\\[\nx_1x_2 + x_2x_3 + \\cdots + x_{n-1}x_n + x_nx_1.\n\\]",
    "solution": "View $x_1, \\dots, x_n$ as an arrangement of the numbers $1, 2, \\dots,\nn$ on a circle.\nWe prove that the optimal arrangement is\n\\[\n\\dots, n-4, n-2, n, n-1, n-3, \\dots\n\\]\nTo show this, note that if\n$a, b$ is a pair of adjacent numbers and $c,d$ is another pair (read\nin the same order around the circle) with $a < d$ and $b > c$, then\nthe segment from $b$ to $c$ can be reversed, increasing the sum by\n\\[\nac + bd - ab - cd = (d-a)(b-c) > 0.\n\\]\nNow relabel the numbers so they appear in order as follows:\n\\[\n\\dots, a_{n-4}, a_{n-2}, a_n = n, a_{n-1}, a_{n-3}, \\dots\n\\]\nwhere without loss of generality we assume $a_{n-1} > a_{n-2}$. By\nconsidering the pairs $a_{n-2}, a_n$ and $a_{n-1}, a_{n-3}$ and using\nthe trivial fact $a_n > a_{n-1}$, we deduce $a_{n-2} > a_{n-3}$. We\nthen compare the pairs $a_{n-4}, a_{n-2}$ and $a_{n-1}, a_{n-3}$, and\nusing that $a_{n-1} > a_{n-2}$, we deduce $a_{n-3} > a_{n-4}$.\nContinuing in this\nfashion, we prove that $a_n > a_{n-1} > \\dots > a_1$ and\nso $a_k = k$ for $k = 1, 2, \\dots, n$, i.e.\\ that the optimal\narrangement is as claimed. In particular, the maximum value of the sum\nis\n\\begin{multline*}\n1 \\cdot 2 + (n-1)\\cdot n + 1 \\cdot 3 + 2 \\cdot 4 + \\cdots + (n-2)\\cdot n \\\\\n\\begin{aligned}\n&= 2 + n^2 - n + (1^2 - 1) + \\cdots + [(n-1)^2 - 1] \\\\\n&= n^2 - n + 2 - (n-1) + \\frac{(n-1)n(2n-1)}{6} \\\\\n&= \\frac{2n^3 + 3n^2 - 11n + 18}{6}.\n\\end{aligned}\n\\end{multline*}\n\nAlternate solution: We prove by induction that the value given above\nis an upper bound; it is clearly a lower bound because of the\narrangement given above. Assume this is the case for $n-1$. The optimal\narrangement for $n$ is obtained from some arrangement for $n-1$ by\ninserting $n$ between some pair $x, y$ of adjacent terms. This\noperation increases the sum by $nx + ny - xy = n^2 - (n-x)(n-y)$,\nwhich is an increasing function of both $x$ and $y$. In particular,\nthis difference is maximal when $x$ and $y$ equal $n-1$ and $n-2$.\nFortunately, this yields precisely the difference between the claimed\nupper bound for $n$ and the assumed upper bound for $n-1$, completing\nthe induction."
  },
  {
    "year": 1996,
    "label": "B4",
    "difficulty": "4",
    "problem": "For any square matrix $A$, we can define $\\sin A$ by the usual power\nseries:\n\\[\n\\sin A = \\sum_{n=0}^\\infty \\frac{(-1)^n}{(2n+1)!} A^{2n+1}.\n\\]\nProve or disprove: there exists a $2 \\times 2$ matrix $A$ with real\nentries such that\n\\[\n\\sin A = \\left( \\begin{array}{cc} 1 & 1996 \\\\ 0 & 1 \\end{array} \\right).\n\\]",
    "solution": "Suppose such a matrix $A$ exists.  If the eigenvalues of $A$ (over\nthe complex numbers) are distinct, then there exists a complex\nmatrix $C$ such that $B=CAC^{-1}$ is diagonal.  Consequently,\n$\\sin B$ is diagonal.  But then $\\sin A=C^{-1}(\\sin B)C$ must\nbe diagonalizable, a contradiction.  Hence the eigenvalues of $A$\nare the same, and $A$ has a conjugate $B=CAC^{-1}$ over\nthe complex numbers of the form\n\\[\n\\left(\n\\begin{array}{cc}\nx & y\\\\\n0 & x\n\\end{array}\n\\right).\n\\]\nA direct computation shows that\n\\[\n\\sin B = \\left(\n\\begin{array}{cc}\n\\sin x & y\\cdot \\cos x\\\\\n0 & \\sin x\n\\end{array}\n\\right).\n\\]\nSince $\\sin A$ and $\\sin B$ are conjugate, their eigenvalues\nmust be the same, and so we must have $\\sin x=1$.  This implies\n$\\cos x=0$, so that $\\sin B$ is the identity matrix, as must be $\\sin\nA$, a contradiction.\nThus $A$ cannot exist.\n\nAlternate solution (due to Craig Helfgott and Alex Popa):\nDefine both $\\sin A$ and $\\cos A$ by the usual power series.\nSince $A$ commutes with itself, the power series identity\n\\[\n\\sin^2 A+\\cos^2 A = I\n\\]\nholds.  But if $\\sin A$ is the given matrix, then by the\nabove identity, $\\cos^2 A$ must equal\n$\\left(\n\\begin{array}{cc}\n0 & -2\\cdot 1996\\\\\n0 & 0\n\\end{array}\n\\right)$\nwhich is a nilpotent matrix.  Thus $\\cos A$ is also nilpotent.\nHowever, the square of any $2\\times 2$ nilpotent matrix must be zero\n(e.g., by the Cayley-Hamilton theorem).  This is a contradiction."
  },
  {
    "year": 1996,
    "label": "B5",
    "difficulty": "5",
    "problem": "Given a finite string $S$ of symbols $X$ and $O$, we write $\\Delta(S)$\nfor the number of $X$'s in $S$ minus the number of $O$'s. For example,\n$\\Delta(XOOXOOX) = -1$. We call a string $S$ \\textbf{balanced} if every\nsubstring $T$ of (consecutive symbols of) $S$ has $-2 \\leq \\Delta(T)\n\\leq 2$. Thus, $XOOXOOX$ is not balanced, since it contains the\nsubstring $OOXOO$. Find, with proof, the number of balanced strings of\nlength $n$.",
    "solution": "Consider a $1 \\times n$ checkerboard, in which we write an $n$-letter\nstring, one letter per square. If the string is balanced, we can cover\neach pair of adjacent squares containing the same letter with a $1\n\\times 2$ domino, and these will not overlap (because no three in a\nrow can be the same). Moreover, any domino is separated from the next\nby an even number of squares, since they must cover opposite letters,\nand the sequence must alternate in between.\n\nConversely, any arrangement of dominoes where adjacent dominoes are\nseparated by an even number of squares corresponds to a unique\nbalanced string, once we choose whether the string starts with $X$ or\n$O$. In other words, the number of balanced strings is twice the\nnumber of acceptable domino arrangements.\n\nWe count these arrangements by numbering the squares $0,1,\\dots,n-1$\nand distinguishing whether the dominoes start on even or odd numbers.\nOnce this is decided, one simply chooses whether or not to put a\ndomino in each eligible position. Thus\nwe have $2^{\\lfloor n/2 \\rfloor}$ arrangements in the first case and $2^{\\lfloor\n(n-1)/2 \\rfloor}$ in the second, but note that the case of no dominoes has\nbeen counted twice. Hence the number of balanced strings is\n\\[\n2^{\\lfloor (n+2)/2 \\rfloor} + 2^{\\lfloor (n+1)/2 \\rfloor} - 2.\n\\]"
  },
  {
    "year": 1996,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $(a_1, b_1), (a_2, b_2), \\ldots, (a_n, b_n)$ be the vertices of a\nconvex polygon which contains the origin in its interior. Prove that\nthere exist positive real numbers $x$ and $y$ such that\n\\begin{gather*}\n(a_1, b_1)x^{a_1} y^{b_1} + (a_2, b_2)x^{a_2}y^{b_2} + \\cdots \\\\\n+ (a_n, b_n)x^{a_n}y^{b_n} = (0,0).\n\\end{gather*}\n\\end{itemize}\n\n\\end{document}",
    "solution": "We will prove the claim assuming only that the convex hull of the\npoints $(a_{i}, b_{i})$ contains the origin in its interior. (Thanks\nto Marshall Buck for pointing out that the last three words are\nnecessary in the previous sentence!) Let $u = \\log x, v = \\log\ny$ so that the left-hand side of the given equation is\n\\begin{multline}\n(a_1, b_1) \\exp(a_1 u + b_1 v) + (a_2, b_2) \\exp(a_2 u + b_2 v) + \\\\\n\\cdots + (a_n, b_n) \\exp(a_n u + b_n v).\n\\end{multline}\nNow note that (1) is the gradient of the function\n\\begin{gather*}\nf(u,v) = exp(a_1 u + b_1 v) +\nexp(a_2 u + b_2 v) + \\\\\n\\cdots + exp(a_n u + b_n v),\n\\end{gather*}\nand so it suffices to show $f$ has a critical point. We will in fact\nshow $f$ has a global minimum.\n\nClearly we have\n\\[\nf(u,v) \\geq \\exp\\left( \\max_i (a_i u + b_i v) \\right).\n\\]\nNote that this maximum is positive for $(u,v) \\neq (0,0)$:  if we had\n$a_i u + b_i v < 0$ for all $i$, then the subset $ur + vs < 0$ of the\n$rs$-plane would be a half-plane containing all of the points $(a_i,\nb_i)$, whose convex hull would then not contain the origin, a\ncontradiction.\n\nThe function $\\max_{i} (a_{i}u + b_{i}v)$ is clearly\ncontinuous on the unit circle $u^{2} + v^{2} = 1$, which is compact.\nHence it has a global minimum $M > 0$, and so for all $u,v$,\n\\[\n\\max_{i} (a_{i} u + b_{i} v) \\geq M \\sqrt{u^{2} + v^{2}}.\n\\]\nIn particular, $f \\geq n+1$ on the disk of radius $\\sqrt{(n+1)/M}$.\nSince $f(0,0) = n$, the infimum of $f$ is the same over the entire\n$uv$-plane as over this disk, which again is compact.\nHence $f$ attains its infimal value at some point in the disk,\nwhich is the desired global minimum.\n\nNoam Elkies has suggested an alternate solution as follows: for $r >\n0$, draw the loop traced by (1) as $(u,v)$ travels\ncounterclockwise around the circle $u^2 + v^2 = r^2$. For $r=0$, this\nof course has winding number 0 about any point, but for $r$ large, one\ncan show this loop has winding number 1 about the origin, so somewhere in\nbetween the loop must pass through the origin. (Proving this latter\nfact is a little tricky.)\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 1997,
    "label": "A1",
    "difficulty": "1",
    "problem": "A rectangle, $HOMF$, has sides $HO=11$ and $OM=5$.  A triangle\n$ABC$ has $H$ as the intersection of the altitudes, $O$ the center of\nthe circumscribed circle, $M$ the midpoint of $BC$, and $F$ the foot of the\naltitude from $A$.  What is the length of $BC$?",
    "solution": "The centroid $G$ of the triangle is collinear with $H$ and $O$\n(Euler line), and the centroid lies two-thirds of the way from $A$ to\n$M$. Therefore $H$ is also two-thirds of the way from $A$ to $F$, so\n$AF = 15$. Since the triangles $BFH$ and $AFC$ are similar (they're\nright triangles and\n\\[\n\\angle HBC = \\pi/2 - \\angle C = \\angle CAF),\n\\]\nwe have\n\\[\nBF/FH = AF/FC\n\\]\nor\n\\[\nBF \\cdot FC = FH \\cdot AF = 75.\n\\]\nNow\n\\[\nBC^2 = (BF + FC)^2 = (BF - FC)^2 + 4 BF \\cdot FC,\n\\]\nbut\n\\[\nBF - FC = BM+MF-(MC-MF) = 2MF = 22,\n\\]\nso\n\\[\nBC = \\sqrt{22^2 + 4 \\cdot 75} = \\sqrt{784} = 28.\n\\]"
  },
  {
    "year": 1997,
    "label": "A2",
    "difficulty": "2",
    "problem": "Players $1,2,3,\\ldots,n$ are seated around a table, and each has\na single penny.  Player 1 passes a penny to player 2, who then passes\ntwo pennies to player 3.  Player 3 then passes one penny to Player 4,\nwho passes two pennies to Player 5, and so on, players alternately\npassing one penny or two to the next player who still has some\npennies.  A player who runs out of pennies drops out of the game and\nleaves the table.  Find an infinite set of numbers $n$ for which some\nplayer ends up with all $n$ pennies.",
    "solution": "We show more precisely that the game terminates with one player\nholding all of the pennies if and only if $n = 2^m + 1$ or $n = 2^m +\n2$ for some $m$. First suppose we are in the following situation for\nsome $k \\geq 2$. (Note: for us, a ``move'' consists of two turns,\nstarting with a one-penny pass.)\n\\begin{itemize}\n\\item\nExcept for the player to move, each player has $k$ pennies;\n\\item\nThe player to move has at least $k$ pennies.\n\\end{itemize}\nWe claim then that\nthe game terminates if and only if the number of players is a\npower of 2. First suppose the number of players is even; then after\n$m$ complete rounds, every other player, starting with the player who\nmoved first, will have $m$ more pennies than initially, and the others\nwill all have 0. Thus we are reduced to the situation with half as\nmany players; by this process, we eventually reduce to the case where\nthe number of players is odd. However, if there is more than one\nplayer, after two complete rounds everyone has as many pennies as they\ndid before (here we need $m \\geq 2$), so the game fails to terminate.\nThis verifies the claim.\n\nReturning to the original game, note that after one complete round,\n$\\lfloor \\frac{n-1}{2} \\rfloor$ players remain, each with 2 pennies\nexcept for the player to move, who has\neither 3 or 4 pennies. Thus by the above argument, the game terminates\nif and only if $\\lfloor \\frac{n-1}{2} \\rfloor$ is a power of 2, that\nis, if and only if $n = 2^m + 1$ or $n = 2^m + 2$ for some $m$."
  },
  {
    "year": 1997,
    "label": "A3",
    "difficulty": "3",
    "problem": "Evaluate\n\\begin{gather*}\n\\int_0^\\infty \\left(x-\\frac{x^3}{2}+\\frac{x^5}{2\\cdot\n4}-\\frac{x^7}{2\\cdot 4\\cdot 6}+\\cdots\\right) \\\\\n\\left(1+\\frac{x^2}{2^2}+\n\\frac{x^4}{2^2\\cdot 4^2}+\\frac{x^6}{2^2\\cdot 4^2 \\cdot 6^2}+\\cdots\\right)\\,dx.\n\\end{gather*}",
    "solution": "Note that the series on the left is simply $x \\exp (-x^2/2)$.  By\nintegration by parts,\n\\[\n\\int_0^\\infty x^{2n+1} e^{-x^2/2} dx =\n2n \\int_0^\\infty x^{2n-1} e^{-x^2/2} dx\n\\]\nand so by induction,\n\\[\n\\int_0^\\infty x^{2n+1} e^{-x^2/2} dx =\n2 \\times 4 \\times \\cdots \\times 2n.\n\\]\nThus the desired\nintegral is simply\n\\[\n\\sum_{n=0}^\\infty \\frac{1}{2^n n!} = \\sqrt{e}.\n\\]"
  },
  {
    "year": 1997,
    "label": "A4",
    "difficulty": "4",
    "problem": "Let $G$ be a group with identity $e$ and $\\phi:G\\rightarrow G$\na function such that\n\\[\\phi(g_1)\\phi(g_2)\\phi(g_3)=\\phi(h_1)\\phi(h_2)\\phi(h_3)\\]\nwhenever $g_1g_2g_3=e=h_1h_2h_3$.  Prove that there exists an element\n$a\\in G$ such that $\\psi(x)=a\\phi(x)$ is a homomorphism (i.e.\n$\\psi(xy)=\\psi(x)\\psi(y)$ for all $x,y\\in G$).",
    "solution": "In order to have $\\psi(x) = a \\phi(x)$ for all $x$, we must in\nparticular have this for $x = e$, and so we take $a = \\phi(e)^{-1}$.\nWe first note that\n\\[\n\\phi(g) \\phi(e) \\phi(g^{-1}) = \\phi(e) \\phi(g) \\phi(g^{-1})\n\\]\nand so $\\phi(g)$ commutes with $\\phi(e)$ for all $g$. Next, we note that\n\\[\n\\phi(x) \\phi(y) \\phi(y^{-1}x^{-1}) = \\phi(e) \\phi(xy) \\phi(y^{-1}x^{-1})\n\\]\nand using the commutativity of $\\phi(e)$, we deduce\n\\[\n\\phi(e)^{-1} \\phi(x) \\phi(e)^{-1} \\phi(y) = \\phi(e)^{-1} \\phi(xy)\n\\]\nor $\\psi(xy) = \\psi(x) \\psi(y)$, as desired."
  },
  {
    "year": 1997,
    "label": "A5",
    "difficulty": "5",
    "problem": "Let $N_n$ denote the number of ordered $n$-tuples of positive\nintegers $(a_1,a_2,\\ldots,a_n)$ such that $1/a_1 + 1/a_2 +\\ldots +\n1/a_n=1$.  Determine whether $N_{10}$ is even or odd.",
    "solution": "We may discard any solutions for which $a_1 \\neq a_2$, since those come in\npairs; so assume $a_1 = a_2$.  Similarly, we may assume that $a_3 = a_4$,\n$a_5 = a_6$, $a_7 = a_8$, $a_9=a_{10}$.  Thus we get the equation\n\\[\n2/a_1 + 2/a_3 + 2/a_5 + 2/a_7 + 2/a_9 = 1.\n\\]\nAgain, we may assume $a_1 = a_3$ and $a_5 = a_7$, so we get $4/a_1 + 4/a_5\n+ 2/a_9 = 1$; and $a_1 = a_5$, so $8/a_1 + 2/a_9 = 1$.  This implies that\n$(a_1-8)(a_9-2) = 16$, which by counting has 5 solutions.  Thus $N_{10}$\nis odd."
  },
  {
    "year": 1997,
    "label": "A6",
    "difficulty": "6",
    "problem": "For a positive integer $n$ and any real number $c$, define\n$x_k$ recursively by $x_0=0$, $x_1=1$, and for $k\\geq 0$,\n\\[x_{k+2}=\\frac{cx_{k+1}-(n-k)x_k}{k+1}.\\]\nFix $n$ and then take $c$ to be the largest value for which $x_{n+1}=0$.\nFind $x_k$ in terms of $n$ and $k$, $1\\leq k\\leq n$.",
    "solution": "Clearly $x_{n+1}$ is a polynomial in $c$ of degree $n$,\nso it suffices to identify $n$ values of $c$ for which $x_{n+1} =\n0$. We claim these are $c = n-1-2r$ for $r=0,1,\\dots, n-1$; in this\ncase, $x_k$ is the coefficient of $t^{k-1}$ in the polynomial\n$f(t) = (1-t)^r (1+t)^{n-1-r}$. This can be verified by noticing that\n$f$ satisfies the differential equation\n\\[\n\\frac{f'(t)}{f(t)} = \\frac{n-1-r}{1+t} - \\frac{r}{1-t}\n\\]\n(by logarithmic differentiation) or equivalently,\n\\begin{align*}\n(1-t^2) f'(t) &= f(t) [(n-1-r)(1-t) - r(1+t)] \\\\\n&= f(t) [(n-1-2r)  - (n-1)t]\n\\end{align*}\nand then taking the coefficient of $t^{k}$ on both sides:\n\\begin{gather*}\n(k+1) x_{k+2} - (k-1) x_k = \\\\\n(n-1-2r) x_{k+1} - (n-1) x_{k}.\n\\end{gather*}\nIn particular, the largest such $c$ is $n-1$, and $x_k =\n\\binom{n-1}{k-1}$ for $k= 1, 2, \\dots, n$.\n\nGreg Kuperberg has suggested an alternate approach to show directly\nthat $c=n-1$ is the largest root, without computing the others. Note\nthat the condition $x_{n+1} = 0$ states that $(x_1, \\dots, x_n)$ is an\neigenvector of the matrix\n\\[\nA_{ij} = \\left\\{ \\begin{array}{cc} i & j = i + 1 \\\\ n-j & j=i-1 \\\\\n0&\\mbox{otherwise} \\end{array} \\right.\n\\]\nwith eigenvalue $c$. By the Perron-Frobenius theorem, $A$ has a unique\neigenvector with positive entries, whose eigenvalue has modulus\ngreater than or equal to that of any other eigenvalue, which proves\nthe claim."
  },
  {
    "year": 1997,
    "label": "B1",
    "difficulty": "1",
    "problem": "Let $\\{x\\}$ denote the distance between the real number $x$ and the\nnearest integer.  For each positive integer $n$, evaluate\n\\[F_n=\\sum_{m=1}^{6n-1} \\min(\\{\\frac{m}{6n}\\},\\{\\frac{m}{3n}\\}).\\]\n(Here $\\min(a,b)$ denotes the minimum of $a$ and $b$.)",
    "solution": "It is trivial to check that $\\frac{m}{6n}=\\{\\frac{m}{6n}\\}\\leq\n\\{\\frac{m}{3n}\\}$ for $1\\leq m\\leq 2n$, that\n$1-\\frac{m}{3n}=\\{\\frac{m}{3n}\\}\\leq \\{\\frac{m}{6n}\\}$ for $2n\\leq\nm\\leq 3n$, that $\\frac{m}{3n}-1=\\{\\frac{m}{3n}\\}\\leq \\{\\frac{m}{6n}\\}$\nfor $3n\\leq m\\leq 4n$, and that $1-\\frac{m}{6n}=\\{\\frac{m}{6n}\\}\\leq\n\\{\\frac{m}{3n}\\}$ for $4n\\leq m\\leq 6n$.  Therefore the desired sum is\n\\begin{gather*}\n\\sum_{m=1}^{2n-1} \\frac{m}{6n}\n +\\sum_{m=2n}^{3n-1} \\left(1-\\frac{m}{3n} \\right) \\\\\n +\\sum_{m=3n}^{4n-1} \\left(\\frac{m}{3n}-1 \\right) + \\sum_{m=4n}^{6n-1} \\left(\n1-\\frac{m}{6n} \\right)\n=n.\n\\end{gather*}"
  },
  {
    "year": 1997,
    "label": "B2",
    "difficulty": "2",
    "problem": "Let $f$ be a twice-differentiable real-valued function satisfying\n\\[f(x)+f''(x)=-xg(x)f'(x),\\]\nwhere $g(x)\\geq 0$ for all real $x$.  Prove that $|f(x)|$ is bounded.",
    "solution": "It suffices to show that $|f(x)|$ is bounded for $x \\geq 0$, since $f(-x)$\nsatisfies the same equation as $f(x)$.  But then\n\\begin{align*}\n\\frac{d}{dx}\\left(\n(f(x))^2 + (f'(x))^2 \\right) &= 2f'(x)(f(x)+f''(x)) \\\\\n&= -2xg(x)(f'(x))^2 \\leq 0,\n\\end{align*}\nso that $(f(x))^2 \\leq (f(0))^2 + (f'(0))^2$ for $x\\geq 0$."
  },
  {
    "year": 1997,
    "label": "B3",
    "difficulty": "3",
    "problem": "For each positive integer $n$, write the sum $\\sum_{m=1}^n\n1/m$ in the form $p_n/q_n$, where $p_n$ and $q_n$ are relatively prime\npositive integers.  Determine all $n$ such that 5 does not divide $q_n$.",
    "solution": "The only such $n$ are the numbers 1--4, 20--24, 100--104, and\n120--124.  For the proof let\n\\[H_n=\\sum_{m=1}^n \\frac{1}{m}\\]\nand introduce the auxiliary function\n\\[I_n=\\sum_{1\\leq m\\leq n, (m,5)=1} \\frac{1}{m}.\\]\nIt is immediate (e.g., by induction) that\n$I_n\\equiv 1,-1,1,0,0$ (mod $5$) for $n\\equiv  1,2,3,4,5$ (mod 5)\nrespectively, and moreover, we have the equality\n\\[\\label{(*)}\nH_n= \\sum_{m=0}^k \\frac{1}{5^m} I_{\\lfloor n/5^m \\rfloor},\\]\nwhere $k=k(n)$ denotes the largest integer such that $5^k\\leq n$.\nWe wish to determine those $n$ such that the above sum has nonnegative\n5--valuation.  (By the 5--valuation of a number $a$ we mean\nthe largest integer $v$ such that $a/5^v$ is an integer.)\n\nIf $\\lfloor n/5^k \\rfloor\\leq 3$, then the last term in the above sum\nhas 5--valuation $-k$, since $I_1$, $I_2$, $I_3$ each have valuation\n0; on the other hand, all other terms must have 5--valuation strictly\nlarger than $-k$.  It follows that $H_n$ has 5--valuation exactly\n$-k$; in particular, $H_n$ has nonnegative 5--valuation in this case\nif and only if $k=0$, i.e., $n=1$, 2, or 3.\n\nSuppose now that $\\lfloor n/5^k \\rfloor=4$.  Then we must also have\n$20\\leq \\lfloor n/5^{k-1}\\rfloor \\leq 24$.  The former condition\nimplies that the last term of the above sum is $I_4/5^k=1/(12\\cdot\n5^{k-2})$, which has 5--valuation $-(k-2)$.\n\nIt is clear that $I_{20}\\equiv I_{24}\\equiv 0$ (mod 25); hence if $\\lfloor\nn/5^{k-1}\\rfloor$ equals 20 or 24, then the second--to--last term of the\nabove sum (if it exists) has valuation at least $-(k-3)$.  The\nthird--to--last term (if it exists) is of the form $I_r/5^{k-2}$, so that\nthe sum of the last term and the third to last term takes the form\n$(I_r+1/12)/5^{k-2}$.  Since $I_r$ can be congruent only to 0,1, or -1\n(mod 5), and $1/12\\equiv 3$ (mod 5), we conclude that the sum of the\nlast term and third--to--last term has valuation $-(k-2)$, while all other\nterms have valuation strictly higher.  Hence $H_n$ has nonnegative\n5--valuation in this case only when $k\\leq 2$, leading to the values\n$n=4$ (arising from $k=0$), 20,24 (arising from $k=1$ and $\\lfloor\nn/5^{k-1}\\rfloor = 20$ and 24 resp.), 101, 102, 103, and 104 (arising\nfrom $k=2$, $\\lfloor n/5^{k-1}\\rfloor = 20$) and 120, 121, 122, 123,\nand 124 (arising from $k=2$, $\\lfloor n/5^{k-1}\\rfloor=24$).\n\nFinally, suppose $\\lfloor n/5^k \\rfloor=4$ and $\\lfloor n/5^{k-1}\n\\rfloor=21$, 22, or 23.  Then as before, the first condition\nimplies that the last term of the sum in (*) has valuation $-(k-2)$,\nwhile the second condition implies that the second--to--last term in the\nsame sum has valuation $-(k-1)$.  Hence all terms in the sum (*) have\n5--valuation strictly higher than $-(k-1)$, except for the\nsecond--to--last term, and therefore $H_n$ has 5--valuation $-(k-1)$ in\nthis case.  In particular, $H_n$ is integral (mod 5) in this case if and\nonly if  $k\\leq 1$, which gives the additional values $n=21$, 22, and 23."
  },
  {
    "year": 1997,
    "label": "B4",
    "difficulty": "4",
    "problem": "Let $a_{m,n}$ denote the coefficient of $x^n$ in the expansion of\n$(1+x+x^2)^m$.  Prove that for all [integers] $k\\geq 0$,\n\\[0\\leq \\sum_{i=0}^{\\lfloor \\frac{2k}{3}\\rfloor} (-1)^i a_{k-i,i}\\leq\n1.\\]",
    "solution": "Let $s_k = \\sum_i (-1)^{i} a_{k-1,i}$ be the given sum (note that\n$a_{k-1,i}$ is nonzero precisely for $i = 0, \\dots, \\lfloor\n\\frac{2k}{3} \\rfloor)$. Since\n\\[\na_{m+1,n} = a_{m,n} + a_{m,n-1} + a_{m,n-2},\n\\]\nwe have\n\\begin{align*}\ns_k - s_{k-1} + s_{k+2}\n&= \\sum_i (-1)^i (a_{n-i,i} + a_{n-i,i+1} + a_{n-i,i+2}) \\\\\n&= \\sum_i (-1)^i a_{n-i+1,i+2} = s_{k+3}.\n\\end{align*}\nBy computing $s_0 = 1, s_1 = 1, s_2 = 0$, we may easily verify by\ninduction that $s_{4j} = s_{4j+1} = 1$ and $s_{4j+2} = s_{4j+3} = 0$\nfor all $j \\geq 0$. (Alternate solution suggested by John Rickert:\nwrite $S(x,y) = \\sum_{i=0}^\\infty (y+xy^2+x^2y^3)^i$, and note\nnote that $s_k$ is the coefficient of $y^k$ in $S(-1,y) = (1+y)/(1-y^4)$.)"
  },
  {
    "year": 1997,
    "label": "B5",
    "difficulty": "5",
    "problem": "Prove that for $n\\geq 2$,\n\\[\n\\overbrace{2^{2^{\\cdots^{2}}}}^{\\mbox{$n$ terms}} \\equiv\n\\overbrace{2^{2^{\\cdots^{2}}}}^{\\mbox{$n-1$ terms}} \\quad \\pmod{n}.\n\\]",
    "solution": "Define the sequence $x_1 = 2$, $x_n = 2^{x_{n-1}}$ for $n > 1$. It\nsuffices to show that for every $n$, $x_m \\equiv x_{m+1} \\equiv \\cdots\n\\pmod n$ for some $m < n$. We do this by induction on $n$, with $n=2$\nbeing obvious.\n\nWrite $n = 2^a b$, where $b$ is odd. It suffices to show that $x_m\n\\equiv \\cdots$ modulo $2^a$ and modulo $b$, for some $m < n$. For the\nformer, we only need $x_{n-1} \\geq a$, but clearly\n$x_{n-1} \\geq n$ by induction on $n$. For the latter, note that\n$x_m \\equiv x_{m+1} \\equiv \\cdots\n\\pmod b$ as long as $x_{m-1} \\equiv x_m \\equiv \\cdots \\pmod{\\phi(b)}$,\nwhere $\\phi(n)$ is the Euler totient function. By hypothesis, this\noccurs for some $m < \\phi(b) + 1 \\leq n$. (Thanks to Anoop Kulkarni\nfor catching a lethal typo in an earlier version.)"
  },
  {
    "year": 1997,
    "label": "B6",
    "difficulty": "6",
    "problem": "The dissection of the 3--4--5 triangle shown below (into four\ncongruent right triangles similar to the original)\nhas diameter $5/2$.\nFind the least diameter of a dissection of this triangle into four parts.\n(The diameter of a dissection is the least upper bound of the distances\nbetween pairs of points belonging to the same part.)\n\n\\end{itemize}\n\n\\end{document}",
    "solution": "The answer is $25/13$.  Place the triangle on the cartesian plane so\nthat its vertices are at $C=(0,0), A=(0,3), B=(4,0)$.  Define also the points \n$D=(20/13,24/13),$ and $E=(27/13,0)$. We then compute that\n\\begin{align*}\n\\frac{25}{13} &= AD=BE=DE\\\\\n\\frac{27}{13} &= BC - CE = BE < BC \\\\\n\\frac{39}{13} &= AC < \\sqrt{AC^2 + CE^2} = AE \\\\\n\\frac{40}{13} &= AB - AD = BD < AB\n\\end{align*}\nand that $AD < CD$. In any dissection of the triangle into four parts, some two of $A,B,C,D,E$ must belong to the same part, forcing the least diameter to be at least $25/13$.\n\nWe now exhibit a dissection with least diameter $25/13$. (Some\nvariations of this dissection are possible.) Put $F = (15/13, 19/13)$,\n$G = (15/13, 0)$, $H = (0, 19/13)$, $J = (32/15, 15/13)$,\nand divide $ABC$ into the convex polygonal regions $ADFH$, $BEJ$, $CGFH$,\n$DFGEJ$. \nTo check that this dissection has least diameter $25/13$, it suffices (by the following remark) to check that the distances\n\\begin{gather*}\nAD, AF, AH, BE, BJ, DE, CF, CG, CH, \\\\\nDF, DG, DH, DJ, EF, EG, EJ, FG, FH, FJ, GJ\n\\end{gather*}\nare all at most $25/13$. This can be checked by a long numerical calculation, which we omit in favor of some shortcuts: note that $ADFH$ and $BEJ$ are contained in\ncircular sectors centered at $A$ and $B$, respectively, of radius\n$25/13$ and angle less than $\\pi/3$, while $CGFH$ is a rectangle with diameter $CF < 25/13$.\n\n\\noindent\n\\textbf{Remark.} The preceding argument uses implicitly the fact that for $P$ a simple closed polygon in the plane, if we let $S$ denote the set of points on or within $P$, then  the maximum distance between two points of $S$ occurs between some pair of vertices of $P$.\nThis is an immediate consequence of the compactness of $S$ (which guarantees the existence of a maximum) and the convexity of the function taking $(x,y) \\in S \\times S$ to the squared distance between $x$ and $y$ (which is obvious in terms of Cartesian coordinates).\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 1998,
    "label": "A1",
    "difficulty": "1",
    "problem": "A right circular cone has base of radius 1 and height 3.  A\ncube is inscribed in the cone so that one face of the cube is\ncontained in the base of the cone.  What is the side-length of\nthe cube?",
    "solution": "Consider the plane containing both the axis of the cone and two opposite\nvertices of the cube's bottom face.  The cross section of the cone and\nthe cube in this plane consists of a rectangle of sides $s$ and\n$s\\sqrt{2}$ inscribed in an isosceles triangle of base $2$ and height\n$3$, where $s$ is the side-length of the cube.  (The $s\\sqrt{2}$ side\nof the rectangle lies on the base of the triangle.)  Similar triangles\nyield $s/3 = (1-s\\sqrt{2}/2)/1$, or $s = (9\\sqrt{2} - 6)/7.$"
  },
  {
    "year": 1998,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $s$ be any arc of the unit circle lying entirely in the first\nquadrant.  Let $A$ be the area of the region lying below $s$ and\nabove the $x$-axis and let $B$ be the area of the region lying to the\nright of the $y$-axis and to the left of $s$.  Prove that $A+B$ depends\nonly on the arc length, and not on the position, of $s$.",
    "solution": "First solution:\nto fix notation, let $A$ be the area\nof region $DEFG$, and $B$ be the area of $DEIH$; further\nlet $C$ denote the area of sector $ODE$, which only depends on the\narc length of $s$.  If $[XYZ]$ denotes the area of triangle\n$[XYZ]$, then we have\n$A = C + [OEG] - [ODF]$ and $B = C + [ODH] - [OEI]$.  But\nclearly $[OEG] = [OEI]$ and $[ODF] = [ODH]$, and so\n$A + B = 2C$.\n\n\\begin{center}\n\\begin{tikzpicture}\n\\draw (0,0) circle (2);\n\\draw (0,2) -- (0,0) -- (2,0);\n\\draw (1.732,0) -- (1.732,1) -- (0,1);\n\\draw (.7,0) -- (.7,1.873) -- (0,1.873);\n\\draw (1.732,1) -- (0,0) -- (.7,1.873);\n\\draw (0,0) node[anchor=north east] {$O$};\n\\draw (.7,0) node[anchor=north] {$F$};\n\\draw (1.732,0) node[anchor=north] {$G$};\n\\draw (1.732,1) node[anchor=south west] {$E$};\n\\draw (.7,1.873) node[anchor=south west] {$D$};\n\\draw (0,1) node[anchor=east] {$I$};\n\\draw (0,1.7) node[anchor=east] {$H$};\n\\end{tikzpicture}\n\\end{center}\n\nSecond solution: We may parametrize a point in $s$ by any of\n$x$, $y$, or $\\theta = \\tan^{-1} (y/x)$.  Then $A$ and $B$ are\njust the integrals of $y\\,dx$ and $x\\,dy$ over the appropriate\nintervals; thus $A+B$ is the integral of $x\\,dy - y\\,dx$\n(minus because the limits of integration are reversed).\nBut $d\\theta = x\\,dy - y\\,dx$, and so $A+B = \\Delta \\theta$\nis precisely the radian measure of $s$. (Of course, one can perfectly well\ndo this problem by computing the two integrals\nseparately. But what's the fun in that?)"
  },
  {
    "year": 1998,
    "label": "A3",
    "difficulty": "3",
    "problem": "Let $f$ be a real function on the real line with continuous third\nderivative.  Prove that there exists a point $a$ such that\n\\[f(a)\\cdot f'(a) \\cdot f''(a) \\cdot f'''(a)\\geq 0 .\\]",
    "solution": "If at least one of $f(a)$, $f'(a)$, $f''(a)$, or $f'''(a)$ vanishes\nat some point $a$, then we are done.  Hence we may assume each of\n$f(x)$, $f'(x)$, $f''(x)$, and $f'''(x)$ is either strictly positive\nor strictly negative on the real line.  By replacing $f(x)$ by $-f(x)$\nif necessary, we may assume $f''(x)>0$; by replacing $f(x)$\nby $f(-x)$ if necessary, we may assume $f'''(x)>0$.  (Notice that these\nsubstitutions do not change the sign of $f(x) f'(x) f''(x) f'''(x)$.)\nNow $f''(x)>0$ implies that $f'(x)$ is increasing, and $f'''(x)>0$\nimplies that $f'(x)$ is convex, so that $f'(x+a)>f'(x)+a f''(x)$\nfor all $x$ and $a$.  By\nletting $a$ increase in the latter inequality, we see that $f'(x+a)$\nmust be positive for sufficiently large $a$; it follows that\n$f'(x)>0$\nfor all $x$.  Similarly, $f'(x)>0$ and $f''(x)>0$ imply\nthat $f(x)>0$ for all $x$.  Therefore $f(x) f'(x) f''(x) f'''(x)>0$ for\nall $x$, and we are done."
  },
  {
    "year": 1998,
    "label": "A4",
    "difficulty": "4",
    "problem": "Let $A_1=0$ and $A_2=1$.  For $n>2$, the number $A_n$ is defined by\nconcatenating the decimal expansions of $A_{n-1}$ and $A_{n-2}$ from\nleft to right.  For example $A_3=A_2 A_1=10$, $A_4=A_3 A_2 = 101$,\n$A_5=A_4 A_3 = 10110$, and so forth.  Determine all $n$ such that\n$11$ divides $A_n$.",
    "solution": "The number of digits in the decimal expansion of $A_n$ is the\nFibonacci number $F_n$, where $F_1=1$, $F_2=1$, and $F_n=F_{n-1}\n+F_{n-2}$ for $n>2$.  It follows that the sequence $\\{A_n\\}$, modulo 11,\nsatisfies the recursion $A_n=(-1)^{F_{n-2}}A_{n-1} + A_{n-2}$.\n(Notice that the recursion for $A_n$ depends only on the value of\n$F_{n-2}$ modulo 2.)  Using these recursions, we find that\n$A_7 \\equiv 0$ and $A_8 \\equiv 1$ modulo 11, and that\n$F_7 \\equiv 1$ and $F_8 \\equiv 1$ modulo 2.\nIt follows that $A_n \\equiv A_{n+6}$ (mod 11) for all $n\\geq 1$.\nWe find that among\n$A_1,A_2,A_3,A_4,A_5$, and $A_6$, only $A_1$ vanishes modulo 11.\nThus 11 divides $A_n$ if and only if $n=6k+1$ for some\nnonnegative integer $k$."
  },
  {
    "year": 1998,
    "label": "A5",
    "difficulty": "5",
    "problem": "Let $\\mathcal F$ be a finite collection of open discs in $\\mathbb R^2$\nwhose union contains a set $E\\subseteq \\mathbb R^2$.  Show that there\nis a pairwise disjoint subcollection $D_1,\\ldots, D_n$ in $\\mathcal F$\nsuch that\n\\[E\\subseteq \\cup_{j=1}^n 3D_j.\\]\nHere, if $D$ is the disc of radius $r$ and center $P$, then $3D$ is the\ndisc of radius $3r$ and center $P$.",
    "solution": "Define the sequence $D_i$ by the following greedy algorithm:\nlet $D_1$ be the disc of largest radius (breaking ties arbitrarily),\nlet $D_2$ be the disc of largest radius not meeting $D_1$, let\n$D_3$ be the disc of largest radius not meeting $D_1$ or $D_2$,\nand so on, up to some final disc $D_n$.\nTo see that $E \\subseteq \\cup_{j=1}^n 3D_j$, consider\na point in $E$; if it lies in one of the $D_i$, we are done. Otherwise,\nit lies in a disc $D$ of radius $r$, which meets one of the $D_i$ having\nradius $s \\geq r$ (this is the only reason a disc can be skipped in\nour algorithm). Thus\nthe centers lie at a distance $t < s+r$, and so every point at distance\nless than $r$ from the center of $D$ lies at distance at most\n$r + t < 3s$ from the center of the corresponding $D_i$."
  },
  {
    "year": 1998,
    "label": "A6",
    "difficulty": "6",
    "problem": "Let $A, B, C$ denote distinct points with integer coordinates in $\\mathbb\nR^2$.  Prove that if\n\\[(|AB|+|BC|)^2<8\\cdot [ABC]+1\\]\nthen $A, B, C$ are three vertices of a square.  Here $|XY|$ is the length\nof segment $XY$ and $[ABC]$ is the area of triangle $ABC$.",
    "solution": "Recall the inequalities $|AB|^2 + |BC|^2 \\geq 2|AB||BC|$ (AM-GM)\nand $|AB||BC| \\geq 2[ABC]$ (Law of Sines). Also recall that the area of\na triangle with integer coordinates is half an integer\n(if its vertices lie at $(0,0), (p,q), (r,s)$, the area is\n$|ps-qr|/2$), and that if $A$ and $B$ have integer coordinates, then\n$|AB|^2$\nis an integer (Pythagoras). Now observe that\n\\begin{align*}\n8[ABC] &\\leq |AB|^2+|BC|^2 + 4[ABC] \\\\\n&\\leq |AB|^2 + |BC|^2 + 2|AB| |BC| \\\\\n&< 8[ABC]+1,\n\\end{align*}\nand that the first and second expressions are both integers.\nWe conclude that\n$8[ABC] = |AB|^2+ |BC|^2+4[ABC]$, and so $|AB|^2+|BC|^2 =\n2|AB| |BC|\n= 4[ABC]$; that is, $B$ is a right angle and $AB=BC$, as desired."
  },
  {
    "year": 1998,
    "label": "B1",
    "difficulty": "1",
    "problem": "Find the minimum value of\n\\[\\frac{(x+1/x)^6-(x^6+1/x^6)-2}{(x+1/x)^3+(x^3+1/x^3)}\\]\nfor $x>0$.",
    "solution": "Notice that\n\\begin{gather*}\n\\frac{(x+1/x)^6-(x^6+1/x^6)-2}{(x+1/x)^3+(x^3+1/x^3)} = \\\\\n(x+1/x)^3-(x^3+1/x^3)=3(x+1/x)\n\\end{gather*}\n(difference of squares).  The latter is easily seen\n(e.g., by AM-GM) to have minimum value 6\n(achieved at $x=1$)."
  },
  {
    "year": 1998,
    "label": "B2",
    "difficulty": "2",
    "problem": "Given a point $(a,b)$ with $0<b<a$, determine the minimum perimeter of a\ntriangle with one vertex at $(a,b)$, one on the $x$-axis, and one on the\nline $y=x$.  You may assume that a triangle of minimum perimeter exists.",
    "solution": "Consider a triangle as described by the problem; label its\nvertices $A,B,C$ so that $A = (a,b)$, $B$ lies on the $x$-axis,\nand $C$ lies on the line $y=x$.  Further let $D = (a,-b)$ be the\nreflection of $A$ in the $x$-axis, and let $E = (b,a)$ be\nthe reflection of $A$ in the line $y=x$.  Then $AB=DB$\nand $AC=CE$, and so the perimeter of $ABC$ is\n$DB+BC+CE \\geq DE = \\sqrt{(a-b)^2 + (a+b)^2}\n= \\sqrt{2a^2+2b^2}$.  It is clear that this lower bound can\nbe achieved; just set $B$ (resp. $C$) to be the\nintersection between the segment $DE$ and the $x$-axis (resp.\nline $x=y$); thus the minimum perimeter is in fact\n$\\sqrt{2a^2+2b^2}$."
  },
  {
    "year": 1998,
    "label": "B3",
    "difficulty": "3",
    "problem": "let $H$ be the unit hemisphere $\\{(x,y,z):x^2+y^2+z^2=1,z\\geq 0\\}$, $C$\nthe unit circle $\\{(x,y,0):x^2+y^2=1\\}$, and $P$ the regular pentagon\ninscribed in $C$.  Determine the surface area of that portion of $H$ lying\nover the planar region inside $P$, and write your answer in the form\n$A \\sin\\alpha + B \\cos\\beta$, where $A,B,\\alpha,\\beta$ are real numbers.",
    "solution": "We use the well-known result that the surface area of the\n``sphere cap'' $\\{(x,y,z)\\,|\\,x^2+y^2+z^2=1,\\,z\\geq z_0\\}$ is\nsimply $2\\pi(1-z_0)$.  (This result is easily verified using\ncalculus; we omit the derivation here.)  Now the desired surface\narea is just $2\\pi$ minus the surface areas of five identical\nhalves of sphere caps; these caps, up to isometry, correspond\nto $z_0$ being the distance from the center of the pentagon\nto any of its sides, i.e., $z_0 = \\cos \\frac{\\pi}{5}$.  Thus\nthe desired area is\n$2\\pi - \\frac{5}{2} \\left(2\\pi (1-\\cos\\frac{\\pi}{5})\\right)\n= 5\\pi\\cos\\frac{\\pi}{5} - 3\\pi$ (i.e., $B=\\pi/2$)."
  },
  {
    "year": 1998,
    "label": "B4",
    "difficulty": "4",
    "problem": "Find necessary and sufficient conditions on positive integers $m$ and $n$\nso that\n\\[\\sum_{i=0}^{mn-1} (-1)^{\\lfloor i/m \\rfloor +\\lfloor i/n\\rfloor}=0.\\]",
    "solution": "For convenience, define $f_{m,n}(i) = \\lfloor \\frac{i}{m} \\rfloor +\n\\lfloor \\frac{i}{n} \\rfloor$, so that the given sum is\n$S(m,n) = \\sum_{i=0}^{mn-1} (-1)^{f_{m,n}(i)}$.\nIf $m$ and $n$ are both odd, then $S(m,n)$ is the sum of\nan odd number of $\\pm 1$'s, and thus cannot be zero.  Now consider\nthe case where $m$ and $n$ have opposite parity.  Note that\n$\\lfloor \\frac{i}{m} \\rfloor + \\lfloor k - \\frac{i+1}{m} \\rfloor\n= k-1$ for all integers $i,k,m$.  Thus\n$\\lfloor \\frac{i}{m} \\rfloor + \\lfloor \\frac{mn-i-1}{m} \\rfloor\n= n-1$ and $\\lfloor \\frac{i}{n} \\rfloor + \\lfloor \\frac{mn-i-1}{n}\n\\rfloor = m-1$; this implies that $f_{m,n}(i) + f_{m,n}(mn-i-1) =\nm+n-2$ is odd, and so $(-1)^{f_{m,n}(i)} =\n-(-1)^{f_{m,n}(mn-i-1)}$ for\nall $i$.  It follows that $S(m,n) = 0$ if $m$ and\n$n$ have opposite parity.\n\nNow suppose that $m=2k$ and $n=2l$ are both even.\nThen $\\lfloor \\frac{2j}{2m} \\rfloor = \\lfloor \\frac{2j+1}{2m} \\rfloor$\nfor all $j$, so $S$ can be computed as twice the sum over only even\nindices:\n\\[\nS(2k, 2l) = 2 \\sum_{i=0}^{2kl-1} (-1)^{f_{k,l}(i)}\n= S(k,l)(1 + (-1)^{k+l}).\n\\]\nThus $S(2k,2l)$ vanishes if and only if $S(k,l)$ vanishes (if $1 +\n(-1)^{k+l} = 0$, then $k$ and $l$ have opposite parity and so\n$S(k,l)$ also vanishes).\n\nPiecing our various cases together, we easily deduce that\n$S(m,n) = 0$ if and only if the highest powers of 2 dividing\n$m$ and $n$ are different."
  },
  {
    "year": 1998,
    "label": "B5",
    "difficulty": "5",
    "problem": "Let $N$ be the positive integer with 1998 decimal digits, all of them 1;\nthat is,\n\\[N=1111\\cdots 11.\\]\nFind the thousandth digit after the decimal point of $\\sqrt N$.",
    "solution": "Write $N=(10^{1998}-1)/9$.  Then\n\\begin{align*}\n\\sqrt{N} &=\\frac{10^{999}}{3}\\sqrt{1-10^{-1998}} \\\\\n&=\\frac{10^{999}}{3}\n(1-\\frac{1}{2}10^{-1998} + r),\n\\end{align*}\nwhere $r<10^{-2000}$.  Now the digits after the decimal point of\n$10^{999}/3$ are given by $.3333\\ldots$, while\nthe digits after the decimal point\nof $\\frac{1}{6}10^{-999}$ are given by $.00000\\ldots 1666666\\ldots$.\nIt follows that the first 1000 digits of $\\sqrt N$ are given\nby $.33333\\ldots 3331$;  in particular, the thousandth digit is $1$."
  },
  {
    "year": 1998,
    "label": "B6",
    "difficulty": "6",
    "problem": "Prove that, for any integers $a, b, c$, there exists a positive integer\n$n$ such that $\\sqrt{n^3+an^2+bn+c}$ is not an integer.\n\n\\end{itemize}\n\n\\end{document}",
    "solution": "First solution: Write $p(n) = n^3 + an^2 + bn + c$. Note that $p(n)$\nand $p(n+2)$ have the same parity, and recall that any perfect square\nis congruent to 0 or 1 (mod 4). Thus if $p(n)$ and $p(n+2)$ are perfect\nsquares, they are congruent mod 4. But $p(n+2) - p(n) \\equiv 2n^2 + 2b$\n(mod 4), which is not divisible by 4 if $n$ and $b$ have opposite parity.\n%\n% and likewise for $p(n+1)$ and $p(n+3)$.\n%But the ``third difference'' of $p$ is $p(n) -\n%3p(n+1) + 3p(n+2) - p(n+3) = 6$ (easy calculation), so that $p(n) +\n%p(n+1) - p(n+2) - p(n+3) \\equiv 2$ (mod 4). Thus not all of $p(n), p(n+1),\n%p(n+2), p(n+3)$ can be perfect squares.\n%(n+2)^3 + a(n+2)^2 + b(n+2) + c\n%n^3 + an^2 + bn + c\n%== 2n^2 + 2b\n\nSecond solution:\nWe prove more generally that for any polynomial $P(z)$ with integer\ncoefficients which is not a perfect square, there exists a positive\ninteger $n$ such that $P(n)$ is not a perfect square. Of course it\nsuffices to assume $P(z)$ has no repeated factors, which is to say $P(z)$\nand its derivative $P'(z)$ are relatively prime.\n\nIn particular, if we carry out the Euclidean algorithm on $P(z)$ and $P'(z)$\nwithout dividing, we get an integer $D$ (the discriminant of $P$) such that\nthe greatest common divisor of $P(n)$ and $P'(n)$ divides $D$ for any $n$.\nNow there exist infinitely many primes $p$ such that $p$ divides $P(n)$ for\nsome $n$: if there were only finitely many, say, $p_1, \\dots, p_k$, then\nfor any $n$ divisible by $m = P(0) p_1 p_2 \\cdots p_k$, we have $P(n)\n\\equiv P(0) \\pmod{m}$, that is, $P(n)/P(0)$ is not divisible by $p_1,\n\\dots, p_k$, so must be $\\pm 1$, but then $P$ takes some value infinitely\nmany times, contradiction. In particular, we can choose some such $p$ not\ndividing $D$, and choose $n$ such that $p$ divides $P(n)$. Then $P(n+kp)\n\\equiv P(n) + kp P'(n) (\\mathrm{mod}\\,p)$\n(write out the Taylor series of the left side);\nin particular, since $p$ does not divide $P'(n)$, we can find some $k$\nsuch that $P(n+kp)$ is divisible by $p$ but not by $p^2$, and so\nis not a perfect square.\n\nThird solution: (from David Rusin, David Savitt, and Richard Stanley\nindependently)\nAssume that $n^{3}+an^{2}+bn+c$ is a square for all $n>0$.\nFor sufficiently large $n$,\n\\begin{align*}\n(n^{3/2} + \\frac{1}{2} an^{1/2} - 1)^{2} &< n^{3} + an^{2}+bn+c \\\\\n&<  (n^{3/2}+ \\frac{1}{2} an^{1/2}+1)^{2};\n\\end{align*}\nthus if $n$ is a large even perfect square, we have $n^{3}+an^{2}+bn+c =\n(n^{3/2} + \\frac{1}{2} an^{1/2})^{2}$. We conclude this is an\nequality of polynomials, but the right-hand side\nis not a perfect square for $n$ an even non-square, contradiction.\n(The reader might try generalizing this approach to arbitrary polynomials.\nA related argument, due to Greg Kuperberg: write $\\sqrt{n^3+an^2+bn+c}$\nas $n^{3/2}$ times a power series in $1/n$ and take two finite differences\nto get an expression which tends to 0 as $n \\to \\infty$, contradiction.)\n\nNote: in case $n^3 + an^2 + bn + c$ has no repeated factors, it is a\nsquare for only finitely many $n$, by a theorem of Siegel; work of Baker gives\nan explicit (but large) bound on such $n$. (I don't know whether the graders\nwill accept this as a solution, though.)\n\n\\end{itemize}\n\n\\end{document}"
  },
  {
    "year": 1999,
    "label": "A1",
    "difficulty": "1",
    "problem": "Find polynomials $f(x)$,$g(x)$, and $h(x)$, if they exist, such\nthat for all $x$,\n\\[\n|f(x)|-|g(x)|+h(x) = \\begin{cases} -1 & \\mbox{if $x<-1$} \\\\\n                     3x+2 & \\mbox{if $-1 \\leq x \\leq 0$} \\\\\n                     -2x+2 & \\mbox{if $x>0$.}\n                     \\end{cases}\n\\]",
    "solution": "Note that if $r(x)$ and $s(x)$ are any two functions, then\n\\[ \\max(r,s) = (r+s + |r-s|)/2.\\]\nTherefore, if $F(x)$ is the given function, we have\n\\begin{align*}\nF(x)\\ &= \\max\\{-3x-3,0\\}-\\max\\{5x,0\\}+3x+2 \\\\\n      &= (-3x-3+|3x+3|)/2 \\\\\n      & \\qquad - (5x + |5x|)/2 + 3x+2 \\\\\n      &= |(3x+3)/2| - |5x/2| -x + \\frac{1}{2},\n\\end{align*}\nso we may set $f(x)=(3x+3)/2$, $g(x) = 5x/2$, and $h(x)=-x+\\frac{1}{2}$."
  },
  {
    "year": 1999,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $p(x)$ be a polynomial that is nonnegative for all real $x$.  Prove that\nfor some $k$, there are polynomials $f_1(x),\\dots,f_k(x$) such that\n\\[p(x) =  \\sum_{j=1}^k (f_j(x))^2.\\]",
    "solution": "First solution:\nFirst factor $p(x) = q(x) r(x)$, where $q$ has all real roots and $r$ has\nall complex roots. Notice that each root of $q$ has even\nmultiplicity, otherwise $p$ would have a sign change at that root.\nThus $q(x)$ has a square root $s(x)$.\n\nNow write $r(x) = \\prod_{j=1}^k (x - a_j)(x - \\overline{a_j})$\n(possible because $r$ has roots in complex conjugate pairs).\nWrite $\\prod_{j=1}^k (x - a_j) = t(x) + i u(x)$ with $t,x$\nhaving real coefficients. Then for $x$ real,\n\\begin{align*}\np(x) &= q(x) r(x) \\\\\n&= s(x)^2 (t(x) + iu(x)) (\\overline{t(x) + iu(x)}) \\\\\n&= (s(x)t(x))^2 + (s(x)u(x))^2.\n\\end{align*}\n(Alternatively, one can factor $r(x)$ as a product of quadratic\npolynomials with real coefficients, write each as a sum of squares, then\nmultiply together to get a sum of many squares.)\n\nSecond solution:\nWe proceed by induction on the degree of $p$, with base case where $p$\nhas degree 0. As in the first solution, we may reduce to a smaller degree\nin case $p$ has any real roots, so assume it has none. Then $p(x) > 0$\nfor all real $x$, and since $p(x) \\to \\infty$ for $x \\to \\pm \\infty$, $p$\nhas a minimum value $c$. Now $p(x) - c$ has real roots, so as above, we\ndeduce that $p(x) - c$ is a sum of squares. Now add one more square,\nnamely $(\\sqrt{c})^2$, to get $p(x)$ as a sum of squares."
  },
  {
    "year": 1999,
    "label": "A3",
    "difficulty": "3",
    "problem": "Consider the power series expansion\n\\[\\frac{1}{1-2x-x^2} = \\sum_{n=0}^\\infty a_n x^n.\\]\nProve that, for each integer $n\\geq 0$, there is an integer $m$ such that\n\\[a_n^2 + a_{n+1}^2 = a_m .\\]",
    "solution": "First solution:\nComputing the coefficient of $x^{n+1}$ in the identity\n$(1-2x-x^2)\\sum_{m=0}^\\infty a_m x^m = 1$ yields the recurrence\n$a_{n+1} = 2a_n + a_{n-1}$; the sequence $\\{a_n\\}$ is then characterized\nby this recurrence and the initial conditions $a_0 = 1, a_1 = 2$.\n\nDefine the sequence $\\{b_n\\}$ by\n$b_{2n} = a_{n-1}^2 + a_n^2,~b_{2n+1} = a_n(a_{n-1}+a_{n+1}).$\nThen\n\\begin{align*}\n2b_{2n+1}+b_{2n} &= 2a_na_{n+1}+2a_{n-1}a_n+a_{n-1}^2+a_n^2 \\\\\n&= 2a_na_{n+1} + a_{n-1}a_{n+1} + a_n^2 \\\\\n&= a_{n+1}^2 + a_n^2 = b_{2n+2},\n\\end{align*}\nand similarly $2b_{2n}+b_{2n-1} = b_{2n+1}$, so that $\\{b_n\\}$ satisfies\nthe same recurrence as $\\{a_n\\}$.  Since further $b_0=1,b_1=2$ (where\nwe use the recurrence for $\\{a_n\\}$ to calculate $a_{-1}=0$),\nwe deduce that $b_n=a_n$ for all $n$.  In particular,\n$a_n^2+a_{n+1}^2 = b_{2n+2} = a_{2n+2}$.\n\nSecond solution:\nNote that\n\\begin{multline*}\n\\frac{1}{1-2x-x^2} \\\\\n\\qquad = \\frac{1}{2\\sqrt{2}} \\left(\n\\frac{\\sqrt{2}+1}{1-(1+\\sqrt{2})x} + \\frac{\\sqrt{2}-1}{1-(1-\\sqrt{2})x}\n\\right)\n\\end{multline*}\nand that\n\\[\n\\frac{1}{1 + (1\\pm\\sqrt{2})x} = \\sum_{n=0}^\\infty (1\\pm\\sqrt{2})^n x^n,\n\\]\nso that\n\\[\na_n = \\frac{1}{2\\sqrt{2}} \\left((\\sqrt{2}+1)^{n+1} - (1-\\sqrt{2})^{n+1}\n\\right).\n\\]\nA simple computation (omitted here) now shows that\n$a_n^2 + a_{n+1}^2 = a_{2n+2}$.\n\nThird solution (by Richard Stanley):\nLet $A$ be the matrix $\\begin{pmatrix} 0 & 1 \\\\1 & 2 \\end{pmatrix}$.\nA simple induction argument shows that\n\\[\nA^{n+2} = \\begin{pmatrix} a_n & a_{n+1} \\\\ a_{n+1} & a_{n+2}\n\\end{pmatrix}.\n\\]\nThe desired result now follows from comparing the top left corner\nentries of the equality $A^{n+2} A^{n+2} = A^{2n+4}$."
  },
  {
    "year": 1999,
    "label": "A4",
    "difficulty": "4",
    "problem": "Sum the series\n\\[\\sum_{m=1}^\\infty \\sum_{n=1}^\\infty \\frac{m^2 n}{3^m(n3^m+m3^n)}.\\]",
    "solution": "Denote the series by $S$, and let $a_n = 3^n/n$.  Note that\n\\begin{align*}\nS &= \\sum_{m=1}^\\infty \\sum_{n=1}^\\infty \\frac{1}\n{a_m(a_m+a_n)} \\\\\n&= \\sum_{m=1}^\\infty \\sum_{n=1}^\\infty \\frac{1}{a_n(a_m+a_n)},\n\\end{align*}\nwhere the second equality follows by interchanging $m$ and $n$.\nThus\n\\begin{align*}\n2S &= \\sum_m \\sum_n \\left( \\frac{1}{a_m(a_m+a_n)} +\n\\frac{1}{a_n(a_m+a_n)}\\right) \\\\\n&= \\sum_m \\sum_n \\frac{1}{a_m a_n} \\\\\n&= \\left( \\sum_{n=1}^\\infty \\frac{n}{3^n} \\right)^2.\n\\end{align*}\nBut\n\\[\n\\sum_{n=1}^\\infty \\frac{n}{3^n} = \\frac34\n\\]\nsince, e.g., it's $f'(1)$,\nwhere\n\\[\nf(x) = \\sum_{n=0}^\\infty \\frac{x^n}{3^n} = \\frac{3}{3-x},\n\\]\nand we conclude that $S = 9/32$."
  },
  {
    "year": 1999,
    "label": "A5",
    "difficulty": "5",
    "problem": "Prove that there is a constant $C$ such that, if $p(x)$ is a polynomial\nof degree 1999, then\n\\[|p(0)|\\leq C \\int_{-1}^1 |p(x)|\\,dx.\\]",
    "solution": "First solution: (by Reid Barton)\nLet $r_1, \\dots, r_{1999}$ be the roots of $P$. Draw a disc of radius\n$\\epsilon$ around each $r_i$, where $\\epsilon < 1/3998$; this\ndisc covers a subinterval of $[-1/2,1/2]$\nof length at most $2\\epsilon$, and so of the 2000 (or fewer) uncovered\nintervals in $[-1/2,1/2]$,\none, which we call $I$, has length at least $\\delta = (1-3998\\epsilon)/2000\n> 0$.\nWe will exhibit an explicit lower bound for the integral of $|P(x)|/P(0)$ over this\ninterval, which will yield such a bound for the entire integral.\n\nNote that\n\\[\n\\frac{|P(x)|}{|P(0)|} = \\prod_{i=1}^{1999} \\frac{|x-r_i|}{|r_i|}.\n\\]\nAlso note that by construction, $|x - r_i| \\geq \\epsilon$ for each $x \\in I$.\nIf $|r_i| \\leq 1$, then we have $\\frac{|x-r_i|}{|r_i|} \\geq \\epsilon$. If $|r_i| > 1$, then\n\\[\n\\frac{|x-r_i|}{|r_i|} = |1 - x/r_i| \\geq 1 - |x/r_i| \\geq = 1/2\n> \\epsilon.\n\\]\nWe conclude that $\\int_I |P(x)/P(0)|\\,dx \\geq \\delta \\epsilon$,\nindependent of $P$.\n\nSecond solution:\nIt will be a bit more convenient to assume $P(0) = 1$ (which we\nmay achieve by rescaling unless $P(0)=0$, in which case\nthere is nothing to prove) and to prove that there exists $D>0$\nsuch that $\\int_{-1}^1 |P(x)|\\,dx \\geq D$, or even\nsuch that $\\int_0^1 |P(x)|\\,dx \\geq D$.\n\nWe first reduce to the case where $P$ has all of its roots in\n$[0,1]$. If this is not the case, we can\nfactor $P(x)$ as $Q(x) R(x)$, where $Q$ has all roots in\nthe interval and $R$ has none. Then $R$ is either always\npositive or always negative on $[0,1]$; assume the former.\nLet $k$ be the largest positive real number such that\n$R(x) - kx \\geq 0$ on $[0,1]$; then\n\\begin{align*}\n\\int_{-1}^1 |P(x)|\\,dx &= \\int_{-1}^1 |Q(x)R(x)|\\,dx \\\\\n&> \\int_{-1}^1 |Q(x)(R(x)-kx)|\\,dx,\n\\end{align*}\nand $Q(x)(R(x)-kx)$ has more roots in $[0,1]$ than does $P$\n(and has the same value at 0).\nRepeating this argument shows that $\\int_{0}^1 |P(x)|\\,dx$\nis greater than the corresponding integral for some polynomial\nwith all of its roots in $[0,1]$.\n\nUnder this assumption, we have\n\\[\nP(x) = c \\prod_{i=1}^{1999} (x-r_i)\n\\]\nfor some $r_i \\in (0,1]$. Since\n\\[\nP(0) = -c \\prod r_i = 1,\n\\]\nwe have\n\\[\n|c| \\geq \\prod |r_i^{-1}| \\geq 1.\n\\]\n\nThus it suffices to prove that if $Q(x)$ is a \\emph{monic} polynomial\nof degree 1999 with all of its roots in $[0,1]$,\nthen $\\int_0^1 |Q(x)|\\,dx \\geq D$ for some constant $D>0$. But the\nintegral of $\\int_0^1 \\prod_{i=1}^{1999} |x-r_i|\\,dx$ is a continuous\nfunction for $r_i \\in [0,1]$. The product of all of these intervals is\ncompact, so the integral achieves a minimum value for some $r_i$. This\nminimum is the desired $D$.\n\nThird solution (by Abe Kunin):\nIt suffices to prove the stronger inequality\n\\[\n\\sup_{x \\in [-1,1]} |P(x)| \\leq C \\int_{-1}^1 |P(x)|\\,dx\n\\]\nholds for some $C$.\nBut this follows immediately from the following standard fact: any two\nnorms on a finite-dimensional vector space (here the polynomials of\ndegree at most 1999) are equivalent. (The proof of this statement is also\na compactness argument: $C$ can be taken to be the maximum of the\nL1-norm divided by the sup norm over the set of polynomials with\nL1-norm 1.)\n\nNote: combining the first two approaches gives a constructive solution with\na constant that is better than that given by the first solution,\nbut is still far from optimal. I don't know\noffhand whether it is even known what the optimal constant and/or the\npolynomials achieving that constant are."
  },
  {
    "year": 1999,
    "label": "A6",
    "difficulty": "6",
    "problem": "The sequence $(a_n)_{n\\geq 1}$ is defined by $a_1=1, a_2=2, a_3=24,$ and, for $n\\geq 4$,\n\\[a_n = \\frac{6a_{n-1}^2a_{n-3} -\n8a_{n-1}a_{n-2}^2}{a_{n-2}a_{n-3}}.\\]\nShow that, for all n, $a_n$ is an integer multiple of $n$.",
    "solution": "Rearranging the given equation yields the much more tractable equation\n\\[\n\\frac{a_n}{a_{n-1}} = 6 \\, \\frac{a_{n-1}}{a_{n-2}}\n- 8 \\, \\frac{a_{n-2}}{a_{n-3}}.\n\\]\nLet $b_n = a_n/a_{n-1}$; with the initial conditions $b_2 = 2, b_3 = 12$,\none easily obtains $b_n = 2^{n-1} (2^{n-2} - 1)$, and so\n\\[\na_n = 2^{n(n-1)/2} \\prod_{i=1}^{n-1} (2^i - 1).\n\\]\n\nTo see that $n$ divides $a_n$, factor $n$ as $2^k m$, with $m$\nodd. Then note that $k \\leq n \\leq n(n-1)/2$, and that there\nexists $i \\leq m-1$ such that $m$ divides $2^i-1$, namely $i =\n\\phi(m)$ (Euler's totient function: the number of integers in\n$\\{1, \\dots, m\\}$ relatively prime to $m$)."
  },
  {
    "year": 1999,
    "label": "B1",
    "difficulty": "1",
    "problem": "Right triangle $ABC$ has right angle at $C$ and $\\angle BAC =\\theta$;\nthe point $D$ is chosen on $AB$ so that $|AC|=|AD|=1$; the point $E$\nis chosen on $BC$ so that $\\angle CDE = \\theta$.  The perpendicular\nto $BC$ at $E$ meets $AB$ at $F$.  Evaluate $\\lim_{\\theta\\rightarrow 0}\n|EF|$.",
    "solution": "The answer is 1/3.\nLet $G$ be the point obtained by reflecting $C$ about the line $AB$.\nSince $\\angle ADC = \\frac{\\pi-\\theta}{2}$, we find that\n$\\angle BDE = \\pi - \\theta - \\angle ADC = \\frac{\\pi-\\theta}{2}\n= \\angle ADC = \\pi - \\angle BDC = \\pi - \\angle BDG$, so that $E,D,G$\nare collinear.  Hence\n\\[\n|EF| = \\frac{|BE|}{|BC|} = \\frac{|BE|}{|BG|} = \\frac{\\sin\n(\\theta/2)}{\\sin (3\\theta/2)},\n\\]\nwhere we have used the law of sines in $\\triangle BDG$.  But by\nl'H\\^opital's Rule,\n\\[\n\\lim_{\\theta \\rightarrow 0}\n\\frac{\\sin(\\theta/2)}{\\sin(3\\theta/2)} =\n\\lim_{\\theta \\rightarrow 0}\n\\frac{\\cos(\\theta/2)}{3\\cos(3\\theta/2)} = 1/3.\n\\]"
  },
  {
    "year": 1999,
    "label": "B2",
    "difficulty": "2",
    "problem": "Let $P(x)$ be a polynomial of degree $n$ such that $P(x)=Q(x)P''(x)$,\nwhere $Q(x)$ is a quadratic polynomial and $P''(x)$ is the second\nderivative of $P(x)$.  Show that if $P(x)$ has at least two distinct\nroots then it must have $n$ distinct roots.",
    "solution": "First solution:\nSuppose that $P$ does not have $n$ distinct roots; then it has\na root of multiplicity at least $2$, which we may assume is $x=0$\nwithout loss of generality.  Let $x^k$ be the greatest power of $x$\ndividing $P(x)$, so that $P(x) = x^k R(x)$ with $R(0) \\neq 0$;\na simple computation yields\n\\[\nP''(x) = (k^2-k)x^{k-2} R(x) + 2kx^{k-1} R'(x) + x^k R''(x).\n\\]\nSince $R(0) \\neq 0$ and $k\\geq 2$, we conclude that the greatest power of $x$\ndividing $P''(x)$ is $x^{k-2}$.  But $P(x) = Q(x) P''(x)$, and so\n$x^2$ divides $Q(x)$.\nWe deduce (since $Q$ is quadratic)\nthat $Q(x)$ is a constant $C$ times $x^2$; in fact, $C=1/(n(n-1))$ by\ninspection of the leading-degree terms of $P(x)$ and $P''(x)$.\n\nNow if $P(x) = \\sum_{j=0}^n a_j x^j$, then the relation\n$P(x) = Cx^2 P''(x)$ implies that $a_j = Cj(j-1)a_j$ for all $j$;\nhence $a_j = 0$ for $j \\leq n-1$, and we conclude that $P(x) = a_n x^n$,\nwhich has all identical roots.\n\nSecond solution (by Greg Kuperberg): Let $f(x) = P''(x)/P(x) = 1/Q(x)$. By\nhypothesis, $f$ has at most two poles (counting multiplicity).\n\nRecall that for any complex polynomial $P$, the roots of $P'$ lie within the convex\nhull of $P$. To show this, it suffices to show that if the roots of $P$ lie on one\nside of a line, say on the positive side of the imaginary axis, then $P'$ has no\nroots on the other side. That follows because if $r_1, \\dots, r_n$ are the roots of $P$,\n\\[\n\\frac{P'(z)}{P(z)} = \\sum_{i=1}^n \\frac{1}{z-r_i}\n\\]\nand if $z$ has negative real part, so does $1/(z-r_i)$ for $i=1, \\dots, n$,\nso the sum is nonzero.\n\nThe above argument also carries through if $z$ lies on the\nimaginary axis, provided that $z$ is not equal to a root of $P$. Thus we also have that\nno roots of $P'$ lie on the sides of the convex hull of $P$, unless they are also\nroots of $P$.\n\nFrom this we conclude that if $r$ is a root of $P$ which is a vertex of the convex hull\nof the roots, and\nwhich is not also a root of $P'$,\nthen $f$ has a single pole at $r$ (as $r$ cannot be a root of $P''$).\nOn the other hand, if $r$ is a root of $P$ which is also a root of $P'$, it\nis a multiple root, and then $f$ has a double pole at $r$.\n\nIf $P$ has roots not all equal, the convex hull of its roots has at least two\nvertices."
  },
  {
    "year": 1999,
    "label": "B3",
    "difficulty": "3",
    "problem": "Let $A=\\{(x,y):0\\leq x,y<1\\}$.  For $(x,y)\\in A$, let\n\\[S(x,y) = \\sum_{\\frac{1}{2}\\leq \\frac{m}{n}\\leq 2} x^m y^n,\\]\nwhere the sum ranges over all pairs $(m,n)$ of positive integers\nsatisfying the indicated inequalities.  Evaluate\n\\[\\lim_{(x,y)\\rightarrow (1,1), (x,y)\\in A} (1-xy^2)(1-x^2y)S(x,y).\\]",
    "solution": "We first note that\n\\[\n\\sum_{m,n > 0} x^m y^n = \\frac{xy}{(1-x)(1-y)}.\n\\]\nSubtracting $S$ from this gives two sums, one of which is\n\\[\n\\sum_{m \\geq 2n+1} x^m y^n = \\sum_n y^n \\frac{x^{2n+1}}{1-x}\n= \\frac{x^3y}{(1-x)(1-x^2y)}\n\\]\nand the other of which sums to $xy^3/[(1-y)(1-xy^2)]$. Therefore\n\\begin{align*}\nS(x,y) &= \\frac{xy}{(1-x)(1-y)} - \\frac{x^3y}{(1-x)(1-x^2y)} \\\\\n&\\qquad - \\frac{xy^3}{(1-y)(1-xy^2)} \\\\\n&= \\frac{xy(1+x+y+xy-x^2y^2)}{(1-x^2y)(1-xy^2)}\n\\end{align*}\nand the desired limit is\n\\[\n\\lim_{(x,y) \\to (1,1)} xy(1+x+y+xy-x^2y^2) = 3.\n\\]"
  },
  {
    "year": 1999,
    "label": "B4",
    "difficulty": "4",
    "problem": "Let $f$ be a real function with a continuous third derivative such that $f(x),\nf'(x), f''(x), f'''(x)$ are positive for all $x$.  Suppose that\n$f'''(x)\\leq f(x)$ for all $x$.  Show that $f'(x)<2f(x)$ for all $x$.",
    "solution": "\\setcounter{equation}{0}\n(based on work by Daniel Stronger)\nWe make repeated use of the following fact: if $f$ is a differentiable function on all of\n$\\RR$, $\\lim_{x \\to -\\infty} f(x) \\geq 0$, and $f'(x) > 0$ for all $x \\in \\RR$, then\n$f(x) > 0$ for all $x \\in \\RR$. (Proof: if $f(y) < 0$ for some $x$, then $f(x)< f(y)$ for all\n$x<y$ since $f'>0$, but then $\\lim_{x \\to -\\infty} f(x) \\leq f(y) < 0$.)\n\nFrom the inequality $f'''(x) \\leq f(x)$ we obtain\n\\[\nf'' f'''(x) \\leq f''(x) f(x) < f''(x) f(x) + f'(x)^2\n\\]\nsince $f'(x)$ is positive. Applying the fact to the difference between the right and left sides,\nwe get\n\\begin{equation}\n\\frac{1}{2} (f''(x))^2 < f(x) f'(x).\n\\end{equation}\n\nOn the other hand, since $f(x)$ and $f'''(x)$ are both positive for all $x$,\nwe have\n\\[\n2f'(x) f''(x) < 2f'(x)f''(x) + 2f(x) f'''(x).\n\\]\nApplying the fact to the difference between the sides yields\n\\begin{equation}\nf'(x)^2 \\leq 2f(x) f''(x).\n\\end{equation}\nCombining (1) and (2), we obtain\n\\begin{align*}\n\\frac{1}{2} \\left( \\frac{f'(x)^2}{2f(x)} \\right)^2\n&< \\frac{1}{2} (f''(x))^2 \\\\\n&< f(x) f'(x),\n\\end{align*}\nor $(f'(x))^3 < 8 f(x)^3$. We conclude $f'(x) < 2f(x)$, as desired.\n\nNote: one can actually prove the result with a smaller constant in place of\n2, as follows. Adding $\\frac{1}{2} f'(x) f'''(x)$ to both sides\nof (1) and again invoking the original bound\n$f'''(x) \\leq f(x)$, we get\n\\begin{align*}\n\\frac{1}{2} [f'(x) f'''(x) + (f''(x))^2] &< f(x) f'(x) + \\frac{1}{2} f'(x) f'''(x) \\\\\n&\\leq \\frac{3}{2} f(x) f'(x).\n\\end{align*}\nApplying the fact again, we get\n\\[\n\\frac{1}{2} f'(x) f''(x) < \\frac{3}{4} f(x)^2.\n\\]\nMultiplying both sides by $f'(x)$ and applying the fact once more, we get\n\\[\n\\frac{1}{6} (f'(x))^3 < \\frac{1}{4} f(x)^3.\n\\]\nFrom this we deduce $f'(x) < (3/2)^{1/3} f(x) < 2f(x)$, as desired.\n\nI don't know what the best constant is, except that it is not less than 1\n(because $f(x) = e^x$ satisfies the given conditions)."
  },
  {
    "year": 1999,
    "label": "B5",
    "difficulty": "5",
    "problem": "For an integer $n\\geq 3$, let $\\theta=2\\pi/n$.  Evaluate the determinant of the\n$n\\times n$ matrix $I+A$, where $I$ is the $n\\times n$ identity matrix and\n$A=(a_{jk})$ has entries $a_{jk}=\\cos(j\\theta+k\\theta)$ for all $j,k$.",
    "solution": "First solution:\nWe claim that the eigenvalues of $A$ are $0$ with multiplicity $n-2$,\nand $n/2$ and $-n/2$, each with multiplicity $1$.  To prove this claim,\ndefine vectors $v^{(m)}$, $0\\leq m\\leq n-1$, componentwise by\n$(v^{(m)})_k = e^{ikm\\theta}$, and note that the $v^{(m)}$ form a basis\nfor $\\CC^n$.  (If we arrange the $v^{(m)}$ into an $n\\times n$ matrix,\nthen the determinant of this matrix is a Vandermonde product which is\nnonzero.)  Now note that\n\\begin{align*}\n(Av^{(m)})_j &= \\sum_{k=1}^n \\cos(j\\theta+k\\theta) e^{ikm\\theta} \\\\\n&= \\frac{e^{ij\\theta}}{2} \\sum_{k=1}^n e^{ik(m+1)\\theta}\n+ \\frac{e^{-ij\\theta}}{2} \\sum_{k=1}^n e^{ik(m-1)\\theta}.\n\\end{align*}\nSince $\\sum_{k=1}^n e^{ik\\ell\\theta} = 0$ for integer $\\ell$ unless\n$n\\,|\\,\\ell$, we conclude that $Av^{(m)}=0$ for $m=0$ or for\n$2 \\leq m \\leq n-1$.  In addition, we find that $(Av^{(1)})_j =\n\\frac{n}{2} e^{-ij\\theta} = \\frac{n}{2}(v^{(n-1)})_j$ and $(Av^{(n-1)})_j =\n\\frac{n}{2} e^{ij\\theta} = \\frac{n}{2}(v^{(1)})_j$, so that\n$A(v^{(1)} \\pm v^{(n-1)}) = \\pm \\frac{n}{2} (v^{(1)} \\pm v^{(n-1)})$.\nThus $\\{v^{(0)},v^{(2)},v^{(3)},\\ldots,v^{(n-2)},\nv^{(1)}+v^{(n-1)},v^{(1)}-v^{(n-1)}\\}$ is a basis for $\\CC^n$ of\neigenvectors of $A$ with the claimed eigenvalues.\n\nFinally, the determinant of $I+A$ is the product of $(1+\\lambda)$\nover all eigenvalues $\\lambda$ of $A$; in this case,\n$\\det (I+A) = (1+n/2)(1-n/2) = 1-n^2/4$.\n\nSecond solution (by Mohamed Omar): Set $x = e^{i \\theta}$ and write\n\\[\nA = \\frac{1}{2} u^T u + \\frac{1}{2} v^T v = \\frac{1}{2} \\begin{pmatrix} u^T& v^T \\end{pmatrix}\n\\begin{pmatrix} u \\\\ v \\end{pmatrix}\n\\]\nfor\n\\[\nu = \\begin{pmatrix} x & x^2 & \\cdots & x^n \\end{pmatrix},\nv = \\begin{pmatrix} x^{-1} & x^{-2} & \\cdots & x^n \\end{pmatrix}.\n\\]\nWe now use the fact that for $R$ an $n \\times m$ matrix and $S$ an $m \\times n$ matrix,\n\\[\n\\det (I_n + RS) = \\det(I_m + SR).\n\\]\nThis yields\n\\begin{align*}\n&\\det(I_N + A) \\\\\n&\\quad = \\det \\left( I_n + \\frac{1}{2} \\begin{pmatrix} u^T & v^T \\end{pmatrix}\n\\begin{pmatrix} u \\\\ v \\end{pmatrix} \\right) \\\\\n&\\quad = \\det \\left( I_2 + \\frac{1}{2} \\begin{pmatrix} u \\\\ v \\end{pmatrix}\\begin{pmatrix} u^T & v^T \\end{pmatrix}\n \\right) \\\\\n &\\quad = \\frac{1}{4} \\det \\begin{pmatrix} 2 + u u^T & uv^T \\\\\n vu^T & 2 + vv^T \\end{pmatrix} \\\\\n &\\quad = \\frac{1}{4} \\det \\begin{pmatrix} 2 + (x^2 + \\cdots + x^{2n}) & n \\\\\n n & 2 + (x^{-2} + \\cdots + x^{-2n}) \\end{pmatrix} \\\\\n  &\\quad = \\frac{1}{4} \\det \\begin{pmatrix} 2 & n \\\\\n n & 2 \\end{pmatrix} = 1 - \\frac{n^2}{4}.\n\\end{align*}"
  },
  {
    "year": 1999,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $S$ be a finite set of integers, each greater than 1.  Suppose that\nfor each integer $n$ there is some $s\\in S$ such that $\\gcd(s,n)=1$ or\n$\\gcd(s,n)=s$.  Show that there exist $s,t\\in S$ such that $\\gcd(s,t)$\nis prime.\n\n\\end{itemize}\n\\end{document}",
    "solution": "First solution:\nChoose a sequence $p_1, p_2, \\dots$ of primes as follows. Let $p_1$ be any prime\ndividing an element of $S$. To define $p_{j+1}$ given $p_1, \\dots, p_j$,\nchoose an integer $N_j \\in S$ relatively prime to $p_1 \\cdots p_j$ and let\n$p_{j+1}$ be a prime divisor of $N_j$, or stop if no such $N_j$ exists.\n\nSince $S$ is finite, the above algorithm eventually terminates in a finite\nsequence $p_1, \\dots, p_k$.\nLet $m$ be the smallest integer such that $p_1 \\cdots p_m$ has a divisor in $S$.\n(By the assumption on $S$ with $n=p_1\\cdots p_k$,\n$m=k$ has this property, so $m$ is well-defined.)\nIf $m=1$, then $p_1\\in S$, and we are done, so assume $m\\geq 2$.\nAny divisor $d$ of $p_1\\cdots p_m$ in $S$ must be a multiple of $p_m$, or else\nit would also be a divisor of $p_1 \\cdots p_{m-1}$, contradicting the choice\nof $m$. But now $\\gcd(d, N_{m-1}) = p_m$, as desired.\n\nSecond solution (from \\texttt{sci.math}):\nLet $n$ be the smallest integer such that $\\gcd(s,n) > 1$ for all $s$ in\n$n$; note that $n$ obviously has no repeated prime factors.\nBy the condition on $S$, there exists $s \\in S$ which divides $n$.\n\nOn the other hand, if $p$ is a prime divisor of $s$, then by the choice\nof $n$, $n/p$ is relatively prime to some element $t$ of $S$. Since $n$ cannot\nbe relatively prime to $t$, $t$ is divisible by $p$, but not by any other\nprime divisor of $n$ (as those primes divide $n/p$). Thus $\\gcd(s,t) = p$,\nas desired.\n\n\\end{itemize}\n\n\\end{document}"
  },
  {
    "year": 2000,
    "label": "A1",
    "difficulty": "1",
    "problem": "Let $A$ be a positive real number.  What are the possible values of\n$\\sum_{j=0}^\\infty x_j^2$, given that $x_0,x_1,\\ldots$ are positive\nnumbers\nfor which $\\sum_{j=0}^\\infty x_j=A$?",
    "solution": "The possible values comprise the interval $(0, A^2)$.\n\nTo see that the values must lie in this interval, note that\n\\[\n\\left(\\sum_{j=0}^m x_j\\right)^2\n= \\sum_{j=0}^m x_j^2 + \\sum_{0\\leq j<k\\leq m} 2x_jx_k,\n\\]\nso $\\sum_{j=0}^m x_j^2 \\leq A^2 - 2x_0x_1$. Letting $m \\to \\infty$,\nwe have $\\sum_{j=0}^\\infty x_j^2 \\leq A^2-2x_0x_1 < A^2$.\n\nTo show that all values in $(0, A^2)$ can be obtained, we\nuse geometric progressions with $x_1/x_0 = x_2/x_1 = \\cdots = d$\nfor variable $d$.\nThen $\\sum_{j=0}^\\infty x_j = x_0/(1-d)$ and\n\\[\n\\sum_{j=0}^\\infty x_j^2 = \\frac{x_0^2}{1-d^2} = \\frac{1-d}{1+d} \\left(\n\\sum_{j=0}^\\infty x_j \\right)^2.\n\\]\nAs $d$ increases from 0 to 1, $(1-d)/(1+d)$ decreases from 1 to 0.\nThus if we take geometric progressions with $\\sum_{j=0}^\\infty\nx_j = A$, $\\sum_{j=0}^\\infty x_j^2$ ranges from 0 to $A^2$.\nThus the possible values are indeed those in the interval $(0, A^2)$,\nas claimed."
  },
  {
    "year": 2000,
    "label": "A2",
    "difficulty": "2",
    "problem": "Prove that there exist infinitely many integers $n$ such that\n$n,n+1,n+2$ are each the sum of the squares of two integers.\n[Example: $0=0^2+0^2$, $1=0^2+1^2$, $2=1^2+1^2$.]",
    "solution": "First solution:\nLet $a$ be an even integer such that $a^2+1$ is not prime. (For example,\nchoose $a \\equiv 2 \\pmod{5}$, so that $a^2+1$ is divisible by 5.)\nThen we can write $a^2+1$ as a difference of squares $x^2-b^2$,\nby factoring $a^2+1$ as $rs$ with $r \\geq s > 1$, and setting $x\n= (r+s)/2$, $b = (r-s)/2$.\nFinally, put $n=x^2-1$, so that $n=a^2+b^2$, $n+1 = x^2$, $n+2 = x^2+1$.\n\nSecond solution:\nIt is well-known that the equation $x^2-2y^2=1$ has infinitely\nmany solutions (the so-called ``Pell'' equation).  Thus setting\n$n=2y^2$ (so that $n=y^2+y^2$, $n+1=x^2+0^2$, $n+2=x^2+1^2$)\nyields infinitely many $n$ with the desired property.\n\nThird solution:\nAs in the first solution, it suffices to exhibit $x$ such that $x^2-1$\nis the sum of two squares. We will take $x=3^{2^n}$, and show that $x^2-1$\nis the sum of two squares by induction on $n$: if $3^{2^n}-1 = a^2+b^2$,\nthen\n\\begin{align*}\n(3^{2^{n+1}}-1) &= (3^{2^n} - 1)(3^{2^n}+1) \\\\\n&= (3^{2^{n-1}}a+b)^2 + (a-3^{2^{n-1}}b)^2.\n\\end{align*}\n\nFourth solution (by Jonathan Weinstein):\nLet $n=4k^4+4k^2=(2k^2)^2+(2k)^2$ for any integer $k$. Then $n+1=(2k^2+1)^2+0^2$ and $n+2=(2k^2+1)^2+1^2$."
  },
  {
    "year": 2000,
    "label": "A3",
    "difficulty": "3",
    "problem": "The octagon $P_1P_2P_3P_4P_5P_6P_7P_8$ is inscribed in a circle, with\nthe\nvertices around the circumference in the given order.  Given that the\npolygon\n$P_1P_3P_5P_7$ is a square of area 5, and the polygon $P_2P_4P_6P_8$ is a\nrectangle of area 4, find the maximum possible area of the octagon.",
    "solution": "The maximum area is $3 \\sqrt{5}$.\n\nWe deduce from the area of $P_1P_3P_5P_7$ that the radius of the circle\nis $\\sqrt{5/2}$.  An easy calculation using the Pythagorean Theorem then\nshows that the rectangle $P_2P_4P_6P_8$ has sides $\\sqrt{2}$ and\n$2\\sqrt{2}$.\nFor notational ease, denote the area of a polygon by putting brackets\naround the name of the polygon.\n\nBy symmetry, the area of the octagon can be expressed as\n\\[\n[P_2P_4P_6P_8] + 2[P_2P_3P_4] + 2[P_4P_5P_6].\n\\]\nNote that $[P_2P_3P_4]$ is $\\sqrt{2}$ times\nthe distance from $P_3$ to $P_2P_4$, which is maximized when $P_3$\nlies on the midpoint of arc $P_2P_4$; similarly, $[P_4P_5P_6]$ is\n$\\sqrt{2}/2$ times the distance from $P_5$ to $P_4P_6$, which is\nmaximized when $P_5$ lies on the midpoint of arc $P_4P_6$. Thus the\narea of the octagon is maximized when $P_3$ is the\nmidpoint of arc $P_2P_4$ and $P_5$ is the midpoint of arc $P_4P_6$.\nIn this case, it is easy to calculate that $[P_2P_3P_4] = \\sqrt{5}-1$\nand $[P_4P_5P_6] = \\sqrt{5}/2-1$, and so the area of the octagon is\n$3\\sqrt{5}$."
  },
  {
    "year": 2000,
    "label": "A4",
    "difficulty": "4",
    "problem": "Show that the improper integral\n\\[ \\lim_{B\\to\\infty}\\int_{0}^B \\sin(x) \\sin(x^2)\\,dx\\]\nconverges.",
    "solution": "To avoid some improper integrals at 0, we may as well replace the left endpoint of integration by some $\\epsilon > 0$. We now use integration by parts:\n\\begin{align*}\n\\int_\\epsilon^B \\sin x \\sin x^2\\,dx\n&= \\int_\\epsilon^B \\frac{\\sin x}{2x} \\sin x^2 (2x\\,dx) \\\\\n&= \\left. -\\frac{\\sin x}{2x} \\cos x^2 \\right|_\\epsilon^B \\\\\n&\\mbox{} + \\int_\\epsilon^B \\left( \\frac{\\cos x}{2x} - \\frac{\\sin x}{2x^2} \\right) \\cos x^2\\,dx.\n\\end{align*}\nNow $\\frac{\\sin x}{2x} \\cos x^2$ tends to 0 as $B \\to \\infty$,\nand the integral of $\\frac{\\sin x}{2x^2} \\cos x^2$ converges absolutely\nby comparison with $1/x^2$. Thus it suffices to note that\n\\begin{align*}\n\\int_\\epsilon^B \\frac{\\cos x}{2x} \\cos x^2\\,dx &=\n\\int_\\epsilon^B \\frac{\\cos x}{4x^2} \\cos x^2(2x\\,dx) \\\\\n&= \\left. \\frac{\\cos x}{4x^2} \\sin x^2 \\right|_\\epsilon^B \\\\\n&\\mbox{} - \\int_\\epsilon^B \\frac{2x\\cos x - \\sin x}{4x^3} \\sin x^2\\,dx,\n\\end{align*}\nand that the final integral converges absolutely by comparison to\n$1/x^3$.\n\nAn alternate approach is to first rewrite $\\sin x \\sin x^2$ as\n$\\frac{1}{2}(\\cos (x^2-x) - \\cos (x^2+x))$. Then\n\\begin{align*}\n\\int_\\epsilon^B \\cos(x^2+x)\\,dx &=\n- \\left. \\frac{\\sin (x^2+x)}{2x+1} \\right|_\\epsilon^B \\\\\n&\\mbox{} - \\int_\\epsilon^B \\frac{2\\sin(x^2+x)}{(2x+1)^2}\\,dx\n\\end{align*}\nconverges absolutely, and $\\int_0^B \\cos (x^2-x)$ can be\ntreated similarly."
  },
  {
    "year": 2000,
    "label": "A5",
    "difficulty": "5",
    "problem": "Three distinct points with integer coordinates lie in the plane on a\ncircle of radius $r>0$.  Show that two of these points are separated by a\ndistance of at least $r^{1/3}$.",
    "solution": "Let $a,b,c$ be the distances between the points. Then the area of the triangle\nwith the three points as vertices\nis $abc/4r$. On the other hand, the area of a triangle whose vertices\nhave integer coordinates is at least 1/2 (for example,\nby Pick's Theorem). Thus $abc/4r \\geq 1/2$,\nand so\n\\[\n\\max\\{a,b,c\\} \\geq (abc)^{1/3} \\geq (2r)^{1/3} > r^{1/3}.\n\\]"
  },
  {
    "year": 2000,
    "label": "A6",
    "difficulty": "6",
    "problem": "Let $f(x)$ be a polynomial with integer coefficients.  Define a\nsequence $a_0,a_1,\\ldots$ of integers such that $a_0=0$ and\n$a_{n+1}=f(a_n)$\nfor all $n\\geq 0$.  Prove that if there exists a positive integer $m$ for\nwhich $a_m=0$ then either $a_1=0$ or $a_2=0$.",
    "solution": "Recall that if $f(x)$ is a polynomial with integer coefficients,\nthen $m-n$ divides $f(m)-f(n)$ for any integers $m$ and $n$. In particular,\nif we put $b_n = a_{n+1} - a_n$, then $b_n$ divides $b_{n+1}$ for all $n$.\nOn the other hand, we are given that $a_0=a_m=0$, which implies that\n$a_1=a_{m+1}$ and so $b_0=b_m$. If $b_0=0$, then $a_0=a_1=\\cdots=a_m$\nand we are done. Otherwise, $|b_0| = |b_1| = |b_2| = \\cdots$, so\n$b_n = \\pm b_0$ for all $n$.\n\nNow $b_0 + \\cdots + b_{m-1} = a_m - a_0 = 0$, so half of the integers $b_0,\n\\dots, b_{m-1}$ are positive and half are negative. In particular, there\nexists an integer $0<k<m$ such that $b_{k-1} = -b_k$, which is to say,\n$a_{k-1} = a_{k+1}$. From this it follows that $a_n = a_{n+2}$ for all\n$n \\geq k-1$; in particular, for $m=n$, we have\n\\[\na_0 = a_m = a_{m+2} = f(f(a_0))\n= a_2.\n\\]"
  },
  {
    "year": 2000,
    "label": "B1",
    "difficulty": "1",
    "problem": "Let $a_j,b_j,c_j$ be integers for $1\\leq j\\leq N$.  Assume for each\n$j$, at least one of $a_j,b_j,c_j$ is odd.  Show that there exist integers\n$r$, $s$, $t$ such that $ra_j+sb_j+tc_j$ is odd for at least $4N/7$ values\nof $j$, $1\\leq j\\leq N$.",
    "solution": "Consider the seven triples $(a,b,c)$ with $a,b,c \\in \\{0,1\\}$ not\nall zero. Notice that if $r_j, s_j, t_j$ are not all even, then four\nof the sums $ar_j + bs_j + ct_j$ with $a,b,c \\in \\{0,1\\}$ are even\nand four are odd. Of course the sum with $a=b=c=0$ is even, so at\nleast four of the seven triples with $a,b,c$ not all zero yield an odd\nsum. In other words, at least $4N$ of the tuples $(a,b,c,j)$ yield\nodd sums. By the pigeonhole principle, there is a triple $(a,b,c)$\nfor which at least $4N/7$ of the sums are odd."
  },
  {
    "year": 2000,
    "label": "B2",
    "difficulty": "2",
    "problem": "Prove that the expression\n\\[ \\frac{gcd(m,n)}{n}\\binom{n}{m} \\]\nis an integer for all pairs of integers $n\\geq m\\geq 1$.",
    "solution": "Since $\\gcd(m,n)$ is an integer linear combination of $m$ and $n$,\nit follows that\n\\[\\frac{gcd(m,n)}{n}\\binom{n}{m}\\]\nis an integer linear combination of the integers\n\\[\\frac{m}{n}\\binom{n}{m}=\\binom{n-1}{m-1} \\mbox{ and }\n\\frac{n}{n}\\binom{n}{m}=\\binom{n}{m} \\]\nand hence is itself an integer."
  },
  {
    "year": 2000,
    "label": "B3",
    "difficulty": "3",
    "problem": "Let $f(t)=\\sum_{j=1}^N a_j \\sin(2\\pi jt)$, where each $a_j$ is real\nand\n$a_N$ is not equal to 0.  Let $N_k$ denote the number of zeroes (including\nmultiplicities) of $\\frac{d^k f}{dt^k}$.\nProve that\n\\[N_0\\leq N_1\\leq N_2\\leq \\cdots \\mbox{ and } \\lim_{k\\to\\infty} N_k =\n2N.\\]\n[Editorial clarification: only zeroes in $[0, 1)$ should be counted.]",
    "solution": "Put $f_k(t) = \\frac{df^k}{dt^k}$.\nRecall Rolle's theorem: if $f(t)$ is differentiable, then between any\ntwo zeroes of $f(t)$ there exists a zero of $f'(t)$. This also applies\nwhen the zeroes are not all distinct: if $f$ has a zero of multiplicity\n$m$ at $t=x$, then $f'$ has a zero of multiplicity at least $m-1$ there.\n\nTherefore, if $0 \\leq a_0 \\leq a_1 \\leq \\cdots \\leq a_r < 1$ are the roots\nof $f_k$ in $[0,1)$, then $f_{k+1}$ has a root\nin each of the intervals $(a_0, a_1), (a_1, a_2), \\dots, (a_{r-1}, a_r)$,\nso long as we\nadopt the convention that the empty interval $(t,t)$ actually contains\nthe point $t$ itself. There is also a root in the ``wraparound'' interval\n$(a_r, a_0)$. Thus $N_{k+1} \\geq N_k$.\n\nNext, note that if we set $z = e^{2\\pi i t}$; then\n\\[\nf_{4k}(t) = \\frac{1}{2i} \\sum_{j=1}^N j^{4k} a_j (z^j - z^{-j})\n\\]\nis equal to $z^{-N}$ times a polynomial of degree $2N$. Hence as a\nfunction of $z$, it has at most $2N$ roots; therefore $f_k(t)$ has\nat most $2N$ roots in $[0,1]$. That is, $N_k \\leq 2N$ for all $N$.\n\nTo establish that $N_k \\to 2N$, we make precise the observation that\n\\[\nf_k(t) = \\sum_{j=1}^N j^{4k} a_j \\sin(2\\pi j t)\n\\]\nis dominated by the term with $j=N$. At the points\n$t = (2i+1)/(2N)$ for $i=0,1, \\dots, N-1$, we have\n$N^{4k} a_N \\sin (2\\pi N t) = \\pm N^{4k} a_N$. If $k$ is chosen large enough\nso that\n\\[\n|a_N| N^{4k} > |a_1| 1^{4k} + \\cdots + |a_{N-1}| (N-1)^{4k},\n\\]\nthen $f_k((2i+1)/2N)$ has the same sign as $a_N \\sin (2\\pi N at)$,\nwhich is to say, the sequence $f_k(1/2N), f_k(3/2N), \\dots$ alternates\nin sign. Thus\nbetween these points (again including the ``wraparound'' interval) we find\n$2N$ sign changes of $f_k$. Therefore $\\lim_{k \\to \\infty} N_k = 2N$."
  },
  {
    "year": 2000,
    "label": "B4",
    "difficulty": "4",
    "problem": "Let $f(x)$ be a continuous function such that $f(2x^2-1)=2xf(x)$ for\nall $x$.  Show that $f(x)=0$ for $-1\\leq x\\leq 1$.",
    "solution": "For $t$ real and not a multiple of $\\pi$, write $g(t) =\n\\frac{f(\\cos t)}{\\sin t}$.\nThen $g(t+\\pi) = g(t)$; furthermore, the given equation implies that\n\\[\ng(2t) = \\frac{f(2\\cos^2 t - 1)}{\\sin (2t)} =\n\\frac{2(\\cos t) f(\\cos t)}{\\sin(2t)} = g(t).\n\\]\nIn particular, for any integer $n$ and $k$, we have\n\\[\ng(1+n\\pi/2^k) = g(2^k + n\\pi) = g(2^k) = g(1).\n\\]\nSince $f$ is continuous, $g$ is continuous where it is defined;\nbut the set $\\{1+n\\pi/2^k | n,k\\in{\\mathbb{Z}}\\}$ is dense\nin the reals, and so $g$ must be constant on its domain.\nSince $g(-t) = -g(t)$ for all $t$, we must have $g(t) = 0$\nwhen $t$ is not a multiple of $\\pi$.\nHence $f(x) = 0$ for $x \\in (-1,1)$.  Finally,\nsetting $x=0$ and $x=1$ in the given equation yields\n$f(-1) = f(1) = 0$."
  },
  {
    "year": 2000,
    "label": "B5",
    "difficulty": "5",
    "problem": "Let $S_0$ be a finite set of positive integers.  We define finite\nsets\n$S_1,S_2,\\ldots$ of positive integers as follows:\nthe integer $a$ is in $S_{n+1}$ if and only if exactly one of $a-1$ or $a$ is\nin\n$S_n$.\nShow that there exist infinitely many integers $N$ for which\n$S_N=S_0\\cup\\{N+a: a\\in S_0\\}$.",
    "solution": "We claim that all integers $N$ of the form $2^k$, with $k$ a positive\ninteger and $N>\\max\\{S_0\\}$, satisfy the desired conditions.\n\nIt follows from the definition of $S_n$, and induction on $n$, that\n\\begin{align*}\n\\sum_{j \\in S_n} x^j &\\equiv (1+x) \\sum_{j \\in S_{n-1}} x^j \\\\\n&\\equiv (1+x)^n \\sum_{j \\in S_0} x^j \\pmod{2}.\n\\end{align*}\nFrom the identity $(x+y)^2 \\equiv x^2+y^2 \\pmod{2}$ and induction\non $n$, we have $(x+y)^{2^n} \\equiv x^{2^n} + y^{2^n} \\pmod{2}$.\nHence if we choose $N$ to be a power of 2 greater than $\\max\\{S_0\\}$, then\n\\[\n\\sum_{j \\in S_n} \\equiv (1+x^N) \\sum_{j \\in S_0} x^j\n\\]\nand $S_N=S_0\\cup\\{N+a: a\\in S_0\\}$, as desired."
  },
  {
    "year": 2000,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $B$ be a set of more than $2^{n+1}/n$ distinct points with\ncoordinates\nof the form $(\\pm 1,\\pm 1,\\ldots,\\pm 1)$ in $n$-dimensional space with\n$n\\geq 3$.\nShow that there are three distinct points in $B$ which are the vertices of\nan\nequilateral triangle.\n\n\\end{itemize}\n\\end{document}",
    "solution": "For each point $P$ in $B$, let $S_P$ be the set of points with\nall coordinates equal to $\\pm 1$ which\ndiffer from $P$ in exactly one coordinate. Since there are more than\n$2^{n+1}/n$ points in $B$, and each $S_P$ has $n$ elements, the\ncardinalities of the sets $S_P$ add up to more than $2^{n+1}$, which\nis to say, more than twice the total number of points. By the\npigeonhole principle, there must be a point in three of the\nsets, say $S_P, S_Q, S_R$. But then any two of $P, Q, R$ differ in\nexactly two coordinates, so $PQR$ is an equilateral triangle, as\ndesired.\n\n\n\\end{itemize}\n\n\\end{document}"
  },
  {
    "year": 2001,
    "label": "A1",
    "difficulty": "1",
    "problem": "Consider a set $S$ and a binary operation $*$, i.e., for each $a,b\\in S$,\n$a*b\\in S$.  Assume $(a*b)*a=b$ for all $a,b\\in S$.  Prove that\n$a*(b*a)=b$ for all $a,b\\in S$.",
    "solution": "The hypothesis implies $((b*a)*b)*(b*a)=b$ for all $a,b\\in S$\n(by replacing $a$ by $b*a$), and\nhence $a*(b*a)=b$ for all $a,b\\in S$ (using $(b*a)*b = a$)."
  },
  {
    "year": 2001,
    "label": "A2",
    "difficulty": "2",
    "problem": "You have coins $C_1,C_2,\\ldots,C_n$.  For each $k$, $C_k$ is biased so\nthat, when tossed, it has probability $1/(2k+1)$ of falling heads.\nIf the $n$ coins are tossed, what is the probability that the number of\nheads is odd?  Express the answer as a rational function of $n$.",
    "solution": "Let $P_n$ denote the desired probability.  Then $P_1=1/3$, and, for\n$n>1$,\n\\begin{align*}\n P_n &= \\left(\\frac{2n}{2n+1}\\right) P_{n-1}\n        +\\left(\\frac{1}{2n+1}\\right) (1-P_{n-1}) \\\\\n       &= \\left(\\frac{2n-1}{2n+1}\\right)P_{n-1} + \\frac{1}{2n+1}.\n\\end{align*}\nThe recurrence yields $P_2=2/5$, $P_3=3/7$, and by a simple\ninduction, one then checks that for general $n$ one has $P_n=n/(2n+1)$.\n\nNote: Richard Stanley points out the following noninductive argument.\nPut $f(x) = \\prod_{k=1}^n (x+2k)/(2k+1)$; then the coefficient of\n$x^i$ in $f(x)$ is the probability of getting exactly $i$ heads. Thus\nthe desired number is $(f(1) - f(-1))/2$, and both values of $f$ can\nbe computed directly: $f(1) = 1$, and\n\\[\nf(-1) = \\frac{1}{3} \\times \\frac{3}{5} \\times \\cdots \\times \\frac{2n-1}{2n+1}\n= \\frac{1}{2n+1}.\n\\]"
  },
  {
    "year": 2001,
    "label": "A3",
    "difficulty": "3",
    "problem": "For each integer $m$, consider the polynomial\n\\[P_m(x)=x^4-(2m+4)x^2+(m-2)^2.\\] For what values of $m$ is $P_m(x)$\nthe product of two non-constant polynomials with integer coefficients?",
    "solution": "By the quadratic formula, if $P_m(x)=0$, then $x^2=m\\pm\n2\\sqrt{2m}+2$, and hence the four roots of $P_m$ are given by\n$S = \\{\\pm\\sqrt{m}\\pm\\sqrt{2}\\}$. If $P_m$ factors into two nonconstant\npolynomials over the integers, then some subset of $S$ consisting of one\nor two elements form the roots of a polynomial with integer coefficients.\n\nFirst suppose this subset has a single element, say $\\sqrt{m} \\pm \\sqrt{2}$;\nthis element must be a rational number.\nThen $(\\sqrt{m} \\pm \\sqrt{2})^2 = 2 + m \\pm  2 \\sqrt{2m}$ is an integer,\nso $m$ is twice a perfect square, say $m = 2n^2$. But then\n$\\sqrt{m} \\pm \\sqrt{2} = (n\\pm 1)\\sqrt{2}$ is only rational if $n=\\pm 1$,\ni.e., if $m = 2$.\n\nNext, suppose that the subset contains two elements; then we can take\nit to be one of $\\{\\sqrt{m} \\pm \\sqrt{2}\\}$, $\\{\\sqrt{2} \\pm \\sqrt{m}\\}$\nor $\\{\\pm (\\sqrt{m} + \\sqrt{2})\\}$. In all cases, the sum and the product\nof the elements of the\nsubset must be a rational number. In the first case, this means\n$2\\sqrt{m} \\in \\QQ$, so $m$ is a perfect square. In the second case,\nwe have $2 \\sqrt{2} \\in \\QQ$, contradiction. In the third case, we have\n$(\\sqrt{m} + \\sqrt{2})^2 \\in \\QQ$, or $m + 2 + 2\\sqrt{2m} \\in \\QQ$, which\nmeans that $m$ is twice a perfect square.\n\nWe conclude that $P_m(x)$ factors into two nonconstant polynomials over\nthe integers if and only if $m$ is either a square or twice a square.\n\nNote: a more sophisticated interpretation of this argument can be given\nusing Galois theory. Namely, if $m$ is neither a square nor twice a square,\nthen the number fields $\\QQ(\\sqrt{m})$ and $\\QQ(\\sqrt{2})$ are distinct\nquadratic fields, so their compositum is a number field of degree 4, whose\nGalois group acts transitively on $\\{\\pm \\sqrt{m} \\pm \\sqrt{2}\\}$. Thus\n$P_m$ is irreducible."
  },
  {
    "year": 2001,
    "label": "A4",
    "difficulty": "4",
    "problem": "Triangle $ABC$ has an area 1.  Points $E,F,G$ lie, respectively,\non sides $BC$, $CA$, $AB$ such that $AE$ bisects $BF$ at point $R$,\n$BF$ bisects $CG$ at point $S$, and $CG$ bisects $AE$ at point $T$.\nFind the area of the triangle $RST$.",
    "solution": "Choose $r,s,t$ so that $EC = rBC, FA = sCA, GB = tCB$, and let\n$[XYZ]$ denote the area of triangle $XYZ$. Then $[ABE] = [AFE]$ since\nthe triangles have the same altitude and base.\nAlso $[ABE] = (BE/BC) [ABC] = 1-r$, and\n$[ECF] = (EC/BC)(CF/CA)[ABC] = r(1-s)$ (e.g., by the law of sines).\nAdding this\nall up yields\n\\begin{align*}\n1 &= [ABE] + [ABF] + [ECF] \\\\\n&= 2(1-r) + r(1-s) = 2-r-rs\n\\end{align*}\nor $r(1+s) = 1$.\nSimilarly $s(1+t) = t(1+r) = 1$.\n\nLet $f: [0, \\infty) \\to [0, \\infty)$ be the function given by\n$f(x) = 1/(1+x)$; then $f(f(f(r))) = r$.\nHowever, $f(x)$ is strictly decreasing in $x$, so $f(f(x))$ is increasing\nand $f(f(f(x)))$ is decreasing. Thus there is at most one $x$ such that\n$f(f(f(x))) = x$;\nin fact, since the equation $f(z) = z$ has a positive root\n$z = (-1 + \\sqrt{5})/2$, we must have $r=s=t=z$.\n\nWe now compute $[ABF] = (AF/AC) [ABC] = z$,\n$[ABR] = (BR/BF) [ABF] = z/2$, analogously $[BCS] = [CAT] = z/2$, and\n$[RST] = |[ABC] - [ABR] - [BCS] - [CAT]| = |1 - 3z/2| = \\frac{7 - 3\n\\sqrt{5}}{4}$.\n\nNote: the key relation $r(1+s) = 1$ can also be derived by computing\nusing homogeneous coordinates or vectors."
  },
  {
    "year": 2001,
    "label": "A5",
    "difficulty": "5",
    "problem": "Prove that there are unique positive integers $a$, $n$ such that\n$a^{n+1}-(a+1)^n=2001$.",
    "solution": "Suppose $a^{n+1} - (a+1)^n = 2001$.\nNotice that $a^{n+1} + [(a+1)^n - 1]$ is a multiple of $a$; thus\n$a$ divides $2002 = 2 \\times 7 \\times 11 \\times 13$.\n\nSince $2001$ is divisible by 3, we must have $a \\equiv 1 \\pmod{3}$,\notherwise one of $a^{n+1}$ and $(a+1)^n$ is a multiple of 3 and the\nother is not, so their difference cannot be divisible by 3. Now\n$a^{n+1} \\equiv 1 \\pmod{3}$, so we must have $(a+1)^n \\equiv 1\n\\pmod{3}$, which forces $n$ to be even, and in particular at least 2.\n\nIf $a$ is even, then $a^{n+1} - (a+1)^n \\equiv -(a+1)^n \\pmod{4}$.\nSince $n$ is even, $-(a+1)^n \\equiv -1 \\pmod{4}$. Since $2001 \\equiv 1\n\\pmod{4}$, this is impossible. Thus $a$ is odd, and so must divide\n$1001 = 7 \\times 11 \\times 13$. Moreover, $a^{n+1} - (a+1)^n \\equiv a\n\\pmod{4}$, so $a \\equiv 1 \\pmod{4}$.\n\nOf the divisors of $7 \\times 11 \\times 13$, those congruent to 1 mod 3\nare precisely those not divisible by 11 (since 7 and 13 are both\ncongruent to 1 mod 3). Thus $a$ divides $7 \\times 13$. Now\n$a \\equiv 1 \\pmod{4}$ is only possible if $a$ divides $13$.\n\nWe cannot have $a=1$, since $1 - 2^n \\neq 2001$ for any $n$. Thus\nthe only possibility is $a = 13$. One easily checks that $a=13, n=2$ is a\nsolution; all that remains is to check that no other $n$ works. In fact,\nif $n > 2$, then $13^{n+1} \\equiv 2001 \\equiv 1 \\pmod{8}$.\nBut $13^{n+1} \\equiv 13 \\pmod{8}$ since $n$ is even, contradiction.\nThus $a=13, n=2$ is the unique solution.\n\nNote: once one has that $n$ is even, one can use that $2002\n=a^{n+1} + 1 - (a+1)^n$ is divisible by $a+1$ to rule out cases."
  },
  {
    "year": 2001,
    "label": "A6",
    "difficulty": "6",
    "problem": "Can an arc of a parabola inside a circle of radius 1 have a length\ngreater than 4?",
    "solution": "The answer is yes.  Consider the arc of the parabola\n$y=Ax^2$ inside the circle $x^2+(y-1)^2 = 1$, where we initially assume\nthat $A > 1/2$.  This intersects the circle in three points,\n$(0,0)$ and $(\\pm \\sqrt{2A-1}/A, (2A-1)/A)$.  We claim that for\n$A$ sufficiently large, the length $L$ of the parabolic arc between\n$(0,0)$ and $(\\sqrt{2A-1}/A, (2A-1)/A)$ is greater than $2$, which\nimplies the desired result by symmetry.  We express $L$ using the\nusual formula for arclength:\n\\begin{align*}\nL &= \\int_0^{\\sqrt{2A-1}/A} \\sqrt{1+(2Ax)^2} \\, dx \\\\\n&= \\frac{1}{2A} \\int_0^{2\\sqrt{2A-1}} \\sqrt{1+x^2} \\, dx \\\\\n&= 2 + \\frac{1}{2A} \\left( \\int_0^{2\\sqrt{2A-1}}\n(\\sqrt{1+x^2}-x)\\,dx -2\\right),\n\\end{align*}\nwhere we have artificially introduced $-x$ into the integrand in the\nlast step.  Now, for $x \\geq 0$,\n\\[\n\\sqrt{1+x^2}-x = \\frac{1}{\\sqrt{1+x^2}+x} > \\frac{1}{2\\sqrt{1+x^2}}\n\\geq \\frac{1}{2(x+1)};\n\\]\nsince $\\int_0^\\infty dx/(2(x+1))$ diverges, so does\n$\\int_0^\\infty (\\sqrt{1+x^2}-x)\\,dx$.  Hence, for sufficiently large\n$A$, we have $\\int_0^{2\\sqrt{2A-1}} (\\sqrt{1+x^2}-x)\\,dx > 2$,\nand hence $L > 2$.\n\nNote: a numerical computation shows that one must take $A > 34.7$ to\nobtain $L > 2$, and that the maximum value of $L$ is about\n$4.0027$, achieved for $A \\approx 94.1$."
  },
  {
    "year": 2001,
    "label": "B1",
    "difficulty": "1",
    "problem": "Let $n$ be an even positive integer.  Write the numbers\n$1,2,\\ldots,n^2$ in the squares of an $n\\times n$ grid so that the\n$k$-th row, from left to right, is\n\\[(k-1)n+1,(k-1)n+2,\\ldots, (k-1)n+n.\\]\nColor the squares of the grid so that half of the squares in each\nrow and in each column are red and the other half are black (a\ncheckerboard coloring is one possibility).  Prove that for each\ncoloring, the sum of the numbers on the red squares is equal to\nthe sum of the numbers on the black squares.",
    "solution": "Let $R$ (resp.\\ $B$) denote the set of red (resp.\\ black) squares in\nsuch a coloring, and for $s\\in R\\cup B$, let $f(s)n+g(s)+1$ denote the\nnumber written in square $s$, where $0\\leq f(s),g(s)\\leq n-1$.\nThen it is clear that the value of $f(s)$ depends only on the row of\n$s$, while the value of $g(s)$ depends only on the column of $s$.  Since\nevery row contains exactly $n/2$ elements of $R$ and $n/2$ elements of $B$,\n\\[ \\sum_{s\\in R} f(s) = \\sum_{s\\in B} f(s) .\\]\nSimilarly, because every column contains exactly $n/2$ elements of $R$ and\n$n/2$ elements of $B$,\n\\[ \\sum_{s\\in R} g(s) = \\sum_{s\\in B} g(s) .\\]\nIt follows that\n\\[\\sum_{s\\in R} f(s)n+g(s)+1 = \\sum_{s\\in B} f(s)n+g(s)+1,\\]\nas desired.\n\nNote: Richard Stanley points out a theorem of Ryser (see Ryser,\n\\textit{Combinatorial Mathematics}, Theorem~3.1) that can also be applied.\nNamely, if $A$ and $B$ are $0-1$ matrices with the same row and column\nsums, then there is a sequence of operations on $2 \\times 2$ matrices\nof the form\n\\[\n\\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} \\to\n\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\n\\]\nor vice versa, which transforms $A$ into $B$. If we identify 0 and 1 with\nred and black, then the given coloring and the checkerboard coloring\nboth satisfy the sum condition. Since the desired result is clearly\ntrue for the checkerboard coloring, and performing the matrix operations\ndoes not affect this, the desired result follows in general."
  },
  {
    "year": 2001,
    "label": "B2",
    "difficulty": "2",
    "problem": "Find all pairs of real numbers $(x,y)$ satisfying the system\nof equations\n\\begin{align*}\n \\frac{1}{x} + \\frac{1}{2y} &= (x^2+3y^2)(3x^2+y^2) \\\\\n   \\frac{1}{x} - \\frac{1}{2y} &= 2(y^4-x^4).\n\\end{align*}",
    "solution": "By adding and subtracting the two given equations, we obtain\nthe equivalent pair of equations\n\\begin{align*}\n2/x &= x^4 + 10x^2y^2 + 5y^4 \\\\\n1/y &= 5x^4 + 10x^2y^2 + y^4.\n\\end{align*}\nMultiplying the former by\n$x$ and the latter by $y$, then adding and subtracting the two\nresulting equations, we obtain another pair of equations equivalent\nto the given ones,\n\\[\n3 = (x+y)^5, \\qquad 1 = (x-y)^5.\n\\]\nIt follows that\n$x = (3^{1/5}+1)/2$ and $y = (3^{1/5}-1)/2$ is the unique solution\nsatisfying the given equations."
  },
  {
    "year": 2001,
    "label": "B3",
    "difficulty": "3",
    "problem": "For any positive integer $n$, let $\\langle n\\rangle$ denote\nthe closest integer to $\\sqrt{n}$.  Evaluate\n\\[\\sum_{n=1}^\\infty \\frac{2^{\\langle n\\rangle}+2^{-\\langle n\\rangle}}\n                         {2^n}.\\]",
    "solution": "Since $(k-1/2)^2 = k^2-k+1/4$ and $(k+1/2)^2 = k^2+k+1/4$,\nwe have that $\\langle n \\rangle = k$ if and only if\n$k^2-k+1 \\leq n \\leq k^2+k$.  Hence\n\\begin{align*}\n\\sum_{n=1}^\\infty \\frac{2^{\\langle n \\rangle} + 2^{-\\langle n \\rangle}}{2^n}\n&= \\sum_{k=1}^\\infty \\sum_{n, \\langle n \\rangle = k}\n    \\frac{2^{\\langle n \\rangle} + 2^{-\\langle n \\rangle}}{2^n} \\\\\n&= \\sum_{k=1}^\\infty \\sum_{n=k^2-k+1}^{k^2+k} \\frac{2^k+2^{-k}}{2^n} \\\\\n&= \\sum_{k=1}^\\infty (2^k+2^{-k})(2^{-k^2+k}-2^{-k^2-k}) \\\\\n&= \\sum_{k=1}^\\infty (2^{-k(k-2)} - 2^{-k(k+2)}) \\\\\n&= \\sum_{k=1}^\\infty 2^{-k(k-2)} - \\sum_{k=3}^\\infty 2^{-k(k-2)} \\\\\n&= 3.\n\\end{align*}\n\nAlternate solution: rewrite the sum as $\\sum_{n=1}^\\infty\n2^{-(n+\\langle n \\rangle)} + \\sum_{n=1}^\\infty\n2^{-(n - \\langle n \\rangle)}$.\nNote that $\\langle n \\rangle \\neq \\langle n+1 \\rangle$\nif and only if $n = m^2+m$ for some $m$. Thus $n + \\langle n \\rangle$\nand $n - \\langle n \\rangle$ each increase by 1 except at $n=m^2+m$,\nwhere the former skips from $m^2+2m$ to $m^2+2m+2$ and the latter\nrepeats the value $m^2$. Thus the sums are\n\\[\n\\sum_{n=1}^\\infty 2^{-n} - \\sum_{m=1}^\\infty 2^{-m^2}\n+ \\sum_{n=0}^\\infty 2^{-n} + \\sum_{m=1}^\\infty 2^{-m^2}\n= 2+1=3.\n\\]"
  },
  {
    "year": 2001,
    "label": "B4",
    "difficulty": "4",
    "problem": "Let $S$ denote the set of rational numbers different from\n$\\{-1,0,1\\}$.  Define $f:S\\rightarrow S$ by $f(x)=x-1/x$.  Prove\nor disprove that\n\\[\\bigcap_{n=1}^\\infty f^{(n)}(S) = \\emptyset,\\]\nwhere $f^{(n)}$ denotes $f$ composed with itself $n$ times.",
    "solution": "For a rational number $p/q$ expressed in lowest terms, define\nits {\\it height} $H(p/q)$ to be $|p|+|q|$.  Then for any $p/q\\in S$\nexpressed in lowest terms, we have $H(f(p/q))=|q^2-p^2|+|pq|$; since\nby assumption $p$ and $q$ are nonzero integers with $|p|\\neq |q|$,\nwe have\n\\begin{align*}\nH(f(p/q)) - H(p/q) &= |q^2-p^2|+|pq| -|p| -|q| \\\\\n  &\\geq 3+ |pq| -|p| - |q| \\\\\n&= (|p|-1)(|q|-1) + 2 \\geq 2 .\n\\end{align*}\nIt follows that $f^{(n)}(S)$ consists solely of numbers of height\nstrictly larger than $2n+2$, and hence\n\\[\\cap_{n=1}^\\infty f^{(n)}(S) = \\emptyset.\\]\n\nNote: many choices for the height function are possible: one can\ntake $H(p/q) = \\max{|p|, |q|}$, or $H(p/q)$ equal to the total number of\nprime factors of $p$ and $q$, and so on. The key properties of the height\nfunction are that on one hand, there are only finitely many rationals with\nheight below any finite bound, and on the other hand, the height function\nis a sufficiently ``algebraic'' function of its argument that one can\nrelate the heights of $p/q$ and $f(p/q)$."
  },
  {
    "year": 2001,
    "label": "B5",
    "difficulty": "5",
    "problem": "Let $a$ and $b$ be real numbers in the interval $(0,1/2)$, and\nlet $g$ be a continuous real-valued function such that\n$g(g(x))= ag(x)+bx$ for all real $x$.  Prove that\n$g(x)=cx$ for some constant $c$.",
    "solution": "Note that $g(x) = g(y)$ implies that $g(g(x)) = g(g(y))$ and hence\n$x = y$ from the given equation. That is, $g$ is injective. Since $g$\nis also continuous, $g$ is either strictly increasing or strictly\ndecreasing. Moreover, $g$ cannot tend to a finite limit $L$ as $x \\to\n+\\infty$, or else we'd have $g(g(x)) - ag(x) = bx$, with the left side\nbounded and the right side unbounded. Similarly, $g$ cannot tend to\na finite limit as $x \\to -\\infty$. Together with monotonicity, this\nyields that $g$ is also surjective.\n\nPick $x_0$ arbitrary, and define $x_n$ for all $n \\in \\ZZ$ recursively\nby $x_{n+1} = g(x_n)$ for $n > 0$, and $x_{n-1} = g^{-1}(x_n)$ for $n<0$.\nLet $r_1 = (a + \\sqrt{a^2+4b})/2$ and $r_2 = (a - \\sqrt{a^2+4b})/2$ and\n$r_2$ be the roots of $x^2 - ax-b = 0$, so that $r_1 > 0 >\nr_2$ and $1 > |r_1| > |r_2|$. Then there exist $c_1, c_2 \\in \\RR$ such that\n$x_n = c_1 r_1^n + c_2 r_2^n$ for all $n \\in \\ZZ$.\n\nSuppose $g$ is strictly increasing. If $c_2 \\neq 0$ for some choice of\n$x_0$, then $x_n$ is dominated by $r_2^n$ for $n$ sufficiently\nnegative. But taking $x_n$ and $x_{n+2}$ for $n$ sufficiently negative of the\nright parity, we get $0 < x_n < x_{n+2}$ but $g(x_n) > g(x_{n+2})$,\ncontradiction. Thus $c_2 = 0$; since $x_0 = c_1$\nand $x_1 = c_1 r_1$, we have $g(x) = r_1 x$ for all $x$.\nAnalogously, if $g$ is strictly decreasing, then $c_2 = 0$ or else\n$x_n$ is dominated by $r_1^n$ for $n$ sufficiently positive. But taking\n$x_n$ and $x_{n+2}$ for $n$ sufficiently positive of the right parity,\nwe get $0 < x_{n+2} <x_n$ but $g(x_{n+2}) < g(x_n)$, contradiction.\nThus in that case, $g(x) = r_2 x$ for all $x$."
  },
  {
    "year": 2001,
    "label": "B6",
    "difficulty": "6",
    "problem": "Assume that $(a_n)_{n\\geq 1}$ is an increasing sequence of\npositive real numbers such that\n$\\lim a_n/n=0$.  Must there exist infinitely many positive integers\n$n$ such that $a_{n-i}+a_{n+i}<2a_n$ for $i=1,2,\\ldots,n-1$?\n\n\\end{itemize}\n\\end{document}",
    "solution": "Yes, there must exist infinitely many such $n$.\nLet $S$ be the convex hull of the set of points $(n,\na_n)$ for $n \\geq 0$. Geometrically, $S$ is the intersection of\nall convex sets (or even all halfplanes) containing the points\n$(n, a_n)$; algebraically, $S$ is the set of points $(x,y)$\nwhich can be written as $c_1(n_1, a_{n_1}) + \\cdots + c_k(n_k, a_{n_k})$\nfor some $c_1, \\dots, c_k$ which are nonnegative of sum 1.\n\nWe prove that for infinitely many $n$, $(n, a_n)$ is a vertex on the upper\nboundary of $S$, and that these $n$ satisfy the given\ncondition. The condition that $(n, a_n)$ is a vertex on the upper\nboundary of $S$ is equivalent to the existence of a line passing through\n$(n, a_n)$ with all other points of $S$ below it.\nThat is, there should exist $m>0$ such that\n\\begin{equation} \\label{eq1}\na_k < a_n + m(k-n) \\qquad \\forall k \\geq 1.\n\\end{equation}\n\nWe first show that $n=1$ satisfies (\\ref{eq1}). The condition\n$a_k/k \\to 0$ as $k \\to \\infty$\nimplies that $(a_k - a_1)/(k-1) \\to 0$ as well. Thus the\nset $\\{(a_k-a_1)/(k-1)\\}$ has an upper bound $m$, and now\n$a_k \\leq a_1 + m(k-1)$, as desired.\n\nNext, we show that given one $n$ satisfying (\\ref{eq1}), there exists a\nlarger one also satisfying (\\ref{eq1}). Again, the condition\n$a_k/k \\to 0$ as $k \\to \\infty$ implies that $(a_k-a_n)/(k-n) \\to 0$ as\n$k \\to \\infty$. Thus the sequence $\\{(a_k-a_n)/(k-n)\\}_{k>n}$ has a\nmaximum element; suppose $k = r$ is the largest value that\nachieves this maximum, and put\n$m = (a_r -a_n)/(r-n)$. Then the line through\n$(r, a_r)$ of slope $m$ lies strictly above $(k, a_k)$ for $k > r$\nand passes through or lies above $(k, a_k)$ for $k< r$.\nThus (\\ref{eq1})\nholds for $n=r$ with $m$ replaced by $m-\\epsilon$ for suitably small\n$\\epsilon > 0$.\n\nBy induction, we have that (\\ref{eq1}) holds for infinitely many $n$.\nFor any such $n$ there exists $m>0$ such that for $i=1, \\dots, n-1$, the\npoints $(n-i, a_{n-i})$ and $(n+i, a_{n+i})$ lie below the line through\n$(n, a_n)$ of slope $m$. That means $a_{n+i} < a_n + mi$\nand $a_{n-i} < a_n - mi$; adding these together gives\n$a_{n-i} + a_{n+i} < 2a_n$, as desired.\n\n\\end{itemize}\n\n\\end{document}"
  },
  {
    "year": 2002,
    "label": "A1",
    "difficulty": "1",
    "problem": "Let $k$ be a fixed positive integer. The $n$-th derivative of\n$\\frac{1}{x^k - 1}$ has the form $\\frac{P_n(x)}{(x^k - 1)^{n+1}}$\nwhere $P_n(x)$ is a polynomial. Find $P_n(1)$.",
    "solution": "By differentiating $P_n(x)/(x^k-1)^{n+1}$, we find that\n$P_{n+1}(x) = (x^k-1)P_n'(x)-(n+1)kx^{k-1}P_n(x)$; substituting\n$x=1$ yields $P_{n+1}(1) = -(n+1)k P_n(1)$.  Since $P_0(1)=1$, an\neasy induction gives $P_n(1) = (-k)^n n!$ for all $n \\geq 0$.\n\nNote: one can also argue by expanding in Taylor series around $1$.\nNamely, we have\n\\[\n\\frac{1}{x^k - 1} = \\frac{1}{k(x-1) + \\cdots}\n= \\frac{1}{k} (x-1)^{-1} + \\cdots,\n\\]\nso\n\\[\n\\frac{d^n}{dx^n} \\frac{1}{x^k - 1}\n= \\frac{(-1)^n n!}{k (x-1)^{-n-1}}\n\\]\nand\n\\begin{align*}\nP_n(x) &= (x^k - 1)^{n+1} \\frac{d^n}{dx^n} \\frac{1}{x^k - 1} \\\\\n&= (k (x-1) + \\cdots)^{n+1} \\left( \\frac{(-1)^n n!}{k}(x-1)^{-n-1}\n+ \\cdots \\right) \\\\\n&= (-k)^n n! + \\cdots.\n\\end{align*}"
  },
  {
    "year": 2002,
    "label": "A2",
    "difficulty": "2",
    "problem": "Given any five points on a sphere, show that some four of them\nmust lie on a closed hemisphere.",
    "solution": "Draw a great circle through two of the points. There are two\nclosed hemispheres with this great circle as boundary, and each of\nthe other three points lies in one of them. By the pigeonhole principle,\ntwo of those three points lie in the same hemisphere, and that hemisphere\nthus contains four of the five given points.\n\nNote: by a similar argument, one can prove that among any $n+3$ points on\nan $n$-dimensional sphere, some $n+2$ of them lie on a closed hemisphere.\n(One cannot get by with only $n+2$ points: put them at the vertices of\na regular simplex.)\nNamely, any $n$ of the points lie on a great sphere, which forms the boundary\nof two hemispheres; of the remaining three points, some two lie in the\nsame hemisphere."
  },
  {
    "year": 2002,
    "label": "A3",
    "difficulty": "3",
    "problem": "Let $n \\geq 2$ be an integer and $T_n$ be the number of non-empty\nsubsets $S$ of $\\{1, 2, 3, \\dots, n\\}$ with the property that the\naverage of the elements of $S$ is an integer. Prove that\n$T_n - n$ is always even.",
    "solution": "Note that each of the sets $\\{1\\}, \\{2\\}, \\dots, \\{n\\}$ has the\ndesired property. Moreover, for each set $S$ with integer average $m$\nthat does not contain $m$, $S \\cup \\{m\\}$ also has average $m$,\nwhile for each set $T$ of more than one element with integer average\n$m$ that contains $m$, $T \\setminus \\{m\\}$ also has average $m$.\nThus the subsets other than $\\{1\\}, \\{2\\}, \\dots, \\{n\\}$ can be grouped\nin pairs, so $T_n - n$ is even."
  },
  {
    "year": 2002,
    "label": "A4",
    "difficulty": "4",
    "problem": "In Determinant Tic-Tac-Toe, Player 1 enters a 1 in an empty\n$3 \\times 3$ matrix. Player 0 counters with a 0 in a vacant position,\nand play continues in turn until the $3 \\times 3$ matrix is\ncompleted with five 1's and four 0's. Player 0 wins if the\ndeterminant is 0 and player 1 wins otherwise. Assuming both\nplayers pursue optimal strategies, who will win and how?",
    "solution": "(partly due to David Savitt)\nPlayer 0 wins with optimal play. In fact, we prove that Player 1 cannot\nprevent Player 0 from creating a row of all zeroes, a column of all\nzeroes, or a $2 \\times 2$ submatrix of all zeroes. Each of these forces\nthe determinant of the matrix to be zero.\n\nFor $i,j=1, 2,3$, let $A_{ij}$ denote the position in row $i$ and\ncolumn $j$. Without loss of generality, we may assume that Player\n1's first move is at $A_{11}$. Player 0 then plays at $A_{22}$:\n\\[\n\\begin{pmatrix}\n1 & * & * \\\\\n* & 0 & * \\\\\n* & * & *\n\\end{pmatrix}\n\\]\nAfter Player 1's second move, at least one of $A_{23}$ and $A_{32}$\nremains vacant. Without loss of generality, assume $A_{23}$ remains\nvacant; Player 0 then plays there.\n\nAfter Player 1's third move, Player 0 wins by playing at $A_{21}$ if that\nposition is unoccupied. So assume instead that Player 1 has played there.\nThus of Player 1's three moves so far, two are at $A_{11}$ and $A_{21}$.\nHence for $i$ equal to one of 1 or 3, and for $j$ equal to one of 2 or 3,\nthe following are both true:\n\\begin{enumerate}"
  },
  {
    "year": 2002,
    "label": "A5",
    "difficulty": "5",
    "problem": "Define a sequence by $a_0=1$, together with the rules\n$a_{2n+1} = a_n$ and $a_{2n+2} = a_n + a_{n+1}$ for each\ninteger $n \\geq 0$. Prove that every positive rational number\nappears in the set\n\\[\n\\left\\{ \\frac{a_{n-1}}{a_n}: n \\geq 1 \\right\\} =\n\\left\\{ \\frac{1}{1}, \\frac{1}{2}, \\frac{2}{1}, \\frac{1}{3},\n\\frac{3}{2}, \\dots \\right\\}.\n\\]",
    "solution": "It suffices to prove that for any relatively prime positive integers\n$r,s$, there exists an integer $n$ with $a_n = r$ and $a_{n+1} = s$.\nWe prove this by induction on $r+s$, the case $r+s=2$ following\nfrom the fact that $a_0=a_1 = 1$. Given $r$ and $s$ not both 1 with\n$\\gcd(r,s) = 1$, we must have $r \\neq s$. If $r>s$, then by\nthe induction hypothesis we have $a_n = r-s$ and $a_{n+1} = s$ for\nsome $n$; then $a_{2n+2} = r$ and $a_{2n+3} = s$. If $r< s$,\nthen we have $a_n = r$ and $a_{n+1} = s-r$ for some $n$; then\n$a_{2n+1} = r$ and $a_{2n+2} = s$.\n\nNote: a related problem is as follows. Starting with the sequence\n\\[\n\\frac{0}{1}, \\frac{1}{0},\n\\]\nrepeat the following operation: insert between each pair\n$\\frac{a}{b}$ and $\\frac{c}{d}$ the pair $\\frac{a+c}{b+d}$.\nProve that each positive rational number eventually appears.\n\nObserve that by induction, if $\\frac{a}{b}$ and $\\frac{c}{d}$\nare consecutive terms in the sequence, then $bc - ad = 1$. The\nsame holds for consecutive terms of the $n$-th \\emph{Farey sequence}, the\nsequence of rational numbers in $[0,1]$ with denominator\n(in lowest terms) at most $n$."
  },
  {
    "year": 2002,
    "label": "A6",
    "difficulty": "6",
    "problem": "Fix an integer $b \\geq 2$. Let $f(1) = 1$, $f(2) = 2$, and for each\n$n \\geq 3$, define $f(n) = n f(d)$, where $d$ is the number of\nbase-$b$ digits of $n$. For which values of $b$ does\n\\[\n\\sum_{n=1}^\\infty \\frac{1}{f(n)}\n\\]\nconverge?",
    "solution": "The sum converges for $b=2$ and diverges for $b \\geq 3$.\nWe first consider $b \\geq 3$. Suppose the sum converges;\nthen the fact\nthat $f(n) = n f(d)$ whenever $b^{d-1} \\leq n \\leq b^{d} - 1$ yields\n\\begin{equation} \\label{a6eq1}\n\\sum_{n=1}^\\infty \\frac{1}{f(n)}\n= \\sum_{d=1}^\\infty \\frac{1}{f(d)} \\sum_{n=b^{d-1}}^{b^d - 1} \\frac{1}{n}.\n\\end{equation}\nHowever, by comparing the integral of $1/x$ with a Riemann sum,\nwe see that\n\\begin{align*}\n\\sum_{n=b^{d-1}}^{b^d - 1} \\frac{1}{n}\n&> \\int_{b^{d-1}}^{b^d} \\frac{dx}{x} \\\\\n&= \\log (b^d) - \\log (b^{d-1}) = \\log b,\n\\end{align*}\nwhere $\\log$ denotes the natural logarithm. Thus \\eqref{a6eq1} yields\n\\[\n\\sum_{n=1}^\\infty \\frac{1}{f(n)}\n> (\\log b) \\sum_{n=1}^\\infty \\frac{1}{f(n)},\n\\]\na contradiction since $\\log b > 1$ for $b \\geq 3$. Therefore the\nsum diverges.\n\nFor $b=2$, we have a slightly different identity because $f(2) \\neq\n2 f(2)$. Instead, for any positive integer $i$, we have\n\\begin{equation} \\label{a6eq2}\n\\sum_{n=1}^{2^i-1} \\frac{1}{f(n)}\n= 1 + \\frac{1}{2} + \\frac{1}{6} +\n\\sum_{d=3}^i \\frac{1}{f(d)} \\sum_{n=2^{d-1}}^{2^d - 1} \\frac{1}{n}.\n\\end{equation}\nAgain comparing an integral to a Riemann sum, we see that for $d\\geq 3$,\n\\begin{align*}\n\\sum_{n=2^{d-1}}^{2^d - 1} \\frac{1}{n} &<\n\\frac{1}{2^{d-1}} - \\frac{1}{2^d} + \\int_{2^{d-1}}^{2^d} \\frac{dx}{x}\n\\\\\n&= \\frac{1}{2^d} + \\log 2 \\\\\n&\\leq \\frac{1}{8} + \\log 2 < 0.125 + 0.7 < 1.\n\\end{align*}\nPut $c = \\frac{1}{8} + \\log 2$ and $L = 1+\\frac{1}{2} +\n\\frac{1}{6(1-c)}$. Then we can prove that $\\sum_{n=1}^{2^i-1}\n\\frac{1}{f(n)} < L$ for all $i \\geq 2$ by induction on $i$. The case\n$i=2$ is clear. For the induction, note that by \\eqref{a6eq2},\n\\begin{align*}\n\\sum_{n=1}^{2^i-1} \\frac{1}{f(n)}\n&< 1 + \\frac{1}{2} + \\frac{1}{6} + c \\sum_{d=3}^i \\frac{1}{f(d)} \\\\\n&< 1 + \\frac{1}{2} + \\frac{1}{6} + c \\frac{1}{6(1-c)} \\\\\n&= 1 + \\frac{1}{2} + \\frac{1}{6(1-c)} = L,\n\\end{align*}\nas desired. We conclude that $\\sum_{n=1}^\\infty \\frac{1}{f(n)}$\nconverges to a limit less than or equal to $L$.\n\nNote: the above argument proves that the sum for $b=2$ is at most\n$L < 2.417$. One can also obtain a lower bound by the same technique,\nnamely $1 + \\frac{1}{2} + \\frac{1}{6(1 - c')}$ with $c' = \\log 2$.\nThis bound exceeds $2.043$. (By contrast, summing the first 100000 terms of\nthe series only yields a lower bound of $1.906$.)\nRepeating the same arguments with $d \\geq 4$\nas the cutoff yields the upper bound $2.185$ and the lower bound $2.079$."
  },
  {
    "year": 2002,
    "label": "B1",
    "difficulty": "1",
    "problem": "Shanille O'Keal shoots free throws on a basketball court. She hits\nthe first and misses the second, and thereafter the probability that\nshe hits the next shot is equal to the proportion of shots she\nhas hit so far. What is the probability she hits exactly 50 of\nher first 100 shots?",
    "solution": "The probability is $1/99$. In fact, we show by induction on $n$\nthat after $n$ shots, the probability of having made any number of\nshots from $1$ to $n-1$ is equal to $1/(n-1)$. This is evident\nfor $n=2$. Given the result for $n$, we see that the probability of\nmaking $i$ shots after $n+1$ attempts is\n\\begin{align*}\n\\frac{i-1}{n} \\frac{1}{n-1} + \\left( 1 - \\frac{i}{n} \\right) \\frac{1}{n-1}\n&= \\frac{(i-1) + (n-i)}{n(n-1)} \\\\\n&= \\frac{1}{n},\n\\end{align*}\nas claimed."
  },
  {
    "year": 2002,
    "label": "B2",
    "difficulty": "2",
    "problem": "Consider a polyhedron with at least five faces such that exactly three\nedges emerge from each of its vertices. Two players play the following\ngame:\n\\begin{verse}\n\\noindent\nEach player, in turn, signs his or her name on a previously\nunsigned face. The winner is the player who first succeeds in\nsigning three faces that share a common vertex.\n\\end{verse}\nShow that the player who signs first will always win by playing\nas well as possible.",
    "solution": "(Note: the problem statement assumes that all polyhedra are connected\nand that no two edges share more than one face,\nso we will do likewise. In particular, these are true for all convex\npolyhedra.)\nWe show that in fact the first player can win on the third move.\nSuppose the polyhedron has a face $A$ with at least four edges. If\nthe first player plays there first, after the second player's first move\nthere will be three consecutive faces $B,C,D$ adjacent to $A$ which\nare all unoccupied. The first player wins by playing in $C$; after\nthe second player's second move, at least one of $B$ and $D$ remains\nunoccupied, and either is a winning move for the first player.\n\nIt remains to show that the polyhedron has a face with at least four\nedges. (Thanks to Russ Mann for suggesting the following argument.)\nSuppose on the contrary that each face has only three edges.\nStarting with any face $F_1$ with vertices $v_1, v_2, v_3$, let\n$v_4$ be the other endpoint of the third edge out of $v_1$. Then\nthe faces adjacent to $F_1$ must have vertices $v_1, v_2, v_4$;\n$v_1, v_3, v_4$; and $v_2, v_3, v_4$. Thus $v_1, v_2, v_3, v_4$ form\na polyhedron by themselves, contradicting the fact that the given\npolyhedron is connected and has at least five vertices.\n(One can also deduce this using Euler's formula\n$V - E + F = 2 - 2g$, where $V,E,F$ are the numbers of vertices,\nedges and faces, respectively, and $g$ is the genus of the polyhedron.\nFor a convex polyhedron, $g=0$ and you get the ``usual'' Euler's formula.)\n\nNote: Walter Stromquist points out the following counterexample if\none relaxes the assumption that a pair of faces may not share multiple\nedges. Take a tetrahedron and remove a smaller tetrahedron from the\ncenter of an edge; this creates two small triangular faces and turns two\nof the original faces into hexagons. Then the second player can draw\nby signing one of the hexagons, one of the large triangles, and one\nof the small triangles. (He does this by ``mirroring'': wherever the first\nplayer signs, the second player signs the other face of the same type.)"
  },
  {
    "year": 2002,
    "label": "B3",
    "difficulty": "3",
    "problem": "Show that, for all integers $n > 1$,\n\\[\n\\frac{1}{2ne} < \\frac{1}{e} - \\left( 1 - \\frac{1}{n} \\right)^n\n< \\frac{1}{ne}.\n\\]",
    "solution": "The desired inequalities can be rewritten as\n\\[\n1 - \\frac{1}{n} < \\exp\\left( 1 + n \\log \\left( 1 - \\frac{1}{n} \\right)\n\\right) < 1 - \\frac{1}{2n}.\n\\]\nBy taking logarithms, we can rewrite the desired inequalities as\n\\begin{align*}\n-\\log \\left( 1 - \\frac{1}{2n} \\right)\n&< -1 - n \\log \\left( 1 - \\frac{1}{n} \\right) \\\\\n&< -\\log \\left( 1 - \\frac{1}{n} \\right).\n\\end{align*}\nRewriting these in terms of the Taylor expansion of\n$-\\log(1-x)$, we see that the desired result is also equivalent\nto\n\\[\n\\sum_{i=1}^\\infty \\frac{1}{i 2^i n^i}\n< \\sum_{i=1}^\\infty \\frac{1}{(i+1) n^i}\n< \\sum_{i=1}^\\infty \\frac{1}{i n^i},\n\\]\nwhich is evident because the inequalities hold term by term.\n\nNote: David Savitt points out that the upper bound can be improved from\n$1/(ne)$ to $2/(3ne)$ with a slightly more complicated argument. (In\nfact, for any $c>1/2$, one has an upper bound of $c/(ne)$, but only\nfor $n$ above a certain bound depending on $c$.)"
  },
  {
    "year": 2002,
    "label": "B4",
    "difficulty": "4",
    "problem": "An integer $n$, unknown to you, has been randomly chosen in the\ninterval $[1, 2002]$ with uniform probability. Your objective is\nto select $n$ in an \\textbf{odd} number of guesses. After\neach incorrect guess, you are informed whether $n$ is higher\nor lower, and you \\textbf{must} guess an integer on your next turn\namong the numbers that are still feasibly correct. Show that you\nhave a strategy so that the chance of winning is greater than $2/3$.",
    "solution": "Use the following strategy: guess $1, 3, 4, 6, 7, 9, \\dots$\nuntil the target number $n$ is revealed to be equal to or lower than one\nof these guesses. If $n \\equiv 1 \\pmod{3}$, it will be guessed on an\nodd turn. If $n \\equiv 0 \\pmod{3}$, it will be guessed on an even turn.\nIf $n \\equiv 2 \\pmod{3}$, then $n+1$ will be guessed on an even turn,\nforcing a guess of $n$ on the next turn. Thus the probability\nof success with this strategy is $1335/2002 > 2/3$.\n\nNote: for any positive integer $m$, this strategy wins when the\nnumber is being guessed from $[1,m]$ with probability\n$\\frac{1}{m} \\lfloor \\frac{2m+1}{3} \\rfloor$. We can prove that\nthis is best possible as follows.\nLet $a_m$ denote $m$ times\nthe probability of winning when playing optimally.  Also, let $b_m$\ndenote $m$ times the corresponding probability of winning if the\nobjective is to select the number in an even number of guesses\ninstead.  (For definiteness, extend the definitions to incorporate\n$a_0 = 0$ and $b_0=0$.)\n\nWe first claim that $a_m = 1 + \\max_{1\\leq k\\leq m} \\{b_{k-1} +\nb_{m-k}\\}$ and $b_m = \\max_{1\\leq k\\leq m} \\{a_{k-1} + a_{m-k}\\}$ for $m\n\\geq 1$.  To establish the first recursive identity, suppose that our\nfirst guess is some integer $k$. We automatically win if $n=k$, with\nprobability $1/m$. If $n<k$, with probability $(k-1)/m$, then we wish\nto guess an integer in $[1,k-1]$ in an even number of guesses; the\nprobability of success when playing optimally is $b_{k-1}/(k-1)$, by\nassumption.  Similarly, if $n<k$, with probability $(m-k)/m$, then the\nsubsequent probability of winning is $b_{m-k}/(m-k)$.  In sum, the\noverall probability of winning if $k$ is our first guess is\n$(1+b_{k-1}+b_{m-k})/m$. For optimal strategy, we choose $k$ such that\nthis quantity is maximized. (Note that this argument still holds if\n$k=1$ or $k=m$, by our definitions of $a_0$ and $b_0$.)  The first\nrecursion follows, and the second recursion is established similarly.\n\nWe now prove by induction that $a_m = \\lfloor (2m+1)/3 \\rfloor$ and\n$b_m = \\lfloor 2m/3 \\rfloor$ for $m \\geq 0$. The inductive step relies\non the inequality $\\lfloor x \\rfloor + \\lfloor y \\rfloor \\leq \\lfloor\nx+y \\rfloor$, with equality when one of $x,y$ is an integer. Now\nsuppose that $a_i = \\lfloor (2i+1)/3 \\rfloor$ and\n$b_i = \\lfloor 2i/3 \\rfloor$ for $i < m$. Then\n\\begin{align*}\n1+b_{k-1}+b_{m-k} &= 1+\\left\\lfloor \\frac{2(k-1)}{3} \\right\\rfloor +\n\\left\\lfloor\n\\frac{2(m-k)}{3} \\right\\rfloor \\\\\n&\\leq \\left\\lfloor \\frac{2m}{3} \\right\\rfloor\n\\end{align*}\nand similarly $a_{k-1}+a_{m-k} \\leq \\lfloor (2m+1)/3 \\rfloor$, with\nequality in both cases attained, e.g., when $k=1$.\nThe inductive formula for $a_m$ and $b_m$ follows."
  },
  {
    "year": 2002,
    "label": "B5",
    "difficulty": "5",
    "problem": "A palindrome in base $b$ is a positive integer whose base-$b$\ndigits read the same backwards and forwards; for example,\n$2002$ is a 4-digit palindrome in base 10. Note that 200 is not\na palindrome in base 10, but it is the 3-digit palindrome\n242 in base 9, and 404 in base 7. Prove that there is an integer\nwhich is a 3-digit palindrome in base $b$ for at least 2002\ndifferent values of $b$.",
    "solution": "(due to Dan Bernstein)\nPut $N = 2002!$. Then for $d=1, \\dots, 2002$,\nthe number $N^2$ written in base $b = N/d - 1$ has digits\n$d^2, 2d^2, d^2$. (Note that these really are digits because\n$2(2002)^2 < (2002!)^2/2002 - 1$.)\n\nNote: one can also produce an integer $N$ which has base $b$\ndigits $1, *, 1$ for $n$ different values of $b$, as follows.\nChoose $c$ with $0 < c < 2^{1/n}$. For $m$ a large positive integer,\nput $N = 1 + (m+1)\\cdots (m+n)\\lfloor cm \\rfloor^{n-2}$.\nFor $m$ sufficiently large, the bases\n\\[\nb = \\frac{N-1}{(m+i)m^{n-2}} = \\prod_{j \\neq i} (m+j)\n\\]\nfor $i=1, \\dots, n$ will\nhave the properties that $N \\equiv 1 \\pmod{b}$ and $b^2 < N < 2b^2$\nfor $m$ sufficiently large.\n\nNote (due to Russ Mann):\none can also give a ``nonconstructive'' argument. Let $N$ be a\nlarge positive integer. For $b \\in (N^2, N^3)$, the number of 3-digit\nbase-$b$ palindromes in the range $[b^2, N^6 - 1]$ is at least\n\\[\n\\left\\lfloor \\frac{N^6 - b^2}{b} \\right\\rfloor - 1\n\\geq \\frac{N^6}{b^2} - b - 2,\n\\]\nsince there is a palindrome in each interval $[kb, (k+1)b-1]$ for\n$k=b, \\dots, b^2-1$. Thus the average number of bases for which\na number in $[1, N^6-1]$ is at least\n\\[\n\\frac{1}{N^6} \\sum_{b=N^2+1}^{N^3-1} \\left( \\frac{N^6}{b} - b-2 \\right)\n\\geq  \\log(N) - c\n\\]\nfor some constant $c>0$. Take $N$ so that the right side exceeds $2002$;\nthen at least one number in $[1, N^6-1]$ is a base-$b$ palindrome\nfor at least 2002 values of $b$."
  },
  {
    "year": 2002,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $p$ be a prime number. Prove that the determinant of the matrix\n\\[\n\\begin{pmatrix}\nx & y & z \\\\\nx^p & y^p & z^p \\\\\nx^{p^2} & y^{p^2} & z^{p^2}\n\\end{pmatrix}\n\\]\nis congruent modulo $p$ to a product of polynomials of the form\n$ax+by+cz$, where $a,b,c$ are integers. (We say two integer\npolynomials are congruent modulo $p$ if corresponding coefficients\nare congruent modulo $p$.)\n\n\\end{itemize}\n\\end{document}",
    "solution": "We prove that the determinant is congruent modulo $p$ to\n\\begin{equation} \\label{b6eq2}\nx \\prod_{i=0}^{p-1} (y+ix) \\prod_{i,j=0}^{p-1} (z + ix + jy).\n\\end{equation}\nWe first check that\n\\begin{equation} \\label{b6eq1}\n\\prod_{i=0}^{p-1} (y+ix) \\equiv y^p - x^{p-1} y \\pmod{p}.\n\\end{equation}\nSince both sides are homogeneous as polynomials in $x$ and $y$,\nit suffices to check \\eqref{b6eq1}\nfor $x=1$, as a congruence between polynomials. Now note that\nthe right side has $0,1,\\dots,p-1$ as roots modulo $p$, as does\nthe left side. Moreover, both sides have the same leading coefficient.\nSince they both have degree only $p$, they must then coincide.\n\nWe thus have\n\\begin{multline*}\nx \\prod_{i=0}^{p-1} (y+ix) \\prod_{i,j=0}^{p-1} (z + ix + jy) \\\\\n\\begin{aligned}\n&\\equiv x (y^p - x^{p-1}y) \\prod_{j=0}^{p-1} ((z+jy)^p - x^{p-1} (z+jy)) \\\\\n&\\equiv (xy^p - x^p y) \\prod_{j=0}^{p-1} (z^p - x^{p-1} z + j y^p - j x^{p-1}\ny) \\\\\n&\\equiv (xy^p - x^p y) ((z^p - x^{p-1} z)^p \\\\\n&\\quad - (y^p - x^{p-1}y)^{p-1}(z^p\n- x^{p-1}z)) \\\\\n &\\equiv (xy^p - x^p y)(z^{p^2} - x^{p^2 - p}z^p) \\\\\n&\\quad - x(y^p - x^{p-1}y)^p\n(z^p - x^{p-1}z) \\\\\n&\\equiv xy^p z^{p^2} - x^p y z^{p^2} - x^{p^2-p+1} y^p z^p\n+ x^{p^2} y z^p \\\\\n&\\quad - xy^{p^2}z^p + x^{p^2-p+1} y^p z^p\n+ x^py^{p^2}z - x^{p^2} y^p z \\\\\n&\\equiv x y^p z^{p^2} + y z^p x^{p^2} + z x^p y^{p^2} \\\\\n&\\quad\n- x z^p y^{p^2} - y x^p z^{p^2} - z y^p x^{p^2},\n\\end{aligned}\n\\end{multline*}\nwhich is precisely the desired determinant.\n\nNote: a simpler conceptual proof is as follows. (Everything in this\nparagraph will be modulo $p$.) Note that for any\nintegers $a,b,c$, the column vector $[ax + by + cz, (ax + by + cz)^p,\n(ax + by + cz)^{p^2}]$ is a linear combination of the columns of the\ngiven matrix. Thus $ax+by+cz$ divides the determinant.\nIn particular, all of the factors of \\eqref{b6eq2} divide the determinant;\nsince both \\eqref{b6eq2} and the determinant have degree $p^2+p+1$,\nthey agree up to a scalar multiple. Moreover, they have the same\ncoefficient of $z^{p^2} y^p x$ (since this term only appears in\nthe expansion of \\eqref{b6eq2} when you choose the first term in\neach factor). Thus the determinant is congruent to \\eqref{b6eq2}, as desired.\n\nEither argument can be used to generalize to a corresponding $n \\times n$\ndeterminant, called a Moore determinant;\nwe leave the precise formulation to the reader. Note\nthe similarity with the classical Vandermonde determinant: if\n$A$ is the $n \\times n$ matrix with $A_{ij} = x_i^j$ for\n$i,j=0, \\dots, n-1$, then\n\\[\n\\det(A) = \\prod_{1 \\leq i < j \\leq n} (x_j - x_i).\n\\]\n\n\\end{itemize}\n\n\\end{document}"
  },
  {
    "year": 2003,
    "label": "A1",
    "difficulty": "1",
    "problem": "Let $n$ be a fixed positive integer. How many ways are there to write  $n$\nas a sum of positive integers,  \n\\[\nn = a_1 + a_2 + \\cdots + a_k,\n\\]\nwith  $k$  an\narbitrary positive integer and  $a_1 \\le a_2 \\le \\cdots \\le a_k \\le a_1  + 1$?\nFor example, with $n=4$ there are four ways: 4, 2+2, 1+1+2, 1+1+1+1.",
    "solution": "There are $n$ such sums. More precisely, there is exactly one such sum\nwith $k$ terms for each of $k=1, \\dots, n$ (and clearly no others).\nTo see this, note that if $n = a_1 + a_2 + \\cdots + a_k$ with\n$a_1 \\leq a_2 \\leq \\cdots \\leq a_k \\leq a_1 + 1$, then\n\\begin{align*}\nka_1 &= a_1 + a_1 + \\cdots + a_1 \\\\\n&\\leq n \\leq a_1 + (a_1 + 1) + \\cdots + (a_1 + 1) \\\\\n&= ka_1 + k-1.\n\\end{align*}\nHowever, there is a unique integer $a_1$ satisfying these inequalities,\nnamely $a_1 = \\lfloor n/k \\rfloor$. Moreover, once $a_1$ is fixed,\nthere are $k$ different possibilities for the sum $a_1 + a_2 + \\cdots + a_k$:\nif $i$ is the last integer such that $a_i = a_1$, then the sum equals\n$ka_1 + (i-1)$. The possible values of $i$ are $1, \\dots, k$,\nand exactly one of these sums comes out equal to $n$, proving\nour claim.\n\n\\textbf{Note:}\nIn summary, there is a unique partition of $n$ with $k$ terms that is\n``as equally spaced as possible''.\nOne can also obtain essentially the same construction inductively: except\nfor the all-ones sum, each partition of $n$ is obtained by ``augmenting''\na unique partition of $n-1$."
  },
  {
    "year": 2003,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $a_1, a_2, \\dots, a_n$  and  $b_1, b_2, \\dots, b_n$\nbe nonnegative real numbers.\nShow that\n\\begin{align*}\n& (a_1 a_2 \\cdots a_n)^{1/n} + (b_1 b_2 \\cdots b_n)^{1/n} \\\\\n&\\leq [(a_1+b_1) (a_2+b_2) \\cdots (a_n + b_n) ]^{1/n}.\n\\end{align*}",
    "solution": "\\textbf{First solution:}\nAssume without loss of generality that $a_i + b_i > 0$\nfor each $i$ (otherwise both sides of the desired inequality are zero).\nThen the AM-GM inequality gives\n\\begin{multline*}\n\\left( \\frac{a_1\\cdots a_n}{(a_1+b_1)\\cdots(a_n+b_n)} \\right)^{1/n} \\\\\n\\leq \\frac{1}{n} \\left( \\frac{a_1}{a_1 + b_1} + \\cdots + \\frac{a_n}{a_n+b_n}\n\\right),\n\\end{multline*}\nand likewise with the roles of $a$ and $b$ reversed. Adding these two\ninequalities and clearing denominators yields the desired result.\n\n\\textbf{Second solution:}\nWrite the desired inequality in the form\n\\[\n(a_1 + b_1)\\cdots(a_n+b_n) \\geq\n[(a_1\\cdots a_n)^{1/n} + (b_1\\cdots b_n)^{1/n}]^n,\n\\]\nexpand both sides, and compare the terms on both sides\nin which $k$ of the terms are among the $a_i$. On the left,\none has the product of each $k$-element subset of $\\{1, \\dots, n\\}$;\non the right, one has\n\\[\n\\binom{n}{k} (a_1\\cdots a_n)^{k/n} \\cdots (b_1 \\dots b_n)^{(n-k)/n},\n\\]\nwhich is precisely $\\binom{n}{k}$ times the geometric mean of the terms\non the left.  Thus AM-GM shows that the terms under consideration on the\nleft exceed those on the right; adding these inequalities over all $k$\nyields the desired result.\n\n\\textbf{Third solution:}\nSince both sides are continuous in each $a_i$, it is sufficient to\nprove the claim with $a_1, \\dots, a_n$ all positive (the general case\nfollows by taking limits as some of the $a_i$ tend to zero).\nPut $r_i = b_i/a_i$; then the given inequality is equivalent to\n\\[\n(1 + r_1)^{1/n} \\cdots (1+r_n)^{1/n} \\geq 1 + (r_1\\cdots r_n)^{1/n}.\n\\]\nIn terms of the function\n\\[\nf(x) = \\log(1 + e^x)\n\\]\nand the quantities $s_i = \\log r_i$,\nwe can rewrite the desired inequality as\n\\[\n\\frac{1}{n}(f(s_1) + \\cdots + f(s_n)) \\geq f\\left( \\frac{s_1 + \\cdots +\ns_n}{n} \\right).\n\\]\nThis will follow from Jensen's inequality if we can verify that $f$\nis a convex function; it is enough to check that $f''(x) > 0$ for all $x$.\nIn fact,\n\\[\nf'(x) = \\frac{e^x}{1+e^x} = 1 - \\frac{1}{1+e^x}\n\\]\nis an increasing function of $x$, so $f''(x) > 0$ and Jensen's inequality\nthus yields the desired result. (As long as the $a_i$ are all positive,\nequality holds when $s_1 = \\cdots = s_n$, i.e., when the vectors\n$(a_1, \\dots, a_n)$ and $(b_1, \\dots, b_n)$. Of course other equality\ncases crop up if some of the $a_i$ vanish, i.e., if $a_1=b_1=0$.)\n\n\\textbf{Fourth solution:}\nWe apply induction on $n$, the case $n=1$ being evident.\nFirst we verify the auxiliary inequality\n\\[\n(a^n + b^n)(c^n + d^n)^{n-1} \\geq (ac^{n-1} + b d^{n-1})^n\n\\]\nfor $a,b,c,d \\geq 0$.\nThe left side can be written as\n\\begin{align*}\na^n c^{n(n-1)} &+ b^n d^{n(n-1)} \\\\\n&+ \\sum_{i=1}^{n-1} \\binom{n-1}{i} b^n c^{ni} d^{n(n-1-i)} \\\\\n&+ \\sum_{i=1}^{n-1} \\binom{n-1}{i-1} a^n c^{n(i-1)} d^{n(n-i)}.\n\\end{align*}\nApplying the weighted AM-GM inequality between matching terms in the two\nsums yields\n\\begin{multline*}\n(a^n + b^n)(c^n + d^n)^{n-1} \\geq a^n c^{n(n-1)} + b^n d^{n(n-1)} \\\\\n+ \\sum_{i=1}^{n-1} \\binom{n}{i} a^i b^{n-i} c^{(n-1)i} d^{(n-1)(n-i)},\n\\end{multline*}\nproving the auxiliary inequality.\n\nNow given the auxiliary inequality and the $n-1$ case of the desired\ninequality, we apply the auxiliary inequality with $a = a_1^{1/n}$,\n$b = b_1^{1/n}$, $c = (a_2 \\cdots a_n)^{1/n(n-1)}$,\n$d = (b_2 \\dots b_n)^{1/n(n-1)}$. The right side will be the $n$-th\npower of the desired inequality. The left side comes out to\n\\[\n(a_1 + b_1)((a_2 \\cdots a_n)^{1/(n-1)} + (b_2 \\cdots b_n)^{1/(n-1)})^{n-1},\n\\]\nand by the induction hypothesis, the second factor is less than\n$(a_2 + b_2)\\cdots(a_n+b_n)$. This yields the desired result.\n\n\\textbf{Note:}\nEquality holds if and only if $a_i=b_i=0$ for some $i$ or if the vectors\n$(a_1, \\dots, a_n)$ and $(b_1, \\dots, b_n)$ are proportional.\nAs pointed out by Naoki Sato, the problem also appeared on the 1992\nIrish Mathematical Olympiad.\nIt is also a special case of a classical inequality,\nknown as H\\\"older's inequality, which generalizes the\nCauchy-Schwarz inequality (this is visible from the $n=2$ case); the\nfirst solution above is adapted from the standard proof of H\\\"older's\ninequality.\nWe don't know whether the declaration\n``Apply H\\\"older's inequality'' by itself is considered\nan acceptable solution to this problem."
  },
  {
    "year": 2003,
    "label": "A3",
    "difficulty": "3",
    "problem": "Find the minimum value of\n\\[\n  | \\sin x + \\cos x + \\tan x + \\cot x + \\sec x + \\csc x |\n\\]\nfor real numbers  $x$.",
    "solution": "\\textbf{First solution:}\nWrite\n\\begin{align*}\nf(x) &= \\sin x + \\cos x + \\tan x + \\cot x + \\sec x + \\csc x \\\\\n&= \\sin x + \\cos x + \\frac{1}{\\sin x \\cos x} + \\frac{\\sin x + \\cos x}{\\sin x\n\\cos x}.\n\\end{align*}\nWe can write $\\sin x + \\cos x = \\sqrt{2} \\cos(\\pi/4 - x)$; this suggests\nmaking the substitution $y = \\pi/4 - x$. In this new coordinate,\n\\[\n\\sin x \\cos x = \\frac{1}{2} \\sin 2x = \\frac{1}{2} \\cos 2y,\n\\]\nand writing $c = \\sqrt{2} \\cos y$, we have\n\\begin{align*}\nf(y) &= (1 + c)\\left(1 + \\frac{2}{c^2 -1} \\right) - 1 \\\\\n&= c + \\frac{2}{c - 1}.\n\\end{align*}\nWe must analyze this function of $c$ in the range $[-\\sqrt{2}, \\sqrt{2}]$.\nIts value at $c=-\\sqrt{2}$ is $2 - 3\\sqrt{2} < -2.24$, and at\n$c = \\sqrt{2}$ is $2 + 3\\sqrt{2}>6.24$.\nIts derivative is $1 - 2/(c-1)^2$, which vanishes when\n$(c-1)^2 = 2$, i.e., where $c = 1 \\pm \\sqrt{2}$. Only the value\n$c = 1 - \\sqrt{2}$ is in bounds, at which\nthe value of $f$ is $1-2\\sqrt{2} > -1.83$. As for the pole at $c=1$,\nwe observe that $f$ decreases as $c$ approaches from below\n(so takes negative values for all $c<1$) and increases as $c$\napproaches from above (so takes positive values for all $c>1$); from\nthe data collected so far, we see that $f$ has no sign crossings, so\nthe minimum of $|f|$ is achieved at a critical point of $f$.\nWe conclude that the minimum of $|f|$ is $2 \\sqrt{2} - 1$.\n\nAlternate derivation (due to Zuming Feng): We can also minimize $|c + 2/(c-1)|$\nwithout calculus (or worrying about boundary conditions). For $c>1$, we have\n\\[\n1 + (c-1) + \\frac{2}{c-1} \\geq 1 + 2 \\sqrt{2}\n\\]\nby AM-GM on the last two terms, with equality for $c-1 = \\sqrt{2}$\n(which is out of range).\nFor $c<1$, we similarly have\n\\[\n-1 + 1-c + \\frac{2}{1-c} \\geq -1 + 2\\sqrt{2},\n\\]\nhere with equality for $1-c = \\sqrt{2}$.\n\n\\textbf{Second solution:}\nWrite\n\\[\nf(a,b) = a+b + \\frac{1}{ab} + \\frac{a+b}{ab}.\n\\]\nThen the problem is to minimize $|f(a,b)|$ subject to the constraint\n$a^2+b^2-1 = 0$. Since the constraint region has no boundary, it is\nenough to check the value at each critical point and each potential\ndiscontinuity (i.e., where $ab=0$) and select the smallest value\n(after checking that $f$ has no sign crossings).\n\nWe locate the critical points using the Lagrange multiplier condition:\nthe gradient of $f$ should be parallel to that of the constraint, which is\nto say, to the vector $(a,b)$. Since\n\\[\n\\frac{\\partial f}{\\partial a}\n= 1 - \\frac{1}{a^2 b} - \\frac{1}{a^2}\n\\]\nand similarly for $b$, the proportionality yields\n\\[\na^2 b^3 - a^3 b^2 + a^3 - b^3 + a^2 - b^2 = 0.\n\\]\nThe irreducible factors of the left side are $1+a$, $1+b$,\n$a-b$, and $ab-a-b$. So we must check what happens when any of\nthose factors, or $a$ or $b$, vanishes.\n\nIf $1+a = 0$, then $b=0$, and the singularity of $f$ becomes removable\nwhen restricted to the circle. Namely, we have\n\\[\nf = a + b + \\frac{1}{a} + \\frac{b+1}{ab}\n\\]\nand $a^2+b^2-1 = 0$ implies $(1+b)/a = a/(1-b)$. Thus we have\n$f = -2$; the same occurs when $1+b=0$.\n\nIf $a-b=0$, then $a=b=\\pm \\sqrt{2}/2$ and either\n$f = 2 + 3 \\sqrt{2} > 6.24$, or $f = 2 - 3 \\sqrt{2} < -2.24$.\n\nIf $a=0$, then either $b = -1$ as discussed above, or $b=1$. In the\nlatter case, $f$ blows up as one approaches this point, so there cannot\nbe a global minimum there.\n\nFinally, if $ab-a-b = 0$, then\n\\[\na^2b^2 = (a + b)^2 = 2ab + 1\n\\]\nand so $ab = 1 \\pm \\sqrt{2}$. The plus sign is impossible since\n$|ab| \\leq 1$, so $ab = 1 - \\sqrt{2}$ and\n\\begin{align*}\nf(a,b) &= ab + \\frac{1}{ab} + 1 \\\\\n&= 1 - 2 \\sqrt{2} > -1.83.\n\\end{align*}\nThis yields the smallest value of $|f|$ in the list (and indeed no sign\ncrossings are possible), so $2\\sqrt{2}-1$ is the desired minimum of $|f|$.\n\n\\textbf{Note:} Instead of using the geometry of the graph of $f$ to rule\nout sign crossings, one can verify explicitly that $f$ cannot\ntake the value 0. In the first solution, note that $c + 2/(c-1)=0$\nimplies $c^2 - c + 2 = 0$, which has no real roots.\nIn the second solution, we would have\n\\[\na^2 b + ab^2 + a + b =  -1.\n\\]\nSquaring both sides and simplifying yields\n\\[\n2a^3b^3 + 5a^2b^2 + 4ab = 0,\n\\]\nwhose only real root is $ab=0$. But the cases with $ab=0$ do not yield\n$f=0$, as verified above."
  },
  {
    "year": 2003,
    "label": "A4",
    "difficulty": "4",
    "problem": "Suppose that $a,b,c,A,B,C$  are real numbers, $a\\ne 0$ and $A \\ne 0$, such that\n\\[\n          | a x^2 + b x + c | \\leq | A x^2 + B x + C |\n\\]\nfor all real numbers  $x$. Show that\n\\[\n              | b^2 - 4 a c | \\leq | B^2 - 4 A C |.\n\\]",
    "solution": "We split into three cases.\nNote first that $|A| \\geq |a|$, by applying the condition for large $x$.\n\n\\textbf{Case 1: $B^2 - 4AC > 0$.}\nIn this case $Ax^2 + Bx + C$ has two distinct real roots $r_1$ and $r_2$.\nThe condition implies that $ax^2 + bx + c$ also vanishes at $r_1$ and $r_2$,\nso $b^2 - 4ac > 0$.\nNow\n\\begin{align*}\nB^2 - 4AC &= A^2(r_1-r_2)^2 \\\\\n&\\geq a^2(r_1 - r_2)^2 \\\\\n&= b^2 - 4ac.\n\\end{align*}\n\n\\textbf{Case 2: $B^2 - 4AC \\leq 0$ and $b^2 - 4ac \\leq 0$.}\nAssume without loss of generality that $A \\geq a > 0$, and that $B=0$\n(by shifting $x$). Then $Ax^2 + Bx + C \\geq ax^2 + bx + c \\geq 0$ for all $x$;\nin particular, $C \\geq c \\geq 0$. Thus\n\\begin{align*}\n4AC - B^2 &= 4AC \\\\\n&\\geq 4ac \\\\\n&\\geq 4ac - b^2.\n\\end{align*}\nAlternate derivation (due to Robin Chapman): the ellipse\n$Ax^2 + Bxy + Cy^2 = 1$ is contained within\nthe ellipse $ax^2 + bxy + cy^2 = 1$,\nand their respective enclosed areas are $\\pi/(4AC-B^2)$ and\n$\\pi/(4ac-b^2)$.\n\n\\textbf{Case 3: $B^2 - 4AC \\leq 0$ and $b^2 - 4ac > 0$.}\nSince $Ax^2 + Bx + C$ has a graph not crossing the $x$-axis,\nso do $(Ax^2 + Bx + C) \\pm (ax^2 + bx + c)$. Thus\n\\begin{gather*}\n(B-b)^2 - 4(A-a)(C-c) \\leq 0, \\\\\n(B+b)^2 - 4(A+a)(C+c) \\leq 0\n\\end{gather*}\nand adding these together yields\n\\[\n2(B^2 - 4AC) + 2(b^2 - 4ac) \\leq 0.\n\\]\nHence $b^2 - 4ac \\leq 4AC - B^2$, as desired."
  },
  {
    "year": 2003,
    "label": "A5",
    "difficulty": "5",
    "problem": "A Dyck $n$-path is a lattice path of  $n$  upsteps $(1,1)$ and  $n$\n  downsteps $(1,-1)$\nthat starts at the origin  $O$  and never dips below the  $x$-axis.\nA return is a maximal sequence of contiguous downsteps that terminates\non the  $x$-axis. For example, the Dyck 5-path illustrated has two returns,\nof length  3  and  1  respectively.\n\\begin{center}\n\\begin{tikzpicture}[scale=.5]\n\\fill (0,0) circle (.2); \\fill (1,1) circle (.2); \\fill (2,2) circle (.2);\n\\fill (3,1) circle (.2); \\fill (4,2) circle (.2); \\fill (5,3) circle (.2);\n\\fill (6,2) circle (.2); \\fill (7,1) circle (.2); \\fill (8,0) circle (.2);\n\\fill (9,1) circle (.2); \\fill (10,0) circle (.2);\n\\draw (0,0) -- (2,2) -- (3,1) -- (5,3) -- (8,0) -- (9,1) -- (10,0) -- cycle;\n\\draw (-.3,-.1) node[anchor=north] {$O$};\n\\end{tikzpicture}\n\\end{center}\nShow that there is a one-to-one correspondence between the Dyck  $n$-paths\nwith no return of even length and the Dyck $(n-1)$-paths.",
    "solution": "\\textbf{First solution:}\nWe represent a Dyck $n$-path by a sequence $a_1\\cdots a_{2n}$, where\neach $a_i$ is either $(1,1)$ or $(1,-1)$.\n\nGiven an $(n-1)$-path $P=a_1\\cdots a_{2n-2}$, we distinguish two cases.\nIf $P$ has no returns of even-length, then let $f(P)$ denote the $n$-path\n$(1,1)(1,-1)P$.  Otherwise, let $a_ia_{i+1}\\cdots a_{j}$ denote the\nrightmost even-length return in $P$, and let $f(P)=(1,1)a_1a_2\\cdots\na_j(1,-1)a_{j+1}\\cdots a_{2n-2}$.  Then $f$ clearly maps the set of Dyck\n$(n-1)$-paths to the set of Dyck $n$-paths having no even return.\n\nWe claim that $f$ is bijective; to see this, we simply construct the\ninverse mapping.  Given an $n$-path $P$, let $R=a_ia_{i+1}...a_j$\ndenote the leftmost return in $P$, and let $g(P)$ denote the\npath obtained by removing $a_1$ and $a_j$ from $P$.  Then evidently\n$f \\circ g$ and $g \\circ f$ are identity maps, proving the claim.\n\n\\textbf{Second solution:} (by Dan Bernstein)\nLet $C_n$ be the number of Dyck paths of length $n$, let $O_n$ be the number\nof Dyck paths whose final return has odd length, and let $X_n$ be the number\nof Dyck paths with no return of even length.\n\nWe first exhibit a recursion for $O_n$; note that $O_0 = 0$.\nGiven a Dyck $n$-path\nwhose final return has odd length, split it just after its next-to-last return.\nFor some $k$ (possibly zero), this yields\na Dyck $k$-path, an upstep, a Dyck $(n-k-1)$-path whose odd return\nhas even length, and a downstep. Thus for $n \\geq 1$,\n\\[\nO_n = \\sum_{k=0}^{n-1} C_k (C_{n-k-1} - O_{n-k-1}).\n\\]\n\nWe next exhibit a similar recursion for $X_n$; note that $X_0 = 1$.\nGiven a Dyck $n$-path with no even return,\nsplitting as above yields for some $k$\na Dyck $k$-path with no even return,\nan upstep, a Dyck $(n-k-1)$-path whose final return has even length,\nthen a downstep. Thus for $n \\geq 1$,\n\\[\nX_n = \\sum_{k=0}^{n-1} X_k (C_{n-k-1} - O_{n-k-1}).\n\\]\n\nTo conclude, we verify that $X_n = C_{n-1}$ for $n \\geq 1$,\nby induction on $n$. This is\nclear for $n=1$ since $X_1 = C_0 = 1$. Given $X_k = C_{k-1}$ for $k<n$, we have\n\\begin{align*}\nX_n  &=\n\\sum_{k=0}^{n-1} X_k (C_{n-k-1} - O_{n-k-1}) \\\\\n&= C_{n-1} - O_{n-1} + \\sum_{k=1}^{n-1} C_{k-1} (C_{n-k-1} - O_{n-k-1}) \\\\\n&= C_{n-1} - O_{n-1} + O_{n-1} \\\\\n&= C_{n-1},\n\\end{align*}\nas desired.\n\n\\textbf{Note:}\nSince the problem only asked about the \\emph{existence} of a\none-to-one correspondence, we believe that any proof, bijective or not,\nthat the two sets\nhave the same cardinality is an acceptable solution. (Indeed, it would be\nhighly unusual to insist on using or not using a specific proof technique!)\nThe second solution\nabove can also be phrased in terms of generating functions.\nAlso, the $C_n$ are well-known to equal the Catalan numbers\n$\\frac{1}{n+1} \\binom{2n}{n}$; the problem at hand is part of a famous\nexercise in Richard Stanley's \\textit{Enumerative Combinatorics, Volume 1}\ngiving 66 combinatorial interpretations of the Catalan numbers."
  },
  {
    "year": 2003,
    "label": "A6",
    "difficulty": "6",
    "problem": "For a set  $S$  of nonnegative integers, let  $r_S(n)$  denote the number of\nordered pairs  $(s_1, s_2)$  such that  $s_1 \\in S$, $s_2 \\in S$, $s_1 \\ne\ns_2$,\nand  $s_1 + s_2 = n$.  Is it possible to partition the nonnegative\nintegers into two sets  $A$  and  $B$  in such a way that  $r_A(n) = r_B(n)$\nfor all  $n$ ?",
    "solution": "\\textbf{First solution:} Yes, such a partition is possible. To achieve it,\nplace each integer into $A$ if it has an even number of 1s in its binary\nrepresentation, and into $B$ if it has an odd number. (One discovers this\nby simply attempting to place the first few numbers by hand and noticing\nthe resulting pattern.)\n\nTo show that $r_A(n) = r_B(n)$, we exhibit a bijection between the pairs\n$(a_1, a_2)$ of distinct elements of $A$ with $a_1 + a_2 = n$ and the\npairs $(b_1, b_2)$ of distinct elements of $B$ with $b_1 + b_2 = n$.\nNamely, given a pair $(a_1, a_2)$ with $a_1+a_2 = n$, write both numbers\nin binary and find the lowest-order place in which they differ (such a\nplace exists because $a_1 \\neq a_2$). Change both numbers in that place\nand call the resulting numbers $b_1, b_2$. Then $a_1 + a_2 = b_1 + b_2 =\nn$, but the parity of the number of 1s in $b_1$ is opposite that of $a_1$,\nand likewise between $b_2$ and $a_2$. This yields the desired bijection.\n\n\\textbf{Second solution:} (by Micah Smukler)\nWrite $b(n)$ for the number of 1s in the base 2 expansion of $n$,\nand $f(n) = (-1)^{b(n)}$.\nThen\nthe desired partition can be described as $A = f^{-1}(1)$ and $B = f^{-1}(-1)$.\nSince $f(2n) + f(2n+1) = 0$, we have\n\\[\n\\sum_{i=0}^n f(n) = \\begin{cases} 0 & \\mbox{$n$ odd} \\\\\nf(n) & \\mbox{$n$ even.} \\end{cases}\n\\]\nIf $p,q$ are both in $A$, then $f(p) + f(q) = 2$;\nif $p,q$ are both in $B$, then $f(p) + f(q) = -2$; if $p,q$ are\nin different sets, then $f(p) + f(q) = 0$. In other words,\n\\[\n2(r_A(n) - r_B(n)) = \\sum_{p+q=n,p < q} (f(p) + f(q))\n\\]\nand it suffices to show that the sum on the right is always zero.\nIf $n$ is odd, that sum is visibly $\\sum_{i=0}^n f(i) = 0$.\nIf $n$ is even, the sum equals\n\\[\n\\left(\\sum_{i=0}^n f(i) \\right) - f(n/2) = f(n) - f(n/2) = 0.\n\\]\nThis yields the desired result.\n\n\\textbf{Third solution:} (by Dan Bernstein)\nPut $f(x) = \\sum_{n \\in A} x^n$ and $g(x) = \\sum_{n \\in B} x^n$; then\nthe value of $r_A(n)$ (resp.\\ $r_B(n)$) is the coefficient of $x^n$\nin $f(x)^2 - f(x^2)$ (resp.\\ $g(x)^2 - g(x^2)$). From the evident identities\n\\begin{align*}\n\\frac{1}{1-x} &= f(x) + g(x) \\\\\nf(x) &= f(x^2) + xg(x^2) \\\\\ng(x) &= g(x^2) + xf(x^2),\n\\end{align*}\nwe have\n\\begin{align*}\nf(x) - g(x) &= f(x^2) - g(x^2) + xg(x^2) - xf(x^2) \\\\\n&= (1-x)(f(x^2) - g(x^2)) \\\\\n&= \\frac{f(x^2) - g(x^2)}{f(x) + g(x)}.\n\\end{align*}\nWe deduce that $f(x)^2 - g(x)^2 = f(x^2) - g(x^2)$, yielding the desired\nequality.\n\n\\textbf{Note:}\nThis partition is actually unique, up to interchanging $A$ and $B$.\nMore precisely, the condition that $0 \\in A$ and $r_A(n) = r_B(n)$ for\n$n=1, \\dots, m$ uniquely determines the positions of $0, \\dots, m$. We\nsee this by induction on $m$: given the result for $m-1$, switching the\nlocation of $m$ changes $r_A(m)$ by one and does not change $r_B(m)$, so\nit is not possible for both positions to work.  Robin Chapman points out\nthis problem is solved in D.J. Newman's \\textit{Analytic Number Theory}\n(Springer, 1998); in that solution, one uses generating functions to find\nthe partition and establish its uniqueness, not just verify it."
  },
  {
    "year": 2003,
    "label": "B1",
    "difficulty": "1",
    "problem": "Do there exist polynomials  $a(x), b(x), c(y), d(y)$  such that\n\\[\n       1 + x y + x^2 y^2 = a(x) c(y) + b(x) d(y)\n\\]\nholds identically?",
    "solution": "No, there do not.\n\n\\textbf{First solution:}\nSuppose the contrary.  By setting $y=-1,0,1$ in succession, we see that\nthe polynomials $1-x+x^2, 1, 1+x+x^2$ are linear combinations of $a(x)$\nand $b(x)$.  But these three polynomials are linearly independent, so\ncannot all be written as linear combinations of two other polynomials,\ncontradiction.\n\nAlternate formulation: the given equation expresses a diagonal matrix with\n$1,1,1$ and zeroes on the diagonal, which has rank 3, as the sum of two\nmatrices of rank 1. But the rank of a sum of matrices is at most the sum\nof the ranks of the individual matrices.\n\n\\textbf{Second solution:}\nIt is equivalent (by relabeling and rescaling)\nto show that $1 + xy + x^2y^2$ cannot be written\nas $a(x) d(y) - b(x) c(y)$.\nWrite $a(x) = \\sum a_i x^i$,\n$b(x) = \\sum b_i x^i$, $c(y) = \\sum c_j y^j$,\n$d(y) = \\sum d_j y^j$. We now start comparing coefficients\nof $1 + xy + x^2 y^2$. By comparing coefficients of\n$1+xy + x^2y^2 $ and $a(x)d(y) - b(x)c(y)$, we get\n\\begin{align*}\n1 &= a_id_i - b_i c_i \\qquad (i=0,1,2)\\\\\n0 &= a_id_j - b_i c_j \\qquad (i \\neq j).\n\\end{align*}\nThe first equation says that $a_i$ and $b_i$ cannot both vanish,\nand $c_i$ and $d_i$ cannot both vanish. The second equation says that\n$a_i/b_i = c_j/d_j$ when $i \\neq j$, where both sides should be viewed\nin $\\RR \\cup \\{\\infty\\}$ (and neither is undetermined if\n$i,j \\in \\{0,1,2\\}$). But then\n\\[\na_0/b_0 = c_1/d_1 = a_2/b_2 = c_0/d_0\n\\]\ncontradicting the equation $a_0d_0 - b_0c_0 = 1$.\n\n\\textbf{Third solution:}\nWe work over the complex numbers, in which we have a primitive cube root\n$\\omega$ of 1. We also use without further comment unique factorization\nfor polynomials in two variables over a field.  And we keep the relabeling\nof the second solution.\n\nSuppose the contrary.  Since $1+xy+x^2y^2 = (1 - xy/\\omega)(1 -\nxy/\\omega^2)$, the rational function $a(\\omega/y) d(y) - b(\\omega/y) c(y)$\nmust vanish identically (that is, coefficient by coefficient).  If one of\nthe polynomials, say $a$, vanished identically, then one of $b$ or $c$\nwould also, and the desired inequality could not hold. So none of them\nvanish identically, and we can write\n\\[\n\\frac{c(y)}{d(y)} = \\frac{a(\\omega/y)}{b(\\omega/y)}.\n\\]\nLikewise,\n\\[\n\\frac{c(y)}{d(y)}= \\frac{a(\\omega^2/y)}{b(\\omega^2/y)}.\n\\]\nPut $f(x) = a(x)/b(x)$; then we have $f(\\omega x) = f(x)$ identically. That is,\n$a(x) b(\\omega x) = b(x) a(\\omega x)$. Since $a$ and $b$ have no common\nfactor (otherwise $1+xy+x^2y^2$ would have a factor divisible only by\n$x$, which it doesn't since it doesn't vanish identically for any particular\n$x$), $a(x)$ divides $a(\\omega x)$. Since they have the same degree, they\nare equal up to scalars. It follows that one of $a(x), xa(x), x^2a(x)$\nis a polynomial in $x^3$ alone, and likewise for $b$ (with the same\npower of $x$).\n\nIf $xa(x)$ and $xb(x)$, or $x^2 a(x)$ and $x^2 b(x)$, are polynomials in\n$x^3$, then $a$ and $b$ are divisible by $x$, but we know $a$ and $b$ have no\ncommon factor. Hence $a(x)$ and $b(x)$ are polynomials in $x^3$. Likewise,\n$c(y)$ and $d(y)$ are polynomials in $y^3$. But then $1 + xy + x^2 y^2 =\na(x)d(y) - b(x) c(y)$ is a polynomial in $x^3$ and $y^3$, contradiction.\n\n\\textbf{Note:}\nThe third solution only works over fields of characteristic not equal to 3,\nwhereas the other two work over arbitrary fields. (In the first solution,\none must replace $-1$ by another value if working in characteristic 2.)"
  },
  {
    "year": 2003,
    "label": "B2",
    "difficulty": "2",
    "problem": "Let  $n$  be a positive integer. Starting with the sequence\n$1, \\frac{1}{2}, \\frac{1}{3}, \\dots, \\frac{1}{n}$,\nform a new sequence of  $n-1$  entries\n$\\frac{3}{4}, \\frac{5}{12}, \\dots, \\frac{2n-1}{2n(n-1)}$\nby taking the averages of\ntwo consecutive entries in the first sequence. Repeat the\naveraging of neighbors on the second sequence to obtain a third\nsequence of  $n-2$  entries, and continue until the final sequence produced\nconsists of a single number  $x_n$.  Show that  $x_n < 2/n$.",
    "solution": "It is easy to see by induction that the $j$-th entry of the $k$-th\nsequence (where the original sequence is $k=1$) is\n$\\sum_{i=1}^k \\binom{k-1}{i-1}/(2^{k-1} (i+j-1))$, and so\n$x_n = \\frac{1}{2^{n-1}} \\sum_{i=1}^n \\binom{n-1}{i-1}/i$.\nNow $\\binom{n-1}{i-1}/i = \\binom{n}{i}/n$; hence\n\\[\nx_n = \\frac{1}{n2^{n-1}} \\sum_{i=1}^n \\binom{n}{i}\n= \\frac{2^n-1}{n 2^{n-1}} < 2/n,\n\\]\nas desired."
  },
  {
    "year": 2003,
    "label": "B3",
    "difficulty": "3",
    "problem": "Show that for each positive integer  n,\n\\[\n    n! = \\prod_{i=1}^n  \\mathrm{lcm}\\{1, 2, \\dots, \\lfloor n/i\\rfloor\\} .\n\\]\n(Here $\\mathrm{lcm}$ denotes the least common multiple, and\n$\\lfloor x \\rfloor$ denotes the greatest integer $\\leq x$.)",
    "solution": "\\textbf{First solution:}\nIt is enough to show that for each prime $p$, the exponent of $p$ in\nthe prime factorization of both sides is the same.\nOn the left side, it is well-known that the exponent of $p$ in the\nprime factorization of $n!$ is\n\\[\n\\sum_{i =1}^n \\left\\lfloor \\frac{n}{p^i} \\right\\rfloor.\n\\]\n(To see this, note that the $i$-th term counts the multiples of $p^i$ among\n$1, \\dots, n$, so that a number divisible exactly by $p^i$ gets counted\nexactly $i$ times.)  This number can be reinterpreted as the cardinality\nof the set $S$ of points in the plane with positive integer coordinates\nlying on or under the curve $y = np^{-x}$: namely, each summand is the\nnumber of points of $S$ with $x=i$.\n\nOn the right side, the exponent of $p$ in the prime factorization of $\\lcm(1,\n\\dots, \\lfloor n/i \\rfloor)$ is $\\lfloor \\log_p \\lfloor n/i \\rfloor \\rfloor\n= \\lfloor \\log_p (n/i) \\rfloor$.  However, this is precisely the number\nof points of $S$ with $y=i$. Thus\n\\[\n\\sum_{i=1}^n\n\\lfloor \\log_p \\lfloor n/i \\rfloor \\rfloor\n= \\sum_{i =1}^n \\left\\lfloor \\frac{n}{p^i} \\right\\rfloor,\n\\]\nand the desired result follows.\n\n\\textbf{Second solution:}\nWe prove the result by induction on $n$, the case $n=1$ being obvious.\nWhat we actually show is that going from $n-1$ to $n$ changes both\nsides by the same multiplicative factor, that is,\n\\[\nn = \\prod_{i=1}^{n-1} \\frac{\\lcm\\{1, 2, \\dots, \\lfloor n/i \\rfloor\\}}{\\lcm\n\\{1, 2, \\dots, \\lfloor (n-1)/i \\rfloor\\}}.\n\\]\nNote that the $i$-th term in the product is equal to 1 if $n/i$ is not\nan integer, i.e., if $n/i$ is not a divisor of $n$.\nIt is also equal to 1 if $n/i$ is a divisor of $n$ but not a prime power,\nsince any composite number divides the lcm of all smaller numbers.\nHowever, if $n/i$ is a power of $p$, then the $i$-th term is equal to $p$.\n\nSince $n/i$ runs over all proper divisors of $n$, the product on the right\nside includes one factor of the prime $p$\nfor each factor of $p$ in the prime factorization of $n$. Thus the whole\nproduct is indeed equal to $n$, completing the induction."
  },
  {
    "year": 2003,
    "label": "B4",
    "difficulty": "4",
    "problem": "Let $f(z) = a z^4 + b z^3 + c z^2 + d z + e = a(z-r_1)(z-r_2)(z-r_3)(z-r_4)$\nwhere  $a,b,c,d,e$  are integers, $a \\ne 0$.  Show that if  $r_1 + r_2$  is a\nrational number and $r_1 + r_2 \\ne r_3 + r_4$,  then  $r_1 r_2$  is a\nrational number.",
    "solution": "\\textbf{First solution:}\nPut $g = r_1 + r_2$, $h = r_3 + r_4$, $u = r_1r_2$, $v = r_3r_4$.\nWe are given that $g$ is rational. The following are also rational:\n\\begin{align*}\n\\frac{-b}{a} &= g+h \\\\\n\\frac{c}{a} &= gh + u + v \\\\\n\\frac{-d}{a} &= gv + hu\n\\end{align*}\nFrom the first line, $h$ is rational. From the second line, $u+v$\nis rational. From the third line, $g(u+v) - (gv+hu) =\n(g-h)u$ is rational. Since $g \\neq h$, $u$ is rational, as desired.\n\n\\textbf{Second solution:} This solution uses some basic\nGalois theory. We may assume $r_1 \\neq r_2$, since otherwise they are both\nrational and so then is $r_1r_2$.\n\nLet $\\tau$ be an automorphism of the field of algebraic numbers; then $\\tau$\nmaps each $r_i$ to another one, and fixes the rational number $r_1 + r_2$.\nIf $\\tau(r_1)$ equals one of $r_1$ or $r_2$, then $\\tau(r_2)$ must equal\nthe other one, and vice versa.  Thus $\\tau$ either fixes the set $\\{r_1,\nr_2\\}$ or moves it to $\\{r_3, r_4\\}$. But if the latter happened, we would\nhave $r_1 +r_2 = r_3+r_4$, contrary to hypothesis.  Thus $\\tau$ fixes the\nset $\\{r_1, r_2\\}$ and in particular the number $r_1r_2$. Since this is\ntrue for any $\\tau$, $r_1r_2$ must be rational.\n\n\\textbf{Note:} The conclusion fails if we allow\n$r_1 + r_2 = r_3 + r_4$. For\ninstance, take the polynomial $x^4 - 2$ and label its roots so that\n$(x-r_1)(x-r_2) = x^2 - \\sqrt{2}$ and\n$(x-r_3)(x-r_4) = x^2 + \\sqrt{2}$."
  },
  {
    "year": 2003,
    "label": "B5",
    "difficulty": "5",
    "problem": "Let  $A,B$, and $C$  be equidistant points on the circumference of a circle\nof unit radius centered at  $O$,  and let  $P$  be any point in the circle's\ninterior.  Let  $a, b, c$  be the distance from  $P$  to $A, B, C$,\nrespectively.\nShow that there is a triangle with side lengths  $a, b, c$,  and that the\narea of this triangle depends only on the distance from  $P$  to  $O$.",
    "solution": "\\textbf{First solution:}\nPlace the unit circle on the complex plane so that $A,B,C$ correspond\nto the complex numbers $1,\\omega,\\omega^2$, where\n$\\omega=e^{2\\pi i/3}$, and let $P$ correspond to the complex number\n$x$. The distances $a,b,c$ are then $|x-1|,|x-\\omega|,|x-\\omega^2|$.\nNow the identity\n\\[\n(x-1) + \\omega(x-\\omega) + \\omega^2(x-\\omega^2) = 0\n\\]\nimplies that there is a triangle whose sides, as vectors, correspond\nto the complex numbers $x-1, \\omega(x-\\omega), \\omega^2(x-\\omega^2)$;\nthis triangle has sides of length $a,b,c$.\n\nTo calculate the area of this triangle, we first note a more general\nformula. If a triangle in the plane has vertices at $0$,\n$v_1=s_1+it_1$, $v_2=s_2+it_2$, then it is well known that the area\nof the triangle is $|s_1t_2-s_2t_1|/2 = |v_1\\overline{v_2}-\nv_2\\overline{v_1}|/4$. In our case, we have $v_1 = x-1$\nand $v_2 = \\omega(x-\\omega)$; then\n\\[\nv_1\\overline{v_2} - v_2\\overline{v_1}\n= (\\omega^2-\\omega)(x\\overline{x}-1)\n= i\\sqrt{3}(|x|^2-1).\n\\]\nHence the area of the triangle is $\\sqrt{3}(1-|x|^2)/4$, which depends\nonly on the distance $|x|$ from $P$ to $O$.\n\n\\textbf{Second solution:} (by Florian Herzig)\nLet $A'$, $B'$, $C'$ be the points obtained by intersecting the lines\n$AP$, $BP$, $CP$ with the unit circle. Let $d$ denote $OP$. Then $A'P =\n(1-d^2)/a$, etc., by using the power of the point $P$. As triangles $A'B'P$\nand $BAP$ are similar, we get that $A'B' = AB \\cdot A'P/b = \\sqrt 3\n(1-d^2)/(ab)$. It follows that triangle $A'B'C'$ has sides proportional\nto $a$, $b$, $c$, by a factor of $\\sqrt 3 (1-d^2)/(abc)$. In particular,\nthere is a triangle with sides $a$, $b$, $c$, and it has circumradius $R =\n(abc)/(\\sqrt 3 (1-d^2))$. Its area is $abc/(4R) = \\sqrt 3 (1-d^2)/4$.\n\n\\textbf{Third solution:} (by Samuel Li)\nConsider the rotation by the angle $\\pi/3$ around $A$ carrying $B$ to $C$, and let $P_A$ be the image of $P$;\ndefine $P_B, P_C$ similarly.\nLet $A'$ be the intersection of the tangents to the circle at $B, C$; define $B', C'$, similarly.\nPut $\\ell = AB = BC = CA$; we then have\n\\begin{gather*}\nAB' = AC' = BC' = BA' = CA' = CB' = \\ell \\\\\nPA = PP_A = P_A A = P_B C' = P_C A' = a \\\\\nPB = PP_B = P_B B = P_C A' = P_A C' = b \\\\\nPC = PP_C = P_C C = P_A B' = P_B A' = c.\n\\end{gather*}\n\nThe triangle $\\triangle A'B'C'$ has area four times that of $\\triangle ABC$.\nWe may dissect it into twelve triangles by first splitting it into three quadrilaterals $PAC'B$, $PBC'A, PCA'B$, then splitting each of these in four around the respective interior points $P_B, P_C, P_A$. \nOf the resulting twelve triangles, three have side lengths $a,b,c$, while three are equilateral triangles\nof respective sides lengths $a,b,c$. The other six are isomorphic to two copies each of\n$\\triangle PAB, \\triangle PBC, \\triangle PCA$, so their total area is twice that of $\\triangle ABC$.\n\nIt thus suffices to compute $a^2 + b^2 + c^2$ in terms of the radius of the circle and the distance $OP$.\nThis can be done readily in terms of\n$OP$ using vectors, Cartesian coordinates, or complex numbers as in the first solution."
  },
  {
    "year": 2003,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let  $f(x)$  be  a continuous real-valued function defined on the interval\n$[0,1]$. Show that\n\\[\n   \\int_0^1 \\int_0^1 | f(x) + f(y) |\\,dx\\,dy \\geq \\int_0^1 |f(x)|\\,dx.\n\\]\n\n\\end{itemize}\n\\end{document}",
    "solution": "\\textbf{First solution:} (composite of solutions by Feng Xie and David\nPritchard)\nLet $\\mu$ denote Lebesgue measure on $[0,1]$. Define\n\\begin{align*}\nE_+ &= \\{x \\in [0,1]: f(x) \\geq 0\\} \\\\\nE_- &= \\{x \\in [0,1]: f(x) < 0\\};\n\\end{align*}\nthen $E_+$, $E_-$ are measurable and $\\mu(E_+) + \\mu(E_-) = 1$.\nWrite $\\mu_+$ and $\\mu_-$ for $\\mu(E_+)$ and $\\mu(E_-)$.\nAlso define\n\\begin{align*}\nI_+ &= \\int_{E_+} |f(x)|\\,dx \\\\\nI_- &= \\int_{E_-} |f(x)|\\,dx,\n\\end{align*}\nso that $\\int_0^1 |f(x)|\\,dx = I_+ + I_-$.\n\nFrom the triangle inequality $|a+b| \\geq \\pm(|a| - |b|)$,\nwe have the inequality\n\\begin{align*}\n&\\iint_{E_+ \\times E_-} |f(x) + f(y)|\\,dx\\,dy \\\\\n&\\geq\n\\pm \\iint_{E_+ \\times E_-} (|f(x)| - |f(y)|)\\,dx\\,dy \\\\\n&= \\pm ( \\mu_- I_+ - \\mu_+ I_-),\n\\end{align*}\nand likewise with $+$ and $-$ switched. Adding these inequalities together\nand allowing all possible choices of the signs, we get\n\\begin{align*}\n&\\iint_{(E_+ \\times E_-) \\cup (E_- \\times E_+)} |f(x) + f(y)|\\,dx\\,dy \\\\\n&\\geq\n\\max\\left\\{ 0, 2 (\\mu_- I_+ - \\mu_+ I_-), 2 (\\mu_+ I_- - \\mu_- I_+) \\right\\}.\n\\end{align*}\nTo this inequality, we add the equalities\n\\begin{align*}\n\\iint_{E_+ \\times E_+} |f(x) + f(y)|\\,dx\\,dy &= 2 \\mu_+ I_+ \\\\\n\\iint_{E_- \\times E_-} |f(x) + f(y)|\\,dx\\,dy &= 2 \\mu_- I_- \\\\\n-\\int_0^1 |f(x)|\\,dx &= -(\\mu_+ + \\mu_-)(I_+ + I_-)\n\\end{align*}\nto obtain\n\\begin{multline*}\n\\int_0^1 \\int_0^1 |f(x)+f(y)|\\,dx\\,dy - \\int_0^1 |f(x)|\\,dx \\\\\n\\geq \\max\\{ (\\mu_+ - \\mu_-)(I_+ + I_-)+ 2\\mu_-(I_- - I_+), \\\\\n(\\mu_+ - \\mu_-)(I_+ - I_-), \\\\\n(\\mu_- - \\mu_+)(I_+ + I_-)+ 2\\mu_+(I_+ - I_-) \\}.\n\\end{multline*}\nNow simply note that for each of the possible comparisons between\n$\\mu_+$ and $\\mu_-$, and between $I_+$ and $I_-$, one of the three\nterms above is manifestly nonnegative. This yields the desired result.\n\n\\textbf{Second solution:}\nWe will show at the end that it\nis enough to prove a discrete analogue: if $x_1, \\dots, x_n$\nare real numbers, then\n\\[\n\\frac{1}{n^2} \\sum_{i,j=1}^n |x_i + x_j| \\geq \\frac{1}{n}\n\\sum_{i=1}^n |x_i|.\n\\]\nIn the meantime, we concentrate on this assertion.\n\nLet $f(x_1, \\dots, x_n)$ denote the difference between the two sides.\nWe induct\non the number of nonzero values of $|x_i|$. We leave for later the base case,\nwhere there is at most one such value. Suppose instead for now that there\nare two or more. Let $s$ be the smallest, and suppose without loss of\ngenerality that $x_1 = \\cdots = x_a = s$, $x_{a+1} = \\cdots = x_{a+b} = -s$,\nand for $i > a+b$, either $x_i = 0$ or $|x_i| > s$. (One of $a,b$ might be\nzero.)\n\nNow consider\n\\[\nf(\\overbrace{t, \\cdots,t}^{\\mbox{$a$ terms}},\\overbrace{-t,\\cdots,-t}^{\\mbox{$b$ terms}},x_{a+b+1},\\cdots, x_n)\n\\]\nas a function of $t$.\nIt is piecewise linear near $s$; in fact, it is\nlinear between 0 and\nthe smallest nonzero value among $|x_{a+b+1}|, \\dots, |x_n|$\n(which exists by hypothesis). Thus its minimum is achieved by one (or both)\nof those two endpoints. In other words, we can reduce the\nnumber of distinct nonzero absolute values among the $x_i$ without\nincreasing $f$. This\nyields the induction, pending verification of the base case.\n\nAs for the base case, suppose that $x_1 = \\cdots = x_a = s > 0$,\n$x_{a+1} = \\cdots = x_{a+b} = -s$, and $x_{a+b+1} = \\cdots = x_n = 0$.\n(Here one or even both of $a,b$ could be zero, though the latter case\nis trivial.)\nThen\n\\begin{multline*}\nf(x_1, \\dots, x_n) = \\frac{s}{n^2} (2a^2 + 2b^2 + (a+b)(n-a-b)) \\\\\n- \\frac{s}{n} (a+b) = \\frac{s}{n^2} (a^2 -2ab + b^2) \\geq 0.\n\\end{multline*}\nThis proves the base case of the induction, completing the solution\nof the discrete analogue.\n\nTo deduce the original statement from the discrete analogue,\napproximate both integrals\nby equally-spaced Riemann sums and take limits. This works because\ngiven a continuous function\non a product of closed intervals,\nany sequence of Riemann sums with mesh size tending to zero\nconverges to the integral. (The domain is compact, so\nthe function is uniformly continuous. Hence for any $\\epsilon > 0$\nthere is a cutoff below\nwhich any mesh size forces the\ndiscrepancy between the Riemann sum and the integral to be less than\n$\\epsilon$.)\n\nAlternate derivation (based on a solution by Dan Bernstein):\nfrom the discrete analogue, we have\n\\[\n\\sum_{1 \\leq i<j\\leq n} |f(x_i) + f(x_j)| \\geq \\frac{n-2}{2}\n\\sum_{i=1}^n |f(x_i)|,\n\\]\nfor all $x_1, \\dots, x_n \\in [0,1]$. Integrating both sides as\n$(x_1, \\dots, x_n)$ runs over\n$[0,1]^n$ yields\n\\begin{align*}\n&\\frac{n(n-1)}{2} \\int_0^1 \\int_0^1 |f(x)+f(y)|\\,dy\\,dx \\\\\n&\\geq\n\\frac{n(n-2)}{2} \\int_0^1 |f(x)|\\,dx,\n\\end{align*}\nor\n\\[\n\\int_0^1 \\int_0^1 |f(x)+f(y)|\\,dy\\,dx\n\\geq\n\\frac{n-2}{n-1} \\int_0^1 |f(x)|\\,dx.\n\\]\nTaking the limit as $n \\to \\infty$ now yields the desired result.\n\n\\textbf{Third solution:} (by David Savitt)\nWe give an argument which yields the following improved result.  Let\n$\\mu_p$ and $\\mu_n$ be the measure of the sets $\\{ x \\ : \\ f(x) > 0\\}$ and\n$\\{ x \\ : \\ f(x) < 0\\}$ respectively, and let $\\mu \\le 1/2$ be\n$\\min(\\mu_p,\\mu_n)$.  Then\n\\begin{align*}\n& \\int_{0}^{1} \\int_{0}^{1} |f(x) + f(y)|\\,dx\\,dy \\\\\n&\\ge (1 + (1-2\\mu)^2)\n\\int_{0}^{1} |f(x)|\\,dx.\n\\end{align*}\nNote that the constant can be seen to be best possible by considering a\nsequence of functions tending towards the step function which is $1$ on\n$[0,\\mu]$ and $-1$ on $(\\mu,1]$.\n\nSuppose without loss of generality that $\\mu = \\mu_p$.  As in the second\nsolution, it suffices to prove a\nstrengthened discrete analogue, namely\n\\[\n\\frac{1}{n^2} \\sum_{i,j} |a_i + a_j| \\ge\n    \\left(1 + \\left(1 - \\frac{2p}{n}\\right)^2\\right)\\left(\\frac{1}{n}\n    \\sum_{i=1}^{n} |a_i| \\right),\n\\]\nwhere $p \\le n/2$ is the number of $a_1,\\ldots,a_n$ which are positive.\n(We need only make sure to choose meshes so that $p/n \\to \\mu$ as\n$n \\to \\infty$.)\nAn equivalent inequality is\n\\[\n\\sum_{1 \\le i < j \\le n} | a_i + a_j | \\ge \\left(n - 1 - 2p +\n    \\frac{2p^2}{n}\\right) \\sum_{i=1}^{n} | a_i |.\n\\]\n\nWrite $r_i = |a_i|$, and assume without loss of generality that $r_i \\ge\nr_{i+1}$ for each $i$. Then for $i<j$,\n$|a_i + a_j| = r_i + r_j$ if $a_i$ and $a_j$\nhave the same sign, and is $r_i - r_j$ if they have opposite signs. The\nleft-hand side is therefore equal to\n\\[\n\\sum_{i = 1}^n (n - i) r_i + \\sum_{j = 1}^n r_j C_j,\n\\]\nwhere\n\\begin{multline*}\nC_j = \\#\\{ i < j \\ : \\sgn(a_i) = \\sgn(a_j)\\} \\\\\n- \\#\\{ i < j : \\sgn(a_i) \\neq \\sgn(a_j)\\}.\n\\end{multline*}\n\nConsider the partial sum $P_k = \\sum_{j = 1}^{k} C_j$.  If exactly $p_k$ of\n$a_1,\\ldots,a_k$ are positive, then this sum is equal to\n\\[\n\\binom{p_k}{2} + \\binom{k-p_k}{2} - \\left[ \\binom {k}{2} -\n\\binom{p_k}{2} - \\binom{k-p_k}{2} \\right],\n\\]\nwhich expands and simplifies to\n\\[\n-2 p_k (k-p_k) + \\binom{k}{2} \\,.\n\\]\nFor $k \\le 2p$ even, this partial sum would be minimized with $p_k = \\frac{k}{2}$,\nand would then equal $-\\frac{k}{2}$; for $k < 2p$ odd, this partial sum would\nbe minimized with $p_k = \\frac{k \\pm 1}{2}$, and would then equal\n$-\\frac{k-1}{2}$.  Either way, $P_k \\ge - \\lfloor \\frac{k}{2} \\rfloor$.  On the other\nhand, if $k > 2p$, then\n\\[\n-2 p_k (k-p_k) + \\binom{k}{2} \\ge -2 p(k-p) + \\binom{k}{2}\n\\]\nsince $p_k$ is at most $p$. Define $Q_k$ to\nbe $- \\lfloor \\frac{k}{2} \\rfloor$ if $k \\le\n2p$ and $-2 p(k-p) + \\binom{k}{2}$ if $k \\ge 2p$, so that $P_k \\ge Q_k$.  Note\nthat $Q_1=0$.\n\nPartial summation gives\n\\begin{align*}\n\\sum_{j = 1}^n r_j C_j & =  r_n P_n + \\sum_{j=2}^{n} (r_{j-1} - r_j)\nP_{j-1} \\\\\n& \\ge r_n Q_n + \\sum_{j=2}^{n} (r_{j-1} - r_j) Q_{j-1} \\\\\n& =  \\sum_{j=2}^{n} r_j (Q_j - Q_{j-1}) \\\\\n& =  - r_2 - r_4 - \\cdots - r_{2p} + \\sum_{j = 2p+1}^{n} (j-1-2p) r_j.\n\\end{align*}\nIt follows that\n\\begin{align*}\n\\sum_{1 \\le i < j \\le n} | a_i + a_j | \n    &= \\sum_{i = 1}^n (n - i) r_i + \\sum_{j = 1}^n r_j C_j \\\\\n& \\ge \\sum_{i = 1}^{2p} (n - i - [ i \\ \\text{even}]) r_i \\\\\n&\\quad + \\sum_{i = 2p+1}^{n} (n - 1 - 2p) r_i \\\\\n&  = (n-1-2p) \\sum_{i=1}^{n} r_i \\\\\n&\\quad + \\sum_{i=1}^{2p} (2p + 1 - i - [i \\ \\text{even}]) r_i \\\\\n&  \\ge  (n-1-2p) \\sum_{i=1}^{n} r_i + p \\sum_{i=1}^{2p} r_i \\\\\n&  \\ge  (n-1-2p) \\sum_{i=1}^{n} r_i + p\\frac{2p}{n} \\sum_{i=1}^{n} r_i\\,,\n\\end{align*}\nas desired.  The next-to-last and last inequalities each follow from the\nmonotonicity of the $r_i$'s, the former by pairing the $i^{\\textrm{th}}$\nterm with the $(2p+1-i)^{\\textrm{th}}$.\n\n\\textbf{Note:}\nCompare the closely related Problem 6 from the 2000 USA Mathematical\nOlympiad: prove that\nfor any nonnegative real numbers $a_1, \\dots, a_n, b_1, \\dots, b_n$,\none has\n\\[\n\\sum_{i,j=1}^n \\min\\{a_i a_j,b_i b_j\\} \\leq\n\\sum_{i,j=1}^n \\min\\{a_i b_j,a_j b_i\\}.\n\\]\n\n\\end{itemize}\n\n\\end{document}"
  },
  {
    "year": 2004,
    "label": "A1",
    "difficulty": "1",
    "problem": "Basketball star Shanille O'Keal's team statistician\nkeeps track of the number, $S(N)$, of successful free throws she has made\nin her first $N$ attempts of the season.\nEarly in the season, $S(N)$  was less than 80\\% of  $N$,\nbut by the end of the season, $S(N)$ was more than 80\\% of $N$.\nWas there necessarily a moment in between when $S(N)$ was exactly 80\\% of\n$N$?",
    "solution": "Yes. Suppose otherwise. Then there would be an $N$ such that $S(N) < .8N$\nand $S(N+1) > .8(N+1)$; that is, O'Keal's free throw percentage is under $80\\%$\nat some point, and after one subsequent free throw (necessarily made),\nher percentage is over $80\\%$. If she makes $m$ of her first $N$ free\nthrows, then $m/N < 4/5$ and $(m+1)/(N+1) > 4/5$. This means that $5m <\n4n < 5m+1$, which is impossible since then $4n$ is an integer between the\nconsecutive integers $5m$ and $5m+1$.\n\n\\textbf{Remark:}\nThis same argument works for any fraction of the form\n$(n-1)/n$ for some integer $n>1$, but not for any other real number\nbetween $0$ and $1$."
  },
  {
    "year": 2004,
    "label": "A2",
    "difficulty": "2",
    "problem": "For $i = 1,2$ let $T_i$ be a triangle with side lengths $a_i, b_i, c_i$,\nand area $A_i$.  Suppose that $a_1 \\le a_2,  b_1 \\le b_2,  c_1 \\le\nc_2$,\nand that $T_2$ is an acute triangle. Does it follow that $A_1\n\\le A_2$?",
    "solution": "\\textbf{First solution:} (partly due to Ravi Vakil)\nYes, it does follow.\nFor $i=1,2$,\nlet $P_i, Q_i, R_i$ be the vertices of $T_i$ opposide the sides of length\n$a_i, b_i, c_i$, respectively.\n\nWe first check the case where $a_1 = a_2$ (or $b_1 = b_2$ or $c_1 = c_2$,\nby the same argument after relabeling).\nImagine $T_2$ as being drawn with the base $Q_2R_2$\nhorizontal and the point $P_2$ above the line $Q_2R_2$. We may then\nposition $T_1$ so that $Q_1 = Q_2$, $R_1 = R_2$, and $P_1$ lies above the line\n$Q_1R_1 = Q_2R_2$. Then $P_1$ also lies inside the region bounded by the\ncircles through $P_2$ centered at $Q_2$ and $R_2$. Since $\\angle Q_2$\nand $\\angle R_2$ are acute, the part of this region above the line\n$Q_2R_2$ lies within $T_2$. In particular, the\ndistance from $P_1$ to the line $Q_2R_2$ is less than or equal to the\ndistance from $P_2$ to the line $Q_2R_2$; hence $A_1 \\leq A_2$.\n\nTo deduce the general case, put\n\\[\nr = \\max\\{a_1/a_2, b_1/b_2, c_1/c_2\\}.\n\\]\nLet $T_3$ be the triangle with sides $ra_2, rb_2, rc_2$, which\nhas area $r^2 A_2$. Applying the special case to $T_1$ and $T_3$,\nwe deduce that $A_1 \\leq r^2 A_2$; since $r \\leq 1$ by hypothesis,\nwe have $A_1 \\leq A_2$ as desired.\n\n\\textbf{Remark:}\nAnother geometric argument in the case $a_1 = a_2$\nis that since angles $\\angle Q_2$ and $\\angle R_2$\nare acute, the perpendicular to $Q_2R_2$ through $P_2$ separates $Q_2$ from\n$R_2$. If $A_1 > A_2$, then $P_1$ lies above the parallel to $Q_2R_2$\nthrough $P_2$; if then it lies on or to the left of the vertical line\nthrough $P_2$, we have $c_1 > c_2$ because the inequality holds\nfor both horizontal and vertical components (possibly with equality for one,\nbut not both). Similarly, if $P_1$ lies to the right of the vertical,\nthen $b_1 > b_2$.\n\n\\textbf{Second solution:} (attribution unknown)\nRetain notation as in the first paragraph of the first solution.\nSince the angle measures in any triangle add up to $\\pi$, some angle\nof $T_1$ must have measure less than or equal to its counterpart in\n$T_2$. Without loss of generality assume that $\\angle P_1 \\leq \\angle\nP_2$. Since the latter is acute (because $T_2$ is acute), we have\n$\\sin \\angle P_1 \\leq \\sin \\angle P_2$. By the Law of Sines,\n\\[\nA_1 = \\frac{1}{2} b_1 c_1 \\sin \\angle P_1 \\leq \\frac{1}{2}\nb_2 c_2 \\sin \\angle P_2 = A_2.\n\\]\n\n\\textbf{Remark:} Many other solutions are possible; for instance,\none uses Heron's formula for the area of a triangle in terms of\nits side lengths."
  },
  {
    "year": 2004,
    "label": "A3",
    "difficulty": "3",
    "problem": "Define a sequence $\\{ u_n \\}_{n=0}^\\infty$\nby  $u_0 = u_1 = u_2 = 1$, and thereafter by\nthe\ncondition that\n\\[\n\\det\\begin{pmatrix}\nu_n &   u_{n+1}\\\\\nu_{n+2} & u_{n+3}\n\\end{pmatrix}\n= n!\n\\]\nfor all $n \\ge 0$. Show that $u_n$ is an integer for all $n$.\n(By convention, $0! = 1$.)",
    "solution": "Define a sequence $v_n$ by $v_n = (n-1)(n-3)\\cdots(4)(2)$ if $n$ is\nodd and $v_n = (n-1)(n-3)\\cdots(3)(1)$ if $n$ is even; it suffices to\nprove that $u_n = v_n$ for all $n \\geq 2$. Now $v_{n+3} v_n =\n(n+2)(n)(n-1)!$ and $v_{n+2}v_{n+1} = (n+1)!$, and so $v_{n+3} v_n -\nv_{n+2} v_{n+1} = n!$. Since we can check that $u_n = v_n$ for\n$n=2,3,4$, and $u_n$ and $v_n$ satisfy the same recurrence, it\nfollows by induction that $u_n = v_n$ for all $n\\geq 2$, as desired."
  },
  {
    "year": 2004,
    "label": "A4",
    "difficulty": "4",
    "problem": "Show that for any positive integer $n$ there is an integer $N$ such that\nthe product $x_1 x_2 \\cdots x_n$ can be expressed identically in the form\n\\[\nx_1 x_2 \\cdots x_n =\n\\sum_{i=1}^N  c_i\n( a_{i1} x_1 + a_{i2} x_2 + \\cdots + a_{in} x_n )^n\n\\]\nwhere the $c_i$ are rational numbers and each $a_{ij}$ is one of the\nnumbers $-1, 0, 1$.",
    "solution": "It suffices to verify that\n\\[\nx_1 \\cdots x_n = \\frac{1}{2^n n!} \\sum_{e_i \\in \\{-1,1\\}}\n(e_1\\cdots e_n) (e_1 x_1 + \\cdots + e_n x_n)^n.\n\\]\nTo check this, first note that the right side vanishes identically\nfor $x_1 = 0$, because each term cancels the corresponding term with $e_1$\nflipped. Hence the right side, as a polynomial, is divisible by $x_1$;\nsimilarly it is divisible by $x_2, \\dots, x_n$. Thus the right side\nis equal to $x_1\\cdots x_n$ times a scalar. (Another way to see this:\nthe right side is clearly odd as a polynomial in each individual variable,\nbut the only degree $n$ monomial in $x_1, \\dots, x_n$ with that property\nis $x_1 \\cdots x_n$.) Since each summand\ncontributes $\\frac{1}{2^n} x_1 \\cdots x_n$ to the sum, the scalar factor is\n1 and we are done.\n\n\\textbf{Remark:} Several variants on the above construction\nare possible; for instance,\n\\[\nx_1 \\cdots x_n = \\frac{1}{n!}\n\\sum_{e_i \\in \\{0,1\\}} (-1)^{n - e_1 - \\cdots - e_n}\n(e_1 x_1 + \\cdots + e_n x_n)^n\n\\]\nby the same argument as above.\n\n\\textbf{Remark:} These construction work over any field of characteristic\ngreater than $n$ (at least for $n>1$).\nOn the other hand, no construction is possible over\na field of characteristic $p \\leq n$, since the coefficient of\n$x_1\\cdots x_n$ in the expansion of\n$(e_1 x_1 + \\cdots + e_n x_n)^n$ is zero for any $e_i$.\n\n\\textbf{Remark:} Richard Stanley asks whether one can use fewer than\n$2^n$ terms, and what the smallest possible number is."
  },
  {
    "year": 2004,
    "label": "A5",
    "difficulty": "5",
    "problem": "An $m \\times n$ checkerboard is colored randomly: each square is\nindependently\nassigned red or black with probability $1/2$. We say that two squares,\n$p$ and $q$,  are in the same connected monochromatic region if there is\na sequence of squares, all of the same color, starting at $p$ and ending\nat $q$, in which successive squares in the sequence share a common side.\nShow that the expected number of connected monochromatic regions is\ngreater than $m n / 8$.",
    "solution": "\\textbf{First solution:}\nFirst recall that any graph with $n$ vertices and $e$ edges has at\nleast $n-e$ connected components (add each edge one at a time, and note\nthat it reduces the number of components by at most 1). Now\nimagine the squares of the checkerboard as a graph, whose vertices are\nconnected if the corresponding squares share a side and are\nthe same color. Let\n$A$ be the number of edges in the graph, and let $B$ be the number of\n4-cycles (formed by monochromatic $2 \\times 2$ squares).\nIf we remove the bottom edge of each 4-cycle, the resulting graph has\nthe same number of connected components as the original one;\nhence this number is at least\n\\[\nmn - A+B.\n\\]\nBy the linearity of expectation, the expected number of connected\ncomponents is at least\n\\[\nmn - E(A) + E(B).\n\\]\nMoreover, we may compute $E(A)$ by summing over the individual\npairs of adjacent squares, and we may compute $E(B)$ by summing over\nthe individual $2 \\times 2$ squares. Thus\n\\begin{align*}\nE(A) &= \\frac{1}{2}(m(n-1) + (m-1)n), \\\\\nE(B) &= \\frac{1}{8}(m-1)(n-1),\n\\end{align*}\nand so the expected number of components is at least\n\\begin{align*}\n& mn - \\frac{1}{2}(m(n-1)+(m-1)n) + \\frac{1}{8}(m-1)(n-1) \\\\\n&= \\frac{mn + 3m + 3n + 1}{8} >\n\\frac{mn}{8}.\n\\end{align*}\n\n\\textbf{Remark:}\nA ``dual'' approach is to consider\nthe graph whose vertices are the corners of the squares of the checkerboard,\nwith two vertices joined if they are adjacent and the edge between then\ndoes not separate two squares of the same color. In this approach,\nthe 4-cycles become isolated vertices, and the bound on components\nis replaced by a call to Euler's formula relating the vertices, edges\nand faces of a planar figure. (One must be careful, however, to correctly\nhandle faces which are not simply connected.)\n\n\\textbf{Second solution:} (by Noam Elkies)\nNumber the squares of the checkerboard $1, \\dots, mn$ by numbering the\nfirst row from left to right, then the second row, and so on. We prove\nby induction on $i$ that if we just consider the figure formed by the\nfirst $i$ squares, its expected number of monochromatic components is\nat least $i/8$. For $i=1$, this is clear.\n\nSuppose the $i$-th square does not abut the left edge or the top row\nof the board.\nThen we may divide into three cases.\n\\begin{itemize}\n\\item\nWith probability $1/4$, the $i$-th square is opposite in color from\nthe adjacent squares directly above and to the left of it. In this case\nadding the $i$-th square adds one component.\n\\item\nWith probability $1/8$, the $i$-th square is the same in color as the\nadjacent squares directly above and to the left of it, but opposite in\ncolor from its diagonal neighbor above and to the left. In this case,\nadding the $i$-th square either removes a component or leaves the number\nunchanged.\n\\item\nIn all other cases, the number of components remains unchanged upon\nadding the $i$-th square.\n\\end{itemize}\nHence adding the $i$-th square increases the expected number of components\nby $1/4 - 1/8 = 1/8$.\n\nIf the $i$-th square does abut the left edge of the board, the situation\nis even simpler: if the $i$-th square differs in color from the square\nabove it, one component is added, otherwise the number does not change. Hence\nadding the $i$-th square increases the expected number of components\nby $1/2$; likewise if the $i$-th square abuts the top edge of the board.\nThus the expected number of components is at least $i/8$ by induction,\nas desired.\n\n\\textbf{Remark:} Some solvers attempted to consider adding one row\nat a time, rather than one square; this must be handled with great\ncare, as it is possible that the number of components can drop\nrather precipitously upon adding an entire row."
  },
  {
    "year": 2004,
    "label": "A6",
    "difficulty": "6",
    "problem": "Suppose that $f(x,y)$ is a continuous real-valued function on the unit\nsquare $0 \\le x \\le 1, 0 \\le y \\le 1$.  Show that\n\\begin{align*}\n& \\int_0^1 \\left( \\int_0^1  f(x,y) dx \\right)^2 dy +\n \\int_0^1 \\left( \\int_0^1  f(x,y) dy \\right)^2 dx \\\\\n&\\leq\n\\left( \\int_0^1 \\int_0^1  f(x,y) dx\\, dy \\right)^2 +\n\\int_0^1 \\int_0^1 \\left[ f(x,y) \\right]^2 dx\\,dy.\n\\end{align*}",
    "solution": "By approximating each integral with a Riemann sum, we may reduce to\nproving the discrete analogue: for $x_{ij} \\in \\RR$ for\n$i,j=1, \\dots, n$,\n\\begin{multline*}\nn \\sum_{i=1}^n \\left( \\sum_{j=1}^n x_{ij} \\right)^2\n+ n \\sum_{j=1}^n \\left( \\sum_{i=1}^n x_{ij} \\right)^2 \\\\\n\\leq \\left( \\sum_{i=1}^n \\sum_{j=1}^n x_{ij} \\right)^2\n+ n^2 \\sum_{i=1}^n \\sum_{j=1}^n x_{ij}^2.\n\\end{multline*}\nThe difference between the right side and the left side is\n\\[\n\\frac{1}{4} \\sum_{i,j,k,l=1}^n (x_{ij} + x_{kl} - x_{il} - x_{kj})^2,\n\\]\nwhich is evidently nonnegative. If you prefer not to discretize,\nyou may rewrite the original inequality as\n\\[\n\\int_0^1 \\int_0^1 \\int_0^1 \\int_0^1 F(x,y,z,w)^2\n\\,dx\\,dy\\,dz\\,dw \\geq 0\n\\]\nfor\n\\[\nF(x,y,z,w) = f(x,y) + f(z,w) - f(x,w) - f(z,y).\n\\]\n\n\\textbf{Remark:} (by Po-Ning Chen)\nThe discrete inequality can be arrived at more systematically\nby repeatedly applying the following identity: for\nany real $a_1, \\dots, a_n$,\n\\[\n\\sum_{1 \\leq i < j \\leq n} (x_i - x_j)^2\n= n \\sum_{i=1}^n x_i^2 - \\left( \\sum_{i=1}^n x_i \\right)^2.\n\\]\n\n\\textbf{Remark:} (by David Savitt)\nThe discrete inequality can also be interpreted as follows.\nFor $c,d \\in \\{1, \\dots, n-1\\}$ and $\\zeta_n = e^{2\\pi i/n}$, put\n\\[\nz_{c,d} = \\sum_{i,j} \\zeta_n^{c i + d j} x_{ij}.\n\\]\nThen the given inequality is equivalent to\n\\[\n\\sum_{c,d=1}^{n-1} |z_{c,d}|^2 \\geq 0.\n\\]"
  },
  {
    "year": 2004,
    "label": "B1",
    "difficulty": "1",
    "problem": "Let $P(x) = c_n x^n + c_{n-1} x^{n-1} + \\cdots + c_0$ be a polynomial with\ninteger coefficients. Suppose that $r$ is a rational number such that\n$P(r) = 0$.  Show that the $n$ numbers\n\\begin{gather*}\nc_n r, \\, c_n r^2 + c_{n-1} r, \\, c_n r^3 + c_{n-1} r^2 + c_{n-2} r, \\\\\n\\dots, \\, c_n r^n + c_{n-1} r^{n-1} + \\cdots + c_1 r\n\\end{gather*}\nare integers.",
    "solution": "Let $k$ be an integer, $0\\leq k\\leq n-1$. Since $P(r)/r^k = 0$, we\nhave\n\\begin{multline*}\nc_n r^{n-k} + c_{n-1} r^{n-k+1} + \\dots + c_{k+1} r \\\\\n= - (c_k + c_{k-1} r^{-1} + \\dots + c_0 r^{-k}).\n\\end{multline*}\nWrite $r = p/q$ where $p$ and $q$ are relatively prime. Then the\nleft hand side of the above equation can be written as a fraction\nwith denominator $q^{n-k}$, while the right hand side is a fraction\nwith denominator $p^k$. Since $p$ and $q$ are relatively prime, both\nsides of the equation must be an integer, and the result follows.\n\n\\textbf{Remark:}\nIf we write $r = a/b$ in lowest terms, then $P(x)$ factors as $(bx-a)Q(x)$,\nwhere the polynomial $Q$ has integer coefficients because you can\neither do the long division from the left and get denominators divisible only\nby primes dividing $b$, or do it from the right and get denominators\ndivisible only by primes dividing $a$. The numbers given in the problem\nare none other than $a$ times the coefficients of $Q$.\nMore generally, if $P(x)$ is divisible,\nas a polynomial over the rationals, by a polynomial $R(x)$ with integer\ncoefficients, then $P/R$ also has integer coefficients; this is known\nas ``Gauss's lemma'' and holds in any unique factorization domain."
  },
  {
    "year": 2004,
    "label": "B2",
    "difficulty": "2",
    "problem": "Let $m$ and $n$ be positive integers.  Show that\n\\[\n\\frac{(m+n)!}{(m+n)^{m+n}}\n< \\frac{m!}{m^m} \\frac{n!}{n^n}.\n\\]",
    "solution": "\\textbf{First solution:}\nWe have\n\\[\n(m+n)^{m+n} > \\binom{m+n}{m} m^m n^n\n\\]\nbecause the binomial expansion of $(m+n)^{m+n}$ includes the term on\nthe right as well as some others. Rearranging this inequality yields\nthe claim.\n\n\\textbf{Remark:}\nOne can also interpret this argument combinatorially.\nSuppose that we choose $m+n$ times (with replacement) uniformly\nrandomly from a set of $m+n$ balls, of which $m$ are red and $n$ are\nblue. Then the probability of picking each ball exactly once is\n$(m+n)!/(m+n)^{m+n}$. On the other hand, if $p$ is the probability\nof picking exactly $m$ red balls, then $p<1$ and the probability\nof picking each ball exactly once is $p (m^m/m!)(n^n/n!)$.\n\n\\textbf{Second solution:} (by David Savitt)\nDefine\n\\[\nS_k = \\{i/k: i=1, \\dots, k\\}\n\\]\nand rewrite the desired inequality as\n\\[\n\\prod_{x \\in S_m} x \\prod_{y \\in S_n} y > \\prod_{z \\in S_{m+n}} z.\n\\]\nTo prove this, it suffices to check that if we sort the multiplicands\non both sides into increasing order, the $i$-th term on the left\nside is greater than or equal to the $i$-th term on the right side.\n(The equality is strict already for $i=1$, so you do get a strict inequality\nabove.)\n\nAnother way to say this is that for\nany $i$, the number of factors on the left side which are less than\n$i/(m+n)$ is less than $i$. But since $j/m < i/(m+n)$ is equivalent to\n$j < im/(m+n)$, that number is\n\\begin{align*}\n&\\left\\lceil \\frac{im}{m+n} \\right\\rceil -1 +\n\\left\\lceil \\frac{in}{m+n} \\right\\rceil -1 \\\\\n&\\leq \\frac{im}{m+n} + \\frac{in}{m+n} - 1 = i-1.\n\\end{align*}\n\n\\textbf{Third solution:}\nPut $f(x) = x (\\log (x+1) - \\log x)$; then for $x>0$,\n\\begin{align*}\nf'(x) &= \\log(1 + 1/x) - \\frac{1}{x+1} \\\\\nf''(x) &= - \\frac{1}{x(x+1)^2}.\n\\end{align*}\nHence $f''(x) < 0$ for all $x$; since $f'(x) \\to 0$ as $x \\to \\infty$,\nwe have $f'(x) > 0$ for $x>0$, so $f$ is strictly increasing.\n\nPut $g(m) = m \\log m - \\log(m!)$; then $g(m+1) - g(m) = f(m)$,\nso $g(m+1)-g(m)$ increases with $m$. By induction,\n$g(m+n) - g(m)$ increases with $n$ for any positive integer $n$,\nso in particular\n\\begin{align*}\ng(m+n) - g(m) &> g(n) - g(1) + f(m) \\\\\n&\\geq g(n)\n\\end{align*}\nsince $g(1) = 0$. Exponentiating yields the desired inequality.\n\n\\textbf{Fourth solution:} (by W.G. Boskoff and Bogdan Suceav\\u{a})\nWe prove the claim by induction on $m+n$. The base case is $m=n=1$, in which case\nthe desired inequality is obviously true: $2!/2^2 = 1/2 < 1 = (1!/1^1)(1!/1^1)$.\nTo prove the induction step, suppose $m+n > 2$; we must then have $m>1$ or $n>1$ or both.\nBecause the desired result is symmetric in $m$ and $n$, we may as well assume $n > 1$.\nBy the induction hypothesis, we have\n\\[\n\\frac{(m+n-1)!}{(m+n-1)^{m+n-1}} < \\frac{m!}{m^m} \\frac{(n-1)!}{(n-1)^{n-1}}.\n\\]\nTo obtain the desired inequality, it will suffice to check that\n\\[\n\\frac{(m+n-1)^{m+n-1}}{(m+n-1)!} \\frac{(m+n)!}{(m+n)^{m+n}}< \\frac{(n-1)^{n-1}}{(n-1)!} \\frac{n!}{(n)^{n}}\n\\]\nor in other words\n\\[\n\\left( 1 - \\frac{1}{m+n} \\right)^{m+n-1} < \\left(1 - \\frac{1}{n} \\right)^{n-1}.\n\\]\nTo show this, we check that the function $f(x) = (1 - 1/x)^{x-1}$\nis strictly decreasing for $x>1$; while this can be achieved using the weighted arithmetic-geometric mean\ninequality, we give a simple calculus proof instead. The derivative of $\\log f(x)$ is\n$\\log (1-1/x) + 1/x$, so it is enough to check that this is negative for $x>1$.\nAn equivalent statement is that $\\log (1-x) + x < 0$ for $0 < x < 1$;\nthis in turn holds because the function $g(x) = \\log(1-x) + x$ tends to 0 as $x \\to 0^+$\nand has derivative $1 - \\frac{1}{1-x} < 0$ for $0 < x < 1$."
  },
  {
    "year": 2004,
    "label": "B3",
    "difficulty": "3",
    "problem": "Determine all real numbers $a > 0$ for which there exists a nonnegative\ncontinuous function $f(x)$ defined on $[0,a]$ with the property that the\nregion\n\\[\nR = \\{ (x,y) ; 0\n\\le x \\le a, 0 \\le y \\le\nf(x) \\}\n\\]\nhas perimeter $k$ units and area $k$ square units for some real number $k$.",
    "solution": "The answer is $\\{a\\,|\\,a>2\\}$. If $a>2$, then the function $f(x) =\n2a/(a-2)$ has the desired property; both perimeter and area of $R$\nin this case are $2a^2/(a-2)$. Now suppose that $a\\leq 2$, and let\n$f(x)$ be a nonnegative continuous function on $[0,a]$. Let\n$P=(x_0,y_0)$ be a point on the graph of $f(x)$ with maximal\n$y$-coordinate; then the area of $R$ is at most $ay_0$ since it lies\nbelow the line $y=y_0$. On the other hand, the points $(0,0)$,\n$(a,0)$, and $P$ divide the boundary of $R$ into three sections. The\nlength of the section between $(0,0)$ and $P$ is at least the\ndistance between $(0,0)$ and $P$, which is at least $y_0$; the\nlength of the section between $P$ and $(a,0)$ is similarly at least\n$y_0$; and the length of the section between $(0,0)$ and $(a,0)$ is\n$a$. Since $a\\leq 2$, we have $2y_0 + a > ay_0$ and hence the\nperimeter of $R$ is strictly greater than the area of $R$."
  },
  {
    "year": 2004,
    "label": "B4",
    "difficulty": "4",
    "problem": "Let $n$ be a positive integer, $n \\ge\n2$, and put  $\\theta = 2 \\pi / n$.\nDefine points $P_k = (k,0)$ in the $xy$-plane, for $k = 1, 2\n, \\dots, n$.\nLet $R_k$ be the map that rotates the plane counterclockwise by the\nangle $\\theta$ about the point $P_k$.  Let $R$ denote the map obtained\nby applying, in order, $R_1$,  then $R_2, \\dots$,\nthen $R_n$.\nFor an arbitrary point $(x,y)$, find, and simplify, the coordinates\nof $R(x,y)$.",
    "solution": "\\textbf{First solution:}\nIdentify the $xy$-plane with the complex plane $\\mathbb{C}$, so that\n$P_k$ is the real number $k$. If $z$ is sent to $z'$ by a\ncounterclockwise rotation by $\\theta$ about $P_k$, then $z'-k =\ne^{i\\theta} (z-k)$; hence the rotation $R_k$ sends $z$ to $\\zeta z +\nk (1-\\zeta)$, where $\\zeta = e^{2\\pi i/n}$. It follows that $R_1$\nfollowed by $R_2$ sends $z$ to $\\zeta(\\zeta z +(1-\\zeta)) + 2\n(1-\\zeta) = \\zeta^2 z + (1-\\zeta)(\\zeta + 2)$, and so forth; an easy\ninduction shows that $R$ sends $z$ to\n\\[\n\\zeta^n z + (1-\\zeta)(\\zeta^{n-1} + 2 \\zeta^{n-2} + \\dots + (n-1)\n\\zeta + n).\n\\]\nExpanding the product $(1-\\zeta)(\\zeta^{n-1} + 2 \\zeta^{n-2} + \\dots\n+ (n-1) \\zeta + n)$ yields $-\\zeta^n - \\zeta^{n-1} - \\dots - \\zeta +\nn = n$. Thus $R$ sends $z$ to $z+n$; in cartesian coordinates,\n$R(x,y) = (x+n,y)$.\n\n\\textbf{Second solution:}\n(by Andy Lutomirski, via Ravi Vakil)\nImagine a regular $n$-gon of side length 1 placed with its top edge\non the $x$-axis and the left endpoint of that edge\nat the origin. Then the rotations\ncorrespond to rolling this $n$-gon along the $x$-axis; after the\n$n$ rotations, it clearly ends up in its original rotation and translated\n$n$ units to the right. Hence the whole plane must do so as well.\n\n\\textbf{Third solution:} (attribution unknown)\nViewing each $R_k$ as a function of a complex number $z$ as in the\nfirst solution, the function $R_n \\circ R_{n-1} \\circ \\cdots \\circ\nR_1(z)$ is linear in $z$ with slope $\\zeta^n = 1$. It thus equals\n$z + T$ for some $T \\in \\CC$. Since $f_1(1) = 1$, we can write\n$1+T = R_n \\circ \\cdots \\circ R_2(1)$. However, we also have\n\\[\nR_n \\circ \\cdots \\circ R_2(1) = R_{n-1} \\circ R_1(0) + 1\n\\]\nby the symmetry in how the $R_i$ are defined. Hence\n\\[\nR_n(1+T) = R_n \\circ R_1(0) + R_n(1) = T + R_n(1);\n\\]\nthat is, $R_n(T) = T$. Hence $T = n$, as desired."
  },
  {
    "year": 2004,
    "label": "B5",
    "difficulty": "5",
    "problem": "Evaluate\n\\[\n\\lim_{x \\to 1^-} \\prod_{n=0}^\\infty \\left(\\frac{1 + x^{n+1}}{1 +\nx^n}\\right)^{x^n}.\n\\]",
    "solution": "\\textbf{First solution:}\nBy taking logarithms, we see that the desired limit is $\\exp(L)$,\nwhere $L = \\lim_{x\\to 1^-} \\sum_{n=0}^{\\infty} x^n \\left(\n\\ln(1+x^{n+1}) - \\ln(1+x^n) \\right)$. Now\n\\begin{align*}\n&\\sum_{n=0}^N x^n \\left( \\ln(1+x^{n+1}) - \\ln(1+x^n) \\right) \\\\\n& = 1/x\n\\sum_{n=0}^N x^{n+1} \\ln(1+x^{n+1}) - \\sum_{n=0}^N x^n\\ln(1+x^n) \\\\\n&=\nx^N \\ln(1+x^{N+1}) - \\ln 2 + (1/x-1) \\sum_{n=1}^N x^n\\ln(1+x^n);\n\\end{align*}\nsince $\\lim_{N\\to\\infty} (x^N\\ln(1+x^{N+1})) = 0$ for $0<x<1$, we\nconclude that $L = - \\ln 2 + \\lim_{x\\to 1^-} f(x)$, where\n\\begin{align*}\nf(x) &= (1/x-1) \\sum_{n=1}^{\\infty} x^n\\ln(1+x^n) \\\\\n&= (1/x-1)\n\\sum_{n=1}^\\infty \\sum_{m=1}^\\infty (-1)^{m+1} x^{n+mn}/m.\n\\end{align*}\nThis final double sum converges absolutely when $0<x<1$, since\n\\begin{align*}\n\\sum_{n=1}^\\infty \\sum_{m=1}^\\infty x^{n+mn}/m &= \\sum_{n=1}^\\infty\nx^n (-\\ln(1-x^n)) \\\\\n&< \\sum_{n=1}^\\infty x^n (-\\ln(1-x)),\n\\end{align*}\nwhich converges. (Note that $-\\ln(1-x)$ and $-\\ln(1-x^n)$ are\npositive.) Hence we may interchange the summations in $f(x)$ to\nobtain\n\\begin{align*}\nf(x) &= (1/x-1) \\sum_{m=1}^\\infty \\sum_{n=1}^\\infty \\frac{(-1)^{m+1}\nx^{(m+1)n}}{m} \\\\\n&= (1/x-1) \\sum_{m=1}^\\infty \\frac{(-1)^{m+1}}\n{m}\\left(\\frac{x^m(1-x)}{1-x^{m+1}}\\right).\n\\end{align*}\nThis last sum converges absolutely uniformly in $x$, so it is legitimate\nto take limits term by term.\nSince $\\lim_{x\\to 1^-} \\frac{x^m{1-x}}{1-x^{m+1}} = \\frac{1}{m+1}$\nfor fixed $m$, we have\n\\begin{align*}\n\\lim_{x\\to 1^-} f(x) &= \\sum_{m=1}^\\infty \\frac{(-1)^{m+1}}{m(m+1)} \\\\\n&= \\sum_{m=1}^\\infty (-1)^{m+1}\\left( \\frac{1}{m}-\\frac{1}{m+1} \\right) \\\\\n&= 2 \\left( \\sum_{m=1}^\\infty \\frac{(-1)^{m+1}}{m} \\right) - 1 \\\\ &= 2\n\\ln 2 - 1,\n\\end{align*}\nand hence $L = \\ln 2 - 1$ and the desired limit is $2/e$.\n\n\\textbf{Remark:} Note that the last series is not absolutely convergent,\nso the recombination must be done without rearranging terms.\n\n\\textbf{Second solution:}\n(by Greg Price, via Tony Zhang and Anders Kaseorg)\nPut $t_n(x) = \\ln(1 + x^n)$;\nwe can then write $x^n = \\exp(t_n(x)) - 1$, and\n\\[\nL = \\lim_{x \\to 1^-} \\sum_{n=0}^\\infty (t_n(x) - t_{n+1}(x))(1 - \\exp(t_n(x))).\n\\]\nThe expression on the right is a Riemann sum approximating the\nintegral $\\int_0^{\\ln 2} (1-e^t)\\,dt$, over the subdivision of $[0,\\ln(2))$\ngiven by the $t_n(x)$. As $x \\to 1^-$, the maximum difference between\nconsecutive $t_n(x)$ tends to 0, so the Riemann sum tends to the value\nof the integral. Hence $L = \\int_0^{\\ln 2}(1 - e^t)\\,dt = \\ln 2 - 1$, as\ndesired.\n\n\\def\\calA{\\mathcal{A}}\n\\def\\calB{\\mathcal{B}}"
  },
  {
    "year": 2004,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $\\mathcal{A}$\nbe a non-empty set of positive integers, and let $N(x)$ denote\nthe number of elements of $\\mathcal{A}$ not exceeding $x$.\nLet $\\mathcal{B}$ denote the set\nof positive integers $b$ that can be written in the form $b = a - a'$ with\n$a \\in \\mathcal{A}$  and $a' \\in  \\mathcal{A}$. Let $b_1 < b_2 < \\cdots$\nbe the members of $\\mathcal{B}$,\nlisted in increasing order. Show that if the sequence $b_{i+1} - b_i$ is\nunbounded, then\n\\[\n\\lim_{x \\to\\infty}  N(x)/x  = 0.\n\\]\n\n\\end{itemize}\n\\end{document}",
    "solution": "\\textbf{First solution:}\n(based on a solution of Dan Bernstein)\nNote that for any $b$, the condition that $b \\notin \\calB$ already\nforces $\\limsup N(x)/x$ to be at most 1/2: pair off $2mb + n$ with\n$(2m+1)b+n$ for $n=1,\\dots, b$, and note that at most one member of each\npair may belong to $\\calA$.\nThe idea of the proof is to do something\nsimilar with pairs replaced by larger clumps, using long runs of\nexcluded elements of $B$.\n\nSuppose we have positive integers\n$b_0 = 1, b_1, \\dots, b_n$ with\nthe following properties:\n\\begin{enumerate}"
  },
  {
    "year": 2005,
    "label": "A1",
    "difficulty": "1",
    "problem": "Show that every positive integer is a sum of one or more numbers of the\nform $2^r 3^s$, where $r$ and $s$ are nonnegative integers and no\nsummand divides another.\n(For example, 23 = 9 + 8 + 6.)",
    "solution": "We proceed by induction, with base case $1 = 2^0 3^0$. Suppose all\nintegers less than $n-1$ can be represented. If $n$ is even, then\nwe can take a representation of $n/2$ and multiply each term by 2 to\nobtain a representation of $n$. If $n$ is odd,\nput $m = \\lfloor \\log_3 n\n\\rfloor$, so that $3^m \\leq n < 3^{m+1}$. If $3^m = n$, we are done.\nOtherwise, choose a representation $(n-3^m)/2 = s_1 + \\cdots + s_k$\nin the desired form. Then\n\\[\nn = 3^m + 2s_1 + \\cdots + 2s_k,\n\\]\nand clearly none of the $2s_i$ divide each other or $3^m$. Moreover,\nsince $2s_i \\leq n-3^m < 3^{m+1} - 3^m$, we have $s_i < 3^m$,\nso $3^m$ cannot divide $2s_i$ either. Thus $n$ has a representation\nof the desired form in all cases, completing the induction.\n\n\\textbf{Remarks:}\nThis problem is originally due to Paul Erd\\H{o}s.\nNote that the representations need not be unique: for instance,\n\\[\n11 = 2+9 = 3+8.\n\\]"
  },
  {
    "year": 2005,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $\\mathbf{S} = \\{(a,b) | a = 1, 2, \\dots,n, b = 1,2,3\\}$.\nA \\emph{rook tour} of $\\mathbf{S}$ is a polygonal path made up of line\nsegments connecting points $p_1, p_2, \\dots, p_{3n}$ in sequence such that\n\\begin{enumerate}",
    "solution": "We will assume $n \\geq 2$ hereafter, since the answer is 0 for $n=1$.\n\n\\textbf{First solution:}\nWe show that the set of rook tours from $(1,1)$ to $(n,1)$ is in bijection with\nthe set of subsets of $\\{1,2,...,n\\}$ that include $n$ and contain an even number\nof elements in total.  Since the latter set evidently contains $2^{n-2}$ elements,\nso does the former.\n\nWe now construct the bijection.  Given a rook tour $P$ from $(1,1)$ to $(n,1)$,\nlet $S=S(P)$ denote the set of all $i \\in \\{1,2,\\ldots,n\\}$ for which there is\neither a directed edge from $(i,1)$ to $(i,2)$ or from $(i,3)$ to $(i,2)$.  It\nis clear that this set $S$ includes $n$ and must contain an even number of\nelements.  Conversely, given a subset $S=\\{a_1,a_2,\\ldots,a_{2r}=n\\}\n\\subset \\{1,2,\\ldots,n\\}$ of this type with $a_1<a_2<\\cdots<a_{2r}$,\nwe notice that there is a unique path $P$ containing\n$(a_i,2+(-1)^i),(a_1,2)$\nfor $i=1,2,\\ldots,2r$.  This establishes the desired bijection.\n\n\n\\textbf{Second solution:}\nLet $A_n$ denote the set of rook tours beginning at $(1,1)$ and\nending at $(n,1)$, and let $B_n$ denote the set of rook tours\nbeginning at $(1,1)$ and ending at $(n,3)$.\n\nFor $n \\geq 2$, we construct a bijection between $A_n$ and $A_{n-1}\n\\cup B_{n-1}$. Any path $P$ in $A_n$ contains either the line segment\n$P_1$ between $(n-1,1)$ and $(n,1)$, or the line segment $P_2$ between\n$(n,2)$ and $(n,1)$. In the former case, $P$ must also contain the\nsubpath $P_1'$ which joins $(n-1,3)$, $(n,3)$, $(n,2)$, and $(n-1,2)$\nconsecutively; then deleting $P_1$ and $P_1'$ from $P$ and adding the\nline segment joining $(n-1,3)$ to $(n-1,2)$ results in a path in\n$A_{n-1}$. (This construction is reversible, lengthening any path in\n$A_{n-1}$ to a path in $A_n$.) In the latter case, $P$ contains the\nsubpath $P_2'$ which joins $(n-1,3)$, $(n,3)$, $(n,2)$, $(n,1)$\nconsecutively; deleting $P_2'$ results in a path in $B_{n-1}$, and\nthis construction is also reversible. The desired bijection follows.\n\nSimilarly, there is a bijection between $B_n$ and $A_{n-1} \\cup\nB_{n-1}$ for $n \\geq 2$. It follows by induction that for $n \\geq 2$,\n$|A_n| = |B_n| = 2^{n-2} (|A_1| + |B_1|)$. But $|A_1| = 0$ and $|B_1|\n= 1$, and hence the desired answer is $|A_n| = 2^{n-2}$.\n\n\\textbf{Remarks:}\nOther bijective arguments are possible: for instance, Noam Elkies\npoints out that each element of $A_n \\cup B_n$\ncontains a different one of the possible sets of\nsegments of the form $(i,2),(i+1,2)$ for $i=1,\\dots,n-1$.\nRichard Stanley provides the reference: K.L. Collins and L.B. Krompart,\nThe number of Hamiltonian paths in a rectangular grid,\n\\textit{Discrete Math.}  \\textbf{169} (1997), 29--38. This problem\nis Theorem~1 of that paper; the cases of $4 \\times n$ and $5 \\times n$\ngrids\nare also treated. The paper can also be found online at the URL\n\\texttt{kcollins.web.wesleyan.edu/vita.htm}."
  },
  {
    "year": 2005,
    "label": "A3",
    "difficulty": "3",
    "problem": "Let $p(z)$ be a polynomial of degree $n$ all of whose zeros have absolute\nvalue 1 in the complex  plane. Put $g(z) = p(z)/z^{n/2}$. Show that all zeros\nof $g'(z) = 0$ have absolute value 1.",
    "solution": "Note that it is implicit in the problem that $p$ is nonconstant,\none may take any branch of the square root, and that $z=0$ should be\nignored.\n\n\\textbf{First solution:}\nWrite $p(z) = c \\prod_{j=1}^n (z-r_j)$, so that\n\\[\n\\frac{g'(z)}{g(z)} = \\frac{1}{2z} \\sum_{j=1}^n \\frac{z+r_j}{z-r_j}.\n\\]\nNow if $z\\neq r_j$ for all $j$,then\n\\[\n\\frac{z+r_j}{z-r_j}\n= \\frac{(z+r_j)(\\overline{z}-\\overline{r_j})}{|z-r_j|^2}\n= \\frac{|z|^2-1+2 \\mathrm{Im}(\\overline{z} r_j)}{|z-r_j|^2},\n\\]\nand so\n\\[\n\\mathrm{Re}\\, \\frac{z g'(z)}{g(z)} = \\frac{|z|^2-1}{2} \\left(\n\\sum_j \\frac{1}{|z-r_j|^2} \\right).\n\\]\nSince the quantity in parentheses\nis positive, $g'(z)/g(z)$ can be $0$ only if $|z|=1$. If on the other\nhand $z = r_j$ for some $j$, then $|z|=1$ anyway.\n\n\\textbf{Second solution:}\nWrite $p(z) = c\\prod_{j=1}^n (z-r_j)$, so that\n\\[\n\\frac{g'(z)}{g(z)}\n= \\sum_{j=1}^n \\left( \\frac{1}{z-r_j} - \\frac{1}{2z} \\right).\n\\]\nWe first check that $g'(z) \\neq 0$ whenever $z$ is real and $z>1$.\nIn this case, for $r_j = e^{i \\theta_j}$, we have $z - r_j =\n(z - \\cos (\\theta_j)) + \\sin(\\theta_j) i$, so the real part of\n$\\frac{1}{z-r_j} - \\frac{1}{2z}$ is\n\\[\n\\frac{z - \\cos(\\theta_j)}{z^2 - 2z \\cos(\\theta_j) + 1} - \\frac{1}{2z}\n= \\frac{z^2-1}{2z(z^2 - 2z \\cos(\\theta_j) + 1)} > 0.\n\\]\nHence $g'(z)/g(z)$ has positive real part, so $g'(z)/g(z)$ and hence\n$g(z)$ are nonzero.\n\nApplying the same argument after replacing $p(z)$ by $p(e^{i \\theta} z)$,\nwe deduce that $g'$ cannot have any roots outside the unit circle.\nApplying the same argument after replacing $p(z)$ by $z^n p(1/z)$, we\nalso deduce that $g'$ cannot have any roots inside the unit circle.\nHence all roots of $g'$ have absolute value 1, as desired.\n\n\\textbf{Third solution:}\nWrite $p(z) = c \\prod_{j=1}^n (z - r_j)$ and\nput $r_j = e^{2 i \\theta_j}$. Note that $g(e^{2 i \\theta})$\nis equal to a nonzero constant times\n\\begin{align*}\nh(\\theta) &= \\prod_{j=1}^n \\frac{e^{i (\\theta + \\theta_j)}\n- e^{-i(\\theta + \\theta_j)}}{2i} = \\prod_{j=1}^n \\sin(\\theta +\\theta_j).\n\\end{align*}\nSince $h$ has at least $2n$ roots (counting multiplicity)\nin the interval $[0, 2\\pi)$, $h'$ does also by repeated application of\nRolle's theorem. Since $g'(e^{2 i \\theta}) = 2i e^{2i \\theta} h'(\\theta)$,\n$g'(z^2)$ has at least $2n$ roots on the unit circle. Since $g'(z^2)$ is equal to\n$z^{-n-1}$ times a polynomial of degree $2n$, $g'(z^2)$ has all roots on the\nunit circle, as then does $g'(z)$.\n\n\\textbf{Remarks:}\nThe second solution imitates the proof of the Gauss-Lucas theorem:\nthe roots of the derivative of a complex polynomial lie in the convex hull of\nthe roots of the original polynomial.\nThe second solution is close to problem B3 from the 2000 Putnam.\nA hybrid between the first and third solutions is to check that\non the unit circle, $\\mathrm{Re}(zg'(z)/g(z)) = 0$ while between any\ntwo roots of $p$, $\\mathrm{Im}(zg'(z)/g(z))$ runs from $+\\infty$ to $-\\infty$\nand so must have a zero crossing. (This only works when $p$ has distinct roots,\nbut the general case follows by the continuity of the roots of a polynomial\nas functions of the coefficients.)\nOne can also construct a  solution using Rouch\\'e's theorem."
  },
  {
    "year": 2005,
    "label": "A4",
    "difficulty": "4",
    "problem": "Let $H$ be an $n \\times n$ matrix all of whose entries are $\\pm 1$ and\nwhose rows are mutually orthogonal. Suppose $H$ has an $a \\times b$ submatrix\nwhose entries are all $1$. Show that $ab \\leq n$.",
    "solution": "\\textbf{First solution:}\nChoose a set of $a$ rows $r_1, \\dots, r_a$\ncontaining an $a \\times b$ submatrix whose\nentries are all 1. Then for $i,j \\in\\{1, \\dots, a\\}$, we have\n$r_i \\cdot r_j = n$ if $i=j$ and 0 otherwise. Hence\n\\[\n\\sum_{i,j=1}^a r_i \\cdot r_j = an.\n\\]\nOn the other hand, the term on the left is the dot product of\n$r_1 + \\cdots + r_a$ with itself, i.e., its squared length. Since\nthis vector has $a$ in each of its first $b$ coordinates, the dot product\nis at least $a^2 b$. Hence $an \\geq a^2 b$,\nwhence $n \\geq ab$ as desired.\n\n\\textbf{Second solution:}\n(by Richard Stanley)\nSuppose without loss of generality that the $a \\times b$ submatrix\noccupies the first $a$ rows and the first $b$ columns.\nLet $M$ be the submatrix occupying the first $a$ rows and the last\n$n-b$ columns. Then the hypothesis implies that the matrix\n$MM^T$ has $n-b$'s on the main diagonal and $-b$'s elsewhere.\nHence the column vector $v$ of length $a$ consisting of all 1's\nsatisfies $MM^T v = (n-ab)v$, so $n-ab$ is an eigenvalue of $MM^T$.\nBut $MM^T$ is semidefinite, so its eigenvalues are all nonnegative\nreal numbers. Hence $n-ab \\geq 0$.\n\n\\textbf{Remarks:}\nA matrix as in the problem is called a \\emph{Hadamard matrix}, because\nit meets the equality condition of Hadamard's inequality:\nany $n \\times n$ matrix with $\\pm 1$ entries has absolute determinant\nat most $n^{n/2}$, with equality if and only if the rows are mutually\northogonal\n(from the interpretation of the determinant as the volume of a paralellepiped\nwhose edges are parallel to the row vectors).\nNote that this implies  that the columns are also mutually orthogonal.\nA generalization of this problem, with a similar proof, is known\nas \\emph{Lindsey's lemma}: the sum of the entries in any\n$a \\times b$ submatrix of a Hadamard matrix is at most $\\sqrt{abn}$.\nStanley notes that Ryser (1981) asked for the smallest size of a Hadamard\nmatrix containing an $r \\times s$ submatrix of all 1's, and refers to\nthe URL \\texttt{www3.interscience.wiley.com/cgi-bin/ abstract/110550861/ABSTRACT} for more information."
  },
  {
    "year": 2005,
    "label": "A5",
    "difficulty": "5",
    "problem": "Evaluate $\\int_0^1 \\frac{\\ln(x+1)}{x^2+1}\\,dx$.",
    "solution": "\\textbf{First solution:}\nWe make the substitution $x = \\tan \\theta$, rewriting the desired integral as\n\\[\n\\int_0^{\\pi/4} \\log(\\tan(\\theta) + 1)\\,d\\theta.\n\\]\nWrite\n\\[\n\\log(\\tan(\\theta)+ 1) = \\log(\\sin(\\theta) + \\cos(\\theta))-\\log(\\cos(\\theta))\n\\]\nand then note that $\\sin(\\theta) + \\cos(\\theta) = \\sqrt{2} \\cos\n(\\pi/4 - \\theta)$. We may thus rewrite the integrand as\n\\[\n\\frac12 \\log(2) + \\log(\\cos(\\pi/4 - \\theta)) - \\log(\\cos(\\theta)).\n\\]\nBut over the interval $[0, \\pi/4]$, the integrals of\n$\\log(\\cos(\\theta))$ and $\\log(\\cos(\\pi/4 - \\theta))$ are equal, so their\ncontributions cancel out. The desired integral is then just the integral\nof $\\frac{1}{2} \\log(2)$ over the interval $[0,\\pi/4]$, which is\n$\\pi \\log(2)/8$.\n\n\\textbf{Second solution:}\n(by Roger Nelsen)\nLet $I$ denote the desired integral. We make the substitution\n$x = (1-u)/(1+u)$ to obtain\n\\begin{align*}\nI &= \\int_0^1 \\frac{(1+u)^2\\log(2/(1+u))}{2(1+u^2)} \\frac{2\\,du}{(1+u)^2} \\\\\n&= \\int_0^1 \\frac{\\log(2) - \\log(1+u)}{1+u^2}\\,du \\\\\n&= \\log(2) \\int_0^1 \\frac{du}{1+u^2} - I,\n\\end{align*}\nyielding\n\\[\nI = \\frac{1}{2} \\log(2) \\int_0^1 \\frac{du}{1+u^2} = \\frac{\\pi \\log(2)}{8}.\n\\]\n\n\\textbf{Third solution:}\n(attributed to Steven Sivek)\nDefine the function\n\\[\nf(t) = \\int_0^1 \\frac{\\log(xt+1)}{x^2+1}\\,dx\n\\]\nso that $f(0) = 0$ and\nthe desired integral is $f(1)$. Then by differentiation under\nthe integral,\n\\[\nf'(t) = \\int_0^1 \\frac{x}{(xt+1)(x^2+1)}\\,dx.\n\\]\nBy partial fractions, we obtain\n\\begin{align*}\nf'(t) &= \\left. \\frac{2 t \\arctan(x) - 2 \\log(tx+1) + \\log(x^2+1)}{2(t^2+1)}\n\\right|_{x=0}^{x=1}\n\\\\ &= \\frac{\\pi t + 2 \\log(2) - 4 \\log(t+1)}{4(t^2+1)},\n\\end{align*}\nwhence\n\\[\nf(t) = \\frac{\\log(2) \\arctan(t)}{2} + \\frac{\\pi \\log(t^2+1)}{8}\n- \\int_0^t \\frac{\\log(t+1)}{t^2+1}\\,dt\n\\]\nand hence\n\\[\nf(1) = \\frac{\\pi \\log(2)}{4} - \\int_0^1 \\frac{\\log(t+1)}{t^2+1}\\,dt.\n\\]\nBut the integral on the right is again the desired integral $f(1)$, so\nwe may move it to the left to obtain\n\\[\n2f(1) = \\frac{\\pi \\log(2)}{4}\n\\]\nand hence $f(1) = \\pi \\log(2)/8$ as desired.\n\n\\textbf{Fourth solution:} (by David Rusin)\nWe have\n\\[\n\\int_0^1 \\frac{\\log(x+1)}{x^2+1}\\,dx =\n\\int_0^1 \\left( \\sum_{n=1}^\\infty \\frac{(-1)^{n-1} x^n}{n(x^2+1)} \\right)\\,dx.\n\\]\nWe next justify moving the sum  through the integral sign.\nNote that\n\\[\n\\sum_{n=1}^\\infty \\int_0^1 \\frac{(-1)^{n-1} x^n\\,dx}{n(x^2+1)}\n\\]\nis an alternating series whose terms strictly decrease to zero, so it\nconverges. Moreover, its partial sums alternately bound the previous\nintegral above and below, so the sum of the series coincides with the integral.\n\nPut\n\\[\nJ_n = \\int_0^1 \\frac{x^n\\,dx}{x^2+1};\n\\]\nthen $J_0 = \\arctan(1) = \\frac{\\pi}{4}$\nand $J_1 = \\frac{1}{2} \\log(2)$. Moreover,\n\\[\nJ_{n} + J_{n+2} = \\int_0^1 x^n\\,dx = \\frac{1}{n+1}.\n\\]\nWrite\n\\begin{align*}\nA_m &= \\sum_{i=1}^m \\frac{(-1)^{i-1}}{2i-1} \\\\\nB_m &= \\sum_{i=1}^m \\frac{(-1)^{i-1}}{2i};\n\\end{align*}\nthen\n\\begin{align*}\nJ_{2n} &= (-1)^n (J_0 - A_n) \\\\\nJ_{2n+1} &= (-1)^n (J_1 - B_{n}).\n\\end{align*}\nNow the $2N$-th partial sum of our series equals\n\\begin{multline*}\n\\sum_{n=1}^{N} \\left[\\frac{J_{2n-1}}{2n-1} -  \\frac{J_{2n}}{2n}\\right] \\\\\n\\begin{aligned}\n&= \\sum_{n=1}^{N} \\frac{(-1)^{n-1}}{2n-1} \\left[(J_1 - B_{n-1})\n- \\frac{(-1)^n}{2n}(J_0 - A_n)\\right] \\\\\n&= A_{N}(J_1 - B_{N-1}) + B_N(J_0 - A_N) + A_N B_N.\n\\end{aligned}\n\\end{multline*}\nAs $N \\to \\infty$, $A_N \\to J_0$ and $B_N \\to J_1$,\nso the sum tends to $J_0 J_1 = \\pi \\log(2)/8$.\n\n\\textbf{Fifth solution:}\n(suggested by Alin Bostan)\nNote that\n\\[\n\\log(1+x) = \\int_0^1 \\frac{x\\,dy}{1 + xy},\n\\]\nso the desired integral $I$ may be written as\n\\[\nI = \\int_0^1 \\int_0^1 \\frac{x\\,dy\\,dx}{(1 + xy)(1+x^2)}.\n\\]\nWe may interchange $x$ and $y$ in this expression, then use Fubini's theorem to interchange\nthe order of summation, to obtain\n\\[\nI = \\int_0^1 \\int_0^1 \\frac{y\\,dy\\,dx}{(1 + xy)(1+y^2)}.\n\\]\nWe then add these expressions to obtain\n\\begin{align*}\n2I &= \\int_0^1 \\int_0^1 \\left( \\frac{x}{1+x^2} + \\frac{y}{1+y^2}\n\\right) \\frac{dy\\,dx}{1+xy} \\\\\n&= \\int_0^1 \\int_0^1  \\frac{x+y+xy^2+x^2y}{(1+x^2)(1+y^2)} \\frac{dy\\,dx}{1+xy}  \\\\\n&= \\int_0^1 \\int_0^1  \\frac{(x+y)\\,dy\\,dx}{(1+x^2)(1+y^2)}.\n\\end{align*}\nBy another symmetry argument, we have\n\\[\n2I = 2 \\int_0^1 \\int_0^1 \\frac{x\\,dy\\,dx}{(1+x^2)(1+y^2)},\n\\]\nso\n\\[\nI = \\left(\\int_0^1 \\frac{x\\,dx}{1+x^2} \\right) \\left( \\int_0^1 \\frac{1}{1+y^2} \\right)\n= \\log(2) \\cdot \\frac{\\pi}{8}.\n\\]\n\n\\textbf{Remarks:}\nThe first two solutions are related by the fact that if $x = \\tan(\\theta)$,\nthen $1-x/(1+x) = \\tan(\\pi/4 - \\theta)$.\nThe strategy of the third solution (introducing a parameter then\ndifferentiating it) was a favorite of physics Nobelist (and Putnam Fellow)\nRichard Feynman.\nThe fifth solution resembles Gauss's evaluation of $\\int_{-\\infty}^\\infty \\exp(-x^2)\\,dx$.\nNoam Elkies notes that this integral is number 2.491\\#8 in\nGradshteyn and Ryzhik,\n\\textit{Table of integrals, series, and products}.\nThe \\emph{Mathematica} computer algebra system (version 5.2)\nsuccessfully computes\nthis integral, but we do not know how."
  },
  {
    "year": 2005,
    "label": "A6",
    "difficulty": "6",
    "problem": "Let $n$ be given, $n \\geq 4$, and suppose that $P_1, P_2, \\dots, P_n$\nare $n$ randomly, independently and uniformly, chosen points on a circle.\nConsider the convex $n$-gon whose vertices are the $P_i$. What is the\nprobability that at least one of the vertex angles of this polygon is\nacute?",
    "solution": "\\textbf{First solution:}\nThe angle at a vertex $P$ is acute if and only if all of the other points\nlie on an open semicircle. We first deduce from this that if there are any\ntwo acute angles at all, they must occur consecutively. Suppose the contrary;\nlabel the vertices $Q_1, \\dots, Q_n$ in counterclockwise order (starting anywhere),\nand suppose that the angles at $Q_1$ and $Q_i$ are acute for some $i$\nwith $3 \\leq i \\leq n-1$.\nThen the open semicircle starting at $Q_2$ and proceeding counterclockwise\nmust contain all of $Q_3, \\dots, Q_n$, while the open semicircle starting at\n$Q_i$ and proceeding counterclockwise must contain $Q_{i+1}, \\dots,\nQ_n, Q_1, \\dots, Q_{i-1}$. Thus two open semicircles cover the entire circle,\ncontradiction.\n\nIt follows that if the polygon has at least one acute angle, then\nit has either one acute angle or two acute angles\noccurring consecutively. In particular, there\nis a unique pair of consecutive vertices $Q_1, Q_2$ in counterclockwise order\nfor which $\\angle Q_2$ is acute and $\\angle Q_1$ is not acute.\nThen the remaining points all lie in the arc from the antipode of $Q_1$\nto $Q_1$, but $Q_2$ cannot lie in the arc, and the remaining points\ncannot all lie in the arc from the antipode of $Q_1$ to the antipode\nof $Q_2$. Given the choice of $Q_1, Q_2$, let $x$ be the measure of\nthe counterclockwise arc from $Q_1$ to $Q_2$; then the probability that\nthe other points fall into position is\n$2^{-n+2} - x^{n-2}$ if $x \\leq 1/2$ and 0 otherwise.\n\nHence the probability that the polygon has at least one acute angle with\na \\emph{given} choice of which two points will act as $Q_1$ and $Q_2$ is\n\\[\n\\int_0^{1/2} (2^{-n+2} - x^{n-2})\\,dx\n= \\frac{n-2}{n-1} 2^{-n+1}.\n\\]\nSince there are $n(n-1)$ choices for which two points act as $Q_1$ and $Q_2$,\nthe probability of at least one acute angle is $n(n-2) 2^{-n+1}$.\n\n\\textbf{Second solution:}\n(by Calvin Lin)\nAs in the first solution, we may compute the probability that for a\nparticular one of the points $Q_1$, the angle at $Q_1$ is not acute but\nthe following angle is, and then multiply by $n$.\nImagine picking the points by first choosing $Q_1$, then\npicking $n-1$ \\emph{pairs}\nof antipodal points and then picking one\nmember of each pair. Let $R_2, \\dots, R_n$ be the points of the pairs\nwhich lie in the semicircle, taken in order away from $Q_1$,\nand let $S_2, \\dots, S_n$ be the antipodes of these. Then to\nget the desired situation,\nwe must choose from the pairs to end up with all but one of the\n$S_i$, and we cannot take $R_n$ and the other $S_i$ or else $\\angle Q_1$ will be\nacute. That gives us $(n-2)$ good choices out of $2^{n-1}$; since we could\nhave chosen $Q_1$ to be any of the $n$ points, the probability is again\n$n(n-2) 2^{-n+1}$."
  },
  {
    "year": 2005,
    "label": "B1",
    "difficulty": "1",
    "problem": "Find a nonzero polynomial $P(x,y)$ such that $P(\\lfloor a \\rfloor,\n\\lfloor 2a \\rfloor) = 0$ for all real numbers $a$.\n(Note: $\\lfloor \\nu \\rfloor$ is the greatest integer less than\nor equal to $\\nu$.)",
    "solution": "Take $P(x,y) = (y-2x)(y-2x-1)$.\nTo see that this works, first note that if $m = \\lfloor a \\rfloor$,\nthen $2m$ is an integer less than or equal to $2a$, so\n$2m \\leq \\lfloor 2a \\rfloor$. On the other hand, $m+1$\nis an integer strictly greater than $a$, so $2m+2$ is an integer\nstrictly greater than $2a$, so $\\lfloor 2a \\rfloor \\leq 2m+1$."
  },
  {
    "year": 2005,
    "label": "B2",
    "difficulty": "2",
    "problem": "Find all positive integers $n, k_1, \\dots, k_n$ such that\n$k_1 + \\cdots + k_n = 5n-4$ and\n\\[\n\\frac{1}{k_1} + \\cdots + \\frac{1}{k_n} = 1.\n\\]",
    "solution": "By the arithmetic-harmonic mean inequality or the Cauchy-Schwarz inequality,\n\\[\n(k_1 + \\cdots + k_n)\\left(\\frac{1}{k_1} + \\cdots + \\frac{1}{k_n} \\right)\n\\geq n^2.\n\\]\nWe must thus have $5n-4 \\geq n^2$, so $n \\leq 4$. Without loss of generality,\nwe may suppose that $k_1 \\leq \\cdots \\leq k_n$.\n\nIf $n=1$, we must have $k_1 = 1$, which works. Note that hereafter we cannot\nhave $k_1 =1$.\n\nIf $n = 2$, we have $(k_1,k_2) \\in \\{(2,4), (3,3)\\}$, neither of which work.\n\nIf $n=3$, we have $k_1 +k_2 +k_3 =11$, so $2 \\leq k_1 \\leq 3$.\nHence\n\\[\n(k_1,k_2,k_3) \\in \\{(2,2,7),(2,3,6),(2,4,5),(3,3,5),(3,4,4)\\},\n\\]\nand only $(2,3,6)$ works.\n\nIf $n = 4$, we must have equality in the AM-HM inequality, which only\nhappens when $k_1 = k_2 = k_3 = k_4 = 4$.\n\nHence the solutions are $n = 1$ and $k_1 = 1$,\n$n=3$ and $(k_1,k_2,k_3)$ is a permutation of $(2,3,6)$,\nand $n=4$ and $(k_1,k_2,k_3,k_4) = (4,4,4,4)$.\n\n\\textbf{Remark:}\nIn the cases $n=2,3$, Greg Kuperberg suggests the alternate\napproach of\nenumerating the\nsolutions of $1/k_1 + \\cdots + 1/k_n = 1$ with $k_1 \\leq \\cdots \\leq k_n$.\nThis is easily done by\nproceeding in lexicographic order: one obtains $(2,2)$ for $n=2$, and\n$(2,3,6), (2,4,4), (3,3,3)$ for $n=3$, and only $(2,3,6)$ contributes\nto the final answer."
  },
  {
    "year": 2005,
    "label": "B3",
    "difficulty": "3",
    "problem": "Find all differentiable functions $f: (0, \\infty) \\to (0, \\infty)$ for which\nthere is a positive real number $a$ such that\n\\[\nf' \\left( \\frac{a}{x} \\right) = \\frac{x}{f(x)}\n\\]\nfor all $x > 0$.",
    "solution": "\\textbf{First solution:}\nThe functions are precisely $f(x) = cx^d$ for $c,d > 0$ arbitrary\nexcept that we must take $c=1$ in case $d=1$. To see that these work,\nnote that $f'(a/x) = d c (a/x)^{d-1}$ and $x/f(x) = 1/(c x^{d-1})$,\nso the given equation holds if and only if $d c^2 a^{d-1} = 1$. If\n$d \\neq 1$, we may solve for $a$ no matter what $c$ is; if\n$d=1$, we must have $c=1$. (Thanks to Brad Rodgers for pointing out\nthe $d=1$ restriction.)\n\nTo check that these are all solutions,\nput $b = \\log(a)$ and $y = \\log(a/x)$; rewrite the given equation as\n\\[\nf(e^{b-y}) f'(e^y) = e^{b-y}.\n\\]\nPut\n\\[\ng(y) = \\log f(e^y);\n\\]\nthen the given equation rewrites as\n\\[\ng(b-y) + \\log g'(y) + g(y) - y = b-y,\n\\]\nor\n\\[\n\\log g'(y) = b -g(y) - g(b-y).\n\\]\nBy the symmetry of the right side,\nwe have $g'(b-y) = g'(y)$. Hence the function\n$g(y) + g(b-y)$ has zero derivative and so is constant,\nas then is $g'(y)$.\nFrom this we deduce that $f(x) = cx^d$ for some $c,d$, both\nnecessarily positive since $f'(x) > 0$ for all $x$.\n\n\\textbf{Second solution:}\n(suggested by several people)\nSubstitute $a/x$ for $x$ in the given equation:\n\\[\nf'(x) = \\frac{a}{xf(a/x)}.\n\\]\nDifferentiate:\n\\[\nf''(x) = - \\frac{a}{x^2 f(a/x)}\n+ \\frac{a^2 f'(a/x)}{x^3 f(a/x)^2}.\n\\]\nNow substitute to eliminate evaluations at $a/x$:\n\\[\nf''(x) = - \\frac{f'(x)}{x}\n+ \\frac{f'(x)^2}{f(x)}.\n\\]\nClear denominators:\n\\[\nx f(x) f''(x) + f(x) f'(x) = x f'(x)^2.\n\\]\nDivide through by $f(x)^2$ and rearrange:\n\\[\n0 = \\frac{f'(x)}{f(x)} + \\frac{x f''(x)}{f(x)} - \\frac{x f'(x)^2}{f(x)^2}.\n\\]\nThe right side is the derivative of $x f'(x)/f(x)$, so that quantity\nis constant. That is, for some $d$,\n\\[\n\\frac{f'(x)}{f(x)} = \\frac{d}{x}.\n\\]\nIntegrating yields $f(x) = cx^d$, as desired."
  },
  {
    "year": 2005,
    "label": "B4",
    "difficulty": "4",
    "problem": "For positive integers $m$ and $n$, let $f(m,n)$ denote the number of\n$n$-tuples $(x_1,x_2,\\dots,x_n)$ of integers such that\n$|x_1| + |x_2| + \\cdots + |x_n| \\leq m$.\nShow that $f(m,n) = f(n,m)$.",
    "solution": "\\textbf{First solution:}\nDefine $f(m,n,k)$ as the number of $n$-tuples $(x_1, x_2,\\dots,x_n)$\nof integers such that $|x_1| + \\cdots + |x_n| \\leq m$ and exactly\n$k$ of $x_1, \\dots, x_n$ are nonzero. To choose such a tuple, we may choose\nthe $k$ nonzero positions, the signs of those $k$ numbers, and\nthen an ordered $k$-tuple of positive integers with sum $\\leq m$.\nThere are $\\binom{n}{k}$ options for the first choice, and $2^k$ for the\nsecond. As for the third, we have\n$\\binom{m}{k}$ options by a ``stars and bars'' argument: depict the\n$k$-tuple by drawing a number of stars for each term, separated by bars,\nand adding stars at the end to get a total of $m$ stars. Then each tuple\ncorresponds to placing $k$ bars, each in a different position behind one\nof the $m$ fixed stars.\n\nWe conclude that\n\\[\nf(m,n,k) = 2^k\\binom{m}{k} \\binom{n}{k} = f(n,m,k);\n\\]\nsumming over $k$ gives $f(m,n) = f(n,m)$. (One may also extract easily a\nbijective interpretation of the equality.)\n\n\\textbf{Second solution:}\n(by Greg Kuperberg)\nIt will be convenient to extend the definition of $f(m,n)$ to $m,n \\geq 0$,\nin which case we have $f(0,m) = f(n,0) = 1$.\n\nLet $S_{m,n}$ be the set of $n$-tuples $(x_1, \\dots, x_n)$ of integers\nsuch that $|x_1| + \\cdots + |x_n| \\leq m$. Then elements of $S_{m,n}$\ncan be classified into three types. Tuples with $|x_1| + \\cdots + |x_n| < m$\nalso belong to $S_{m-1,n}$. Tuples with $|x_1| + \\cdots + |x_n| = m$\nand $x_n \\geq 0$ correspond to elements of $S_{m,n-1}$ by dropping $x_n$.\nTuples with $|x_1| + \\cdots + |x_n| = m$ and $x_n < 0$ correspond to\nelements of $S_{m-1,n-1}$ by dropping $x_n$. It follows that\n\\[\nf(m,n) = f(m-1,n) + f(m,n-1) + f(m-1,n-1),\n\\]\nso $f$ satisfies a symmetric recurrence with symmetric boundary conditions\n$f(0,m) = f(n,0) = 1$. Hence $f$ is symmetric.\n\n\\def\\ZZ{\\mathbb{Z}}\n\\textbf{Third solution:}\n(by Greg Martin)\nAs in the second solution,\nit is convenient to allow $f(m,0)=f(0,n)=1$. Define the generating function\n\\[\nG(x,y) = \\sum_{m=0}^\\infty \\sum_{n=0}^\\infty f(m,n) x^m y^n.\n\\]\nAs equalities of formal power series (or convergent series on,\nsay, the region $|x|,|y|<\\frac13$), we have\n\\begin{align*}\nG(x,y) &= \\sum_{m\\ge0} \\sum_{n\\ge0} x^m y^n \\sum_{\\substack{k_1,\\,\\dots,\\,k_n \\in \\ZZ \\\\ |k_1| + \\cdots + |k_n| \\le m}} 1 \\\\\n&= \\sum_{n\\ge0} y^n \\sum_{k_1,\\,\\dots,\\,k_n \\in \\ZZ} \\sum_{m\\ge|k_1| + \\cdots + |k_n|} x^m \\\\\n&= \\sum_{n\\ge0} y^n \\sum_{k_1,\\,\\dots,\\,k_n \\in \\ZZ} \\frac{x^{|k_1| + \\cdots + |k_n|}}{1-x} \\\\\n&= \\frac1{1-x} \\sum_{n\\ge0} y^n \\bigg( \\sum_{k\\in\\ZZ} x^{|k|} \\bigg)^n \\\\\n&= \\frac1{1-x} \\sum_{n\\ge0} y^n \\bigg( \\frac{1+x}{1-x} \\bigg)^n \\\\\n&= \\frac1{1-x} \\cdot \\frac1{1-y(1+x)/(1-x)} \\\\\n&= \\frac1{1-x-y-xy}.\n\\end{align*}\nSince $G(x,y) = G(y,x)$, it follows that $f(m,n) = f(n,m)$ for all $m,n\\ge0$."
  },
  {
    "year": 2005,
    "label": "B5",
    "difficulty": "5",
    "problem": "Let $P(x_1,\\dots,x_n)$ denote a polynomial with real coefficients in the\nvariables $x_1, \\dots, x_n$, and suppose that\n\\[\n\\left( \\frac{\\partial^2}{\\partial x_1^2} + \\cdots + \\frac{\\partial^2}{\\partial\nx_n^2}\\right) P(x_1, \\dots,x_n) = 0 \\quad \\mbox{(identically)}\n\\] % Equation labelled (a) (label to the left of the equation) in AMM version.\nand that\n\\[\nx_1^2 + \\cdots + x_n^2 \\mbox{ divides } P(x_1, \\dots, x_n).\n\\] % Equation labelled (b) (label to the left of the equation) in AMM version.\nShow that $P=0$ identically.",
    "solution": "\\textbf{First solution:}\nPut $Q = x_1^2 + \\cdots + x_n^2$. Since $Q$ is homogeneous, $P$ is divisible\nby $Q$ if and only if each of the homogeneous components of $P$ is divisible\nby $Q$. It is thus sufficient to solve the problem in case $P$ itself is\nhomogeneous, say of degree $d$.\n\nSuppose that we have a factorization $P = Q^m R$ for some $m>0$, where\n$R$ is homogeneous\nof degree $d$ and not divisible by $Q$;\nnote that the homogeneity implies that\n\\[\n\\sum_{i=1}^n x_i \\frac{\\partial R}{\\partial x_i} = dR.\n\\]\nWrite $\\nabla^2$ as shorthand for $\\frac{\\partial^2}{\\partial\nx_1^2} + \\cdots + \\frac{\\partial^2}{\\partial x_n^2}$; then\n\\begin{align*}\n0 &= \\nabla^2 P \\\\\n&= 2mn Q^{m-1}R + Q^m \\nabla^2 R + 2 \\sum_{i=1}^n 2mx_i Q^{m-1}\n\\frac{\\partial R}{\\partial\nx_i} \\\\\n&= Q^m \\nabla^2 R + (2mn + 4md) Q^{m-1} R.\n\\end{align*}\nSince $m>0$, this forces $R$ to be divisible by $Q$, contradiction.\n\n\\textbf{Second solution:}\n(by Noam Elkies)\nRetain notation as in the first solution.\nLet $P_d$ be the set of homogeneous\npolynomials of degree $d$, and let $H_d$ be the subset of $P_d$\nof polynomials killed by $\\nabla^2$, which has dimension\n$\\geq \\dim(P_d) - \\dim(P_{d-2})$; the given problem amounts to showing\nthat this inequality is actually an equality.\n\nConsider the operator $Q \\nabla^2$ (i.e., apply $\\nabla^2$ then multiply\nby $Q$) on $P_d$; its zero eigenspace is precisely $H_d$.\nBy the calculation from the first solution, if $R \\in P_d$, then\n\\[\n\\nabla^2 (QR) - Q \\nabla^2 R = (2n+4d)R.\n\\]\nConsequently, $Q^j H_{d-2j}$ is contained in the eigenspace of $Q \\nabla^2$\non $P_d$ of eigenvalue\n\\[\n(2n+4(d-2j)) + \\cdots + (2n+4(d-2)).\n\\]\nIn particular, the $Q^j H^{d-2j}$ lie in distinct eigenspaces, so are\nlinearly independent within $P_d$. But by dimension counting,\ntheir total dimension is at least that of $P_d$.\nHence they exhaust $P_d$, and the zero eigenspace cannot have dimension\ngreater than $\\dim(P_d) - \\dim(P_{d-2})$, as desired.\n\n\\textbf{Third solution:}\n(by Richard Stanley)\nWrite $x = (x_1, \\dots, x_n)$ and $\\nabla = (\\frac{\\partial}{\\partial x_1},\n\\dots, \\frac{\\partial}{\\partial x_n})$.\nSuppose that $P(x) = Q(x)(x_1^2 + \\cdots + x_n^2)$. Then\n\\[\nP(\\nabla)P(x) = Q(\\nabla)(\\nabla^2)P(x) =0.\n\\]\nOn the other hand,\nif $P(x) = \\sum_\\alpha c_\\alpha x^\\alpha$ (where $\\alpha = (\\alpha_1,\n\\dots, \\alpha_n)$ and $x^\\alpha = x_1^{\\alpha_1} \\cdots\nx_n^{\\alpha_n}$), then the constant term of $P(\\nabla)P(x)$\nis seen to be $\\sum_\\alpha c_\\alpha^2$. Hence $c_\\alpha = 0$ for all\n$\\alpha$.\n\n\\textbf{Remarks:}\nThe first two solutions apply directly over any field of characteristic zero.\n(The result fails in characteristic $p>0$ because we may take\n$P = (x_1^2 + \\cdots + x_n^2)^p = x_1^{2p} + \\cdots + x_n^{2p}$.)\nThe third solution can be extended to complex coefficients\nby replacing $P(\\nabla)$ by its complex conjugate, and again the result\nmay be deduced for any field of characteristic zero.\nStanley also suggests\nSection 5 of the arXiv e-print \\texttt{math.CO/0502363} for\nsome  algebraic background for this problem."
  },
  {
    "year": 2005,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $S_n$ denote the set of all permutations of the numbers $1,2,\\dots,n$.\nFor $\\pi \\in S_n$, let $\\sigma(\\pi) = 1$ if $\\pi$ is an even permutation\nand $\\sigma(\\pi) = -1$ if $\\pi$ is an odd permutation.\nAlso, let $\\nu(\\pi)$ denote the number of fixed points of $\\pi$.\nShow that\n\\[\n\\sum_{\\pi \\in S_n} \\frac{\\sigma(\\pi)}{\\nu(\\pi) + 1} = (-1)^{n+1}\n\\frac{n}{n+1}.\n\\]\n\\end{itemize}\n\\end{document}",
    "solution": "\\textbf{First solution:}\nLet $I$ be the identity matrix, and let\n$J_x$ be the matrix with $x$'s on the diagonal and 1's elsewhere.\nNote that $J_x - (x-1)I$, being the all 1's matrix, has rank 1 and trace $n$,\nso has $n-1$ eigenvalues equal to 0 and one equal to $n$.\nHence $J_x$ has $n-1$ eigenvalues equal to $x-1$ and one equal to $x+n-1$,\nimplying\n\\[\n\\det J_x = (x+n-1)(x-1)^{n-1}.\n\\]\nOn the other hand, we may expand the determinant as a sum indexed by\npermutations, in which case we get\n\\[\n\\det J_x = \\sum_{\\pi \\in S_n} \\sgn(\\pi) x^{\\nu(\\pi)}.\n\\]\nIntegrating both sides from 0 to 1 (and substituting $y=1-x$) yields\n\\begin{align*}\n\\sum_{\\pi \\in S_n} \\frac{\\sgn(\\pi)}{\\nu(\\pi) + 1}\n&= \\int_0^1 (x+n-1)(x-1)^{n-1}\\,dx \\\\\n&= \\int_0^1 (-1)^{n+1} (n-y)y^{n-1}\\,dy \\\\\n&= (-1)^{n+1} \\frac{n}{n+1},\n\\end{align*}\nas desired.\n\n\\textbf{Second solution:}\nWe start by recalling a form of the principle of inclusion-exclusion:\nif $f$ is a function on the power set of $\\{1, \\dots, n\\}$, then\n\\[\nf(S) = \\sum_{T \\supseteq S} (-1)^{|T|-|S|} \\sum_{U \\supseteq T} f(U).\n\\]\nIn this case we take $f(S)$ to be the sum of $\\sigma(\\pi)$\nover all permutations $\\pi$ whose fixed points are exactly $S$.\nThen $\\sum_{U \\supseteq T} f(U) = 1$ if $|T| \\geq n-1$\nand 0 otherwise (since a permutation group on 2 or more symbols has as many even and odd permutations), so\n\\[\nf(S) = (-1)^{n-|S|}(1 - n + |S|).\n\\]\nThe desired sum can thus be written, by grouping over fixed point sets, as\n\\begin{multline*}\n\\sum_{i=0}^n \\binom{n}{i} (-1)^{n-i} \\frac{1-n+i}{i+1} \\\\\n\\begin{aligned}\n&= \\sum_{i=0}^n (-1)^{n-i} \\binom{n}{i} - \\sum_{i=0}^n (-1)^{n-i} \\frac{n}{i+1}\n\\binom{n}{i} \\\\\n&= 0 - \\sum_{i=0}^n (-1)^{n-i} \\frac{n}{n+1} \\binom{n+1}{i+1} \\\\\n&= (-1)^{n+1} \\frac{n}{n+1}.\n\\end{aligned}\n\\end{multline*}\n\n\\textbf{Third solution:}\n(by Richard Stanley)\nThe \\emph{cycle indicator} of the symmetric group $S_n$ is defined by\n\\[\nZ_n(x_1, \\dots, x_n) = \\sum_{\\pi \\in S_n} x_1^{c_1(\\pi)} \\cdots x_n^{c_n(\\pi)},\n\\]\nwhere $c_i(\\pi)$ is the number of cycles of $\\pi$ of length $i$.\nPut\n\\[\nF_n = \\sum_{\\pi \\in S_n} \\sigma(\\pi) x^{\\nu(\\pi)} =\nZ_n(x,-1,1,-1,1,\\dots)\n\\]\nand\n\\[\nf(n) =  \\sum_{\\pi \\in S_n} \\frac{\\sigma(\\pi)}{\\nu(\\pi) + 1}\n= \\int_0^1 F_n(x)\\,dx.\n\\]\nA standard argument in enumerative combinatorics (the\nExponential Formula) gives\n\\[\n\\sum_{n=0}^\\infty Z_n(x_1,\\dots,x_n) \\frac{t^n}{n!}\n= \\exp \\sum_{k=1}^{\\infty} x_k \\frac{t^k}{k},\n\\]\nyielding\n\\begin{align*}\n\\sum_{n=0}^\\infty\nf(n) \\frac{t^n}{n!} &= \\int_0^1 \\exp \\left( xt - \\frac{t^2}{2}\n+ \\frac{t^3}{3} - \\cdots \\right)\\,dx \\\\\n&= \\int_0^1 e^{(x-1)t + \\log(1+t)}\\,dx \\\\\n&= \\int_0^1 (1+t) e^{(x-1)t}\\,dx \\\\\n&= \\frac{1}{t} (1-e^{-t}) (1+t).\n\\end{align*}\nExpanding the right side as a Taylor series and comparing coefficients\nyields the desired result.\n\n\\textbf{Fourth solution (sketch):}\n(by David Savitt)\nWe prove the identity of rational functions\n\\[\n\\sum_{\\pi \\in S_n} \\frac{\\sigma(\\pi)}{\\nu(\\pi) + x}\n= \\frac{(-1)^{n+1} n! (x+n-1)}{x(x+1)\\cdots(x+n)}\n\\]\nby induction on $n$, which for $x=1$ implies the desired result.\n(This can also be deduced as in the other solutions, but in this argument\nit is necessary to formulate the strong induction hypothesis.)\n\nLet $R(n,x)$ be the right hand side of the above equation. It is\neasy to verify that\n\\begin{align*}\nR(x,n) &= R(x+1,n-1) + (n-1)! \\frac{(-1)^{n+1}}{x} \\\\\n&\\qquad + \\sum_{l=2}^{n-1} (-1)^{l-1}  \\frac{(n-1)!}{(n-l)!} R(x,n-l),\n\\end{align*}\nsince the sum telescopes. To prove the desired equality,\nit suffices to show that the left hand side satisfies the same\nrecurrence. This follows because we can classify each $\\pi \\in S_n$\nas either fixing $n$, being an $n$-cycle, or having $n$ in an\n$l$-cycle for one of $l=2,\\dots,n-1$; writing the sum\nover these classes gives the desired recurrence.\n\n\\end{itemize}\n\n\n\\end{document}"
  },
  {
    "year": 2006,
    "label": "A1",
    "difficulty": "1",
    "problem": "Find the volume of the region of points $(x,y,z)$ such that\n\\[\n(x^2 + y^2 + z^2 + 8)^2 \\leq 36(x^2 + y^2).\n\\]",
    "solution": "We change to cylindrical coordinates, i.e., we put $r = \\sqrt{x^2 + y^2}$.\nThen the given inequality is equivalent to\n\\[\nr^2 + z^2 + 8 \\leq 6r,\n\\]\nor\n\\[\n(r-3)^2 + z^2 \\leq 1.\n\\]\nThis defines a solid of revolution (a solid torus); the area being rotated\nis the disc $(x-3)^2 + z^2 \\leq 1$ in the $xz$-plane. By Pappus's theorem,\nthe volume of this equals the area of this disc, which is $\\pi$, times the\ndistance through which the center of mass is being rotated, which is $(2\\pi)3$.\nThat is, the total volume is $6 \\pi^2$."
  },
  {
    "year": 2006,
    "label": "A2",
    "difficulty": "2",
    "problem": "Alice and Bob play a game in which they take turns removing stones from\na heap that initially has $n$ stones. The number of stones removed at\neach turn must be one less than a prime number. The winner is the player\nwho takes the last stone. Alice plays first. Prove that there are\ninfinitely many $n$ such that Bob has a winning strategy.\n(For example, if $n=17$, then Alice might take 6 leaving 11; then\nBob might take 1 leaving 10; then Alice can take the remaining stones\nto win.)",
    "solution": "Suppose on the contrary that the set $B$ of values of $n$ for which Bob\nhas a winning strategy is finite; for convenience, we include $n=0$ in $B$,\nand write $B = \\{b_1, \\dots, b_m\\}$.\nThen for every nonnegative integer $n$ not\nin $B$, Alice must have some move on a heap of $n$ stones leading to a\nposition in which the second player wins. That is, every nonnegative integer\nnot in $B$ can be written as $b + p - 1$ for some $b \\in B$ and some prime\n$p$. However, there are numerous ways to show that this cannot happen.\n\n\\textbf{First solution:}\nLet $t$ be any integer bigger than all of the $b \\in B$. Then it is easy to\nwrite down $t$ consecutive composite integers, e.g., $(t+1)! + 2, \\dots,\n(t+1)! + t+1$. Take $n = (t+1)! + t$; then for each $b \\in B$,\n$n - b + 1$ is one of the composite integers we just wrote down.\n\n\\textbf{Second solution:}\nLet $p_1, \\dots, p_{2m}$ be\nany prime numbers; then by the Chinese remainder theorem, there exists a\npositive integer $x$ such that\n\\begin{align*}\nx - b_1 &\\equiv -1 \\pmod{p_1 p_{m+1}} \\\\\n\\dots \\\\\nx - b_n &\\equiv -1 \\pmod{p_m p_{2m}}.\n\\end{align*}\nFor each $b \\in B$,\nthe unique integer $p$ such that $x=b+p-1$ is divisible\nby at least two primes, and so cannot itself be prime.\n\n\\textbf{Third solution:} (by Catalin Zara)\nPut $b_1 = 0$, and take $n = (b_2 - 1)\\cdots(b_m - 1)$; then $n$ is\ncomposite because $3, 8 \\in B$, and for any nonzero $b \\in B$,\n$n - b_i + 1$ is divisible by but not equal to $b_i - 1$.\n(One could also take $n = b_2 \\cdots b_m - 1$, so that\n$n-b_i+1$ is divisible by $b_i$.)"
  },
  {
    "year": 2006,
    "label": "A3",
    "difficulty": "3",
    "problem": "Let $1, 2, 3, \\dots, 2005, 2006, 2007, 2009, 2012, 2016, \\dots$\nbe a sequence defined by $x_k = k$ for $k=1, 2, \\dots, 2006$ and\n$x_{k+1} = x_k + x_{k-2005}$ for $k \\geq 2006$. Show that the sequence has\n2005 consecutive terms each divisible by 2006.",
    "solution": "We first observe that given any sequence of integers\n$x_1, x_2, \\dots$ satisfying a recursion\n\\[\nx_k = f(x_{k-1}, \\dots, x_{k-n}) \\qquad (k > n),\n\\]\nwhere $n$ is fixed and $f$ is a fixed polynomial of $n$ variables with\ninteger coefficients, for any positive integer $N$, the sequence modulo $N$\nis eventually periodic. This is simply because there are only finitely many\npossible sequences of $n$ consecutive values modulo $N$, and once such\na sequence is repeated, every subsequent value is repeated as well.\n\nWe next observe that if one can rewrite the same recursion as\n\\[\nx_{k-n} = g(x_{k-n+1}, \\dots, x_k) \\qquad (k > n),\n\\]\nwhere $g$ is also a polynomial with integer coefficients, then\nthe sequence extends uniquely to a doubly infinite sequence $\\dots,\nx_{-1}, x_0, x_1, \\dots$ which is fully periodic modulo any $N$.\nThat is the case in the\nsituation at hand, because we can rewrite the given recursion as\n\\[\nx_{k-2005} = x_{k+1} - x_k.\n\\]\nIt thus suffices to find 2005 consecutive terms divisible by $N$ in the\ndoubly infinite sequence, for any fixed $N$ (so in particular for\n$N = 2006$).\nRunning the recursion backwards, we easily find\n\\begin{gather*}\nx_1 = x_0 = \\cdots = x_{-2004} = 1 \\\\\nx_{-2005} = \\cdots = x_{-4009} = 0,\n\\end{gather*}\nyielding the desired result."
  },
  {
    "year": 2006,
    "label": "A4",
    "difficulty": "4",
    "problem": "Let $S = \\{1, 2, \\dots, n\\}$ for some integer $n > 1$. Say a permutation\n$\\pi$ of $S$ has a \\emph{local maximum} at $k \\in S$ if\n\\begin{enumerate} % The for parts are aligned in the AMM version",
    "solution": "\\textbf{First solution:}\nBy the linearity of expectation, the average number of local maxima is equal\nto the sum of the probability of having a local maximum at $k$ over\n$k=1,\\dots, n$.\nFor $k=1$, this probability is 1/2: given the pair\n$\\{\\pi(1), \\pi(2)\\}$, it is equally likely that $\\pi(1)$ or $\\pi(2)$ is\nbigger. Similarly, for $k=n$, the probability is 1/2. For $1 < k < n$,\nthe probability is 1/3: given the pair $\\{\\pi(k-1), \\pi(k), \\pi(k+1)\\}$,\nit is equally likely that any of the three is the largest.\nThus the average number of local maxima is\n\\[\n2 \\cdot \\frac{1}{2} + (n-2) \\cdot \\frac{1}{3} =\n\\frac{n+1}{3}.\n\\]\n\n\\textbf{Second solution:}\nAnother way to apply the linearity of expectation is to compute the\nprobability that $i \\in \\{1, \\dots, n\\}$ occurs as a local maximum.\nThe most efficient way to do this is to imagine the permutation\nas consisting of the symbols $1, \\dots, n, *$ written in a circle in\nsome order. The number $i$ occurs as a local maximum if the two symbols\nit is adjacent to both belong to the set $\\{*, 1, \\dots, i-1\\}$. There are\n$i(i-1)$ pairs of such symbols and $n(n-1)$ pairs in total, so the\nprobability of $i$ occurring as a local maximum is $i(i-1)/(n(n-1))$, and\nthe average number of local maxima is\n\\begin{align*}\n\\sum_{i=1}^n \\frac{i(i-1)}{n(n-1)} &=\n\\frac{2}{n(n-1)} \\sum_{i=1}^n \\binom{i}{2} \\\\\n&= \\frac{2}{n(n-1)} \\binom{n+1}{3} \\\\\n&= \\frac{n+1}{3}.\n\\end{align*}\nOne can obtain a similar (if slightly more intricate)\nsolution inductively, by removing the known\nlocal maximum $n$ and splitting into two shorter sequences.\n\n\\textbf{Remark:}\nThe usual term for a local maximum in this sense is a \\emph{peak}.\nThe complete distribution for the number of peaks is known;\nRichard Stanley suggests the reference:\nF. N. David and D. E. Barton, \\textit{Combinatorial Chance}, Hafner, New York,\n1962, p.\\ 162 and subsequent."
  },
  {
    "year": 2006,
    "label": "A5",
    "difficulty": "5",
    "problem": "Let $n$ be a positive odd integer and let $\\theta$ be a real number such\nthat $\\theta/\\pi$ is irrational. Set $a_k = \\tan (\\theta + k \\pi/n)$,\n$k=1,2,\\dots,n$. Prove that\n\\[\n\\frac{a_1 + a_2 + \\cdots + a_n}{a_1 a_2 \\cdots a_n}\n\\]\nis an integer, and determine its value.",
    "solution": "Since the desired expression involves symmetric functions of $a_1,\n\\dots, a_n$, we start by finding a polynomial with $a_1, \\dots, a_n$\nas roots. Note that\n\\[\n1 \\pm i \\tan \\theta = e^{\\pm i \\theta} \\sec \\theta\n\\]\nso that\n\\[\n1 + i \\tan \\theta = e^{2 i \\theta} (1 - i \\tan \\theta).\n\\]\nConsequently, if we put $\\omega = e^{2 i n \\theta}$, then the polynomial\n\\[\nQ_n(x) = (1 + ix)^n - \\omega (1-ix)^n\n\\]\nhas among its roots $a_1, \\dots, a_n$. Since these are distinct and\n$Q_n$ has degree $n$, these must be exactly the roots.\n\nIf we write\n\\[\nQ_n(x) = c_n x^n + \\cdots + c_1 x + c_0,\n\\]\nthen $a_1 + \\cdots + a_n = -c_{n-1}/c_n$ and $a_1\\cdots a_n = -c_0/c_n$,\nso the ratio we are seeking is $c_{n-1}/c_0$.\nBy inspection,\n\\begin{align*}\nc_{n-1} &= n i^{n-1} - \\omega n (-i)^{n-1} = n i^{n-1} (1-\\omega)\\\\\nc_0 &= 1 - \\omega\n\\end{align*}\nso\n\\[\n\\frac{a_1+ \\cdots + a_n}{a_1 \\cdots a_n}\n= \\begin{cases} n & n \\equiv 1 \\pmod{4} \\\\ -n & n \\equiv 3 \\pmod{4}.\n\\end{cases}\n\\]\n\n\\textbf{Remark:} The same argument shows that the ratio between\nany two \\emph{odd} elementary\nsymmetric functions of $a_1, \\dots, a_n$ is independent\nof $\\theta$."
  },
  {
    "year": 2006,
    "label": "A6",
    "difficulty": "6",
    "problem": "Four points are chosen uniformly and independently at random in the interior\nof a given circle. Find the probability that they are the vertices\nof a convex quadrilateral.",
    "solution": "\\textbf{First solution:}\n(by Daniel Kane)\nThe probability is $1 - \\frac{35}{12\\pi^2}$.\nWe start with some notation and simplifications.\nFor simplicity, we\nassume without loss of generality that the circle has radius 1.\nLet $E$ denote the expected value of a random variable over all\nchoices of $P,Q,R$.\nWrite $[XYZ]$ for the area of triangle $XYZ$.\n\nIf $P,Q,R,S$ are the four points, we may ignore the case where three\nof them are collinear, as this occurs with probability zero. Then the only\nway they can fail to form the vertices of a convex quadrilateral is if one\nof them lies inside the triangle formed by the other three. There are four\nsuch configurations, depending on which point lies inside the triangle, and\nthey are mutually exclusive. Hence the desired probability is 1 minus\nfour times the probability that $S$ lies inside triangle $PQR$. That latter\nprobability is simply $E([PQR])$ divided by the area of\nthe disc.\n\nLet $O$ denote the center of the circle,\nand let $P',Q',R'$ be the projections of $P,Q,R$ onto the circle from $O$.\nWe can write\n\\[\n[PQR] = \\pm [OPQ] \\pm [OQR] \\pm [ORP]\n\\]\nfor a suitable choice of signs, determined as follows. If the points\n$P',Q',R'$ lie on no semicircle, then all of the signs are positive.\nIf $P',Q',R'$ lie on a semicircle in that order and\n$Q$ lies inside the triangle $OPR$, then the sign on $[OPR]$ is\npositive and the others are negative.\nIf $P',Q',R'$ lie on a semicircle in that order and\n$Q$ lies outside the triangle $OPR$, then the sign on $[OPR]$ is\nnegative and the others are positive.\n\nWe first calculate\n\\[\nE([OPQ] + [OQR] + [ORP]) = 3 E([OPQ]).\n\\]\nWrite $r_1 = OP, r_2 = OQ, \\theta = \\angle POQ$, so that\n\\[\n[OPQ] = \\frac{1}{2} r_1 r_2 (\\sin \\theta).\n\\]\nThe distribution of $r_1$ is given by $2r_1$ on $[0,1]$\n(e.g., by the change of variable formula to polar coordinates),\nand similarly for $r_2$.\nThe distribution of $\\theta$ is uniform on $[0,\\pi]$.\nThese three distributions are independent; hence\n\\begin{align*}\n& E([OPQ]) \\\\\n&= \\frac{1}{2} \\left( \\int_0^{1} 2r^2\\,dr \\right)^2\n\\left( \\frac{1}{\\pi} \\int_0^\\pi \\sin (\\theta)\\,d\\theta \\right) \\\\\n&= \\frac{4}{9 \\pi},\n\\end{align*}\nand\n\\[\nE([OPQ] + [OQR] + [ORP]) = \\frac{4}{3 \\pi}.\n\\]\n\nWe now treat the case where $P',Q',R'$ lie on a semicircle in\nthat order.\nPut $\\theta_1 = \\angle POQ$ and $\\theta_2 = \\angle QOR$; then\nthe distribution of $\\theta_1, \\theta_2$ is uniform on the region\n\\[\n0 \\leq \\theta_1, \\quad 0 \\leq \\theta_2, \\quad \\theta_1 + \\theta_2 \\leq \\pi.\n\\]\nIn particular, the distribution on $\\theta = \\theta_1 + \\theta_2$\nis $\\frac{2\\theta}{\\pi^2}$ on $[0, \\pi]$.\nPut $r_P = OP, r_Q = OQ, r_R = OR$. Again, the distribution on $r_P$\nis given by $2 r_P$ on $[0,1]$, and similarly for $r_Q, r_R$; these\nare independent from each other and from the joint distribution\nof $\\theta_1,\\theta_2$.\nWrite $E'(X)$ for the expectation of a random variable $X$\nrestricted to this part of the domain.\n\nLet $\\chi$ be the random variable with value 1 if $Q$ is inside\ntriangle $OPR$ and 0 otherwise.\nWe now compute\n\\begin{align*}\n&E'([OPR]) \\\\\n&=\n\\frac{1}{2} \\left( \\int_0^1 2r^2\\,dr \\right)^2\n\\left( \\int_0^\\pi \\frac{2\\theta}{\\pi^2} \\sin(\\theta) \\,d\\theta \\right)\\\\\n&= \\frac{4}{9 \\pi} \\\\\n& E'(\\chi [OPR]) \\\\\n&= E'(2 [OPR]^2 / \\theta) \\\\\n&=\n\\frac{1}{2} \\left( \\int_0^1 2r^3\\,dr \\right)^2\n\\left( \\int_0^\\pi \\frac{2\\theta}{\\pi^2} \\theta^{-1} \\sin^2(\\theta) \\,d\\theta \\right)\\\\\n&= \\frac{1}{8\\pi}.\n\\end{align*}\nAlso recall that given any triangle $XYZ$, if $T$ is chosen uniformly\nat random inside $XYZ$, the expectation of $[TXY]$ is the area of\ntriangle bounded by $XY$ and the centroid of $XYZ$, namely\n$\\frac{1}{3} [XYZ]$.\n\nLet $\\chi$ be the random variable with value 1 if $Q$ is inside\ntriangle $OPR$ and 0 otherwise. Then\n\\begin{align*}\n&E'([OPQ] + [OQR] + [ORP] - [PQR]) \\\\\n&= 2 E'(\\chi ([OPQ] + [OQR]) + 2 E'((1-\\chi)[OPR]) \\\\\n&= 2 E'(\\frac{2}{3} \\chi [OPR]) + 2 E'([OPR]) - 2 E'(\\chi [OPR]) \\\\\n&= 2E'([OPR]) - \\frac{2}{3} E'(\\chi [OPR]) = \\frac{29}{36 \\pi}.\n\\end{align*}\nFinally, note that the case when $P',Q',R'$\nlie on a semicircle in some order occurs with probability $3/4$.\n(The case where they lie on a semicircle proceeding clockwise from $P'$\nto its antipode has probability 1/4; this case and its two analogues are\nexclusive and exhaustive.) Hence\n\\begin{align*}\n&E([PQR]) \\\\\n&= E([OPQ]+[OQR]+[ORP]) \\\\\n&\\quad - \\frac{3}{4} E'([OPQ] + [OQR] + [ORP] - [PQR]) \\\\\n&= \\frac{4}{3 \\pi} - \\frac{29}{48 \\pi} = \\frac{35}{48 \\pi},\n\\end{align*}\nso the original probability is\n\\[\n1 - \\frac{4 E([PQR])}{\\pi} = 1 - \\frac{35}{12 \\pi^2}.\n\\]\n\n\\textbf{Second solution:}\n(by David Savitt)\nAs in the first solution, it suffices to check that for\n$P,Q,R$ chosen uniformly at random in the disc, $E([PQR]) = \\frac{35}{48 \\pi}$.\nDraw the lines $PQ, QR, RP$, which with probability 1 divide the interior\nof the circle into seven regions. Put $a = [PQR]$, let $b_1,b_2,b_3$\ndenote the areas of the\nthree other regions sharing a side with the triangle, and let\n$c_1,c_2,c_3$ denote the areas of the other three regions.\nPut $A = E(a)$, $B = E(b_1)$, $C = E(c_1)$, so that\n$A + 3B + 3C = \\pi$.\n\nNote that $c_1 + c_2 + c_3 + a$ is the area of the region in which we can\nchoose a fourth point $S$ so that the quadrilateral $PQRS$ fails to be\nconvex. By comparing expectations, we have $3C + A = 4A$,\nso $A = C$ and $4A + 3B = \\pi$.\n\nWe will compute $B + 2A = B + 2C$, which is the expected area of the part\nof the circle cut off by a chord through two random points $D,E$, on the\nside of the chord not containing a third random point $F$.\nLet $h$ be the distance from the center $O$ of the circle to the line $DE$.\nWe now determine the distribution of $h$.\n\nPut $r = OD$; the distribution of $r$ is $2r$ on $[0,1]$.\nWithout loss of generality, suppose $O$ is the origin and\n$D$ lies on the positive $x$-axis.\nFor fixed $r$, the distribution of $h$ runs over $[0,r]$,\nand can be computed as the area of the infinitesimal region in which\n$E$ can be chosen so the chord through $DE$ has distance to $O$\nbetween $h$ and $h+dh$, divided by $\\pi$.\nThis region splits into two symmetric pieces, one of which lies\nbetween chords making angles of $\\arcsin(h/r)$ and\n$\\arcsin((h + dh)/r)$ with the $x$-axis.\nThe angle between these is $d\\theta = dh/(r^2 - h^2)$.\nDraw the chord through $D$ at distance $h$ to $O$, and let $L_1,L_2$ be the\nlengths of the parts on opposite sides of $D$; then\nthe area we are looking for is $\\frac{1}{2}(L_1^2 + L_2^2) d\\theta$.\nSince\n\\[\n\\{L_1, L_2 \\} = \\sqrt{1-h^2} \\pm \\sqrt{r^2 - h^2},\n\\]\nthe area we are seeking (after doubling) is\n\\[\n2\\frac{1 + r^2 - 2h^2}{\\sqrt{r^2 - h^2}}.\n\\]\nDividing by $\\pi$, then integrating over $r$, we compute the distribution\nof $h$ to be\n\\begin{align*}\n&\\frac{1}{\\pi} \\int_h^1 2 \\frac{1 + r^2 - 2h^2}{\\sqrt{r^2 - h^2}} 2r\\,dr \\\\\n&= \\frac{16}{3\\pi} (1-h^2)^{3/2}.\n\\end{align*}\n\nWe now return to computing $B +2A$.\nLet $A(h)$ denote the smaller of the two areas of the disc cut off\nby a chord at distance $h$.\nThe chance that the third point is in the smaller (resp.\\\nlarger) portion is $A(h)/\\pi$ (resp.\\ $1 - A(h)/\\pi$),\nand then the area we are trying to compute is $\\pi - A(h)$\n(resp.\\ $A(h)$).\nUsing the distribution on $h$,\nand the fact that\n\\begin{align*}\nA(h) &= 2 \\int_h^1 \\sqrt{1-h^2}\\,dh \\\\\n&= \\frac{\\pi}{2}  - \\arcsin(h) - h \\sqrt{1-h^2},\n\\end{align*}\nwe find\n\\begin{align*}\n&B+2A \\\\\n&= \\frac{2}{\\pi} \\int_0^1 A(h) (\\pi - A(h))\\, \\frac{16}{3\\pi} (1-h^2)^{3/2}\n\\,dh \\\\\n&= \\frac{35 + 24 \\pi^2}{72 \\pi}.\n\\end{align*}\nSince $4A + 3B = \\pi$, we solve to obtain\n$A = \\frac{35}{48 \\pi}$ as in the first solution.\n\n\\textbf{Third solution:} (by Noam Elkies)\nAgain, we reduce to computing the average area of a triangle formed by\nthree random points $A,B,C$ inside a unit circle.\nLet $O$ be the center of the circle, and put $c = \\max\\{OA,OB,OC\\}$;\nthen the probability that $c \\leq r$ is $(r^2)^3$, so the distribution\nof $c$ is $6c^5\\,dc$ on $[0,1]$.\n\nGiven $c$, the expectation of $[ABC]$ is equal to $c^2$ times $X$, the expected\narea of a triangle formed by two random points $P,Q$ in a circle and\na fixed point $R$ on the boundary. We introduce polar coordinates centered\nat $R$, in which the circle is given by $r = 2 \\sin \\theta$ for\n$\\theta \\in [0, \\pi]$. The distribution of a random point in that circle is\n$\\frac{1}{\\pi} r\\,dr\\,d\\theta$ over $\\theta \\in [0,\\pi]$ and\n$r \\in [0, 2 \\sin \\theta]$. If $(r,\\theta)$ and $(r',\\theta')$ are the\ntwo random points, then the area is $\\frac{1}{2} rr' \\sin |\\theta - \\theta'|$.\n\nPerforming the integrals over $r$ and $r'$ first, we find\n\\begin{align*}\nX &= \\frac{32}{9 \\pi^2} \\int_0^\\pi \\int_0^\\pi \\sin^3 \\theta \\sin^3 \\theta'\n\\sin |\\theta-\\theta'|\\,d\\theta'\\,d\\theta \\\\\n&= \\frac{64}{9 \\pi^2} \\int_0^\\pi \\int_0^\\theta \\sin^3 \\theta \\sin^3 \\theta'\n\\sin (\\theta-\\theta') \\,d\\theta'\\,d\\theta.\n\\end{align*}\nThis integral is unpleasant but straightforward; it yields\n$X = 35/(36 \\pi)$, and\n$E([PQR]) = \\int_0^1 6c^7 X\\,dc = 35/(48 \\pi)$, giving the desired\nresult.\n\n\\textbf{Remark:}\nThis is one of the oldest problems in geometric probability; it is an instance\nof Sylvester's four-point problem, which nowadays is usually solved using\na device known as Crofton's formula.\nWe defer to \\texttt{http://mathworld.wolfram.com/} for\nfurther discussion."
  },
  {
    "year": 2006,
    "label": "B1",
    "difficulty": "1",
    "problem": "Show that the curve $x^3 + 3xy + y^3 = 1$ contains only one set of three\ndistinct points, $A$, $B$, and $C$, which are vertices of an equilateral\ntriangle, and find its area.",
    "solution": "The ``curve'' $x^3 + 3xy + y^3 - 1 = 0$ is actually reducible, because the\nleft side factors as\n\\[\n(x+y-1)(x^2 -xy + y^2 + x + y + 1).\n\\]\nMoreover, the second factor is\n\\[\n\\frac{1}{2} ((x+1)^2 + (y+1)^2 + (x-y)^2),\n\\]\nso it only vanishes at $(-1,-1)$. Thus the curve in question consists of the\nsingle point $(-1,-1)$ together with the line $x+y=1$. To form a triangle\nwith three points on this curve, one of its vertices must be $(-1,-1)$.\nThe other two vertices lie on the line $x+y=1$, so the length of the altitude\nfrom $(-1,-1)$ is the distance from $(-1,-1)$ to $(1/2,1/2)$, or\n$3 \\sqrt{2}/2$. The area of an equilateral triangle of height $h$ is\n$h^2 \\sqrt{3}/3$, so the desired area is\n$3 \\sqrt{3}/2$.\n\n\\textbf{Remark:} The factorization used above is a special case of the fact\nthat\n\\begin{align*}\n&x^3 + y^3 + z^3 - 3xyz \\\\\n&= (x+y+z)(x+\\omega y + \\omega^2 z)(x + \\omega^2 y\n+ \\omega z),\n\\end{align*}\nwhere $\\omega$ denotes a primitive cube root of unity. That fact in turn follows\nfrom the evaluation of the determinant of the \\emph{circulant matrix}\n\\[\n\\begin{pmatrix} x & y & z \\\\ z & x & y \\\\ y & z & x\n\\end{pmatrix}\n\\]\nby reading off the eigenvalues of the eigenvectors\n$(1, \\omega^i, \\omega^{2i})$ for $i=0,1,2$."
  },
  {
    "year": 2006,
    "label": "B2",
    "difficulty": "2",
    "problem": "Prove that, for every set $X = \\{x_1, x_2, \\dots, x_n\\}$ of $n$\nreal numbers, there exists a non-empty subset $S$ of $X$ and an integer $m$\nsuch that\n\\[\n\\left| m + \\sum_{s \\in S} s \\right| \\leq \\frac{1}{n+1}.\n\\]",
    "solution": "Let $\\{x\\} = x - \\lfloor x \\rfloor$ denote the fractional part of $x$.\nFor $i=0,\\dots, n$, put $s_i = x_1 + \\cdots + x_i$ (so that $s_0 = 0$).\nSort the numbers $\\{s_0\\}, \\dots, \\{s_n\\}$ into ascending order,\nand call the result $t_0, \\dots, t_n$. Since $0 = t_0 \\leq \\cdots \\leq\nt_n < 1$, the differences\n\\[\nt_1 - t_0, \\dots, t_n - t_{n-1}, 1 - t_n\n\\]\nare nonnegative and add up to 1. Hence (as in  the pigeonhole principle) one\nof these differences\nis no more than $1/(n+1)$; if it is anything other than $1 - t_n$,\nit equals $\\pm (\\{s_i\\} - \\{s_j\\})$ for some\n$0 \\leq i < j \\leq n$. Put $S = \\{x_{i+1}, \\dots, x_j\\}$ and\n$m = \\lfloor s_i \\rfloor - \\lfloor s_j \\rfloor$; then\n\\begin{align*}\n\\left| m + \\sum_{s \\in S} s \\right|\n&= |m + s_j - s_i| \\\\\n&= |\\{s_j\\} - \\{s_i\\}| \\\\\n&\\leq \\frac{1}{n+1},\n\\end{align*}\nas desired. In case $1 - t_n \\leq 1 / (n+1)$, we take\n$S = \\{x_1, \\dots, x_n\\}$ and $m = -\\lceil s_n \\rceil$, and again obtain\nthe desired conclusion."
  },
  {
    "year": 2006,
    "label": "B3",
    "difficulty": "3",
    "problem": "Let $S$ be a finite set of points in the plane. A linear partition of $S$\nis an unordered pair $\\{A,B\\}$ of subsets of $S$ such that $A \\cup B = S$,\n$A \\cap B = \\emptyset$, and $A$ and $B$ lie on opposite sides of some\nstraight line disjoint from $S$ ($A$ or $B$ may be empty). Let $L_S$ be the\nnumber of linear partitions of $S$. For each positive integer $n$, find the\nmaximum of $L_S$ over all sets $S$ of $n$ points.",
    "solution": "The maximum is $\\binom{n}{2} + 1$, achieved for instance by a\nconvex $n$-gon: besides the trivial partition (in which all of the points\nare in one part), each linear\npartition occurs by drawing a line crossing a unique pair\nof edges.\n\n\\textbf{First solution:}\nWe will prove that $L_S = \\binom{n}{2} + 1$ in any configuration in which\nno two of the lines joining points of $S$ are parallel. This suffices\nto imply the maximum in all configurations: given a maximal configuration,\nwe may vary the points slightly to get another maximal configuration in which\nour hypothesis is satisfied.\nFor convenience, we assume $n \\geq 3$, as the cases $n=1,2$ are easy.\n\nLet $P$ be the line at infinity in the real projective plane; i.e., $P$\nis the set of possible directions of lines in the plane, viewed as a circle.\nRemove the directions corresponding to lines through two points of $S$;\nthis leaves behind $\\binom{n}{2}$ intervals.\n\nGiven a direction in one of the intervals, consider the set of linear\npartitions achieved by lines parallel to that direction. Note that the\nresulting collection of partitions depends only on the interval. Then\nnote that the collections associated to adjacent intervals differ in only\none element.\n\nThe trivial partition that puts all of $S$ on one side is in every such\ncollection. We now observe that for any other linear partition\n$\\{A,B\\}$, the set of intervals to which $\\{A,B\\}$ is:\n\\begin{enumerate}"
  },
  {
    "year": 2006,
    "label": "B4",
    "difficulty": "4",
    "problem": "Let $Z$ denote the set of points in $\\mathbb{R}^n$ whose coordinates are 0\nor 1. (Thus $Z$ has $2^n$ elements, which are the vertices of a unit\nhypercube in $\\mathbb{R}^n$.) Given a vector subspace $V$\nof $\\mathbb{R}^n$, let $Z(V)$\ndenote the number of members of $Z$ that lie in $V$. Let $k$ be given,\n$0 \\leq k \\leq n$. Find the maximum, over all vector subspaces $V\n\\subseteq \\mathbb{R}^n$ of dimension $k$, of the number of points in\n$V \\cap Z$. [Editorial note: the proposers probably intended to write\n$Z(V)$ instead of\n``the number of points in $V \\cap Z$'', but this changes nothing.]",
    "solution": "The maximum is $2^k$, achieved for instance by the subspace\n\\[\n\\{(x_1, \\dots, x_n) \\in \\mathbb{R}^n: x_1 = \\cdots = x_{n-k} = 0\\}.\n\\]\n\n\\textbf{First solution:}\nMore generally, we show that any affine $k$-dimensional plane in\n$\\mathbb{R}^n$ can contain at most $2^k$ points in $Z$. The proof is by\ninduction on $k+n$; the case $k=n=0$ is clearly true.\n\nSuppose that $V$ is a $k$-plane in $\\mathbb{R}^n$. Denote the\nhyperplanes $\\{x_n = 0\\}$ and $\\{x_n = 1\\}$ by $V_0$ and $V_1$,\nrespectively. If $V\\cap V_0$ and $V\\cap V_1$ are each at most\n$(k-1)$-dimensional, then $V\\cap V_0\\cap Z$ and $V\\cap V_1 \\cap Z$ each\nhave cardinality at most $2^{k-1}$ by the induction assumption, and\nhence $V\\cap Z$ has at most $2^k$ elements. Otherwise, if $V\\cap V_0$ or\n$V\\cap V_1$ is $k$-dimensional, then $V \\subset V_0$ or $V\\subset V_1$;\nnow apply the induction hypothesis on $V$, viewed as a subset of\n$\\mathbb{R}^{n-1}$ by dropping the last coordinate.\n\n\\textbf{Second solution:}\nLet $S$ be a subset of $Z$ contained in a $k$-dimensional subspace of $V$.\nThis is equivalent to asking that any $t_1, \\dots, t_{k+1} \\in S$\nsatisfy a nontrivial linear dependence $c_1 t_1 + \\cdots + c_{k+1} t_{k+1} = 0$\nwith $c_1, \\dots, c_{k+1} \\in \\mathbb{R}$. Since $t_1, \\dots, t_{k+1} \\in\n\\mathbb{Q}^n$, given such a dependence we can always find another one with\n$c_1, \\dots, c_{k+1} \\in \\mathbb{Q}$; then by clearing denominators, we\ncan find one with $c_1, \\dots, c_{k+1} \\in \\mathbb{Z}$ and not all having a\ncommon factor.\n\nLet $\\mathbb{F}_2$ denote the field of two elements, and let\n$\\overline{S} \\subseteq \\mathbb{F}_2^n$ be the reductions modulo 2 of the points of\n$S$. Then any $t_1, \\dots, t_{k+1} \\in \\overline{S}$ satisfy a nontrivial\nlinear dependence, because we can take the dependence from the end of\nthe previous paragraph and reduce modulo 2. Hence $\\overline{S}$ is contained\nin a $k$-dimensional subspace of $\\mathbb{F}_{2^n}$, and the latter has cardinality\nexactly $2^k$. Thus $\\overline{S}$ has at most $2^k$ elements, as does\n$S$.\n\nVariant (suggested by David Savitt): if $\\overline{S}$ contained $k+1$\nlinearly independent elements, the $(k+1) \\times n$ matrix formed by these\nwould have a nonvanishing maximal minor. The lift of that minor back to $\\RR$\nwould also not vanish, so $S$ would contain $k+1$ linearly independent\nelements.\n\n\\textbf{Third solution:} (by Catalin Zara)\nLet $V$ be a $k$-dimensional subspace. Form the matrix whose rows are the elements\nof $V \\cap Z$; by construction, it has row rank at most $k$. It thus also has\ncolumn rank at most $k$; in particular, we can choose $k$ coordinates such that\neach point of $V \\cap Z$ is determined by those $k$ of its coordinates. Since\neach coordinate of a point in $Z$ can only take two values, $V \\cap Z$ can have\nat most $2^k$ elements.\n\n\\textbf{Remark:} The proposers probably did not realize that this problem appeared\nonline about three months before the exam, at\n\\texttt{http://www.artofproblemsolving.com/ Forum/viewtopic.php?t=105991}. (It\nmay very well have also appeared even earlier.)"
  },
  {
    "year": 2006,
    "label": "B5",
    "difficulty": "5",
    "problem": "For each continuous function $f: [0,1] \\to \\mathbb{R}$, let $I(f) =\n\\int_0^1 x^2 f(x)\\,dx$ and $J(x) = \\int_0^1 x \\left(f(x)\\right)^2\\,dx$.\nFind the maximum value of $I(f) - J(f)$ over all such functions $f$.",
    "solution": "The answer is $1/16$. We have\n\\begin{align*}\n&\\int_0^1 x^2 f (x)\\,dx - \\int_0^1 x f(x)^2\\,dx \\\\\n&= \\int_0^1 (x^3/4 - x\n( f(x)-x/2)^2)\\,dx \\\\\n&\\leq \\int_0^1 x^3/4\\,dx = 1/16,\n\\end{align*}\nwith equality when $f(x) = x/2$."
  },
  {
    "year": 2006,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $k$ be an integer greater than 1. Suppose $a_0 > 0$, and define\n\\[\na_{n+1} = a_n + \\frac{1}{\\sqrt[k]{a_n}}\n\\]\nfor $n > 0$. Evaluate\n\\[\n\\lim_{n \\to \\infty} \\frac{a_n^{k+1}}{n^k}.\n\\]\n\\end{itemize}\n\n\\end{document}",
    "solution": "\\textbf{First solution:}\nWe start with some easy\nupper and lower bounds on $a_n$.\nWe write $O(f(n))$ and $\\Omega(f(n))$ for functions $g(n)$ such that\n$f(n)/g(n)$ and $g(n)/f(n)$, respectively, are bounded above.\nSince $a_n$ is a nondecreasing sequence, $a_{n+1}-a_n$ is bounded above,\nso $a_n = O(n)$. That means $a_n^{-1/k} = \\Omega(n^{-1/k})$, so\n\\[\na_n = \\Omega \\left( \\sum_{i=1}^n i^{-1/k} \\right)\n= \\Omega(n^{(k-1)/k}).\n\\]\nIn fact, all we will need is that $a_n \\to \\infty$ as $n \\to \\infty$.\n\nBy Taylor's theorem with remainder, for $1 < m < 2$ and $x>0$,\n\\[\n|(1+x)^m - 1 - mx| \\leq \\frac{m(m-1)}{2}x^2.\n\\]\nTaking $m = (k+1)/k$ and $x = a_{n+1}/a_n = 1 + a_n^{-(k+1)/k}$, we obtain\n\\[\n\\left| a_{n+1}^{(k+1)/k} - a_n^{(k+1)/k} - \\frac{k+1}{k} \\right|\n\\leq \\frac{k+1}{2k^2} a_n^{-(k+1)/k}.\n\\]\nIn particular,\n\\[\n\\lim_{n \\to \\infty} a_{n+1}^{(k+1)/k} - a_n^{(k+1)/k} = \\frac{k+1}{k}.\n\\]\n\nIn general, if $x_n$ is a sequence with $\\lim_{n \\to \\infty} x_n = c$, then\nalso\n\\[\n\\lim_{n \\to \\infty} \\frac{1}{n} \\sum_{i=1}^n x_i = c\n\\]\nby Cesaro's lemma. Explicitly, for any $\\epsilon > 0$, we can find $N$ such that\n$|x_n - c| \\leq \\epsilon/2$ for $n \\geq N$, and then\n\\[\n\\left| c - \\frac{1}{n} \\sum_{i=1}^n x_i \\right|\n\\leq \\frac{n-N}{n} \\frac{\\epsilon}{2} + \\frac{N}{n} \\left| \\sum_{i=1}^N (c-x_i) \\right|;\n\\]\nfor $n$ large, the right side is smaller than $\\epsilon$.\n\nIn our case, we deduce that\n\\[\n\\lim_{n \\to \\infty} \\frac{a_n^{(k+1)/k}}{n} = \\frac{k+1}{k}\n\\]\nand so\n\\[\n\\lim_{n \\to \\infty} \\frac{a_n^{k+1}}{n^k} = \\left(\\frac{k+1}{k} \\right)^k,\n\\]\nas desired.\n\n\\textbf{Remark:}\nThe use of Cesaro's lemma above is the special case $b_n = n$\nof the \\emph{Cesaro-Stolz\ntheorem}: if $a_n,b_n$ are sequences such that $b_n$ is positive,\nstrictly increasing, and unbounded, and\n\\[\n\\lim_{n \\to \\infty} \\frac{a_{n+1} - a_n}{b_{n+1} - b_n} = L,\n\\]\nthen\n\\[\n\\lim_{n \\to \\infty} \\frac{a_n}{b_n} = L.\n\\]\n\n\\textbf{Second solution:}\nIn this solution, rather than applying Taylor's theorem with remainder\nto $(1+x)^m$ for $1 < m < 2$ and $x > 0$, we only apply convexity to deduce\nthat $(1+x)^m \\geq 1 + mx$. This gives\n\\[\na_{n+1}^{(k+1)/k} - a_n^{(k+1)/k} \\geq \\frac{k+1}{k},\n\\]\nand so\n\\[\na_n^{(k+1)/k} \\geq \\frac{k+1}{k} n + c\n\\]\nfor some $c \\in \\RR$. In particular,\n\\[\n\\liminf_{n \\to \\infty} \\frac{a_n^{(k+1)/k}}{n} \\geq \\frac{k+1}{k}\n\\]\nand so\n\\[\n\\liminf_{n \\to \\infty} \\frac{a_n}{n^{k/(k+1)}} \\geq \\left(\\frac{k+1}{k} \\right)^{k/(k+1)}.\n\\]\nBut turning this around, the fact that\n\\begin{align*}\n&a_{n+1} - a_n \\\\\n&= a_n^{-1/k} \\\\\n&\\leq \\left(\\frac{k+1}{k} \\right)^{-1/(k+1)} n^{-1/(k+1)}\n(1 + o(1)),\n\\end{align*}\nwhere $o(1)$ denotes a function tending to 0 as $n \\to \\infty$,\nyields\n\\begin{align*}\n&a_n \\\\\n&\\leq\n\\left(\\frac{k+1}{k} \\right)^{-1/(k+1)} \\sum_{i=1}^n i^{-1/(k+1)} (1 + o(1)) \\\\\n&= \\frac{k+1}{k} \\left(\\frac{k+1}{k} \\right)^{-1/(k+1)} n^{k/(k+1)}(1 + o(1)) \\\\\n&= \\left( \\frac{k+1}{k} \\right)^{k/(k+1)} n^{k/(k+1)}(1 + o(1)),\n\\end{align*}\nso\n\\[\n\\limsup_{n \\to \\infty} \\frac{a_n}{n^{k/(k+1)}} \\leq \\left( \\frac{k+1}{k}\n\\right)^{k/(k+1)}\n\\]\nand this completes the proof.\n\n\\textbf{Third solution:}\nWe argue that $a_n \\to \\infty$ as in the first solution.\nWrite $b_n = a_n - L n^{k/(k+1)}$, for a value of $L$ to be determined\nlater.\nWe have\n\\begin{align*}\n&b_{n+1} \\\\\n &= b_n + a_n^{-1/k} - L ((n+1)^{k/(k+1)} - n^{k/(k+1)}) \\\\\n&= e_1 + e_2,\n\\end{align*}\nwhere\n\\begin{align*}\ne_1 &= b_n + a_n^{-1/k} - L^{-1/k} n^{-1/(k+1)} \\\\\ne_2 &= L ((n+1)^{k/(k+1)} - n^{k/(k+1)}) \\\\\n&\\quad - L^{-1/k} n^{-1/(k+1)}.\n\\end{align*}\nWe first estimate $e_1$.\nFor $-1 < m < 0$, by the convexity of $(1+x)^m$\nand $(1+x)^{1-m}$, we have\n\\begin{align*}\n1 + mx &\\leq (1+x)^m \\\\\n&\\leq 1 + mx (1+x)^{m-1}.\n\\end{align*}\nHence\n\\begin{align*}\n-\\frac{1}{k} L^{-(k+1)/k} n^{-1} b_n &\\leq e_1 - b_n \\\\\n&\\leq\n-\\frac{1}{k} b_n a_n^{-(k+1)/k}.\n\\end{align*}\nNote that both bounds have sign opposite to $b_n$; moreover,\nby the bound $a_n = \\Omega(n^{(k-1)/k})$, both bounds have absolutely\nvalue strictly less than that of $b_n$ for $n$ sufficiently large. Consequently,\nfor $n$ large,\n\\[\n|e_1| \\leq |b_n|.\n\\]\nWe now work on $e_2$.\nBy Taylor's theorem\nwith remainder applied to $(1+x)^m$ for $x > 0$ and $0 < m < 1$,\n\\begin{align*}\n1+mx &\\geq (1+x)^m \\\\\n&\\geq 1 + mx + \\frac{m(m-1)}{2} x^2.\n\\end{align*}\nThe ``main term'' of $L ((n+1)^{k/(k+1)} - n^{k/(k+1)})$\nis $L \\frac{k}{k+1} n^{-1/(k+1)}$. To make this coincide with\n$L^{-1/k} n^{-1/(k+1)}$, we take\n\\[\nL = \\left( \\frac{k+1}{k} \\right)^{k/(k+1)}.\n\\]\nWe then find that\n\\[\n|e_2| = O(n^{-2}),\n\\]\nand because $b_{n+1} = e_1 + e_2$, we have\n$|b_{n+1}| \\leq |b_n| + |e_2|$. Hence\n\\[\n|b_n| = O\\left (\\sum_{i=1}^n i^{-2} \\right) = O(1),\n\\]\nand so\n\\[\n\\lim_{n \\to \\infty} \\frac{a_n^{k+1}}{n^k} = L^{k+1} = \\left( \\frac{k+1}{k} \\right)^k.\n\\]\n\n\\textbf{Remark:}\nThe case $k=2$ appeared on the 2004 Romanian Olympiad (district level).\n\n\\textbf{Remark:}\nOne can make a similar argument for any sequence given by\n$a_{n+1} = a_n + f(a_n)$, when $f$ is a \\emph{decreasing} function.\n\n\\textbf{Remark:}\nRichard Stanley suggests a heuristic for determining the asymptotic\nbehavior of sequences of this type: replace the given recursion\n\\[\na_{n+1} - a_n = a_n^{-1/k}\n\\]\nby the differential equation\n\\[\ny' = y^{-1/k}\n\\]\nand determine the asymptotics of the latter.\n\\end{itemize}\n\n\n\\end{document}"
  },
  {
    "year": 2007,
    "label": "A1",
    "difficulty": "1",
    "problem": "Find all values of $\\alpha$ for which the curves $y = \\alpha x^2 +\n\\alpha x + \\frac{1}{24}$ and $x = \\alpha y^2 + \\alpha y + \\frac{1}{24}$\nare tangent to each other.",
    "solution": "The only such $\\alpha$ are $2/3, 3/2, (13 \\pm \\sqrt{601})/12$.\n\n\\textbf{First solution:}\nLet $C_1$ and $C_2$ be the curves\n$y=\\alpha x^2 + \\alpha x + \\frac{1}{24}$\nand $x=\\alpha y^2 + \\alpha y + \\frac{1}{24}$, respectively,\nand let $L$ be the line $y=x$.\nWe consider three cases.\n\nIf $C_1$ is tangent to $L$, then the point of tangency $(x,x)$ satisfies\n\\[\n2\\alpha x + \\alpha = 1, \\qquad x = \\alpha x^2 + \\alpha x + \\frac{1}{24};\n\\]\nby symmetry, $C_2$ is tangent to $L$ there, so $C_1$ and $C_2$ are tangent.\nWriting $\\alpha = 1/(2x+1)$ in the first equation and substituting into\nthe second, we must have\n\\[\nx = \\frac{x^2+x}{2x+1} + \\frac{1}{24},\n\\]\nwhich simplifies to $0 = 24x^2 - 2x - 1\n= (6x+1)(4x-1)$, or $x \\in \\{1/4, -1/6\\}$. This yields\n$\\alpha = 1/(2x+1) \\in \\{2/3, 3/2\\}$.\n\nIf $C_1$ does not intersect $L$, then $C_1$ and $C_2$ are separated by $L$\nand so cannot be tangent.\n\nIf $C_1$ intersects $L$ in two distinct points $P_1, P_2$, then it is not\ntangent to $L$ at either point. Suppose at one of these points, say $P_1$,\nthe tangent to $C_1$ is perpendicular to $L$; then by symmetry, the same\nwill be true of $C_2$, so $C_1$ and $C_2$ will be tangent at $P_1$. In this\ncase, the point $P_1 = (x,x)$ satisfies\n\\[\n2 \\alpha x + \\alpha = -1, \\qquad x = \\alpha x^2 + \\alpha x + \\frac{1}{24};\n\\]\nwriting $\\alpha = -1/(2x+1)$ in the first equation and substituting into\nthe second, we have\n\\[\nx = -\\frac{x^2+x}{2x+1} + \\frac{1}{24},\n\\]\nor\n$x = (-23 \\pm \\sqrt{601})/72$.\nThis yields\n$\\alpha = -1/(2x+1) = (13 \\pm \\sqrt{601})/12$.\n\nIf instead the tangents to $C_1$ at $P_1, P_2$ are not perpendicular to\n$L$, then we claim there cannot be any point where $C_1$ and $C_2$ are tangent.\nIndeed, if we count intersections of $C_1$ and $C_2$ (by using $C_1$ to\nsubstitute for $y$ in $C_2$, then solving for $y$), we get at most four\nsolutions counting multiplicity. Two of these are $P_1$ and $P_2$,\nand any point of tangency counts for two more. However, off of $L$,\nany point of tangency would have a mirror image which is also a point of\ntangency, and there cannot be six solutions. Hence we have now found all\npossible $\\alpha$.\n\n\\textbf{Second solution:}\nFor any nonzero value of $\\alpha$, the two\nconics will intersect in four points in the complex projective plane\n$\\mathbb{P}^2(\\mathbb{C})$. To determine the\n$y$-coordinates of these intersection points, subtract the two equations\nto obtain\n\\[\n(y-x) = \\alpha(x-y)(x+y) + \\alpha(x-y).\n\\]\nTherefore, at\na point of intersection we have either $x=y$, or $x = -1/\\alpha - (y+1)$.\nSubstituting these two possible linear conditions into the second\nequation shows that the $y$-coordinate of a point of intersection is a\nroot of either\n$Q_1(y) = \\alpha y^2+(\\alpha-1)y + 1/24$ or\n$Q_2(y) = \\alpha y^2 + (\\alpha+1) y + 25/24 +1/\\alpha$.\n\nIf two curves\nare tangent, then the $y$-coordinates of at least two of the\nintersection points will coincide; the converse is also true because one of the\ncurves is the graph of a function in $x$. The coincidence\noccurs precisely when either\nthe discriminant of at least one of $Q_1$ or $Q_2$ is zero, or\nthere is a common root of $Q_1$ and $Q_2$. Computing the discriminants of $Q_1$\nand $Q_2$ yields (up to constant factors) $f_1(\\alpha)=6\\alpha^2 -\n13\\alpha + 6$ and $f_2(\\alpha)=6\\alpha^2 - 13\\alpha - 18$, respectively.\nIf on the other hand $Q_1$ and $Q_2$ have a common root, it must\nbe also a root of $Q_2(y) - Q_1(y) = 2y +1 + 1/\\alpha$,\nyielding $y = -(1+\\alpha)/(2\\alpha)$ and\n$0 = Q_1(y) = -f_2(\\alpha)/(24 \\alpha)$.\n\nThus the values of\n$\\alpha$ for which the two curves are tangent must be contained in the\nset of zeros of $f_1$ and $f_2$, namely $2/3$, $3/2$, and\n$(13\\pm\\sqrt{601})/12$.\n\n\\textbf{Remark:}\nThe fact that the two conics in $\\mathbb{P}^2(\\CC)$ meet in four points, counted\nwith multiplicities, is a special case of \\emph{B\\'ezout's theorem}: two\ncurves in $\\mathbb{P}^2(\\CC)$ of degrees $m, n$ and not sharing any common component\nmeet in exactly $mn$ points when counted with multiplicity.\n\nMany solvers were surprised that the proposers chose the parameter $1/24$\nto give two rational roots and two nonrational roots. In fact, they had\nno choice in the matter: attempting to make all four roots rational\nby replacing $1/24$ by $\\beta$ amounts\nto asking for $\\beta^2 + \\beta$ and $\\beta^2 + \\beta + 1$ to be perfect\nsquares. This cannot happen outside of trivial cases ($\\beta = 0, -1$)\nultimately because the elliptic curve 24A1 (in Cremona's notation)\nover $\\mathbb{Q}$ has rank $0$. (Thanks to Noam Elkies for providing this\ncomputation.)\n\nHowever, there are choices that make the radical milder,\ne.g., $\\beta = 1/3$  gives\n$\\beta^2 + \\beta = 4/9$ and $\\beta^2 + \\beta + 1 = 13/9$,\nwhile $\\beta = 3/5$ gives $\\beta^2 + \\beta = 24/25$\nand $\\beta^2 + \\beta + 1 = 49/25$."
  },
  {
    "year": 2007,
    "label": "A2",
    "difficulty": "2",
    "problem": "Find the least possible area of a convex set in the plane that\nintersects both branches of the hyperbola $xy = 1$ and both branches of\nthe hyperbola $xy = -1$. (A set $S$ in the plane is called \\emph{convex}\nif for any two points in $S$ the line segment connecting them is\ncontained in $S$.)",
    "solution": "The minimum is 4, achieved by the square with vertices $(\\pm 1, \\pm 1)$.\n\n\\textbf{First solution:}\nTo prove that 4 is a lower bound, let $S$ be a convex set of the desired\nform. Choose $A,B,C,D \\in S$ lying on the branches of the two hyperbolas,\nwith $A$ in the upper right\nquadrant, $B$ in the upper left, $C$ in the lower left, $D$ in the lower right.\nThen the area of the quadrilateral $ABCD$ is a lower bound for\nthe area of $S$.\n\nWrite $A = (a,1/a)$,\n$B = (-b,1/b)$, $C = (-c,-1/c)$, $D = (d, -1/d)$ with $a,b,c,d > 0$.\nThen the area of the quadrilateral $ABCD$ is\n\\[\n\\frac{1}{2}(a/b + b/c + c/d + d/a + b/a + c/b + d/c + a/d),\n\\]\nwhich by the arithmetic-geometric mean inequality is at least\n$4$.\n\n\\textbf{Second solution:}\nChoose $A,B,C,D$ as in the first solution.\nNote that both the hyperbolas and the area of the convex hull of $ABCD$ are\ninvariant under the transformation $(x,y) \\mapsto (xm, y/m)$ for any\n$m>0$. For $m$ small, the counterclockwise angle from the line $AC$ to\nthe line $BD$ approaches 0; for $m$ large, this angle approaches $\\pi$.\nBy continuity, for some $m$ this angle becomes $\\pi/2$, that is,\n$AC$ and $BD$ become perpendicular. The area of $ABCD$\nis then $AC \\cdot BD$.\n\nIt thus suffices to note that $AC \\geq 2 \\sqrt{2}$ (and similarly for $BD$).\nThis holds because if we draw the tangent lines to the hyperbola $xy=1$\nat the points $(1,1)$ and $(-1,-1)$, then $A$ and $C$ lie outside the region\nbetween these lines. If we project the segment $AC$ orthogonally\nonto the line $x=y=1$, the resulting projection has length at\nleast $2 \\sqrt{2}$,\nso $AC$ must as well.\n\n\\textbf{Third solution:}\n(by Richard Stanley)\nChoose $A,B,C,D$ as in the first solution. Now fixing $A$ and $C$, move $B$ and\n$D$ to the points at which the tangents to the curve are parallel to the line\n$AC$. This does not increase the area of the quadrilateral $ABCD$ (even if\nthis quadrilateral is not convex).\n\nNote that $B$ and $D$ are now diametrically opposite; write $B = (-x, 1/x)$\nand $D = (x, -1/x)$. If we thus repeat the\nprocedure, fixing $B$ and $D$ and moving $A$ and $C$ to the points where the\ntangents are parallel to $BD$, then $A$ and $C$ must move to $(x, 1/x)$\nand $(-x,-1/x)$, respectively, forming a rectangle of area 4.\n\n\\textbf{Remark:}\nMany geometric solutions are possible. An example suggested by David Savitt\n(due to Chris Brewer):\nnote that $AD$ and $BC$ cross the\npositive and negative $x$-axes, respectively, so the convex hull of $ABCD$\ncontains $O$. Then check that the area of triangle $OAB$ is at least 1, et cetera."
  },
  {
    "year": 2007,
    "label": "A3",
    "difficulty": "3",
    "problem": "Let $k$ be a positive integer. Suppose that the integers $1, 2, 3,\n\\dots, 3k+1$ are written down in random order. What is the probability\nthat at no time during this process, the sum of the integers that have\nbeen written up to that time is a positive integer divisible by 3? Your\nanswer should be in closed form, but may include factorials.",
    "solution": "Assume that we have an ordering of $1,2,\\dots,3k+1$ such\n  that no initial subsequence sums to $0$ mod $3$. If we omit the\n  multiples of $3$ from this ordering, then the remaining sequence mod\n  $3$ must look like $1,1,-1,1,-1,\\ldots$ or $-1,-1,1,-1,1,\\ldots$.\n  Since there is one more integer in the ordering congruent to $1$ mod\n  $3$ than to $-1$, the sequence mod $3$ must look like\n  $1,1,-1,1,-1,\\ldots$.\n\n  It follows that the ordering satisfies the given condition if and\n  only if the following two conditions hold: the first element in the\n  ordering is not divisible by $3$, and the sequence mod $3$ (ignoring\nzeroes) is of the form $1,1,-1,1,-1,\\ldots$. The two conditions are\n  independent, and the probability of the first is $(2k+1)/(3k+1)$\nwhile the probability of the second is\n$1/\\binom{2k+1}{k}$,\n  since there are $\\binom{2k+1}{k}$ ways to order $(k+1)$ $1$'s and $k$\n  $-1$'s.\n  Hence the desired probability is the product of these two, or\n  $\\frac{k!(k+1)!}{(3k+1)(2k)!}$."
  },
  {
    "year": 2007,
    "label": "A4",
    "difficulty": "4",
    "problem": "A \\emph{repunit} is a positive integer whose digits in base 10 are\nall ones. Find all polynomials $f$ with real coefficients such that if\n$n$ is a repunit, then so is $f(n)$.",
    "solution": "Note that $n$ is a repunit if and only if $9n+1 = 10^m$ for some power of\n10 greater than 1. Consequently, if we put\n\\[\ng(n) = 9f\\left( \\frac{n-1}{9} \\right) + 1,\n\\]\nthen $f$ takes repunits to repunits if and only if $g$ takes powers of 10\ngreater than 1 to powers of 10 greater than 1. We will show that the only\nsuch functions $g$ are those of the form $g(n) = 10^c n^d$ for $d \\geq 0$,\n$c \\geq 1-d$ (all of which clearly work),\nwhich will mean that the desired polynomials $f$ are those of the form\n\\[\nf(n) = \\frac{1}{9}(10^c (9n+1)^d - 1)\n\\]\nfor the same $c,d$.\n\nIt is convenient to allow ``powers of 10'' to be of the form\n$10^k$ for any integer $k$. With this convention, it suffices to check that\nthe polynomials $g$ taking powers of 10 greater than 1 to powers of 10\nare of the form $10^c n^d$ for any integers $c,d$ with $d \\geq 0$.\n\n\\textbf{First solution:}\nSuppose that the leading term of $g(x)$ is $ax^d$, and note that\n$a>0$. As $x \\to \\infty$, we have $g(x)/x^d \\to a$; however, for $x$\na power of 10 greater than 1, $g(x)/x^d$ is a power of 10.\nThe set of powers of 10 has no positive limit point, so $g(x)/x^d$\nmust be equal to $a$ for $x = 10^k$ with $k$ sufficiently large,\nand we must have $a = 10^c$ for some $c$.\nThe polynomial $g(x) - 10^c x^d$ has infinitely many roots, so\nmust be identically zero.\n\n\\textbf{Second solution:}\nWe proceed by induction on $d = \\deg(g)$.\nIf $d=0$, we have $g(n) = 10^c$ for some $c$. Otherwise,\n$g$ has rational coefficients by Lagrange's interpolation formula (this\napplies to any polynomial of degree $d$ taking at least $d+1$\ndifferent rational numbers to rational numbers), so $g(0) = t$ is rational.\nMoreover, $g$ takes each value only finitely many times, so the sequence\n$g(10^0), g(10^1), \\dots$ includes arbitrarily large powers of 10.\nSuppose that $t \\neq 0$; then we can choose a positive integer $h$ such that\nthe numerator of $t$ is not divisible by $10^h$.\nBut for $c$ large enough, $g(10^c) - t$ has numerator divisible by\n$10^b$ for some $b>h$, contradiction.\n\nConsequently, $t=0$, and we may apply the induction hypothesis to $g(n)/n$\nto deduce the claim.\n\n\\textbf{Remark:} The second solution amounts to the fact that $g$, being\na polynomial with rational coefficients, is continuous for the $2$-adic\nand $5$-adic topologies on $\\mathbb{Q}$. By contrast, the first solution\nuses the ``$\\infty$-adic'' topology, i.e., the usual real topology."
  },
  {
    "year": 2007,
    "label": "A5",
    "difficulty": "5",
    "problem": "Suppose that a finite group has exactly $n$ elements of order $p$,\nwhere $p$ is a prime. Prove that either $n=0$ or $p$ divides $n+1$.",
    "solution": "In all solutions, let $G$ be a finite group of order $m$.\n\n\\textbf{First solution:}\nBy Lagrange's theorem, if $m$ is\nnot divisible by $p$, then $n = 0$. Otherwise, let $S$ be the set of\n$p$-tuples $(a_0,\\dots,a_{p-1}) \\in G^p$ such that $a_0 \\cdots a_{p-1} = e$;\nthen $S$ has cardinality $m^{p-1}$, which is divisible by $p$.\nNote that this set is invariant under cyclic permutation, that is,\nif $(a_0,\\dots,a_{p-1}) \\in S$, then $(a_1,\\dots,a_{p-1},a_0) \\in S$ also.\nThe fixed points under this operation are the tuples\n$(a,\\dots,a)$ with $a^p = e$; all other tuples can be grouped into orbits\nunder cyclic permutation, each of which has size $p$. Consequently,\nthe number of $a \\in G$ with $a^p = e$ is divisible by $p$; since that number\nis $n+1$ (only $e$ has order 1), this proves the claim.\n\n\\textbf{Second solution:}\n(by Anand Deopurkar)\nAssume that $n > 0$, and let $H$ be any subgroup of $G$ of order $p$.\nLet $S$ be the set of all elements of $G \\setminus H$\nof order dividing $p$, and let\n$H$ act on $G$ by conjugation. Each orbit has size $p$ except for those\nwhich consist of individual elements $g$ which commute with $H$.\nFor each such $g$, $g$ and $H$ generate an elementary abelian subgroup of\n$G$ of order $p^2$. However, we can group these $g$ into sets of size\n$p^2-p$ based on which subgroup they generate together with $H$.\nHence the cardinality of $S$ is divisible by $p$; adding the $p-1$\nnontrivial elements of $H$ gives $n \\equiv -1 \\pmod{p}$ as desired.\n\n\\textbf{Third solution:}\nLet $S$ be the set of elements in $G$ having order dividing $p$, and let\n$H$ be an elementary abelian $p$-group of maximal order in $G$.  If\n$|H|=1$, then we are done.  So assume $|H|=p^k$ for some $k\\geq 1$, and\nlet $H$ act on $S$ by conjugation.  Let $T\\subset S$ denote the set of\nfixed points of this action.  Then the size of every $H$-orbit on $S$\ndivides $p^k$, and so $|S|\\equiv |T| \\pmod{p}$.\nOn the other hand, $H\\subset T$, and if $T$ contained an element not in $H$,\nthen that would contradict the maximality of $H$.  It follows that\n$H=T$, and so $|S|\\equiv |T| = |H| = p^k \\equiv 0 \\pmod{p}$,\ni.e., $|S|=n+1$ is a multiple of $p$.\n\n\\textbf{Remark:} This result is a theorem of Cauchy; the first solution\nabove is due to McKay. A more general (and more difficult) result was proved\nby Frobenius: for any positive integer $m$, if $G$ is a finite group of order\ndivisible by $m$, then the number of elements of $G$ of order dividing $m$\nis a multiple of $m$."
  },
  {
    "year": 2007,
    "label": "A6",
    "difficulty": "6",
    "problem": "A \\emph{triangulation} $\\mathcal{T}$ of a polygon $P$ is a finite\ncollection of triangles whose union is $P$, and such that the\nintersection of any two triangles is either empty, or a shared vertex,\nor a shared side. Moreover, each side is a side of exactly one triangle\nin $\\mathcal{T}$. Say that $\\mathcal{T}$ is \\emph{admissible} if every\ninternal vertex is shared by 6 or more triangles. For example, [figure\nomitted.] Prove that there is an integer $M_n$, depending only on $n$,\nsuch that any admissible triangulation of a polygon $P$ with $n$ sides\nhas at most $M_n$ triangles.",
    "solution": "For an admissible triangulation $\\mathcal{T}$, number the\n  vertices of $P$ consecutively $v_1,\\dots,v_n$, and let $a_i$ be the\n  number of edges in $\\mathcal{T}$ emanating from $v_i$; note that\n  $a_i \\geq 2$ for all $i$.\n\n  We first claim that $a_1+\\dots+a_n \\leq 4n-6$. Let $V,E,F$ denote\n  the number of vertices, edges, and faces in $\\mathcal{T}$. By\n  Euler's Formula, $(F+1)-E+V=2$ (one must add 1 to the face count for the\n  region exterior to $P$). Each face has three edges, and each edge but the\n  $n$ outside edges belongs to two faces; hence $F = 2E-n$. On the\n  other hand, each edge has two endpoints, and each of the $V-n$\n  internal vertices is an endpoint of at least $6$ edges; hence\n  $a_1+\\dots+a_n+6(V-n) \\leq 2E$. Combining this inequality with the\n  previous two equations gives\n\\begin{align*}\na_1+\\dots+a_n &\\leq 2E+6n-6(1-F+E) \\\\\n&= 4n-6,\n\\end{align*}\nas claimed.\n\nNow set $A_3 = 1$ and $A_n = A_{n-1}+2n-3$ for $n \\geq 4$; we will\nprove by induction on $n$ that $\\mathcal{T}$ has at most $A_n$\ntriangles. For $n=3$, since $a_1+a_2+a_3=6$, $a_1=a_2=a_3=2$ and hence\n$\\mathcal{T}$ consists of just one triangle.\n\nNext assume that an admissible triangulation of an $(n-1)$-gon has at\nmost $A_{n-1}$ triangles, and let $\\mathcal{T}$ be an admissible\ntriangulation of an $n$-gon. If any $a_i = 2$, then we can remove the\ntriangle of $\\mathcal{T}$ containing vertex $v_i$ to obtain an\nadmissible triangulation of an $(n-1)$-gon; then the number of\ntriangles in $\\mathcal{T}$ is at most $A_{n-1}+1 < A_n$ by induction.\nOtherwise, all $a_i \\geq 3$. Now the average of $a_1,\\dots,a_n$ is\nless than $4$, and thus there are more $a_i = 3$ than $a_i \\geq 5$. It\nfollows that there is a sequence of $k$ consecutive vertices in $P$\nwhose degrees are $3,4,4,\\ldots,4,3$ in order, for some $k$ with\n$2\\leq k\\leq n-1$ (possibly $k=2$, in which case there are no degree\n$4$ vertices separating the degree $3$ vertices). If we remove from\n$\\mathcal{T}$ the $2k-1$ triangles which contain at least one of these\nvertices, then we are left with an admissible triangulation of an\n$(n-1)$-gon. It follows that there are at most $A_{n-1}+2k-1 \\leq\nA_{n-1}+2n-3 = A_n$ triangles in $\\mathcal{T}$. This completes the\ninduction step and the proof.\n\n\\textbf{Remark:}\nWe can refine the bound $A_n$ somewhat.\nSupposing that $a_i \\geq 3$ for all\n$i$, the fact that $a_1 + \\cdots + a_n \\leq 4n-6$ implies that there are at least\nsix more indices $i$ with $a_i = 3$ than with $a_i \\geq 5$. Thus there exist\nsix sequences with degrees $3,4,\\dots,4,3$, of total length at most\n$n+6$. We may thus choose a sequence of length $k \\leq \\lfloor \\frac{n}{6}\n\\rfloor + 1$, so we may improve the upper bound to $A_n = A_{n-1} +\n2 \\lfloor \\frac{n}{6} \\rfloor + 1$, or asymptotically\n$\\frac{1}{6} n^2$.\n\nHowever (as noted by Noam Elkies), a hexagonal swatch of a triangular\nlattice, with the boundary as close to regular as possible,\nachieves asymptotically $\\frac{1}{6} n^2$ triangles."
  },
  {
    "year": 2007,
    "label": "B1",
    "difficulty": "1",
    "problem": "Let $f$ be a polynomial with positive integer coefficients. Prove\nthat if $n$ is a positive integer, then $f(n)$ divides $f(f(n)+1)$ if\nand only if $n=1$. [Editor's note: one must assume $f$ is nonconstant.]",
    "solution": "The problem fails if $f$ is allowed to be constant, e.g., take $f(n) = 1$.\nWe thus assume that $f$ is nonconstant.\nWrite $f(n) = \\sum_{i=0}^d a_i n^i$ with $a_i > 0$. Then\n\\begin{align*}\nf(f(n)+1) &= \\sum_{i=0}^d a_i (f(n) + 1)^i \\\\\n&\\equiv f(1) \\pmod{f(n)}.\n\\end{align*}\nIf $n = 1$, then this implies that $f(f(n)+1)$ is divisible by $f(n)$.\nOtherwise, $0 < f(1) < f(n)$ since $f$ is nonconstant and has positive\ncoefficients, so $f(f(n)+1)$ cannot be divisible by $f(n)$."
  },
  {
    "year": 2007,
    "label": "B2",
    "difficulty": "2",
    "problem": "Suppose that $f: [0,1] \\to \\mathbb{R}$ has a continuous derivative\nand that $\\int_0^1 f(x)\\,dx = 0$. Prove that for every $\\alpha \\in (0,1)$,\n\\[\n\\left| \\int_0^\\alpha f(x)\\,dx \\right| \\leq \\frac{1}{8} \\max_{0 \\leq x\n\\leq 1} |f'(x)|.\n\\]",
    "solution": "Put $B = \\max_{0 \\leq x \\leq 1} |f'(x)|$\nand $g(x) = \\int_0^x f(y)\\,dy$. Since $g(0) = g(1) = 0$, the maximum value\nof $|g(x)|$ must occur at a critical point $y \\in (0,1)$ satisfying\n$g'(y) = f(y) = 0$. We may thus take $\\alpha = y$ hereafter.\n\nSince $\\int_0^\\alpha f(x)\\,dx = -\\int_0^{1-\\alpha} f(1-x)\\,dx$,\nwe may assume that $\\alpha \\leq 1/2$. By then substituting $-f(x)$\nfor $f(x)$ if needed, we may assume that $\\int_0^\\alpha f(x)\\,dx \\geq 0$.\n{}From the inequality $f'(x) \\geq -B$, we deduce\n$f(x) \\leq B(\\alpha - x)$ for $0 \\leq x \\leq \\alpha$, so\n\\begin{align*}\n\\int_0^\\alpha f(x)\\,dx \\leq &\\int_0^\\alpha B(\\alpha-x)\\,dx \\\\\n&= -\\left. \\frac{1}{2} B (\\alpha - x)^2 \\right|_0^\\alpha \\\\\n&= \\frac{\\alpha^2}{2} B \\leq \\frac{1}{8} B\n\\end{align*}\nas desired."
  },
  {
    "year": 2007,
    "label": "B3",
    "difficulty": "3",
    "problem": "Let $x_0 = 1$ and for $n \\geq 0$, let $x_{n+1} = 3x_n + \\lfloor x_n\n\\sqrt{5} \\rfloor$. In particular, $x_1 = 5$, $x_2 = 26$, $x_3 = 136$,\n$x_4 = 712$. Find a closed-form expression for $x_{2007}$. ($\\lfloor a\n\\rfloor$ means the largest integer $\\leq a$.)",
    "solution": "\\textbf{First solution:}\nObserving that $x_2/2 = 13$, $x_3/4=34$, $x_4/8=89$, we\nguess that $x_n = 2^{n-1} F_{2n+3}$, where $F_k$ is the $k$-th\nFibonacci number. Thus we claim that $x_n = \\frac{2^{n-1}}{\\sqrt{5}}\n(\\alpha^{2n+3}-\\alpha^{-(2n+3)})$, where $\\alpha =\n\\frac{1+\\sqrt{5}}{2}$, to make the answer $x_{2007} =\n\\frac{2^{2006}}{\\sqrt{5}}(\\alpha^{3997}-\\alpha^{-3997})$.\n\nWe prove the claim by induction; the base case $x_0 = 1$ is true, and\nso it suffices to show that the recursion $x_{n+1} = 3x_n + \\lfloor\nx_n \\sqrt{5} \\rfloor$ is satisfied for our formula for $x_n$. Indeed,\nsince $\\alpha^2 = \\frac{3+\\sqrt{5}}{2}$, we have\n\\begin{align*}\nx_{n+1}-(3+\\sqrt{5})x_n &= \\frac{2^{n-1}}{\\sqrt{5}}\n(2(\\alpha^{2n+5}-\\alpha^{-(2n+5)}) \\\\\n&\\quad-(3+\\sqrt{5})(\\alpha^{2n+3}-\\alpha^{-(2n+3)})) \\\\\n&= 2^n \\alpha^{-(2n+3)}.\n\\end{align*}\nNow $2^n \\alpha^{-(2n+3)} =\n(\\frac{1-\\sqrt{5}}{2})^3 (3-\\sqrt{5})^n$ is between $-1$ and $0$; the\nrecursion follows since $x_n,x_{n+1}$ are integers.\n\n\\textbf{Second solution:}\n(by Catalin Zara)\nSince $x_n$ is rational, we have $0 < x_n \\sqrt{5} - \\lfloor x_n \\sqrt{5}\n\\rfloor < 1$. We now have the inequalities\n\\begin{gather*}\nx_{n+1}-3x_n < x_n \\sqrt{5} < x_{n+1} -3x_n+1 \\\\\n(3+\\sqrt{5})x_n - 1 < x_{n+1} < (3+\\sqrt{5})x_n \\\\\n4x_n - (3-\\sqrt{5}) < (3-\\sqrt{5})x_{n+1} < 4x_n \\\\\n3x_{n+1} - 4x_n < x_{n+1} \\sqrt{5} < 3x_{n+1}-4x_n + (3-\\sqrt{5}).\n\\end{gather*}\nSince $0 < 3-\\sqrt{5} < 1$, this yields $\\lfloor x_{n+1} \\sqrt{5}\n\\rfloor = 3x_{n+1} - 4x_n$, so we can rewrite the recursion as\n$x_{n+1} = 6x_n - 4x_{n-1}$ for $n \\geq 2$. It is routine to solve\nthis recursion to obtain the same solution as above.\n\n\\textbf{Remark:}\nWith an initial 1 prepended,\nthis becomes\nsequence A018903 in Sloane's On-Line Encyclopedia of Integer Sequences:\n(\\texttt{http://www.research.att.com/\\~{}njas/ sequences/}).\nTherein, the sequence is described as the case $S(1,5)$ of the sequence\n$S(a_0, a_1)$ in which $a_{n+2}$ is the least integer for which\n$a_{n+2}/a_{n+1}>a_{n+1}/a_n$. Sloane cites\n D. W. Boyd, Linear recurrence relations for some generalized Pisot sequences,\n\\textit{Advances in Number Theory (Kingston, ON, 1991)}, Oxford Univ.\nPress, New York, 1993, p.\\ 333--340."
  },
  {
    "year": 2007,
    "label": "B4",
    "difficulty": "4",
    "problem": "Let $n$ be a positive integer. Find the number of pairs $P, Q$ of\npolynomials with real coefficients such that\n\\[\n(P(X))^2 + (Q(X))^2 = X^{2n} + 1\n\\]\nand $\\deg P > \\deg Q$.",
    "solution": "The number of pairs is $2^{n+1}$. The degree condition forces\n$P$ to have degree $n$ and leading coefficient $\\pm 1$; we may count\npairs in which $P$ has leading coefficient 1 as long as we multiply by $2$\nafterward.\n\nFactor both sides:\n\\begin{align*}\n& (P(X) + Q(X)i)(P(X) - Q(X)i) \\\\\n& = \\prod_{j=0}^{n-1}\n(X - \\exp(2 \\pi i (2j+1)/(4n))) \\\\\n& \\quad \\cdot \\prod_{j=0}^{n-1}\n(X + \\exp(2 \\pi i (2j+1)/(4n))).\n\\end{align*}\nThen each choice of $P,Q$ corresponds to equating $P(X) + Q(X)i$\nwith the product of some $n$ factors on the right,\nin which we choose exactly of the two factors for each $j=0,\\dots,n-1$.\n(We must take exactly $n$\nfactors because as a polynomial in $X$ with complex coefficients, $P(X) + Q(X)i$\nhas degree exactly $n$. We must choose one for each $j$ to ensure that\n$P(X) + Q(X)i$ and $P(X) -Q(X)i$ are complex conjugates, so that $P, Q$ have\nreal coefficients.) Thus there are $2^n$ such pairs;\nmultiplying by 2 to allow $P$ to have\nleading coefficient $-1$ yields the desired result.\n\n\\textbf{Remark:} If we allow $P$ and $Q$ to have complex coefficients but\nstill require $\\deg(P) > \\deg(Q)$, then the number of pairs increases\nto $2\\binom{2n}{n}$, as we may choose any $n$ of the $2n$ factors of\n$X^{2n}+1$ to use to form $P(X) + Q(X)i$."
  },
  {
    "year": 2007,
    "label": "B5",
    "difficulty": "5",
    "problem": "Let $k$ be a positive integer. Prove that there exist polynomials\n$P_0(n), P_1(n), \\dots, P_{k-1}(n)$ (which may depend on $k$) such that\nfor any integer $n$,\n\\[\n\\left\\lfloor \\frac{n}{k} \\right\\rfloor^k = P_0(n) + P_1(n) \\left\\lfloor\n\\frac{n}{k} \\right\\rfloor + \\cdots + P_{k-1}(n) \\left\\lfloor \\frac{n}{k}\n\\right\\rfloor^{k-1}.\n\\]\n($\\lfloor a \\rfloor$ means the largest integer $\\leq a$.)",
    "solution": "For $n$ an integer, we have\n$\\left\\lfloor \\frac{n}{k} \\right\\rfloor = \\frac{n-j}{k}$ for $j$\nthe unique integer in $\\{0,\\dots,k-1\\}$ congruent to $n$ modulo $k$;\nhence\n\\[\n\\prod_{j=0}^{k-1} \\left( \\left\\lfloor \\frac{n}{k} \\right\\rfloor - \\frac{n-j}{k}\n\\right) = 0.\n\\]\nBy expanding this out, we obtain\nthe desired polynomials $P_0(n), \\dots, P_{k-1}(n)$.\n\n\\textbf{Remark:} Variants of this solution are possible that\nconstruct the $P_i$\nless explicitly, using Lagrange interpolation or Vandermonde determinants."
  },
  {
    "year": 2007,
    "label": "B6",
    "difficulty": "6",
    "problem": "For each positive integer $n$, let $f(n)$ be the number of ways to\nmake $n!$ cents using an unordered collection of coins, each worth $k!$\ncents for some $k$, $1 \\leq k \\leq n$. Prove that for some constant $C$,\nindependent of $n$,\n\\[\nn^{n^2/2 - Cn} e^{-n^2/4} \\leq f(n) \\leq n^{n^2/2 + Cn}e^{-n^2/4}.\n\\]\n\n\\end{itemize}\n\n\\end{document}",
    "solution": "(Suggested by Oleg Golberg)\nAssume $n \\geq 2$, or else the problem\nis trivially false.\nThroughout this proof, any $C_i$ will be a positive constant whose exact\nvalue is immaterial.\nAs in the proof of Stirling's approximation, we\nestimate for any fixed $c \\in \\RR$,\n\\[\n\\sum_{i=1}^n (i+c) \\log i =\n\\frac{1}{2} n^2 \\log n - \\frac{1}{4} n^2 + O(n \\log n)\n\\]\nby comparing the sum to an integral. This gives\n\\begin{align*}\nn^{n^2/2-C_1 n} e^{-n^2/4} &\\leq 1^{1+c} 2^{2+c} \\cdots n^{n+c} \\\\\n&\\leq n^{n^2/2+C_2 n} e^{-n^2/4}.\n\\end{align*}\nWe now interpret $f(n)$ as counting the number of $n$-tuples\n$(a_1, \\dots, a_n)$ of nonnegative integers such that\n\\[\na_1 1! + \\cdots + a_n n! = n!.\n\\]\nFor an upper bound on $f(n)$, we use the inequalities\n$0 \\leq a_i \\leq n!/i!$ to deduce that there are at most $n!/i! + 1 \\leq 2(n!/i!)$\nchoices for $a_i$. Hence\n\\begin{align*}\nf(n) &\\leq 2^n \\frac{n!}{1!} \\cdots \\frac{n!}{n!} \\\\\n&= 2^n 2^1 3^2 \\cdots n^{n-1} \\\\\n&\\leq n^{n^2/2+C_3 n} e^{-n^2/4}.\n\\end{align*}\nFor a lower bound on $f(n)$, we note that if $0 \\leq a_i < (n-1)!/i!$\nfor $i=2,\\dots,n-1$ and $a_n = 0$,\nthen $0 \\leq a_2 2! + \\cdots + a_n n! \\leq n!$, so there is a unique\nchoice of $a_1$ to complete this to a solution of\n$a_1 1! + \\cdots + a_n n! = n!$. Hence\n\\begin{align*}\nf(n) &\\geq \\frac{(n-1)!}{2!} \\cdots \\frac{(n-1)!}{(n-1)!} \\\\\n&= 3^1 4^2 \\cdots (n-1)^{n-3} \\\\\n&\\geq n^{n^2/2+C_4 n} e^{-n^2/4}.\n\\end{align*}\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2008,
    "label": "A1",
    "difficulty": "1",
    "problem": "Let $f: \\mathbb{R}^2 \\to \\mathbb{R}$ be a function such that $f(x,y) + f(y,z)\n+ f(z,x) = 0$ for all real numbers $x$, $y$, and $z$. Prove that there exists\na function $g: \\mathbb{R} \\to \\mathbb{R}$ such that $f(x,y) = g(x) - g(y)$\nfor all real numbers $x$ and $y$.",
    "solution": "The function $g(x) = f(x,0)$ works. Substituting $(x,y,z) = (0,0,0)$ into the given functional equation yields $f(0,0) = 0$, whence substituting $(x,y,z) = (x,0,0)$ yields $f(x,0)+f(0,x)=0$. Finally, substituting $(x,y,z) = (x,y,0)$ yields $f(x,y) = -f(y,0)-f(0,x) = g(x)-g(y)$.\n\n\\textbf{Remark:} A similar argument shows that the possible functions $g$\nare precisely those of the form  $f(x,0) + c$ for some $c$."
  },
  {
    "year": 2008,
    "label": "A2",
    "difficulty": "2",
    "problem": "Alan and Barbara play a game in which they take turns filling entries of\nan initially empty $2008 \\times 2008$ array. Alan plays first. At each\nturn, a player chooses a real number and places it in a vacant entry.\nThe game ends when all the entries are filled. Alan wins if the\ndeterminant of the resulting matrix is nonzero; Barbara wins if it is zero.\nWhich player has a winning strategy?",
    "solution": "Barbara wins using one of the following strategies.\n\n\\textbf{First solution:}\nPair each entry of the first row with the entry directly below it in\nthe second row. If Alan ever writes a number in one of the first two\nrows, Barbara writes the same number in the other entry in the pair.\nIf Alan writes a number anywhere other than the first two rows, Barbara\ndoes likewise.\nAt the end, the resulting matrix will have two identical rows, so its\ndeterminant will be zero.\n\n\\textbf{Second solution:} (by Manjul Bhargava)\nWhenever Alan writes a number $x$ in an entry in some row, Barbara writes\n$-x$ in some other entry in the same row.\nAt the end, the resulting matrix will have all rows summing to zero,\nso it cannot have full rank."
  },
  {
    "year": 2008,
    "label": "A3",
    "difficulty": "3",
    "problem": "Start with a finite sequence $a_1, a_2, \\dots, a_n$ of positive integers.\nIf possible, choose two indices $j < k$ such that $a_j$ does not divide\n$a_k$, and replace $a_j$ and $a_k$ by $\\mathrm{gcd}(a_j, a_k)$\nand $\\mathrm{lcm}(a_j, a_k)$, respectively. Prove that if this process is\nrepeated, it must eventually stop and the final sequence does not depend\non the choices made. (Note: gcd means greatest common divisor and lcm\nmeans least common multiple.)",
    "solution": "We first prove that the process stops. Note first that the product\n$a_1 \\cdots a_n$ remains constant, because\n$a_j a_k = \\gcd(a_j, a_k) \\lcm(a_j, a_k)$. Moreover,\nthe last number in the sequence can never decrease, because it is always\nreplaced by its least common multiple with another number.\nSince it is bounded above (by the product\nof all of the numbers), the last number must eventually reach its\nmaximum value, after which it remains constant throughout. After this\nhappens, the next-to-last number will never decrease, so it eventually\nbecomes constant, and so on. After finitely many steps, all of the numbers\nwill achieve their final values, so\nno more steps will be possible. This only happens when\n$a_j$ divides $a_k$ for all pairs $j < k$.\n\nWe next check that there is only one possible final sequence.\nFor $p$ a prime and $m$ a nonnegative integer, we claim that the number\nof integers in the list divisible by $p^m$ never changes. To see this,\nsuppose we replace $a_j, a_k$ by $\\gcd(a_j, a_k),\\lcm(a_j,a_k)$.\nIf neither of $a_j, a_k$ is divisible by $p^m$, then neither of\n$\\gcd(a_j, a_k),\\lcm(a_j,a_k)$ is either.\nIf exactly one $a_j, a_k$ is divisible by $p^m$, then\n$\\lcm(a_j,a_k)$ is divisible by $p^m$ but $\\gcd(a_j, a_k)$ is not.\n\n$\\gcd(a_j, a_k),\\lcm(a_j,a_k)$ are as well.\n\nIf we started out with exactly $h$ numbers not divisible by $p^m$,\nthen in the final sequence $a'_1, \\dots, a'_n$, the numbers\n$a'_{h+1}, \\dots, a'_n$ are divisible by $p^m$ while the numbers\n$a'_1, \\dots, a'_h$ are not. Repeating this argument for each\npair $(p,m)$ such that $p^m$ divides the initial product\n$a_1,\\dots,a_n$, we can determine the exact prime factorization\nof each of $a'_1,\\dots,a'_n$. This proves that the final sequence\nis unique.\n\n\\textbf{Remark:}\n(by David Savitt and Noam Elkies)\nHere are two other ways to prove the termination.\nOne is to observe that $\\prod_j a_j^j$\nis \\emph{strictly} increasing at each step, and bounded above by\n$(a_1\\cdots a_n)^n$. The other is to notice that $a_1$ is nonincreasing\nbut always positive, so eventually becomes constant; then\n$a_2$ is nonincreasing but always positive, and so on.\n\n\\textbf{Reinterpretation:}\nFor each $p$, consider the sequence consisting of the\nexponents of $p$ in the prime factorizations of $a_1,\\dots,a_n$.\nAt each step, we pick two positions $i$ and $j$ such that the exponents\nof some prime $p$ are in the wrong order at positions $i$ and $j$.\nWe then sort these two position into the correct order for every prime $p$\nsimultaneously.\n\nIt is clear that this can only terminate with all sequences being sorted\ninto the correct order. We must still check that the process terminates;\nhowever, since all but finitely many of the exponent\nsequences consist of all zeroes,\nand each step makes a nontrivial switch in at least one of the other exponent\nsequences, it is enough to check the case of a single exponent sequence.\nThis can be done as in the first solution.\n\n\\textbf{Remark:}\nAbhinav Kumar suggests the following proof that the process always terminates\nin at most  $\\binom{n}{2}$ steps.\n(This is a variant of the worst-case analysis of the \\emph{bubble sort}\nalgorithm.)\n\nConsider the number of pairs $(k,l)$\nwith $1 \\leq k < l \\leq n$ such that $a_k$ does not divide $a_l$\n(call these \\emph{bad pairs}).\nAt each step, we find one bad pair $(i,j)$ and eliminate it, and we do not\ntouch any pairs that do not involve either $i$ or $j$.\nIf $i < k < j$, then neither of the pairs $(i,k)$ and $(k,j)$ can become\nbad,\nbecause $a_i$ is replaced by a divisor of itself, while $a_j$ is replaced by\na multiple of itself. If $k < i$, then $(k,i)$ can only become a bad pair if\n$a_k$ divided $a_i$ but not $a_j$, in which case $(k,j)$ stops being bad.\nSimilarly, if $k > j$, then $(i,k)$ and $(j,k)$\neither stay the same or switch status. Hence the number of bad pairs\ngoes down by at least 1 each time; since it is at most $\\binom{n}{2}$\nto begin with, this is an upper bound for the number of steps.\n\n\\textbf{Remark:}\nThis problem is closely related to the classification theorem for\nfinite abelian groups. Namely, if $a_1,\\dots,a_n$\nand $a'_1,\\dots,a'_n$ are the sequences obtained at two different\nsteps in the process, then the abelian groups\n$\\ZZ/a_1 \\ZZ \\times \\cdots \\times \\ZZ/a_n \\ZZ$\nand\n$\\ZZ/a'_1 \\ZZ \\times \\cdots \\times \\ZZ/a'_n \\ZZ$\nare isomorphic. The final sequence gives a canonical\npresentation of this group; the terms of this sequence are called the\n\\emph{elementary divisors} or \\emph{invariant factors} of the group.\n\n\\textbf{Remark:} (by Tom Belulovich)\nA \\emph{lattice} is a partially ordered set $L$ in which for\nany two $x,y \\in L$, there is a unique minimal element $z$ with $z \\geq\nx$ and $z \\geq y$, called the \\emph{join} and denoted $x \\wedge y$,\nand there is a unique maximal element $z$ with $z \\leq x$ and $z \\leq y$,\ncalled the \\emph{meet} and denoted $x \\vee y$. In terms of a lattice $L$,\none can pose the following generalization of the given problem.\nStart with $a_1,\\dots,a_n \\in L$. If $i < j$ but $a_i \\not\\leq a_j$,\nit is permitted to replace $a_i, a_j$ by $a_i \\vee a_j, a_i \\wedge a_j$,\nrespectively. The same argument as above shows that this always terminates\nin at most $\\binom{n}{2}$ steps. The question is, under what conditions on\nthe lattice $L$ is the final sequence uniquely determined by the initial\nsequence?\n\nIt turns out that this holds if and only if $L$ is \\emph{distributive},\ni.e., for any $x,y,z \\in L$,\n\\[\nx \\wedge (y \\vee z)\n= (x \\wedge y) \\vee (x \\wedge z).\n\\]\n(This is equivalent to the same axiom with the operations interchanged.)\nFor example, if $L$ is a \\emph{Boolean algebra}, i.e., the set of subsets\nof a given set $S$ under inclusion, then $\\wedge$ is union, $\\vee$\nis intersection, and the distributive law holds.\nConversely, any finite\ndistributive lattice is contained in a Boolean algebra by a theorem of\nBirkhoff. The correspondence takes each  $x \\in L$ to the set of\n$y \\in L$ such that $x \\geq y$ and $y$ cannot be written as a join\nof two elements of $L \\setminus \\{y\\}$. (See for instance\nBirkhoff, \\textit{Lattice Theory}, Amer. Math. Soc., 1967.)\n\nOn one hand, if $L$ is distributive, it can be shown that the $j$-th term\nof the final sequence is equal to the meet of $a_{i_1} \\wedge \\cdots\n\\wedge a_{i_j}$ over all sequences $1 \\leq i_1 < \\cdots < i_j \\leq n$.\nFor instance, this can be checked by forming the smallest subset $L'$\nof $L$ containing $a_1,\\dots,a_n$ and closed under meet and join,\nthen embedding $L'$ into a Boolean algebra using\nBirkhoff's theorem, then checking the claim for all Boolean algebras.\nIt can also be checked directly (as suggested by Nghi Nguyen)\nby showing that for $j=1,\\dots,n$,\nthe meet of all joins of $j$-element subsets of $a_1,\\dots,a_n$ is\ninvariant at each step.\n\nOn the other hand,\na lattice fails to be distributive if and only if\nit contains five elements $a,b,c,0,1$ such that either the only relations\namong them are implied by\n\\[\n1 \\geq a,b,c \\geq 0\n\\]\n(this lattice is sometimes called the \\emph{diamond}),\nor the only relations among them  are implied by\n\\[\n1 \\geq a \\geq b \\geq 0, \\qquad 1 \\geq c \\geq 0\n\\]\n(this lattice is sometimes called the \\emph{pentagon}).\n(For a proof, see the Birkhoff reference given above.) For each of these\nexamples, the initial sequence $a,b,c$ fails to determine the final\nsequence; for the diamond, we can end up with $0, *, 1$ for\nany of $* = a,b,c$, whereas for the pentagon we can end up with\n$0, *, 1$ for any of $* = a, b$.\n\nConsequently, the final sequence is determined by the initial sequence\nif and only if $L$ is distributive."
  },
  {
    "year": 2008,
    "label": "A4",
    "difficulty": "4",
    "problem": "Define $f: \\mathbb{R} \\to \\mathbb{R}$ by\n\\[\nf(x) = \\begin{cases} x & \\mbox{if $x \\leq e$} \\\\ x f(\\ln x) &\n\\mbox{if $x > e$.} \\end{cases}\n\\]\nDoes $\\sum_{n=1}^\\infty \\frac{1}{f(n)}$ converge?",
    "solution": "The sum diverges. From the definition, $f(x) = x$ on $[1,e]$, $x\\ln x$ on $(e,e^e]$, $x\\ln x\\ln\\ln x$ on $(e^e,e^{e^e}]$, and so forth. It follows that on $[1,\\infty)$, $f$ is positive, continuous, and increasing. Thus $\\sum_{n=1}^\\infty \\frac{1}{f(n)}$, if it converges, is bounded below by $\\int_1^{\\infty} \\frac{dx}{f(x)}$; it suffices to prove that the integral diverges.\n\nWrite $\\ln^1 x  = \\ln x $ and $\\ln^k x = \\ln(\\ln^{k-1} x)$ for $k \\geq 2$; similarly write $\\exp^1 x = e^x$ and $\\exp^k x  = e^{\\exp^{k-1} x}$. If we write $y = \\ln^k x$, then $x = \\exp^k y$ and $dx = (\\exp^ky)(\\exp^{k-1}y)\\cdots (\\exp^1y)dy =\nx(\\ln^1 x) \\cdots (\\ln^{k-1}x)dy$. Now on\n$[\\exp^{k-1} 1,\\exp^k 1]$, we have\n$f(x) = x(\\ln^1 x) \\cdots (\\ln^{k-1}x)$, and thus substituting $y=\\ln^k x$ yields\n\\[\n\\int_{\\exp^{k-1} 1}^{\\exp^k 1} \\frac{dx}{f(x)} =\n\\int_{0}^{1} dy = 1.\n\\]\nIt follows that $\\int_1^{\\infty} \\frac{dx}{f(x)} = \\sum_{k=1}^{\\infty} \\int_{\\exp^{k-1} 1}^{\\exp^k 1} \\frac{dx}{f(x)}$ diverges, as desired."
  },
  {
    "year": 2008,
    "label": "A5",
    "difficulty": "5",
    "problem": "Let $n \\geq 3$ be an integer. Let $f(x)$ and $g(x)$ be polynomials\nwith real coefficients such that the points\n$(f(1), g(1)), (f(2), g(2)), \\dots, (f(n), g(n))$\nin $\\mathbb{R}^2$ are the vertices of a regular $n$-gon in\ncounterclockwise order. Prove that at least one of $f(x)$\nand $g(x)$ has degree greater than or equal to $n-1$.",
    "solution": "Form the polynomial $P(z) = f(z) + i g(z)$ with complex coefficients.\nIt suffices to prove that $P$ has degree at least $n-1$, as then one\nof $f, g$ must have degree at least $n-1$.\n\nBy replacing $P(z)$ with $a P(z) + b$ for suitable $a,b \\in \\CC$,\nwe can force the regular $n$-gon to have vertices\n$\\zeta_n, \\zeta_n^2, \\dots, \\zeta_n^n$ for\n$\\zeta_n = \\exp(2 \\pi i/n)$. It thus suffices to check that\nthere cannot exist a polynomial $P(z)$ of degree at most $n-2$\nsuch that $P(i) = \\zeta_n^i$ for $i=1,\\dots,n$.\n\nWe will prove more generally that for any complex number\n$t \\notin \\{0,1\\}$, and any integer $m \\geq 1$,\nany polynomial $Q(z)$ for which\n$Q(i) = t^i$ for $i=1,\\dots,m$ has degree at least $m-1$.\nThere are several ways to do this.\n\n\\textbf{First solution:}\nIf $Q(z)$ has degree $d$ and leading coefficient $c$,\nthen $R(z) = Q(z+1) - t Q(z)$ has degree $d$ and leading coefficient $(1-t)c$.\nHowever, by hypothesis, $R(z)$ has the distinct roots\n$1,2,\\dots,m-1$, so we must have $d \\geq m-1$.\n\n\\textbf{Second solution:}\nWe proceed by induction on $m$.\nFor the base case $m=1$, we have $Q(1) = t^1 \\neq 0$,\nso $Q$ must be nonzero, and so its degree is at least $0$.\nGiven the assertion for $m-1$, if $Q(i) = t^i$ for $i=1,\\dots,m$,\nthen the polynomial $R(z) = (t-1)^{-1} (Q(z+1) - Q(z))$ has degree\none less than that of $Q$,\nand satisfies $R(i) = t^i$ for $i=1,\\dots,m-1$. Since $R$ must have\ndegree at least $m-2$ by the induction hypothesis, $Q$ must have\ndegree at least $m-1$.\n\n\\textbf{Third solution:}\nWe use the method of \\emph{finite differences} (as in the second\nsolution) but without induction. Namely,\nthe $(m-1)$-st finite difference\nof $P$ evaluated at 1 equals\n\\[\n\\sum_{j=0}^{m-1} (-1)^j \\binom{m-1}{j} Q(m-j)\n= t(1 - t)^{m-1} \\neq 0,\n\\]\nwhich is impossible if $Q$ has degree less than $m-1$.\n\n\\textbf{Remark:} One can also establish the claim by computing\na Vandermonde-type determinant, or by using the Lagrange interpolation\nformula to compute the leading coefficient of $Q$."
  },
  {
    "year": 2008,
    "label": "A6",
    "difficulty": "6",
    "problem": "Prove that there exists a constant $c>0$ such that in every\nnontrivial finite group $G$ there exists a sequence of length\nat most $c \\log |G|$ with the property that each element of $G$\nequals the product of some subsequence. (The elements of $G$ in the\nsequence are not required to be distinct. A \\emph{subsequence}\nof a sequence is obtained by selecting some of the terms,\nnot necessarily consecutive, without reordering them; for\nexample, $4, 4, 2$ is a subsequence of $2, 4, 6, 4, 2$, but\n$2, 2, 4$ is not.)",
    "solution": "For notational convenience, we will interpret the problem as\nallowing the empty subsequence, whose product is the identity element of\nthe group. To solve the problem in the interpretation where the empty\nsubsequence is not allowed, simply append the identity element to the sequence\ngiven by one of the following solutions.\n\n\\textbf{First solution:}\nPut $n = |G|$.\nWe will say that a sequence $S$ \\emph{produces}\nan element $g \\in G$ if $g$ occurs as the product of some subsequence\nof $S$.\nLet $H$ be the set of elements produced by the sequence $S$.\n\nStart with $S$ equal to the empty sequence. If at any point\nthe set $H^{-1}H = \\{h_1 h_2: h_1^{-1}, h_2 \\in H\\}$ fails to be\nall of $G$, extend $S$ by appending an element $g$ of $G$ not in\n$H^{-1} H$. Then $Hg \\cap H$ must be empty, otherwise there would\nbe an equation of the form $h_1 g= h_2 $ with $h_1, h_2 \\in G$,\nor $g = h_1^{-1} h_2$, a contradiction. Thus we can extend $S$ by one\nelement and double the size of $H$.\n\nAfter $k \\leq \\log_2 n$ steps, we must obtain a sequence $S\n= a_1,\\dots,a_k$ for which $H^{-1} H = G$. Then\nthe sequence $a_k^{-1}, \\dots, a_1^{-1}, a_1, \\dots, a_k$\nproduces all of $G$ and has length at most $(2/\\ln 2) \\ln n$.\n\n\\textbf{Second solution:}\n\nPut $m = |H|$. We will show that we can append one element\n$g$ to $S$ so that the resulting sequence of $k+1$ elements will produce\nat least $2m-m^2/n$ elements of $G$. To see this, we compute\n\\begin{align*}\n\\sum_{g \\in G} |H \\cup Hg|\n&= \\sum_{g \\in G} (|H| + |Hg| - |H \\cap Hg|) \\\\\n&= 2mn - \\sum_{g \\in G} |H \\cap Hg| \\\\\n&= 2mn - |\\{(g,h) \\in G^2: h \\in H \\cap Hg\\}| \\\\\n&= 2mn - \\sum_{h \\in H} |\\{g \\in G: h \\in Hg\\}| \\\\\n&= 2mn - \\sum_{h \\in H} |H^{-1} h| \\\\\n&= 2mn - m^2.\n\\end{align*}\nBy the pigeonhole principle, we have $|H \\cup Hg| \\geq 2m - m^2/n$ for\nsome choice of $g$, as claimed.\n\nIn other words, by extending the sequence by one element,\nwe can replace the ratio $s = 1-m/n$ (i.e., the fraction\nof elements of $G$ not generated by $S$)\nby a quantity no greater than\n\\[\n1-(2m-m^2/n)/n = s^2.\n\\]\nWe start out with $k = 0$ and $s = 1 - 1/n$;\nafter $k$ steps, we have $s \\leq (1-1/n)^{2^k}$.\nIt is enough to prove that for some $c > 0$, we can always find\nan integer $k \\leq c \\ln n$ such that\n\\[\n\\left(1 - \\frac{1}{n} \\right)^{2^k} < \\frac{1}{n},\n\\]\nas then we have $n-m < 1$ and hence $H = G$.\n\nTo obtain this last inequality, put\n\\[\nk = \\lfloor 2 \\log_2 n \\rfloor < (2/\\ln 2) \\ln n,\n\\]\nso that $2^{k+1} \\geq n^2$.\nFrom the facts that $\\ln n \\leq \\ln 2 + (n-2)/2 \\leq n/2$ and\n$\\ln (1-1/n) < -1/n$ for all $n \\geq 2$, we have\n\\[\n2^k \\ln \\left( 1 - \\frac{1}{n} \\right) < -\\frac{n^2}{2n} =  -\\frac{n}{2} < -\\ln n,\n\\]\nyielding the desired inequality.\n\n\\textbf{Remark:} An alternate approach in the second solution\nis to distinguish betwen the cases of $H$ small (i.e.,\n$m < n^{1/2}$, in which case $m$ can be replaced by a value\nno less than $2m-1$) and $H$ large.\nThis strategy is used in a number of recent results\nof Bourgain, Tao, Helfgott, and others on \\emph{small doubling}\nor \\emph{small tripling}\nof subsets of finite groups.\n\nIn the second solution, if we avoid the rather weak inequality\n$\\ln n \\leq n/2$, we instead get sequences of length\n$\\log_2 (n \\ln n) = \\log_2(n) + \\log_2 (\\ln n)$.\nThis is close to optimal: one cannot use fewer than $\\log_2 n$\nterms because the number of subsequences must be at least $n$."
  },
  {
    "year": 2008,
    "label": "B1",
    "difficulty": "1",
    "problem": "What is the maximum number of rational points that can lie on a circle\nin $\\mathbb{R}^2$ whose center is not a rational point? (A \\emph{rational\npoint} is a point both of whose coordinates are rational numbers.)",
    "solution": "There are at most two such points. For example,\nthe points $(0,0)$ and $(1,0)$ lie on a circle with center\n$(1/2, x)$ for any real number $x$, not necessarily rational.\n\nOn the other hand, suppose $P = (a,b), Q = (c,d), R = (e,f)$\nare three rational points that lie\non a circle. The midpoint $M$ of the side $PQ$ is\n$((a+c)/2, (b+d)/2)$, which is again rational. Moreover, the slope\nof the line $PQ$ is $(d-b)/(c-a)$, so the slope of the line through\n$M$ perpendicular to $PQ$ is $(a-c)/(b-d)$, which is rational or infinite.\n\nSimilarly, if $N$ is the midpoint of $QR$, then $N$ is a rational point\nand the line through $N$ perpendicular to $QR$ has rational slope.\nThe center of the circle lies on both of these lines, so its\ncoordinates $(g,h)$ satisfy two linear equations with rational\ncoefficients, say $Ag + Bh = C$ and $Dg + Eh = F$. Moreover,\nthese equations have a unique solution. That solution must then be\n\\begin{align*}\ng &= (CE - BD)/(AE - BD) \\\\\nh &= (AF - BC)/(AE - BD)\n\\end{align*}\n(by elementary algebra, or Cramer's rule),\nso the center of the circle is rational. This proves the desired result.\n\n\\textbf{Remark:} The above solution is deliberately more verbose\nthan is really necessary. A shorter way to say this is that any two distinct\nrational points determine a \\emph{rational line}\n(a line of the form $ax + by + c = 0$ with $a,b,c$ rational),\nwhile any two nonparallel rational lines intersect at a rational point.\nA similar statement holds with the rational numbers replaced by any\nfield.\n\n\\textbf{Remark:} A more explicit argument is to show that the equation of\nthe circle through the rational points $(x_1, y_1), (x_2, y_2), (x_3, y_3)$ is\n\\[\n0 = \\det \\begin{pmatrix}\nx_1^2 + y_1^2 & x_1 & y_1 & 1 \\\\\nx_2^2 + y_2^2 & x_2 & y_2 & 1 \\\\\nx_3^2 + y_3^2 & x_3 & y_3 & 1 \\\\\nx^2 + y^2 & x & y & 1 \\\\\n\\end{pmatrix}\n\\]\nwhich has the form $a(x^2+y^2) + dx + ey + f = 0$ for $a,d,e,f$ rational.\nThe center of this circle is $(-d/(2a), -e/(2a))$, which is again a rational\npoint."
  },
  {
    "year": 2008,
    "label": "B2",
    "difficulty": "2",
    "problem": "Let $F_0(x) = \\ln x$. For $n \\geq 0$ and $x > 0$, let\n$F_{n+1}(x) = \\int_0^x F_n(t)\\,dt$. Evaluate\n\\[\n\\lim_{n \\to \\infty} \\frac{n! F_n(1)}{\\ln n}.\n\\]",
    "solution": "We claim that $F_n(x) = (\\ln x-a_n)x^n/n!$, where $a_n = \\sum_{k=1}^n 1/k$. Indeed, temporarily write $G_n(x) = (\\ln x-a_n)x^n/n!$ for $x>0$ and $n\\geq 1$; then $\\lim_{x\\to 0} G_n(x) = 0$ and $G_n'(x) = (\\ln x-a_n+1/n) x^{n-1}/(n-1)! = G_{n-1}(x)$, and the claim follows by the Fundamental Theorem of Calculus and induction on $n$.\n\nGiven the claim, we have $F_n(1) = -a_n/n!$ and so we need to evaluate $-\\lim_{n\\to\\infty} \\frac{a_n}{\\ln n}$. But since the function $1/x$ is strictly decreasing for $x$ positive, $\\sum_{k=2}^n 1/k = a_n-1$ is bounded below by $\\int_2^n dx/x = \\ln n-\\ln 2$ and above by $\\int_1^n dx/x=\\ln n$. It follows that $\\lim_{n\\to\\infty} \\frac{a_n}{\\ln n} = 1$, and the desired limit is $-1$."
  },
  {
    "year": 2008,
    "label": "B3",
    "difficulty": "3",
    "problem": "What is the largest possible radius of a circle contained in a 4-dimensional\nhypercube of side length 1?",
    "solution": "The largest possible radius is $\\frac{\\sqrt{2}}{2}$.\nIt will be convenient to solve\nthe problem for a hypercube of side length 2 instead, in which case\nwe are trying to show that the largest radius is $\\sqrt{2}$.\n\nChoose coordinates so that the interior of the hypercube\nis the set $H = [-1,1]^4$ in $\\RR^4$. Let $C$ be a circle\ncentered at the point $P$. Then $C$ is contained both in $H$\nand its reflection across $P$; these intersect in a rectangular\nparalellepiped each of whose pairs of opposite faces are at most\n2 unit apart. Consequently, if we translate $C$ so that its center\nmoves to the point $O = (0,0,0,0)$ at the center of $H$,\nthen it remains entirely inside $H$.\n\nThis means that the answer we seek equals the largest possible radius\nof a circle $C$ contained in $H$ \\emph{and centered at $O$}.\nLet $v_1 = (v_{11}, \\dots, v_{14})$ and $v_2 = (v_{21},\\dots,v_{24})$\nbe two points on $C$ lying on radii perpendicular to each other.\nThen the points of the circle can be expressed as\n$v_1 \\cos \\theta + v_2 \\sin \\theta$ for $0 \\leq \\theta < 2\\pi$.\nThen $C$ lies in $H$ if and only if for each $i$, we have\n\\[\n|v_{1i} \\cos \\theta + v_{2i} \\sin \\theta|\n\\leq 1 \\qquad (0 \\leq \\theta < 2\\pi).\n\\]\nIn geometric terms, the vector $(v_{1i}, v_{2i})$ in $\\RR^2$\nhas dot product at most 1 with every unit vector. Since this holds\nfor the unit vector in the same direction as\n$(v_{1i}, v_{2i})$, we must have\n\\[\nv_{1i}^2 + v_{2i}^2 \\leq 1 \\qquad (i=1,\\dots,4).\n\\]\nConversely, if this holds, then the Cauchy-Schwarz inequality\nand the above analysis imply that $C$ lies in $H$.\n\nIf $r$ is the radius of $C$, then\n\\begin{align*}\n2 r^2 &= \\sum_{i=1}^4 v_{1i}^2 + \\sum_{i=1}^4 v_{2i}^2 \\\\\n&= \\sum_{i=1}^4 (v_{1i}^2 + v_{2i}^2) \\\\\n&\\leq 4,\n\\end{align*}\nso $r \\leq \\sqrt{2}$.\nSince this is achieved by the circle\nthrough $(1,1,0,0)$ and $(0,0,1,1)$,\nit is the desired maximum.\n\n\\textbf{Remark:}\nOne may similarly ask for the radius of the largest $k$-dimensional\nball inside an $n$-dimensional unit hypercube; the given problem is\nthe case $(n,k) = (4,2)$.\nDaniel Kane gives the following argument to show that the maximum radius\nin this case is $\\frac{1}{2} \\sqrt{\\frac{n}{k}}$.\n(Thanks for Noam Elkies for passing this along.)\n\nWe again scale up by a factor of 2, so that we are trying to show that\nthe maximum radius $r$ of a $k$-dimensional ball contained in the hypercube\n$[-1,1]^n$ is $\\sqrt{\\frac{n}{k}}$. Again, there is no loss of generality\nin centering the ball at the origin. Let $T: \\RR^k \\to \\RR^n$ be a\nsimilitude carrying the unit ball to this embedded $k$-ball.\nThen there exists a vector $v_i \\in \\RR^k$ such that\nfor $e_1,\\dots,e_n$ the standard basis of $\\RR^n$,\n$x \\cdot v_i = T(x) \\cdot e_i$ for all $x \\in \\RR^k$.\nThe condition of the problem is equivalent to requiring\n$|v_i| \\leq 1$ for all $i$, while the radius $r$ of the embedded ball\nis determined by the fact that for all $x \\in \\RR^k$,\n\\[\nr^2 (x \\cdot x) = T(x) \\cdot T(x) = \\sum_{i=1}^n x \\cdot v_i.\n\\]\nLet $M$ be the matrix with columns $v_1,\\dots,v_k$; then $MM^T = r^2 I_k$,\nfor $I_k$ the $k \\times k$ identity matrix. We then have\n\\begin{align*}\nkr^2 &= \\Trace(r^2 I_k) = \\Trace(MM^T)\\\\\n&= \\Trace(M^TM) = \\sum_{i=1}^n |v_i|^2 \\\\\n&\\leq n,\n\\end{align*}\nyielding the upper bound $r \\leq \\sqrt{\\frac{n}{k}}$.\n\nTo show that this bound is optimal, it is enough to show that one can\nfind an orthogonal projection of $\\RR^n$ onto $\\RR^k$ so that the\nprojections of the $e_i$ all have the same norm (one can then rescale\nto get the desired configuration of  $v_1,\\dots,v_n$). We construct\nsuch a configuration by a ``smoothing'' argument. Startw with any\nprojection.\nLet $w_1,\\dots,w_n$ be the projections of $e_1,\\dots,e_n$.\nIf the desired condition is not\nachieved, we can choose $i,j$ such that\n\\[\n|w_i|^2 < \\frac{1}{n} (|w_1|^2 + \\cdots + |w_n|^2) < |w_j|^2.\n\\]\nBy precomposing\nwith a suitable rotation that fixes $e_h$ for $h \\neq i,j$,\nwe can vary $|w_i|, |w_j|$ without varying $|w_i|^2 + |w_j|^2$\nor $|w_h|$ for $h \\neq i,j$. We can thus choose such a rotation to\nforce one of $|w_i|^2, |w_j|^2$ to become equal to\n$\\frac{1}{n} (|w_1|^2 + \\cdots + |w_n|^2)$.\nRepeating at most $n-1$ times gives the desired configuration."
  },
  {
    "year": 2008,
    "label": "B4",
    "difficulty": "4",
    "problem": "Let $p$ be a prime number. Let $h(x)$ be a polynomial with integer coefficients\nsuch that $h(0), h(1), \\dots, h(p^2-1)$ are distinct modulo $p^2$.\nShow that $h(0), h(1), \\dots, h(p^3-1)$ are distinct modulo $p^3$.",
    "solution": "We use the identity given by Taylor's theorem:\n\\[\nh(x+y) = \\sum_{i=0}^{\\deg(h)} \\frac{h^{(i)}(x)}{i!} y^i.\n\\]\nIn this expression, $h^{(i)}(x)/i!$ is a polynomial in $x$\nwith integer coefficients, so its value at an integer $x$ is an\ninteger.\n\nFor $x = 0,\\dots,p-1$, we deduce that\n\\[\nh(x+p) \\equiv h(x) + p h'(x) \\pmod{p^2}.\n\\]\n(This can also be deduced more directly using the binomial theorem.)\nSince we assumed $h(x)$ and $h(x+p)$ are distinct modulo $p^2$,\nwe conclude that $h'(x) \\not\\equiv 0 \\pmod{p}$. Since $h'$\nis a polynomial with integer coefficients, we have\n$h'(x) \\equiv h'(x + mp) \\pmod{p}$ for any integer $m$,\nand so $h'(x) \\not\\equiv 0 \\pmod{p}$ for \\emph{all} integers $x$.\n\nNow for $x= 0,\\dots,p^2-1$ and $y=0,\\dots,p-1$, we write\n\\[\nh(x + y p^2) \\equiv h(x) + p^2 y h'(x) \\pmod{p^3}.\n\\]\nThus $h(x), h(x+p^2),\\dots,h(x+(p-1)p^2)$ run over all of the residue\nclasses modulo $p^3$ congruent to $h(x)$ modulo $p^2$.\nSince the $h(x)$ themselves cover all the residue classes modulo $p^2$,\nthis proves that $h(0), \\dots, h(p^3-1)$ are distinct modulo $p^3$.\n\n\\textbf{Remark:}\nMore generally, the same proof shows that for any integers $d,e > 1$,\n$h$ permutes the residue classes modulo $p^d$ if and only if it permutes\nthe residue classes modulo $p^e$. The argument used in the proof is related\nto a general result in number theory known as\n\\emph{Hensel's lemma}."
  },
  {
    "year": 2008,
    "label": "B5",
    "difficulty": "5",
    "problem": "Find all continuously differentiable functions $f: \\mathbb{R} \\to \\mathbb{R}$\nsuch that for every rational number $q$, the number $f(q)$ is rational\nand has the same denominator as $q$. (The denominator of a rational number\n$q$ is the unique positive integer $b$ such that $q = a/b$\nfor some integer $a$ with $\\mathrm{gcd}(a,b) = 1$.)\n(Note: gcd means greatest common\ndivisor.)",
    "solution": "The functions $f(x) = x+n$ and $f(x)=-x+n$ for any integer $n$ clearly satisfy the condition of the problem; we claim that these are the only possible $f$.\n\nLet $q=a/b$ be any rational number with $\\gcd(a,b)=1$ and $b>0$. For $n$ any positive integer, we have\n\\[\n\\frac{f(\\frac{an+1}{bn}) - f(\\frac{a}{b})}{\\frac{1}{bn}}\n= bn f\\left(\\frac{an+1}{bn}\\right) - nb f\\left(\\frac{a}{b}\\right)\n\\]\nis an integer by the property of $f$. Since $f$ is differentiable at $a/b$, the left hand side has a limit. It follows that for sufficiently large $n$, both sides must be equal to some integer $c=f'(\\frac{a}{b})$: $f(\\frac{an+1}{bn}) = f(\\frac{a}{b})+\\frac{c}{bn}$. Now $c$ cannot be $0$, since otherwise $f(\\frac{an+1}{bn}) = f(\\frac{a}{b})$ for sufficiently large $n$ has denominator $b$ rather than $bn$. Similarly, $|c|$ cannot be greater than $1$: otherwise\nif we take $n=k|c|$ for $k$ a sufficiently large positive integer,\nthen $f(\\frac{a}{b})+\\frac{c}{bn}$ has denominator $bk$, contradicting the fact that $f(\\frac{an+1}{bn})$ has denominator $bn$. It follows that $c = f'(\\frac{a}{b}) = \\pm 1$.\n\nThus the derivative of $f$ at any rational number is $\\pm 1$. Since $f$ is continuously differentiable, we conclude that $f'(x) = 1$ for all real $x$ or $f'(x) = -1$ for all real $x$. Since $f(0)$ must be an integer (a rational number with denominator $1$), $f(x)=x+n$ or $f(x)=-x+n$ for some integer $n$.\n\n\\textbf{Remark:}\nAfter showing that $f'(q)$ is an integer for each $q$, one can instead\nargue that $f'$ is a continuous function from the rationals to the integers,\nso must be constant. One can then write $f(x) = ax+b$ and check that\n$b \\in \\ZZ$ by evaluation at $a=0$, and that $a= \\pm 1$ by evaluation at\n$x=1/a$."
  },
  {
    "year": 2008,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $n$ and $k$ be positive integers. Say that a permutation $\\sigma$\nof $\\{1,2,\\dots,n\\}$ is \\emph{$k$-limited} if $|\\sigma(i) - i| \\leq k$\nfor all $i$. Prove that the number of $k$-limited permutations of\n$\\{1,2,\\dots,n\\}$ is odd if and only if $n \\equiv 0$ or $1$\n(mod $2k+1$).\n\n\\end{itemize}\n\n\\end{document}",
    "solution": "In all solutions,\nlet $F_{n,k}$ be the number of $k$-limited permutations of\n$\\{1,\\dots,n\\}$.\n\n\\textbf{First solution:}\n(by Jacob Tsimerman)\nNote that any permutation is $k$-limited if and only if its inverse is\n$k$-limited. Consequently, the number of $k$-limited permutations of\n$\\{1,\\dots,n\\}$ is the same as the number of $k$-limited involutions\n(permutations equal to their inverses) of $\\{1,\\dots,n\\}$.\n\nWe use the following fact several times: the number of involutions\nof $\\{1,\\dots,n\\}$ is odd if $n=0,1$ and even otherwise. This follows from\nthe fact that non-involutions come in pairs, so the number of involutions\nhas the same parity as the number of permutations, namely $n!$.\n\nFor $n \\leq k+1$, all involutions are $k$-limited.\nBy the previous paragraph, $F_{n,k}$ is odd for $n=0,1$ and even for\n$n=2,\\dots,k+1$.\n\nFor $n > k+1$, group the  $k$-limited involutions into classes based on\ntheir actions on $k+2,\\dots,n$. Note that for $C$ a class and $\\sigma \\in C$,\nthe set of elements of $A = \\{1,\\dots,k+1\\}$ which map into $A$ under\n$\\sigma$ depends only on $C$, not on $\\sigma$. Call this set $S(C)$; then\nthe size of $C$ is exactly the number of involutions of $S(C)$.\nConsequently, $|C|$ is even unless $S(C)$ has at most one element.\nHowever, the element 1 cannot map out of $A$ because we are looking at\n$k$-limited involutions. Hence if $S(C)$ has one element and $\\sigma \\in C$,\nwe must have $\\sigma(1) = 1$. Since $\\sigma$ is $k$-limited and\n$\\sigma(2)$ cannot belong to $A$, we must have $\\sigma(2) = k+2$. By\ninduction, for $i=3,\\dots,k+1$, we must have  $\\sigma(i) = k+i$.\n\nIf $n < 2k+1$, this shows that no class $C$ of odd cardinality can exist,\nso $F_{n,k}$ must be even. If $n \\geq 2k+1$, the classes of odd cardinality\nare in bijection with $k$-limited involutions of $\\{2k+2,\\dots,n\\}$,\nso $F_{n,k}$ has the same parity as $F_{n-2k-1,k}$. By induction on $n$,\nwe deduce the desired result.\n\n\\textbf{Second solution:}\n(by Yufei Zhao)\nLet $M_{n,k}$ be the $n \\times n$ matrix with\n\\[\n(M_{n,k})_{ij} = \\begin{cases} 1 & |i-j|\\leq k \\\\ 0 & \\mbox{otherwise.}\n\\end{cases}\n\\]\nWrite $\\det(M_{n,k})$ as the sum over permutations\n$\\sigma$ of $\\{1,\\dots,n\\}$ of\n$(M_{n,k})_{1 \\sigma(1)} \\cdots (M_{n,k})_{n \\sigma(n)}$\ntimes the signature of $\\sigma$. Then $\\sigma$ contributes $\\pm 1$\nto $\\det (M_{n,k})$ if $\\sigma$ is $k$-limited and 0 otherwise.\nWe conclude that\n\\[\n\\det(M_{n,k}) \\equiv F_{n,k} \\pmod{2}.\n\\]\nFor the rest of the solution, we interpret $M_{n,k}$ as a matrix\nover the field of two elements. We compute its determinant using\nlinear algebra modulo 2.\n\nWe first show that for $n \\geq 2k+1$,\n\\[\nF_{n,k} \\equiv F_{n-2k-1,k} \\pmod{2},\n\\]\nprovided that we interpret $F_{0,k} = 1$. We do this by\ncomputing $\\det(M_{n,k})$ using row and column operations.\nWe will verbally describe these operations for general $k$,\nwhile illustrating with the example $k=3$.\n\nTo begin with, $M_{n,k}$ has the following form.\n\\[\n\\left(\n\\begin{array}{ccccccc|c}\n1 & 1 & 1 & 1 & 0 & 0 & 0 & \\emptyset \\\\\n1 & 1 & 1 & 1 & 1 & 0 & 0 & \\emptyset \\\\\n1 & 1 & 1 & 1 & 1 & 1 & 0 & \\emptyset \\\\\n1 & 1 & 1 & 1 & 1 & 1 & 1 & \\emptyset \\\\\n0 & 1 & 1 & 1 & 1 & 1 & 1 & ? \\\\\n0 & 0 & 1 & 1 & 1 & 1 & 1 & ? \\\\\n0 & 0 & 0 & 1 & 1 & 1 & 1 & ? \\\\\n\\hline\n\\emptyset & \\emptyset & \\emptyset & \\emptyset & ? & ? & ? & *\n\\end{array}\n\\right)\n\\]\nIn this presentation, the first $2k+1$ rows and columns are shown\nexplicitly; the remaining rows and columns are shown in a compressed format.\nThe symbol $\\emptyset$ indicates that the unseen entries are all zeroes,\nwhile the symbol $?$ indicates that they are not. The symbol $*$ in the\nlower right corner represents the matrix $F_{n-2k-1,k}$.\nWe will preserve the unseen structure of the matrix by only adding\nthe first $k+1$ rows or columns to any of the others.\n\nWe first add row 1 to each of rows $2, \\dots, k+1$.\n\\[\n\\left(\n\\begin{array}{ccccccc|c}\n1 & 1 & 1 & 1 & 0 & 0 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 1 & 1 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 1 & 1 & 1 & \\emptyset \\\\\n0 & 1 & 1 & 1 & 1 & 1 & 1 & ? \\\\\n0 & 0 & 1 & 1 & 1 & 1 & 1 & ? \\\\\n0 & 0 & 0 & 1 & 1 & 1 & 1 & ? \\\\\n\\hline\n\\emptyset & \\emptyset & \\emptyset & \\emptyset & ? & ? & ? & *\n\\end{array}\n\\right)\n\\]\nWe next add column 1 to each of columns $2, \\dots, k+1$.\n\\[\n\\left(\n\\begin{array}{ccccccc|c}\n1 & 0 & 0 & 0 & 0 & 0 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 1 & 1 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 1 & 1 & 1 & \\emptyset \\\\\n0 & 1 & 1 & 1 & 1 & 1 & 1 & ? \\\\\n0 & 0 & 1 & 1 & 1 & 1 & 1 & ? \\\\\n0 & 0 & 0 & 1 & 1 & 1 & 1 & ? \\\\\n\\hline\n\\emptyset & \\emptyset & \\emptyset & \\emptyset & ? & ? & ? & *\n\\end{array}\n\\right)\n\\]\nFor $i=2$, for each of $j=i+1,\\dots,2k+1$\nfor which the $(j, k+i)$-entry is nonzero,\nadd row $i$ to row $j$.\n\\[\n\\left(\n\\begin{array}{ccccccc|c}\n1 & 0 & 0 & 0 & 0 & 0 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 1 & \\emptyset \\\\\n0 & 1 & 1 & 1 & 0 & 1 & 1 & ? \\\\\n0 & 0 & 1 & 1 & 0 & 1 & 1 & ? \\\\\n0 & 0 & 0 & 1 & 0 & 1 & 1 & ? \\\\\n\\hline\n\\emptyset & \\emptyset & \\emptyset & \\emptyset & \\emptyset & ? & ? & *\n\\end{array}\n\\right)\n\\]\nRepeat the previous step for $i=3,\\dots,k+1$ in succession.\n\\[\n\\left(\n\\begin{array}{ccccccc|c}\n1 & 0 & 0 & 0 & 0 & 0 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 1 & \\emptyset \\\\\n0 & 1 & 1 & 1 & 0 & 0 & 0 & ? \\\\\n0 & 0 & 1 & 1 & 0 & 0 & 0 & ? \\\\\n0 & 0 & 0 & 1 & 0 & 0 & 0 & ? \\\\\n\\hline\n\\emptyset & \\emptyset & \\emptyset & \\emptyset & \\emptyset & \\emptyset & \\emptyset & *\n\\end{array}\n\\right)\n\\]\nRepeat the two previous steps with the roles of the rows and columns reversed.\nThat is, for $i=2,\\dots,k+1$,\nfor each of $j=i+1,\\dots,2k+1$\nfor which the $(j, k+i)$-entry is nonzero,\nadd row $i$ to row $j$.\n\\[\n\\left(\n\\begin{array}{ccccccc|c}\n1 & 0 & 0 & 0 & 0 & 0 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 1 & \\emptyset \\\\\n0 & 1 & 0 & 0 & 0 & 0 & 0 & \\emptyset \\\\\n0 & 0 & 1 & 0 & 0 & 0 & 0 & \\emptyset \\\\\n0 & 0 & 0 & 1 & 0 & 0 & 0 & \\emptyset \\\\\n\\hline\n\\emptyset & \\emptyset & \\emptyset & \\emptyset & \\emptyset & \\emptyset & \\emptyset & *\n\\end{array}\n\\right)\n\\]\nWe now have a block diagonal matrix in which the top left\nblock is a $(2k+1) \\times (2k+1)$ matrix with nonzero determinant (it\nresults from reordering the rows of the identity matrix), the bottom right\nblock is $M_{n-2k-1,k}$, and the other two blocks are zero. We conclude that\n\\[\n\\det(M_{n,k}) \\equiv \\det(M_{n-2k-1,k})\n\\pmod{2},\n\\]\nproving the desired congruence.\n\nTo prove the desired result, we must now check that\n$F_{0,k}, F_{1,k}$ are odd and $F_{2,k}, \\dots, F_{2k,k}$ are even.\nFor $n=0,\\dots,k+1$, the matrix $M_{n,k}$ consists of all ones,\nso its determinant is 1 if $n=0,1$ and 0 otherwise.\n(Alternatively, we have $F_{n,k} = n!$ for $n=0,\\dots,k+1$,\nsince every permutation of $\\{1,\\dots,n\\}$ is $k$-limited.)\nFor $n=k+2,\\dots,2k$,\nobserve that rows $k$ and $k+1$ of $M_{n,k}$  both consist of all ones,\nso $\\det(M_{n,k}) = 0$ as desired.\n\n\\textbf{Third solution:} (by Tom Belulovich)\nDefine $M_{n,k}$ as in the second solution. We prove\n$\\det(M_{n,k})$ is odd for $n \\equiv 0,1 \\pmod{2k+1}$ and even otherwise,\nby directly determining whether or not $M_{n,k}$ is invertible as a matrix\nover the field of two elements.\n\nLet $r_i$ denote row $i$ of $M_{n,k}$.\nWe first check that if $n \\equiv 2, \\dots, 2k \\pmod{2k+1}$, then $M_{n,k}$\nis not invertible. In this case, we can find integers $0 \\leq a < b \\leq k$\nsuch that $n + a + b \\equiv 0 \\pmod{2k+1}$.\nPut $j = (n+a+b)/(2k+1)$. We can then write the\nall-ones vector both as\n\\[\n\\sum_{i=0}^{j-1} r_{k+1-a + (2k+1)i}\n\\]\nand as\n\\[\n\\sum_{i=0}^{j-1} r_{k+1-b + (2k+1)i}.\n\\]\nHence $M_{n,k}$ is not invertible.\n\nWe next check that if $n \\equiv 0,1 \\pmod{2k+1}$, then $M_{n,k}$\nis invertible. Suppose that $a_1,\\dots,a_n$ are scalars such that\n$a_1 r_1 + \\cdots + a_n r_n$ is the zero vector. The $m$-th coordinate\nof this vector equals $a_{m-k} + \\cdots + a_{m+k}$, where we regard\n$a_i$ as zero if $i \\notin \\{1,\\dots,n\\}$. By comparing consecutive\ncoordinates, we obtain\n\\[\na_{m-k} = a_{m+k+1} \\qquad (1 \\leq m < n).\n\\]\nIn particular, the $a_i$ repeat with period $2k+1$.\nTaking $m=1,\\dots,k$ further yields that\n\\[\na_{k+2} = \\cdots = a_{2k+1} = 0\n\\]\nwhile taking $m=n-k, \\dots,n-1$ yields\n\\[\na_{n-2k} =  \\dots = a_{n-1-k} = 0.\n\\]\nFor $n \\equiv 0 \\pmod{2k+1}$, the latter can be rewritten as\n\\[\na_1 = \\cdots = a_k = 0\n\\]\nwhereas for $n \\equiv 1 \\pmod{2k+1}$, it can be rewritten as\n\\[\na_2 = \\cdots = a_{k+1} = 0.\n\\]\nIn either case, since we also have\n\\[\na_1 + \\cdots + a_{2k+1} = 0\n\\]\nfrom the $(k+1)$-st coordinate, we deduce that all of the $a_i$ must be\nzero, and so $M_{n,k}$ must be invertible.\n\n\n\\textbf{Remark:}\nThe matrices $M_{n,k}$ are examples of \\emph{banded matrices},\nwhich occur frequently in numerical applications of linear algebra.\nThey are also examples of \\emph{Toeplitz matrices}.\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2009,
    "label": "A1",
    "difficulty": "1",
    "problem": "Let $f$ be a real-valued function on the plane such that for every\nsquare $ABCD$ in the plane, $f(A)+f(B)+f(C)+f(D)=0$. Does it follow that\n$f(P)=0$ for all points $P$ in the plane?",
    "solution": "Yes, it does follow. Let $P$ be any point in the plane. Let $ABCD$ be any square with center $P$.\nLet $E,F,G,H$ be the midpoints of the segments $AB, BC, CD, DA$, respectively. The function\n$f$ must satisfy the equations\n\\begin{align*}\n0 &= f(A) + f(B) + f(C) + f(D) \\\\\n0 &= f(E) + f(F) + f(G) + f(H) \\\\\n0 &= f(A) + f(E) + f(P) + f(H) \\\\\n0 &= f(B) + f(F) + f(P) + f(E) \\\\\n0 &= f(C) + f(G) + f(P) + f(F) \\\\\n0 &= f(D) + f(H) + f(P) + f(G).\n\\end{align*}\nIf we add the last four equations, then subtract the first equation and twice the second equation,\nwe obtain $0 = 4f(P)$, whence $f(P) = 0$.\n\n\\textbf{Remark.} Problem 1 of the 1996 Romanian IMO team selection exam asks the same\nquestion with squares replaced by regular polygons of any (fixed) number of vertices."
  },
  {
    "year": 2009,
    "label": "A2",
    "difficulty": "2",
    "problem": "Functions $f,g,h$ are differentiable on some open interval around $0$\nand satisfy the equations and initial conditions\n\\begin{gather*}\nf' = 2f^2gh+\\frac{1}{gh},\\quad f(0)=1, \\\\\ng'=fg^2h+\\frac{4}{fh}, \\quad g(0)=1, \\\\\nh'=3fgh^2+\\frac{1}{fg}, \\quad h(0)=1.\n\\end{gather*}\nFind an explicit formula for $f(x)$, valid in some open interval around $0$.",
    "solution": "Multiplying the first differential equation by $gh$, the second by $fh$,\nand the third by $fg$, and summing gives\n\\[\n(fgh)' = 6(fgh)^2+6.\n\\]\nWrite $k(x) = f(x)g(x)h(x)$; then $k' = 6k^2+6$ and $k(0) = 1$. One\nsolution for this differential equation with this initial condition is\n$k(x) = \\tan(6x+\\pi/4)$; by standard uniqueness, this must necessarily\nhold for $x$ in some open interval around $0$. Now the first given\nequation becomes\n\\begin{align*}\nf'/f &= 2k(x)+1/k(x) \\\\\n&= 2\\tan(6x+\\pi/4)+\\cot(6x+\\pi/4);\n\\end{align*}\nintegrating both sides gives\n\\[\n\\ln(f(x)) = \\frac{-2\\ln\\cos(6x+\\pi/4) + \\ln\\sin(6x+\\pi/4)}{6}+c,\n\\]\nwhence $f(x) = e^c\n\\left(\\frac{\\sin(6x+\\pi/4)}{\\cos^2(6x+\\pi/4)}\\right)^{1/6}$.\nSubstituting $f(0)=1$ gives $e^c = 2^{-1/12}$ and thus $f(x) = 2^{-1/12}\n\\left(\\frac{\\sin(6x+\\pi/4)}{\\cos^2(6x+\\pi/4)}\\right)^{1/6}$.\n\n\\textbf{Remark.} The answer can be put in alternate forms using\ntrigonometric identities. One particularly simple one is\n\\[\n f(x) = (\\sec 12x)^{1/12} (\\sec 12x + \\tan 12x)^{1/4}.\n\\]"
  },
  {
    "year": 2009,
    "label": "A3",
    "difficulty": "3",
    "problem": "Let $d_n$ be the determinant of the $n \\times n$ matrix whose entries, from\nleft to right and then from top to bottom, are $\\cos 1, \\cos 2, \\dots, \\cos\nn^2$. (For example,\n\\[\n d_3 = \\left| \\begin{matrix} \\cos 1 & \\cos 2 & \\cos 3 \\\\\n               \\cos 4 & \\cos 5 & \\cos 6 \\\\\n\\cos 7 & \\cos 8 & \\cos 9\n              \\end{matrix} \\right|.\n\\]\nThe argument of $\\cos$ is always in radians, not degrees.) Evaluate\n$\\lim_{n\\to\\infty} d_n$.",
    "solution": "The limit is $0$; we will show this by checking that $d_n = 0$ for all $n \\geq 3$.\nStarting from the given matrix, add the third column to the first column; this does not change the\ndeterminant. However, thanks to the identity\n$\\cos x + \\cos y = 2 \\cos \\frac{x+y}{2} \\cos \\frac{x-y}{2}$,\nthe resulting matrix has the form\n\\[\n \\begin{pmatrix} 2 \\cos 2 \\cos 1 & \\cos 2 & \\cdots \\\\\n  2 \\cos (n+2) \\cos 1 & \\cos (n+2) & \\cdots \\\\\n  2 \\cos (2n+2) \\cos 1 & 2 \\cos (2n+2) & \\cdots \\\\\n\\vdots & \\vdots & \\ddots\n \\end{pmatrix}\n\\]\nwith the first column being a multiple of the second. Hence $d_n = 0$.\n\n\\textbf{Remark.}\nAnother way to draw the same conclusion is to observe that the given matrix is the sum\nof the two rank 1 matrices $A_{jk} = \\cos (j-1)n \\cos k$ and $B_{jk} = -\\sin (j-1)n \\sin k$,\nand so has rank at most 2. One can also use the matrices\n$A_{jk} = e^{i((j-1)n+k)}$, $B_{jk} = e^{-i(j-1)n+k}$."
  },
  {
    "year": 2009,
    "label": "A4",
    "difficulty": "4",
    "problem": "Let $S$ be a set of rational numbers such that\n\\begin{enumerate}",
    "solution": "The answer is no; indeed, $S = \\mathbb{Q} \\setminus \\{n+2/5 \\,|\\,\nn\\in\\mathbb{Z}\\}$ satisfies the given conditions. Clearly $S$ satisfies\n(a) and (b); we need only check that it satisfies (c). It suffices to\nshow that if $x = p/q$ is a fraction with $(p,q)=1$ and $p>0$, then we\ncannot have $1/(x(x-1)) = n+2/5$ for an integer $n$. Suppose otherwise; then\n\\[\n(5n+2)p(p-q) = 5q^2.\n\\]\nSince $p$ and $q$ are relatively prime, and $p$ divides $5q^2$, we must\nhave $p\\,|\\,5$, so $p=1$ or $p=5$. On the other hand, $p-q$ and $q$ are\nalso relatively prime, so $p-q$ divides $5$ as well, and $p-q$ must be\n$\\pm 1$ or $\\pm 5$. This leads to eight possibilities for $(p,q)$:\n$(1,0)$,  $(5,0)$,  $(5,10)$, $(1,-4)$, $(1,2)$, $(1,6)$, $(5,4)$,\n$(5,6)$. The first three are impossible, while the final five lead to\n$5n+2 = 16,-20,-36,16,-36$ respectively, none of which holds for\nintegral $n$.\n\n\\textbf{Remark.} More generally, no rational number of the form $m/n$,\nwhere $m,n$ are relatively prime and neither of $\\pm m$ is a quadratic\nresidue mod $n$, need be in $S$. If $x=p/q$ is in lowest terms and\n$1/(x(x-1)) = m/n+k$ for some integer $k$, then $p(p-q)$ is relatively\nprime to $q^2$; $q^2/(p(p-q)) = (m+kn)/n$ then implies that $m+kn = \\pm\nq^2$ and so $\\pm m$ must be a quadratic residue mod $n$."
  },
  {
    "year": 2009,
    "label": "A5",
    "difficulty": "5",
    "problem": "Is there a finite abelian group $G$ such that the product of the\norders of all its elements is $2^{2009}$?",
    "solution": "No, there is no such group.\nBy the structure theorem for finitely generated abelian groups,\n$G$ can be written as a product of cyclic groups.\nIf any of these factors has odd order, then $G$ has an element of odd order,\nso the product of the orders of all of its elements cannot be a power of 2.\n\nWe may thus consider only abelian $2$-groups hereafter.\nFor such a group $G$, the product of the orders of all of its elements\nhas the form $2^{k(G)}$ for some nonnegative integer $G$, and we must show\nthat it is impossible to achieve $k(G) = 2009$.\nAgain by the structure theorem, we may write\n\\[\nG \\cong \\prod_{i=1}^\\infty (\\ZZ/2^i \\ZZ)^{e_i}\n\\]\nfor some nonnegative integers $e_1,e_2,\\dots$, all but finitely many of\nwhich are $0$.\n\nFor any nonnegative integer $m$, the elements of $G$ of order at most $2^m$\nform a subgroup isomorphic to\n\\[\n\\prod_{i=1}^\\infty (\\ZZ/2^{\\min\\{i,m\\}} \\ZZ)^{e_i},\n\\]\nwhich has $2^{s_m}$ elements for $s_m = \\sum_{i=1}^\\infty \\min\\{i,m\\} e_i$.\nHence\n\\[\nk(G) = \\sum_{i=1}^\\infty i(2^{s_i} - 2^{s_{i-1}}).\n\\]\nSince $s_1 \\leq s_2 \\leq \\cdots$, $k(G)+1$ is always divisible by $2^{s_1}$.\nIn particular, $k(G) = 2009$ forces $s_1 \\leq 1$.\n\nHowever, the only cases where $s_1 \\leq 1$ are where all of the $e_i$ are $0$,\nin which case $k(G) = 0$, or where $e_i = 1$ for some $i$ and $e_j = 0$\nfor $j \\neq i$, in which case $k(G) = (i-1)2^i + 1$.\nThe right side is a strictly increasing function\nof $i$ which equals $1793$ for $i=8$ and $4097$ for $i=9$, so it can never equal\n2009. This proves the claim.\n\n\\textbf{Remark.} One can also arrive at the key congruence by dividing $G$\ninto equivalence classes, by declaring two elements to be equivalent if they generate the\nsame cyclic subgroup of $G$.\nFor $h>0$, an element of order $2^h$ belongs to an equivalence class of size $2^{h-1}$,\nso the products of the orders of the elements of this equivalence class is $2^j$\nfor $j = h 2^{h-1}$. This quantity is divisible by 4 as long as $h > 1$;\nthus to have $k(G) \\equiv 1 \\pmod{4}$, the number of elements of $G$ of order 2 must be\ncongruent to 1 modulo 4. However, there are exactly $2^e-1$ such elements,\nfor $e$ the number of cyclic factors of $G$. Hence $e = 1$, and one concludes as in the\ngiven solution."
  },
  {
    "year": 2009,
    "label": "A6",
    "difficulty": "6",
    "problem": "Let $f:[0,1]^2 \\to \\mathbb{R}$ be a continuous function on the closed unit\nsquare such that $\\frac{\\partial f}{\\partial x}$ and $\\frac{\\partial f}{\\partial y}$ exist\nand are continuous on the interior $(0,1)^2$. Let $a = \\int_0^1 f(0,y)\\,dy$,\n$b = \\int_0^1 f(1,y)\\,dy$, $c = \\int_0^1 f(x,0)\\,dx$, $d = \\int_0^1 f(x,1)\\,dx$.\nProve or disprove: There must be a point $(x_0,y_0)$ in $(0,1)^2$ such that\n\\[\n\\frac{\\partial f}{\\partial x} (x_0,y_0) = b - a\n\\quad \\mbox{and} \\quad\n\\frac{\\partial f}{\\partial y} (x_0,y_0) = d - c.\n\\]",
    "solution": "We disprove the assertion using the example\n\\[\nf(x,y) = 3(1 + y)(2x-1)^2 -y.\n\\]\nWe have $b-a = d-c = 0$ because the identity $f(x,y) = f(1-x,y)$ forces $a=b$,\nand because\n\\begin{align*}\nc &= \\int_0^1 3(2x-1)^2\\,dx = 1, \\\\\nd &= \\int_0^1 (6(2x-1)^2-1)\\,dx = 1.\n\\end{align*}\nMoreover, the partial derivatives\n\\begin{align*}\n \\frac{\\partial f}{\\partial x}(x_0,y_0) &= 3(1+y_0)(8x_0-4) \\\\\n\\frac{\\partial f}{\\partial y}(x_0,y_0) &= 3(2x_0-1)^2-1.\n\\end{align*}\nhave no common zero in $(0,1)^2$. Namely,\nfor the first partial to vanish, we must have $x_0 = 1/2$ since\n$1 + y_0$ is nowhere zero, but for $x_0 = 1/2$\nthe second partial cannot vanish.\n\n\\textbf{Remark.}\nThis problem amounts to refuting a potential generalization of the Mean Value Theorem to bivariate\nfunctions. Many counterexamples are possible. Kent Merryfield suggests\n$y \\sin(2 \\pi x)$, for which all four of the boundary integrals vanish;\nhere the partial derivatives are $2\\pi y \\cos (2 \\pi x)$ and $\\sin (2 \\pi x)$.\nCatalin Zara suggests $x^{1/3} y^{2/3}$. Qingchun Ren suggests $xy(1-y)$."
  },
  {
    "year": 2009,
    "label": "B1",
    "difficulty": "1",
    "problem": "Show that every positive rational number can be written as a quotient of products of factorials\nof (not necessarily distinct) primes. For example,\n\\[\n\\frac{10}{9} = \\frac{2!\\cdot 5!}{3!\\cdot 3! \\cdot 3!}.\n\\]\n\\,",
    "solution": "Every positive rational number can be uniquely written in lowest terms\nas $a/b$ for $a,b$ positive integers. We prove the statement in the\nproblem by induction on the largest prime dividing either $a$ or $b$\n(where this is considered to be $1$ if $a=b=1$). For the base case, we\ncan write $1/1 = 2!/2!$. For a general $a/b$, let $p$ be the largest\nprime dividing either $a$ or $b$; then $a/b = p^k a'/b'$ for some $k\\neq\n0$ and positive integers $a',b'$ whose largest prime factors are\nstrictly less than $p$. We now have $a/b = (p!)^k \\frac{a'}{(p-1)!^k b'}$,\nand all prime factors of $a'$ and $(p-1)!^k b'$ are strictly less than $p$.\nBy the induction assumption, $\\frac{a'}{(p-1)!^k b'}$ can be written as a\nquotient of products of prime factorials, and so $a/b = (p!)^k\n\\frac{a'}{(p-1)!^k b'}$ can as well. This completes the induction.\n\n\\textbf{Remark.} Noam Elkies points out that the representations are unique\nup to rearranging and canceling common factors."
  },
  {
    "year": 2009,
    "label": "B2",
    "difficulty": "2",
    "problem": "A game involves jumping to the right on the real number line. If $a$ and $b$ are real numbers\nand $b > a$, the cost of jumping from $a$ to $b$ is $b^3-ab^2$. For what real numbers\n$c$ can one travel from $0$ to $1$ in a finite number of jumps with total cost exactly $c$?",
    "solution": "The desired real numbers $c$ are precisely those for which $1/3 < c \\leq 1$.\nFor any positive integer $m$ and any\nsequence $0 = x_0 < x_1 < \\cdots < x_m = 1$,\nthe cost of jumping along this sequence is\n$\\sum_{i=1}^m (x_i - x_{i-1})x_i^2$. Since\n\\begin{align*}\n1 = \\sum_{i=1}^m (x_i - x_{i-1}) &\\geq \\sum_{i=1}^m (x_i - x_{i-1})x_i^2 \\\\\n&> \\sum_{i=1}^m \\int_{x_i}^{x_{i-1}} t^2\\,dt \\\\\n&= \\int_0^1 t^2\\,dt = \\frac{1}{3},\n\\end{align*}\nwe can only achieve costs $c$ for which $1/3 < c \\leq 1$.\n\nIt remains to check that any such $c$ can be achieved.\nSuppose $0 = x_0 < \\dots < x_m = 1$ is a sequence with $m \\geq 1$.\nFor $i=1,\\dots,m$,\nlet $c_i$ be the cost of the sequence $0, x_i, x_{i+1},\\dots,x_m$.\nFor $i > 1$ and $0 < y \\leq x_{i-1}$,\nthe cost of the sequence $0, y, x_{i}, \\dots, x_m$\nis\n\\[\nc_{i} + y^3 + (x_i - y)x_i^2 - x_i^3\n= c_i - y(x_i^2 - y^2),\n\\]\nwhich is less than $c_i$ but approaches $c_i$ as $y \\to 0$.\nBy continuity, for $i=2,\\dots,m$,\nevery value in the interval $[c_{i-1}, c_{i})$ can be achieved,\nas can $c_m = 1$ by the sequence $0,1$.\n\nTo show that all costs $c$ with $1/3 < c \\leq 1$ can be achieved, it now suffices\nto check that for every $\\epsilon > 0$, there exists a sequence with cost at most\n$1/3 + \\epsilon$. For instance, if we take $x_i = i/m$ for $i=0,\\dots,m$, the cost\nbecomes\n\\[\n\\frac{1}{m^3} (1^2 + \\cdots + m^2)\n = \\frac{(m+1)(2m+1)}{6m^2},\n\\]\nwhich converges to $1/3$ as $m \\to +\\infty$.\n\n\\textbf{Reinterpretation.} The cost of jumping along a particular sequence is an\nupper Riemann sum of the function $t^2$. The fact that this function admits a Riemann\nintegral implies that for any $\\epsilon > 0$, there exists $\\delta_0$ such that the\ncost of the sequence $x_0,\\dots,x_m$ is at most $1/3 + \\epsilon$ as long as\n$\\max_i \\{x_i - x_{i-1}\\} < \\epsilon$. (The computation of the integral using the\nsequence $x_i = i/m$ was already known to Archimedes.)"
  },
  {
    "year": 2009,
    "label": "B3",
    "difficulty": "3",
    "problem": "Call a subset $S$ of $\\{1, 2, \\dots, n\\}$ \\emph{mediocre} if it has the following property:\nWhenever $a$ and $b$ are elements of $S$ whose average is an integer, that average is also\nan element of $S$. Let $A(n)$ be the number of mediocre subsets of $\\{1,2,\\dots,n\\}$.\n[For instance, every subset of $\\{1,2,3\\}$ except $\\{1,3\\}$ is mediocre, so $A(3) =7$.]\nFind all positive integers $n$ such that $A(n+2) - 2A(n+1) + A(n) = 1$.",
    "solution": "The answer is $n=2^k-1$ for some integer $k\\geq 1$.\nThere is a bijection between mediocre subsets of $\\{1,\\ldots,n\\}$ and\nmediocre subsets of $\\{2,\\ldots,n+1\\}$ given by adding $1$ to each\nelement of the subset; thus $A(n+1)-A(n)$ is the number of mediocre\nsubsets of $\\{1,\\ldots,n+1\\}$ that contain $1$. It follows that\n$A(n+2)-2A(n+1)+A_n = (A(n+2)-A(n+1))-(A(n+1)-A(n))$ is the difference\nbetween the number of mediocre subsets of $\\{1,\\ldots,n+2\\}$ containing\n$1$ and the number of mediocre subsets of $\\{1,\\ldots,n+1\\}$ containing\n$1$. This difference is precisely the number of mediocre subsets of\n$\\{1,\\ldots,n+2\\}$ containing both $1$ and $n+2$, which we term\n``mediocre subsets containing the endpoints.'' Since $\\{1,\\ldots,n+2\\}$\nitself is a mediocre subset of itself containing the endpoints, it\nsuffices to prove that this is the only mediocre subset of\n$\\{1,\\ldots,n+2\\}$ containing the endpoints if and only if $n=2^k-1$ for\nsome $k$.\n\nIf $n$ is not of the form $2^k-1$, then we can write $n+1 = 2^a b$ for\nodd $b>1$. In this case, the set $\\{1+m b \\, | \\, 0 \\leq m \\leq 2^a\\}$\nis a mediocre subset of $\\{1,\\ldots,n+2\\}$ containing the endpoints: the\naverage of $1+m_1 b$ and $1+m_2 b$, namely $1+\\frac{m_1+m_2}{2} b$, is\nan integer if and only if $m_1+m_2$ is even, in which case this average\nlies in the set.\n\nIt remains to show that if $n=2^k-1$, then the only mediocre subset of\n$\\{1,\\ldots,n+2\\}$ containing the endpoints is itself. This is readily\nseen by induction on $k$. For $k=1$, the statement is obvious. For\ngeneral $k$, any mediocre subset $S$ of $\\{1,\\ldots,n+2=2^k+1\\}$\ncontaining $1$ and $2^k+1$ must also contain their average, $2^{k-1}+1$.\nBy the induction assumption, the only mediocre subset of\n$\\{1,\\ldots,2^{k-1}+1\\}$ containing the endpoints is itself, and so $S$\nmust contain all integers between $1$ and $2^{k-1}+1$. Similarly, a\nmediocre subset of $\\{2^{k-1}+1,\\ldots,2^k+1\\}$ containing the endpoints\ngives a mediocre subset of $\\{1,\\ldots,2^{k-1}+1\\}$ containing the\nendpoints by subtracting $2^{k-1}$ from each element. By the induction\nassumption again, it follows that $S$ must contain all integers between\n$2^{k-1}+1$ and $2^k+1$. Thus $S = \\{1,\\ldots,2^k+1\\}$ and the induction\nis complete.\n\n\\textbf{Remark.} One can also proceed by checking that a nonempty subset of\n$\\{1,\\dots,n\\}$ is mediocre if and only if it is an arithmetic progression\nwith odd common difference. Given this fact, the number of\nmediocre subsets of $\\{1,\\dots,n+2\\}$ containing the endpoints is seen to be\nthe number of odd factors of $n+1$, from which the desired result is evident.\n(The sequence $A(n)$ appears as sequence A124197 in the Encyclopedia of Integer Sequences.)"
  },
  {
    "year": 2009,
    "label": "B4",
    "difficulty": "4",
    "problem": "Say that a polynomial with real coefficients in two variables, $x,y$, is \\emph{balanced} if\nthe average value of the polynomial on each circle centered at the origin is $0$.\nThe balanced polynomials of degree at most $2009$ form a vector space $V$ over $\\mathbb{R}$.\nFind the dimension of $V$.",
    "solution": "Any polynomial $P(x,y)$ of degree at most $2009$ can be written uniquely\nas a sum $\\sum_{i=0}^{2009} P_i(x,y)$ in which $P_i(x,y)$ is a homogeneous\npolynomial of degree $i$.\nFor $r>0$, let $C_r$ be the path $(r\\cos \\theta, r\\sin \\theta)$\nfor $0 \\leq \\theta \\leq 2\\pi$. Put $\\lambda(P_i) = \\oint_{C_1} P_i$; then\nfor $r>0$,\n\\[\n\\oint_{C_r} P = \\sum_{i=0}^{2009} r^i \\lambda(P_i).\n\\]\nFor fixed $P$, the right side is a polynomial in $r$, which vanishes for\nall $r>0$ if and only if its coefficients vanish.\nIn other words,\n$P$ is balanced\nif and only if $\\lambda(P_i) = 0$ for $i=0,\\dots,2009$.\n\nFor $i$ odd, we have $P_i(-x,-y) = -P_i(x,y)$.\nHence $\\lambda(P_i) = 0$, e.g.,\nbecause the contributions to the integral from\n$\\theta$ and $\\theta + \\pi$ cancel.\n\nFor $i$ even, $\\lambda(P_i)$ is a linear function of the coefficients of\n$P_i$. This function is not identically zero, e.g., because for $P_i =\n(x^2 + y^2)^{i/2}$, the integrand is always positive and so\n$\\lambda(P_i) > 0$. The kernel of $\\lambda$ on the space of homogeneous\npolynomials of degree $i$ is thus a subspace of codimension 1.\n\nIt follows that the dimension of $V$ is\n\\[\n(1 + \\cdots + 2010) - 1005 = (2011 - 1) \\times 1005 = 2020050.\n\\]"
  },
  {
    "year": 2009,
    "label": "B5",
    "difficulty": "5",
    "problem": "Let $f: (1, \\infty) \\to \\mathbb{R}$ be a differentiable function such that\n\\[\n f'(x) = \\frac{x^2 - f(x)^2}{x^2 (f(x)^2 + 1)}\n\\qquad \\mbox{for all $x>1$.}\n\\]\nProve that $\\lim_{x \\to \\infty} f(x) = \\infty$.",
    "solution": "\\textbf{First solution.}\nIf $f(x) \\geq x$ for all $x > 1$, then the desired conclusion clearly holds.\nWe may thus assume hereafter that there exists $x_0 > 1$ for which $f(x_0) < x_0$.\n\nRewrite the original differential equation as\n\\[\n f'(x) = 1 - \\frac{x^2 + 1}{x^2} \\frac{f(x)^2}{1 + f(x)^2}.\n\\]\nPut $c_0 = \\min\\{0, f(x_0) - 1/x_0\\}$.\nFor all $x \\geq x_0$, we have $f'(x) > -1/x^2$ and so\n\\[\nf(x) \\geq f(x_0) -\\int_{x_0}^x dt/t^2 > c_0.\n\\]\nIn the other direction, we claim that $f(x) < x$ for all $x \\geq x_0$.\nTo see this, suppose the contrary; then by continuity, there is a least\n$x \\geq x_0$ for which $f(x) \\geq x$, and this least value satisfies $f(x) = x$.\nHowever, this forces $f'(x) = 0 < 1$ and so\n$f(x-\\epsilon) > x-\\epsilon$ for $\\epsilon > 0$ small,\ncontradicting the choice of $x$.\n\nPut $x_1 = \\max\\{x_0, -c_0\\}$. For $x \\geq x_1$, we have\n$|f(x)| < x$ and so $f'(x) > 0$.\nIn particular, the limit $\\lim_{x \\to +\\infty} f(x) = L$\nexists.\n\nSuppose that $L < +\\infty$; then $\\lim_{x \\to +\\infty}\nf'(x) = 1/(1 + L^2) > 0$. Hence for any sufficiently small $\\epsilon > 0$,\nwe can choose $x_2 \\geq x_1$ so that $f'(x) \\geq \\epsilon$\nfor $x \\geq x_2$. But then $f(x) \\geq f(x_2) + \\epsilon(x-x_2)$,\nwhich contradicts $L < +\\infty$. Hence $L = +\\infty$,\nas desired.\n\n\\textbf{Variant.} (by Leonid Shteyman) One obtains a similar argument by\nwriting\n\\[\n f'(x) = \\frac{1}{1 + f(x)^2} - \\frac{f(x)^2}{x^2(1+f(x)^2)},\n\\]\nso that\n\\[\n-\\frac{1}{x^2} \\leq f'(x) - \\frac{1}{1 + f(x)^2} \\leq 0.\n\\]\nHence $f'(x) - 1/(1 + f(x)^2)$ tends to 0 as $x \\to +\\infty$, so $f(x)$ is bounded below, and\ntends to $+\\infty$\nif and only if the improper integral $\\int dx/(1+f(x)^2)$ diverges. However, if the integral were to\nconverge, then as $x \\to +\\infty$ we would have $1/(1+f(x)^2) \\to 0$; however, since $f$ is bounded below,\nthis again forces $f(x) \\to +\\infty$.\n\n\\textbf{Second solution.} (by Catalin Zara)\nThe function $g(x) = f(x)+x$ satisfies the differential equation\n\\[\ng'(x) = 1 + \\frac{1 - (g(x)/x - 1)^2}{1 + x^2(g(x)/x - 1)^2}.\n\\]\nThis implies that $g'(x) > 0$ for all $x > 1$, so\nthe limit $L_1 = \\lim_{x \\to +\\infty} g(x)$ exists. In addition, we cannot have\n$L_1 < +\\infty$, or else we would have\n$\\lim_{x \\to +\\infty} g'(x) = 0$ whereas the differential equation forces\nthis limit to be 1.\nHence $g(x) \\to +\\infty$ as $x \\to +\\infty$.\n\nSimilarly, the function $h(x) = -f(x) + x$ satisfies the differential equation\n\\[\nh'(x) = 1 - \\frac{1 - (h(x)/x - 1)^2}{1 + x^2(h(x)/x - 1)^2}.\n\\]\nThis implies that $h'(x) \\geq 0$ for all $x$,\nso the limit $L_2 = \\lim_{x \\to +\\infty} h(x)$ exists. In addition, we cannot have\n$L_2 < +\\infty$, or else we would have\n$\\lim_{x \\to +\\infty} h'(x) = 0$ whereas the differential equation forces\nthis limit to be 1.\nHence $h(x) \\to +\\infty$ as $x \\to +\\infty$.\n\nFor some $x_1 > 1$, we must have $g(x), h(x) > 0$ for all $x \\geq x_1$. For\n$x \\geq x_1$, we have $|f(x)| < x$ and hence $f'(x) > 0$, so the limit\n$L = \\lim_{x \\to +\\infty} f(x)$ exists. Once again,\nwe cannot have $L < +\\infty$, or else we would have\n$\\lim_{x \\to +\\infty} f'(x) = 0$ whereas the original differential equation (e.g., in the form\ngiven in the first solution) forces\nthis limit to be $1/(1 + L^2) > 0$.\nHence $f(x) \\to +\\infty$ as $x \\to \\infty$, as desired.\n\n\\textbf{Third solution.}\n(by Noam Elkies)\nConsider the function $g(x) = f(x) + \\frac{1}{3}f(x)^3$, for which\n\\[\n g'(x) = f'(x)(1 + f(x)^2) = 1 - \\frac{f(x)^2}{x^2}\n\\]\nfor $x>1$. Since evidently $g'(x) < 1$,\n$g(x) - x$ is bounded above for $x$ large.\nAs in the first solution,\n$f(x)$ is bounded below for $x$ large,\nso $\\frac{1}{3} f(x)^3 - x$ is bounded above by some $c>0$. For $x \\geq c$,\nwe obtain $f(x) \\leq (6x)^{1/3}$.\n\nSince $f(x)/x \\to 0$ as $x \\to +\\infty$, $g'(x) \\to 1$ and so\n$g(x)/x \\to 1$. Since $g(x)$ tends to $+\\infty$,\nso does $f(x)$. (With a tiny bit of extra work, one shows that in fact $f(x)/(3x)^{1/3} \\to 1$ as $x \\to +\\infty$.)"
  },
  {
    "year": 2009,
    "label": "B6",
    "difficulty": "6",
    "problem": "Prove that for every positive integer $n$, there is a sequence of integers\n$a_0, a_1, \\dots, a_{2009}$ with $a_0 = 0$ and $a_{2009} = n$ such that each term\nafter $a_0$ is either an earlier term plus $2^k$ for some nonnegative integer $k$,\nor of the form $b\\,\\mathrm{mod}\\,c$ for some earlier positive terms $b$ and $c$.\n[Here $b\\,\\mathrm{mod}\\,c$ denotes the remainder when $b$ is divided by $c$,\nso $0 \\leq (b\\,\\mathrm{mod}\\,c) < c$.]\n\n\\end{itemize}\n\n\\end{document}",
    "solution": "\\textbf{First solution.}\n(based on work of Yufei Zhao)\nSince any sequence of the desired form remains of the desired form upon multiplying each term by 2,\nwe may reduce to the case where $n$ is odd. In this case, take $x = 2^h$ for some\npositive integer $h$ for which $x \\geq n$, and set\n\\begin{align*}\na_0 &= 0\\\\\na_1 &= 1\\\\\na_2 &= 2x+1 = a_1 + 2x \\\\\na_3 &= (x+1)^2 = a_2 + x^2 \\\\\na_4 &= x^n+1 = a_1 + x^n\\\\\na_5 &= n(x+1) = a_4 \\mod a_3\\\\\na_6 &= x \\\\\na_7 &= n = a_5 \\mod a_6.\n\\end{align*}\nWe may pad the sequence to the desired length by taking\n$a_8 = \\cdots = a_{2009} = n$.\n\n\\textbf{Second solution.}\n(by James Merryfield)\nSuppose first that $n$ is not divisible by 3. Recall that since $2$ is a primitive root modulo\n$3^2$, it is also a primitive root modulo $3^h$ for any positive integer $h$. In particular,\nif we choose $h$ so that $3^{2h} > n$, then\nthere exists a positive integer $c$ for which $2^c \\mod 3^{2h} = n$.\nWe now take $b$ to be a positive integer for which $2^b > 3^{2h}$, and then put\n\\begin{align*}\na_0 &= 0\\\\\na_1 &= 1\\\\\na_2 &= 3 = a_1 + 2\\\\\na_3 &= 3 + 2^b \\\\\na_4 &= 2^{2hb} \\\\\na_5 &= 3^{2h} = a_4 \\mod a_3 \\\\\na_6 &= 2^c \\\\\na_7 &= n = a_6 \\mod a_5.\n\\end{align*}\nIf $n$ is divisible by 3, we can force $a_7 = n-1$ as in the above\nconstruction, then put $a_{8} = a_7 + 1 = n$. In both cases, we then pad the sequence\nas in the first solution.\n\n\\textbf{Remark.}\nHendrik Lenstra, Ronald van Luijk, and Gabriele Della Torre\nsuggest the following variant of the first solution requiring only 6 steps.\nFor $n$ odd and $x$ as in the first solution, set\n\\begin{align*}\na_0 &= 0\\\\\na_1 &= 1\\\\\na_2 &= x+1 = a_1 + x\\\\\na_3 &= x^n+x+1 = a_2 + x^n\\\\\na_4 &= x^{(n-1)(\\phi(a_3)-1)}\\\\\na_5 &= \\frac{x^n+1}{x+1} = a_4 \\mod a_3 \\\\\na_6 &= n = a_5 \\mod a_2.\n\\end{align*}\nIt seems unlikely that a shorter solution can be constructed without relying on\nany deep number-theoretic conjectures.\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2010,
    "label": "A1",
    "difficulty": "1",
    "problem": "Given a positive integer $n$, what is the largest $k$ such that the\nnumbers $1,2,\\dots,n$ can be put into $k$ boxes so that the sum of the numbers\nin each box is the same? [When $n=8$, the example $\\{1,2,3,6\\}, \\{4,8\\}, \\{5,7\\}$\nshows that the largest $k$ is \\emph{at least} 3.]",
    "solution": "The largest such $k$ is $\\lfloor \\frac{n+1}{2} \\rfloor = \\lceil \\frac{n}{2} \\rceil$.\nFor $n$ even, this value is achieved by the partition\n\\[\n\\{1, n\\}, \\{2, n-1\\}, \\dots;\n\\]\nfor $n$ odd, it is achieved by the partition\n\\[\n\\{n\\}, \\{1, n-1\\}, \\{2, n-2\\}, \\dots.\n\\]\nOne way to see that this is optimal is to note that the common sum can never be less than $n$,\nsince $n$ itself belongs to one of the boxes. This implies that $k \\leq (1 + \\cdots + n)/n = (n+1)/2$.\nAnother argument is that if $k > (n+1)/2$, then there would have to be two boxes with one number each\n(by the pigeonhole principle), but such boxes could not have the same sum.\n\n\n\\textbf{Remark.} A much subtler question would be to find the smallest $k$ (as a function of $n$)\nfor which no such arrangement exists."
  },
  {
    "year": 2010,
    "label": "A2",
    "difficulty": "2",
    "problem": "Find all differentiable functions $f:\\mathbb{R} \\to \\mathbb{R}$ such that\n\\[\nf'(x) = \\frac{f(x+n)-f(x)}{n}\n\\]\nfor all real numbers $x$ and all positive integers $n$.",
    "solution": "The only such functions are those of the form $f(x) = cx+d$ for some real numbers $c,d$ (for which the\nproperty is obviously satisfied). To see this, suppose that $f$ has the desired property. Then for any $x \\in \\RR$,\n\\begin{align*}\n2f'(x) &= f(x+2)-f(x) \\\\\n&= (f(x+2) - f(x+1)) + (f(x+1) - f(x)) \\\\\n&= f'(x+1) + f'(x).\n\\end{align*}\nConsequently, $f'(x+1) = f'(x)$.\n\nDefine the function $g: \\RR \\to \\RR$ by $g(x) = f(x+1) - f(x)$, and put $c = g(0)$, $d = f(0)$. For all $x \\in \\RR$,\n$g'(x) = f'(x+1) -f'(x) = 0$, so $g(x) = c$ identically,\nand $f'(x) = f(x+1)-f(x) = g(x) = c$, so $f(x) = cx+d$ identically as desired."
  },
  {
    "year": 2010,
    "label": "A3",
    "difficulty": "3",
    "problem": "Suppose that the function $h:\\mathbb{R}^2\\to \\mathbb{R}$ has continuous partial\nderivatives and satisfies the equation\n\\[\nh(x,y) = a \\frac{\\partial h}{\\partial x}(x,y) +\nb \\frac{\\partial h}{\\partial y}(x,y)\n\\]\nfor some constants $a,b$. Prove that if there is a constant $M$ such that\n$|h(x,y)|\\leq M$ for all $(x,y) \\in \\mathbb{R}^2$, then $h$ is identically zero.",
    "solution": "If $a=b=0$, then the desired result holds trivially, so we assume that at least one of $a,b$ is nonzero.\nPick any point $(a_0, b_0) \\in \\mathbb{R}^2$, and let $L$ be the line given by the parametric equation\n$L(t) = (a_0,b_0) + (a,b) t$ for $t\\in \\mathbb{R}$. By the chain rule and the given equation, we have $\\frac{d}{dt}(h\\circ L) = h\\circ L$. If we write $f = h\\circ L:\\mathbb{R} \\to \\mathbb{R}$, then $f'(t) = f(t)$ for all $t$. It follows that $f(t) = Ce^t$ for some constant $C$. Since $|f(t)| \\leq M$ for all $t$, we must have $C=0$.\nIt follows that $h(a_0,b_0) = 0$; since $(a_0,b_0)$ was an arbitrary point,\n$h$ is identically $0$ over all of $\\mathbb{R}^2$."
  },
  {
    "year": 2010,
    "label": "A4",
    "difficulty": "4",
    "problem": "Prove that for each positive integer $n$, the number\n$10^{10^{10^n}} + 10^{10^n} + 10^n - 1$\nis not prime.",
    "solution": "Put\n\\[\nN = 10^{10^{10^n}} + 10^{10^n} + 10^n - 1.\n\\]\nWrite $n = 2^m k$ with $m$ a nonnegative integer and $k$ a positive odd integer.\nFor any nonnegative integer $j$,\n\\[\n10^{2^m j} \\equiv (-1)^j \\pmod{10^{2^m} + 1}.\n\\]\nSince $10^n \\geq n \\geq 2^m \\geq m+1$, $10^n$ is divisible by $2^n$ and hence by $2^{m+1}$,\nand similarly $10^{10^n}$ is divisible by $2^{10^n}$ and hence by $2^{m+1}$. It follows that\n\\[\nN \\equiv 1 + 1 + (-1) + (-1) \\equiv 0 \\pmod{10^{2^m} + 1}.\n\\]\nSince $N \\geq 10^{10^n} > 10^n + 1 \\geq 10^{2^m} + 1$, it follows that $N$ is composite."
  },
  {
    "year": 2010,
    "label": "A5",
    "difficulty": "5",
    "problem": "Let $G$ be a group, with operation $*$. Suppose that\n\\begin{enumerate}",
    "solution": "We start with three lemmas.\n\\setcounter{lemma}{0}\n\\begin{lemma}\nIf $\\mathbf{x},\\mathbf{y} \\in G$ are nonzero orthogonal vectors, then $\\mathbf{x}*\\mathbf{x}$ is parallel to $\\mathbf{y}$.\n\\end{lemma}\n\\begin{proof}\nPut $\\mathbf{z} = \\mathbf{x} \\times \\mathbf{y} \\neq 0$, so that $\\mathbf{x},\\mathbf{y}$, and $\\mathbf{z} = \\mathbf{x}*\\mathbf{y}$ are nonzero and mutually orthogonal.\nThen $\\mathbf{w} = \\mathbf{x} \\times \\mathbf{z} \\neq 0$, so $\\mathbf{w} = \\mathbf{x}*\\mathbf{z}$ is nonzero and orthogonal to $\\mathbf{x}$ and $\\mathbf{z}$.\nHowever, if $(\\mathbf{x}*\\mathbf{x}) \\times \\mathbf{y} \\neq 0$, then $\\mathbf{w} = \\mathbf{x}*(\\mathbf{x}*\\mathbf{y}) = (\\mathbf{x}*\\mathbf{x})*\\mathbf{y} = (\\mathbf{x}*\\mathbf{x}) \\times \\mathbf{y}$ is also orthogonal to $\\mathbf{y}$, a contradiction.\n\\end{proof}\n\\begin{lemma}\nIf $\\mathbf{x} \\in G$ is nonzero, and there exists $\\mathbf{y} \\in G$ nonzero and orthogonal to $\\mathbf{x}$, then $\\mathbf{x}*\\mathbf{x} = 0$.\n\\end{lemma}\n\\begin{proof}\nLemma~1 implies that $\\mathbf{x}*\\mathbf{x}$ is parallel to both $\\mathbf{y}$ and $\\mathbf{x} \\times \\mathbf{y}$, so it must be zero.\n\\end{proof}\n\\begin{lemma}\nIf $\\mathbf{x},\\mathbf{y} \\in G$ commute, then $\\mathbf{x} \\times \\mathbf{y} = 0$.\n\\end{lemma}\n\\begin{proof}\nIf $\\mathbf{x} \\times \\mathbf{y} \\neq 0$, then $\\mathbf{y} \\times \\mathbf{x}$ is nonzero\nand distinct from $\\mathbf{x} \\times \\mathbf{y}$. Consequently,\n$\\mathbf{x}*\\mathbf{y} = \\mathbf{x} \\times \\mathbf{y}$\nand $\\mathbf{y}*\\mathbf{x} = \\mathbf{y} \\times \\mathbf{x} \\neq \\mathbf{x} * \\mathbf{y}$.\n\\end{proof}\n\nWe proceed now to the proof. Assume by way of contradiction that there exist $\\mathbf{a},\\mathbf{b} \\in G$ with $\\mathbf{a} \\times \\mathbf{b}\n\\neq 0$. Put $\\mathbf{c} = \\mathbf{a}\\times \\mathbf{b} = \\mathbf{a}*\\mathbf{b}$, so that $\\mathbf{a},\\mathbf{b},\\mathbf{c}$ are nonzero and linearly independent. Let $\\mathbf{e}$ be the identity\nelement of $G$. Since $\\mathbf{e}$ commutes with $\\mathbf{a},\\mathbf{b},\\mathbf{c}$, by Lemma~3 we have $\\mathbf{e} \\times \\mathbf{a} = \\mathbf{e} \\times \\mathbf{b} = \\mathbf{e} \\times \\mathbf{c} = 0$.\nSince $\\mathbf{a},\\mathbf{b},\\mathbf{c}$ span $\\RR^3$, $\\mathbf{e} \\times \\mathbf{x} = 0$ for all $\\mathbf{x} \\in \\RR^3$, so $\\mathbf{e} = 0$.\n\nSince $\\mathbf{b},\\mathbf{c}$, and $\\mathbf{b} \\times \\mathbf{c} = \\mathbf{b}*\\mathbf{c}$ are nonzero and mutually orthogonal, Lemma~2 implies\n\\[\n\\mathbf{b}*\\mathbf{b} = \\mathbf{c}*\\mathbf{c} = (\\mathbf{b}*\\mathbf{c})*(\\mathbf{b}*\\mathbf{c}) = 0 = \\mathbf{e}.\n\\]\nHence $\\mathbf{b}*\\mathbf{c} = \\mathbf{c}*\\mathbf{b}$, contradicting Lemma~3 because $\\mathbf{b} \\times \\mathbf{c} \\neq 0$.\nThe desired result follows."
  },
  {
    "year": 2010,
    "label": "A6",
    "difficulty": "6",
    "problem": "Let $f:[0,\\infty)\\to \\mathbb{R}$ be a strictly decreasing continuous function\nsuch that $\\lim_{x\\to\\infty} f(x) = 0$. Prove that\n$\\int_0^\\infty \\frac{f(x)-f(x+1)}{f(x)}\\,dx$ diverges.",
    "solution": "\\textbf{First solution.}\nNote that the hypotheses on $f$ imply that $f(x) > 0$ for all $x \\in [0, +\\infty)$,\nso the integrand is a continuous function of $f$ and the integral makes sense. Rewrite the integral as\n\\[\n\\int_0^\\infty \\left(1 - \\frac{f(x+1)}{f(x)} \\right)\\,dx,\n\\]\nand suppose by way of contradiction that it converges to a finite limit $L$.\nFor $n \\geq 0$, define the Lebesgue measurable set\n\\[\nI_n = \\{x \\in [0,1]: 1 - \\frac{f(x+n+1)}{f(x+n)} \\leq 1/2 \\}.\n\\]\nThen $L \\geq \\sum_{n=0}^\\infty \\frac{1}{2} (1 - \\mu(I_n))$,\nso the latter sum converges.\nIn particular, there exists a nonnegative integer $N$ for which $\\sum_{n=N}^\\infty (1 - \\mu(I_n)) < 1$;\nthe intersection\n\\[\nI = \\bigcup_{n=N}^\\infty I_n = [0,1] - \\bigcap_{n=N}^\\infty ([0,1] - I_n)\n\\]\nthen has positive Lebesgue measure.\n\nBy Taylor's theorem with remainder, for $t \\in [0,1/2]$,\n\\begin{align*}\n-\\log (1-t) &\\leq t + \\frac{t^2}{2} \\sup_{t \\in [0,1/2]} \\left\\{\\frac{1}{(1-t)^2}\n\\right\\} \\\\\n&= t + 2 t^2 \\leq 2t.\n\\end{align*}\nFor each nonnegative integer $n \\geq N$, we then have\n\\begin{align*}\nL &\\geq \\int_N^{n} \\left(1 - \\frac{f(x+1)}{f(x)} \\right)\\,dx \\\\\n&= \\sum_{i=N}^{n-1} \\int_0^1 \\left( 1 - \\frac{f(x+i+1)}{f(x+i)}\\right)\\,dx \\\\\n&\\geq \\sum_{i=N}^{n-1} \\int_I \\left( 1 - \\frac{f(x+i+1)}{f(x+i)}\\right)\\,dx \\\\\n&\\geq \\frac{1}{2} \\sum_{i=N}^{n-1} \\int_I \\log \\frac{f(x+i)}{f(x+i+1)}\\,dx \\\\\n&= \\frac{1}{2} \\int_I \\left( \\sum_{i=N}^{n-1} \\log \\frac{f(x+i)}{f(x+i+1)}\\right) \\,dx \\\\\n&= \\frac{1}{2} \\int_I \\log \\frac{f(x+N)}{f(x+n)} \\,dx.\n\\end{align*}\nFor each $x \\in I$, $\\log f(x+N)/f(x+n)$ is a strictly increasing unbounded function of $n$.\nBy the monotone convergence theorem, the integral $\\int_I \\log (f(x+N)/f(x+n)) \\,dx$ grows without bound\nas $n \\to +\\infty$, a contradiction. Thus the original integral diverges, as desired.\n\n\\textbf{Remark.}\nThis solution is motivated by the commonly-used fact that an infinite product\n$(1 + x_1)(1 + x_2) \\cdots$ converges absolutely if and only if the sum\n$x_1 + x_2 + \\cdots$ converges absolutely. The additional measure-theoretic argument at the beginning is needed\nbecause one cannot bound $-\\log(1-t)$ by a fixed multiple of $t$ uniformly for all $t \\in [0,1)$.\n\nGreg Martin suggests a variant solution that avoids use of Lebesgue measure.\nNote first that if $f(y) > 2f(y+1)$, then either $f(y) > \\sqrt{2} f(y+1/2)$ or $f(y+1/2) > \\sqrt{2} f(y+1)$,\nand in either case we deduce that\n\\[\n\\int_{y-1/2}^{y+1/2} \\frac{f(x)-f(x+1)}{f(x)}\\,dx > \\frac{1}{2} \\left(1 - \\frac{1}{\\sqrt{2}} \\right)  > \\frac{1}{7}.\n\\]\nIf there exist arbitrarily large values of $y$ for which $f(y) > 2f(y+1)$, we deduce that\nthe original integral is greater than any multiple of $1/7$, and so diverges. Otherwise,\nfor $x$ large we may argue that\n\\[\n\\frac{f(x)-f(x+1)}{f(x)} > \\frac{3}{5} \\log \\frac{f(x)}{f(x+1)}\n\\]\nas in the above solution, and again get divergence using a telescoping sum.\n\n\\textbf{Second solution.}\n(Communicated by Paul Allen.)\nLet $b>a$ be nonnegative integers. Then\n\\begin{align*}\n\\int_a^b \\frac{f(x)-f(x+1)}{f(x)}dx &=\n\\sum_{k=a}^{b-1} \\int_0^1 \\frac{f(x+k)-f(x+k+1)}{f(x+k)}dx \\\\\n&= \\int_0^1 \\sum_{k=a}^{b-1} \\frac{f(x+k)-f(x+k+1)}{f(x+k)}dx \\\\\n&\\geq \\int_0^1 \\sum_{k=a}^{b-1} \\frac{f(x+k)-f(x+k+1)}{f(x+a)}dx \\\\\n&= \\int_0^1 \\frac{f(x+a)-f(x+b)}{f(x+a)} dx.\n\\end{align*}\nNow since $f(x)\\rightarrow 0$, given $a$, we can choose an integer $l(a)>a$ for which $f(l(a)) < f(a+1)/2$; then $\\frac{f(x+a)-f(x+l(a))}{f(x+a)} \\geq 1 - \\frac{f(l(a))}{f(a+1)} > 1/2$ for all $x\\in [0,1]$. Thus if we define a sequence of integers $a_n$ by $a_0=0$, $a_{n+1}=l(a_n)$, then\n\\begin{align*}\n\\int_0^\\infty \\frac{f(x)-f(x+1)}{f(x)} dx &=\n\\sum_{n=0}^\\infty \\int_{a_n}^{a_{n+1}} \\frac{f(x)-f(x+1)}{f(x)} dx \\\\\n&> \\sum_{n=0}^\\infty \\int_0^1 (1/2) dx,\n\\end{align*}\nand the final sum clearly diverges.\n\n\\textbf{Third solution.}\n(By Joshua Rosenberg, communicated by Catalin Zara.)\nIf the original integral converges, then\non one hand the integrand $(f(x)-f(x+1))/f(x) = 1 - f(x+1)/f(x)$\ncannot tend to 1 as $x \\to \\infty$.\nOn the other hand, for any $a \\geq 0$,\n\\begin{align*}\n0 &< \\frac{f(a+1)}{f(a)} \\\\\n&< \\frac{1}{f(a)} \\int_a^{a+1} f(x)\\,dx \\\\\n&= \\frac{1}{f(a)} \\int_a^\\infty (f(x) - f(x+1))\\,dx \\\\\n&\\leq \\int_a^\\infty \\frac{f(x) - f(x+1)}{f(x)}\\,dx,\n\\end{align*}\nand the last expression tends to 0 as $a \\to \\infty$.\nHence by the squeeze theorem, $f(a+1)/f(a) \\to 0$ as $a \\to \\infty$, a contradiction."
  },
  {
    "year": 2010,
    "label": "B1",
    "difficulty": "1",
    "problem": "Is there an infinite sequence of real numbers $a_1, a_2, a_3, \\dots$ such that\n\\[\na_1^m + a_2^m + a_3^m + \\cdots = m\n\\]\nfor every positive integer $m$?",
    "solution": "\\textbf{First solution.}\nNo such sequence exists. If it did, then the Cauchy-Schwartz inequality would imply\n\\begin{align*}\n8 &= (a_1^2 + a_2^2 +  \\cdots)(a_1^4 + a_2^4 + \\cdots) \\\\\n&\\geq (a_1^3 + a_2^3 + \\cdots)^2 = 9,\n\\end{align*}\ncontradiction.\n\n\\textbf{Second solution.}\n(Communicated by Catalin Zara.)\nSuppose that such a sequence exists.\nIf $a_k^2 \\in [0,1]$ for all $k$, then $a_k^4 \\leq a_k^2$ for all $k$, and so\n\\[\n4 = a_1^4 + a_2^4 + \\cdots \\leq a_1^2 + a_2^2 + \\cdots = 2,\n\\]\ncontradiction. There thus exists a positive integer $k$ for which $a_k^2 \\geq 1$.\nHowever, in this case, for $m$ large, $a_k^{2m} > 2m$ and so\n$a_1^{2m} + a_2^{2m} + \\cdots \\neq 2m$.\n\n\\textbf{Third solution.}\nWe generalize the second solution to show that for any positive integer $k$, it is impossible for a sequence\n$a_1, a_2,\\dots$ of complex numbers to satisfy the given conditions in case\nthe series $a_1^k + a_2^k + \\cdots$ converges absolutely. This includes the original problem by taking\n$k=2$, in which case the series $a_1^2 + a_2^2 + \\cdots$ consists of nonnegative\nreal numbers and so converges absolutely if it converges at all.\n\nSince the sum $\\sum_{i=1}^\\infty |a_i|^k$ converges by hypothesis, we can find a positive integer $n$\nsuch that $\\sum_{i=n+1}^\\infty |a_i|^k < 1$. For each positive integer $d$, we then have\n\\[\n\\left|kd - \\sum_{i=1}^n a_i^{kd} \\right|\n\\leq \\sum_{i=n+1}^\\infty |a_i|^{kd} < 1.\n\\]\nWe thus cannot have $|a_1|,\\dots,|a_n| \\leq 1$, or else the sum $\\sum_{i=1}^n a_i^{kd}$ would be bounded\nin absolute value by $n$ independently of $d$. But if we put $r = \\max\\{|a_1|,\\dots,|a_n|\\} > 1$, we\nobtain another contradiction because for any $\\epsilon > 0$,\n\\[\n\\limsup_{d \\to \\infty} (r-\\epsilon)^{-kd} \\left| \\sum_{i=1}^n a_i^{kd} \\right| > 0.\n\\]\nFor instance, this follows from applying the root test to the rational function\n\\[\n\\sum_{i=1}^n \\frac{1}{1 - a_i^k z} = \\sum_{d=0}^\\infty \\left( \\sum_{i=1}^n a_i^{kd} \\right) z^d,\n\\]\nwhich has a pole within the circle $|z| \\leq r^{-1/k}$.\n(An elementary proof is also possible.)\n\n\\textbf{Fourth solution.}\n(Communicated by Noam Elkies.)\nSince $\\sum_k a_k^2 = 2$, for each positive integer $k$ we have $a_k^2 \\leq 2$ and so $a_k^4 \\leq 2 a_k^2$,\nwith equality only for $a_k^2 \\in \\{0,2\\}$. Thus to have $\\sum_k a_k^4 = 4$, there must be a single index\n$k$ for which $a_k^2 = 2$, and the other $a_k$ must all equal 0. But then $\\sum_k a_k^{2m} = 2^m \\neq 2m$\nfor any positive integer $m>2$.\n\n\\textbf{Remark.} Manjul Bhargava points out it is easy to construct sequences of complex numbers with the\ndesired property if we drop the condition of absolute convergence. Here is an inductive construction\n(of which several variants are possible).\nFor $n=1,2,\\dots$ and $z \\in \\CC$, define the finite sequence\n\\[\ns_{n,z} = \\left( \\frac{1}{z} e^{2 \\pi i j/n}: j = 0, \\dots, n-1 \\right).\n\\]\nThis sequence has the property that for any positive integer $j$, the sum of the $j$-th powers\nof the terms of $s_{n,z}$ equals $1/z^{j}$ if $j$ is divisible by $n$ and 0 otherwise.\nMoreover, any partial sum of $j$-th powers is bounded in absolute value by $n/|z|^j$.\n\nThe desired sequence will be constructed as follows. Suppose that we have a finite sequence\nwhich has the correct sum of $j$-th powers for $j=1,\\dots,m$. (For instance, for $m=1$,\nwe may start with the singleton sequence 1.) We may then extend it to a new sequence which has\nthe correct sum of $j$-th powers for $j=1,\\dots,m+1$, by appending $k$ copies of $s_{m+1,z}$\nfor suitable choices of a positive integer $k$ and a complex number $z$ with $|z| < m^{-2}$.\nThis last restriction ensures that the resulting infinite sequence $a_1,a_2,\\dots$ is such that\nfor each positive integer $m$, the series $a_1^m + a_2^m + \\cdots$ is convergent (though not absolutely\nconvergent). Its partial sums include a subsequence equal to the constant value $m$, so the sum of the series\nmust equal $m$ as desired."
  },
  {
    "year": 2010,
    "label": "B2",
    "difficulty": "2",
    "problem": "Given that $A$, $B$, and $C$ are noncollinear points in the plane with integer coordinates\nsuch that the distances $AB$, $AC$, and $BC$ are integers, what is the smallest possible value of $AB$?",
    "solution": "The smallest distance is 3, achieved by $A = (0,0)$, $B = (3,0)$, $C = (0,4)$.\nTo check this, it suffices to check that $AB$ cannot equal 1 or 2. (It cannot equal 0\nbecause if two of the points were to coincide, the three points would be collinear.)\n\nThe triangle inequality implies that $|AC - BC| \\leq AB$, with equality if and only if $A,B,C$\nare collinear. If $AB = 1$, we may assume without loss of generality that $A = (0,0)$, $B = (1,0)$.\nTo avoid collinearity, we must have $AC = BC$, but this forces $C = (1/2, y)$ for some $y \\in \\RR$,\na contradiction. (One can also treat this case by scaling by a factor of 2 to reduce to the case $AB=2$,\ntreated in the next paragraph.)\n\nIf $AB = 2$, then we may assume without loss of generality that $A = (0,0), B = (2,0)$.\nThe triangle inequality implies $|AC - BC| \\in \\{0,1\\}$.\nAlso, for $C = (x,y)$, $AC^2 = x^2 + y^2$ and $BC^2 = (2-x)^2 + y^2$ have the same parity;\nit follows that $AC = BC$. Hence $c = (1,y)$ for some $y \\in \\RR$, so $y^2$ and $y^2+1=BC^2$\nare consecutive perfect squares. This can only happen for $y = 0$, but then $A,B,C$ are collinear,\na contradiction again.\n\n\\textbf{Remark.} Manjul Bhargava points out that more generally, a \\emph{Heronian triangle}\n(a triangle with integer sides and rational area) cannot have a side of length 1 or 2 (and again\nit is enough to treat the case of length 2). The original\nproblem follows from this because a triangle whose vertices have integer coordinates has area\nequal to half an integer (by Pick's formula or the explicit formula for the area as a determinant)."
  },
  {
    "year": 2010,
    "label": "B3",
    "difficulty": "3",
    "problem": "There are 2010 boxes labeled $B_1, B_2, \\dots, B_{2010}$, and $2010n$ balls have been distributed\namong them, for some positive integer $n$. You may redistribute the balls by a sequence of moves,\neach of which consists of choosing an $i$ and moving \\emph{exactly} $i$ balls from box $B_i$ into any\none other box. For which values of $n$ is it possible to reach the distribution with exactly $n$ balls\nin each box, regardless of the initial distribution of balls?\n\\medskip",
    "solution": "It is possible if and only if $n \\geq 1005$.\nSince\n\\[\n1 + \\cdots + 2009 = \\frac{2009 \\times 2010}{2} = 2010 \\times 1004.5,\n\\]\nfor $n \\leq 1004$, we can start with an initial distribution in which each box\n$B_i$ starts with at most $i-1$ balls (so in particular $B_1$ is empty).\nFrom such a distribution, no moves are possible, so\nwe cannot reach the desired final distribution.\n\nSuppose now that $n \\geq 1005$.\nBy the pigeonhole principle, at any time, there exists at least one index $i$ for which the box $B_i$\ncontains at least $i$ balls. We will describe any such index as being \\emph{eligible}.\nThe following sequence of operations then has the desired effect.\n\\begin{itemize}"
  },
  {
    "year": 2010,
    "label": "B4",
    "difficulty": "4",
    "problem": "Find all pairs of polynomials $p(x)$ and $q(x)$ with real coefficients for which\n\\[\np(x) q(x+1) - p(x+1) q(x) = 1.\n\\]",
    "solution": "\\textbf{First solution.}\nThe pairs $(p,q)$ satisfying the given equation are those of the form $p(x) = ax+b, q(x) = cx+d$\nfor $a,b,c,d \\in \\RR$ such that $bc- ad = 1$. We will see later that these indeed give solutions.\n\nSuppose $p$ and $q$ satisfy the given equation; note that neither $p$ nor $q$ can be identically zero.\nBy subtracting the equations\n\\begin{align*}\np(x) q(x+1) - p(x+1) q(x) &= 1 \\\\\np(x-1) q(x) - p(x) q(x-1) &= 1,\n\\end{align*}\nwe obtain the equation\n\\[\np(x) (q(x+1) + q(x-1)) = q(x) (p(x+1) + p(x-1)).\n\\]\nThe original equation implies that $p(x)$ and $q(x)$ have no common nonconstant factor,\nso $p(x)$ divides $p(x+1) + p(x-1)$. Since each of $p(x+1)$ and $p(x-1)$ has the same degree and leading\ncoefficient as $p$, we must have\n\\[\np(x+1) + p(x-1) = 2p(x).\n\\]\nIf we define the polynomials $r(x) = p(x+1) - p(x)$, $s(x) = q(x+1) - q(x)$,\nwe have $r(x+1) = r(x)$, and similarly $s(x+1) = s(x)$.\nPut\n\\[\na = r(0), b = p(0), c = s(0), d = q(0).\n\\]\nThen $r(x) = a, s(x) = c$ for all $x \\in \\ZZ$, and hence identically;\nconsequently, $p(x) = ax + b, q(x) = cx + d$ for all $x \\in \\ZZ$, and hence identically.\nFor $p$ and $q$ of this form,\n\\[\np(x) q(x+1) - p(x+1) q(x) = bc - ad,\n\\]\nso we get a solution if and only if $bc-ad=1$, as claimed.\n\n\\textbf{Second solution.}\n(Communicated by Catalin Zara.)\nAgain, note that $p$ and $q$ must be nonzero.\nWrite\n\\begin{align*}\np(x) &= p_0 + p_1 x + \\cdots + p_m x^m \\\\\nq(x) &= q_0 + q_1 x + \\cdots + q_n x^n\n\\end{align*}\nwith $p_m, q_n \\neq 0$, so that $m = \\deg(p), n = \\deg(q)$. It is enough to derive a contradiction\nassuming that $\\max\\{m,n\\} > 1$, the remaining cases being treated as in the\nfirst solution.\n\nPut $R(x) = p(x) q(x+1) - p(x+1) q(x)$. Since $m+n \\geq 2$ by assumption,\nthe coefficient of $x^{m+n-1}$ in $R(x)$\nmust vanish. By easy algebra, this coefficient equals $(m-n) p_m q_n$, so we must have $m=n > 1$.\n\nFor $k=1,\\dots,2m-2$, the coefficient of $x^k$ in $R(x)$ is\n\\[\n\\sum_{i+j>k, j>i} \\left( \\binom{j}{k-i} - \\binom{i}{k-j} \\right)(p_i q_j - p_j q_i)\n\\]\nand must vanish.\nFor $k=2m-2$, the only summand is for $(i,j) = (m-1,m)$, so $p_{m-1} q_m = p_m q_{m-1}$.\n\nSuppose now that $h \\geq 1$ and that $p_i q_j = p_j q_i$ is known to vanish whenever\n$j>i \\geq h$. (By the previous paragraph, we initially have this for $h=m-1$.)\nTake $k = m+h-2$ and note that the conditions $i+j > h, j \\leq m$ force $i \\geq h-1$.\nUsing the hypothesis, we see that the only possible nonzero contribution to the coefficient of $x^k$ in $R(x)$\nis from $(i,j) = (h-1,m)$. Hence $p_{h-1} q_m = p_m q_{h-1}$; since $p_m, q_m \\neq 0$, this implies\n$p_{h-1} q_j = p_j q_{h-1}$ whenever $j > h-1$.\n\nBy descending induction, we deduce that $p_i q_j = p_j q_i$ whenever $j>i \\geq 0$. Consequently,\n$p(x)$ and $q(x)$ are scalar multiples of each other, forcing $R(x) = 0$, a contradiction.\n\n\\textbf{Third solution.}\n(Communicated by David Feldman.)\nAs in the second solution, we note that there are no solutions where $m = \\deg(p), n = \\deg(q)$\nare distinct and $m+n \\geq 2$. Suppose $p,q$ form a solution with $m = n \\geq 2$.\nThe desired identity asserts that the matrix\n\\[\n\\begin{pmatrix}\np(x) & p(x+1) \\\\\nq(x) & q(x+1)\n\\end{pmatrix}\n\\]\nhas determinant 1. This condition is preserved by replacing $q(x)$ with $q(x) - tp(x)$ for any\nreal number $t$. In particular, we can choose $t$ so that $\\deg(q(x) - tp(x)) < m$;\nwe then obtain a contradiction."
  },
  {
    "year": 2010,
    "label": "B5",
    "difficulty": "5",
    "problem": "Is there a strictly increasing function $f: \\mathbb{R} \\to \\mathbb{R}$ such that $f'(x) = f(f(x))$ for all $x$?",
    "solution": "\\textbf{First solution.}\nThe answer is no. Suppose otherwise. For the condition to make sense, $f$ must be differentiable.\nSince $f$ is strictly increasing, we must have $f'(x) \\geq 0$ for all $x$.\nAlso, the function $f'(x)$ is strictly increasing: if $y>x$ then $f'(y) = f(f(y)) > f(f(x)) = f'(x)$.\nIn particular, $f'(y) > 0$ for all $y \\in \\RR$.\n\nFor any $x_0 \\geq -1$, if $f(x_0) = b$ and $f'(x_0) = a > 0$, then $f'(x) > a$ for $x>x_0$ and thus $f(x) \\geq a(x-x_0)+b$ for $x\\geq x_0$. Then either $b < x_0$ or\n$a = f'(x_0) = f(f(x_0)) = f(b) \\geq a(b-x_0)+b$. In the latter case,\n$b \\leq a(x_0+1)/(a+1) \\leq x_0+1$. We conclude in either case that $f(x_0) \\leq x_0+1$ for all $x_0 \\geq -1$.\n\nIt must then be the case that $f(f(x)) = f'(x) \\leq 1$ for all $x$, since otherwise $f(x) > x+1$ for large $x$. Now by the above reasoning, if $f(0) = b_0$ and $f'(0) = a_0>0$, then $f(x) > a_0x+b_0$ for $x>0$. Thus for $x > \\max\\{0,-b_0/a_0\\}$, we have\n$f(x) > 0$ and $f(f(x)) > a_0x+b_0$. But then $f(f(x)) > 1$ for sufficiently large $x$, a contradiction.\n\n\\textbf{Second solution.}\n(Communicated by Catalin Zara.)\nSuppose such a function exists. Since $f$ is strictly increasing and differentiable, so is $f \\circ f = f'$.\nIn particular, $f$ is twice differentiable; also, $f''(x) = f'(f(x)) f'(x)$ is the product of two strictly\nincreasing nonnegative functions, so it is also strictly increasing and nonnegative. In particular, we can choose\n$\\alpha>0$ and $M \\in \\RR$ such that $f''(x) > 4\\alpha$ for all $x \\geq M$. Then for all $x \\geq M$,\n\\[\nf(x) \\geq f(M) + f'(M)(x-M) + 2\\alpha (x-M)^2.\n\\]\nIn particular, for some $M' > M$, we have $f(x) \\geq \\alpha x^2$ for all $x \\geq M'$.\n\nPick $T>0$ so that $\\alpha T^2 > M'$. Then for $x \\geq T$,\n$f(x) > M'$ and so $f'(x) = f(f(x)) \\geq \\alpha f(x)^2$.\nNow\n\\[\n\\frac{1}{f(T)} - \\frac{1}{f(2T)}\n= \\int_T^{2T} \\frac{f'(t)}{f(t)^2}\\,dt \\geq \\int_T^{2T} \\alpha\\,dt;\n\\]\nhowever, as $T \\to \\infty$, the left side of this inequality\ntends to 0 while the right side tends to $+\\infty$,\na contradiction.\n\n\\textbf{Third solution.}\n(Communicated by Noam Elkies.)\nSince $f$ is strictly increasing, for some $y_0$, we can define the inverse function\n$g(y)$ of $f$ for $y \\geq y_0$. Then $x = g(f(x))$, and we may differentiate to find that\n$1 = g'(f(x)) f'(x) = g'(f(x)) f(f(x))$. It follows that $g'(y) = 1/f(y)$ for $y \\geq y_0$;\nsince $g$ takes arbitrarily large values, the integral $\\int_{y_0}^\\infty dy/f(y)$ must diverge.\nOne then gets a contradiction from any reasonable lower bound on $f(y)$ for $y$ large,\ne.g., the bound $f(x) \\geq \\alpha x^2$ from the second solution. (One can also\nstart with a linear lower bound $f(x) \\geq \\beta x$, then use the integral expression for $g$\nto deduce that $g(x) \\leq \\gamma \\log x$, which in turn forces $f(x)$ to grow exponentially.)"
  },
  {
    "year": 2010,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $A$ be an $n \\times n$ matrix of real numbers for some $n \\geq 1$.\nFor each positive integer $k$, let $A^{[k]}$ be the matrix obtained by raising each entry to the $k$th\npower. Show that if $A^k = A^{[k]}$ for $k=1,2,\\dots,n+1$, then $A^k = A^{[k]}$ for all $k \\geq 1$.\n\n\\end{itemize}\n\n\\end{document}",
    "solution": "For any polynomial $p(x)$, let $[p(x)]A$ denote the $n\\times n$ matrix obtained by replacing each entry $A_{ij}$ of $A$ by $p(A_{ij})$; thus $A^{[k]} = [x^k]A$. Let $P(x) = x^n + a_{n-1}x^{n-1} + \\cdots + a_0$ denote the characteristic polynomial of $A$. By the Cayley-Hamilton theorem,\n\\begin{align*}\n0 &= A \\cdot P(A) \\\\\n&= A^{n+1} + a_{n-1}A^n+\\cdots+a_0 A \\\\\n&= A^{[n+1]}+a_{n-1}A^{[n]}+\\cdots + a_0 A^{[1]} \\\\\n&=[xp(x)]A.\n\\end{align*}\nThus each entry of $A$ is a root of the polynomial $xp(x)$.\n\nNow suppose $m \\geq n+1$. Then\n\\begin{align*}\n0 &= [x^{m+1-n}P(x)]A  \\\\\n&= A^{[m+1]} + a_{n-1} A^{[m]} + \\cdots + a_0 A^{[m+1-n]}\n\\end{align*}\nsince each entry of $A$ is a root of $x^{m+1-n}P(x)$. On the other hand,\n\\begin{align*}\n0 &= A^{m+1-n} \\cdot P(A) \\\\\n&= A^{m+1} + a_{n-1} A^m + \\cdots + a_0 A^{m+1-n}.\n\\end{align*}\nTherefore if $A^k = A^{[k]}$ for $m+1-n \\leq k \\leq m$, then $A^{m+1} = A^{[m+1]}$. The desired result follows by induction on $m$.\n\n\\textbf{Remark.}\nDavid Feldman points out that the result is best possible in the following sense: there exist\nexamples of $n \\times n$ matrices $A$ for which $A^k = A^{[k]}$ for $k=1,\\dots,n$ but $A^{n+1} \\neq A^{[n+1]}$.\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2011,
    "label": "A1",
    "difficulty": "1",
    "problem": "Define a \\textit{growing spiral} in the plane to be a sequence\nof points with integer coordinates $P_0 = (0,0), P_1, \\dots, P_n$ such\nthat $n \\geq 2$ and:\n\\begin{itemize}\n\\item the directed line segments $P_0 P_1, P_1 P_2, \\dots, P_{n-1} P_n$\nare in the successive coordinate directions east (for $P_0 P_1$), north,\nwest, south, east, etc.;\n\\item the lengths of these line segments are positive and strictly\nincreasing.\n\\end{itemize} [Picture omitted.]  How many of the points $(x,y)$ with\ninteger coordinates $0\\leq x\\leq 2011, 0\\leq y\\leq 2011$ \\emph{cannot}\nbe the last point, $P_n$ of any growing spiral?",
    "solution": "We claim that the set of points with $0\\leq x\\leq 2011$ and $0\\leq\ny\\leq 2011$ that cannot be the last point of a growing spiral are as follows:\n$(0,y)$ for $0\\leq y\\leq 2011$; $(x,0)$ and $(x,1)$ for $1\\leq x\\leq 2011$;\n$(x,2)$ for $2\\leq x\\leq 2011$; and $(x,3)$ for $3\\leq x\\leq 2011$. This\ngives a total of\n\\[\n2012 + 2011 + 2011 + 2010 + 2009 = 10053\n\\]\nexcluded points.\n\nThe complement of this set is the set of $(x,y)$ with $0<x<y$, along with\n$(x,y)$ with $x \\geq y \\geq 4$. Clearly the former set is achievable as\n$P_2$ in a growing spiral, while a point $(x,y)$ in the latter set is $P_6$\nin a growing spiral with successive lengths $1$, $2$, $3$, $x+1$, $x+2$,\nand $x+y-1$.\n\nWe now need to rule out the other cases. Write $x_1<y_1<x_2<y_2<\\ldots$\nfor the lengths of the line segments in the spiral in order, so that $P_1 =\n(x_1,0)$, $P_2 = (x_1,y_1)$, $P_3 = (x_1-x_2,y_1)$, and so forth. Any point\nbeyond $P_0$ has $x$-coordinate of the form $x_1-x_2+\\cdots+(-1)^{n-1}\nx_n$ for $n\\geq 1$; if $n$ is odd, we can write this as $x_1 + (-x_2+x_3)\n+ \\cdots + (-x_{n-1}+x_n) > 0$, while if $n$ is even, we can write this as\n$(x_1-x_2) + \\cdots + (x_{n-1}-x_n) < 0$. Thus no point beyond $P_0$ can have\n$x$-coordinate $0$, and we have ruled out $(0,y)$ for $0\\leq y\\leq 2011$.\n\nNext we claim that any point beyond $P_3$ must have $y$-coordinate either\nnegative or $\\geq 4$. Indeed, each such point has $y$-coordinate of the\nform $y_1-y_2+\\cdots+(-1)^{n-1} y_n$ for $n \\geq 2$, which we can write\nas $(y_1-y_2) + \\cdots + (y_{n-1}-y_n) < 0$ if $n$ is even, and\n\\[\ny_1 +(-y_2+y_3) + \\cdots + (-y_{n-1}+y_n) \\geq y_1 + 2 \\geq 4\n\\]\nif $n \\geq 3$\nis odd. Thus to rule out the rest of the forbidden points, it suffices to\ncheck that they cannot be $P_2$ or $P_3$ for any growing spiral. But none\nof them can be $P_3 = (x_1-x_2,y_1)$ since $x_1-x_2<0$, and none of them\ncan be $P_2 = (x_1,y_1)$ since they all have $y$-coordinate at most equal\nto their $x$-coordinate."
  },
  {
    "year": 2011,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $a_1,a_2,\\dots$ and $b_1,b_2,\\dots$ be sequences of positive\nreal numbers such that $a_1 = b_1 = 1$ and $b_n = b_{n-1} a_n - 2$ for\n$n=2,3,\\dots$. Assume that the sequence $(b_j)$ is bounded. Prove that\n\\[\nS = \\sum_{n=1}^\\infty \\frac{1}{a_1...a_n}\n\\]\nconverges, and evaluate $S$.",
    "solution": "For $m\\geq 1$, write\n\\[\nS_m = \\frac{3}{2}\\left(1 - \\frac{b_1\\cdots b_m}{(b_1+2)\\cdots(b_m+2)}\\right).\n \\]\nThen $S_1 = 1 = 1/a_1$ and a quick calculation yields\n\\[\nS_m-S_{m-1} = \\frac{b_1\\cdots b_{m-1}}{(b_2+2)\\cdots(b_m+2)} = \\frac{1}{a_1\\cdots a_m}\n\\]\nfor $m\\geq 2$, since $a_j = (b_j+2)/b_{j-1}$ for $j \\geq 2$. It follows\nthat $S_m = \\sum_{n=1}^m 1/(a_1\\cdots a_n)$.\n\nNow if $(b_j)$ is bounded above by $B$, then $\\frac{b_j}{b_j+2}\n\\leq \\frac{B}{B+2}$ for all $j$, and so $3/2 > S_m \\geq\n3/2(1-(\\frac{B}{B+2})^m)$. Since $\\frac{B}{B+2} < 1$, it follows that the\nsequence $(S_m)$ converges to $S = 3/2$."
  },
  {
    "year": 2011,
    "label": "A3",
    "difficulty": "3",
    "problem": "Find a real number $c$ and a positive number $L$ for which\n\\[\n\\lim_{r\\to\\infty} \\frac{r^c \\int_0^{\\pi/2} x^r \\sin x \\,dx}{\\int_0^{\\pi/2} x^r \\cos x \\,dx} = L.\n\\]",
    "solution": "We claim that $(c,L) = (-1,2/\\pi)$ works.\nWrite $f(r) = \\int_0^{\\pi/2} x^r\\sin x\\,dx$. Then\n\\[\nf(r)  < \\int_0^{\\pi/2} x^r\\,dx = \\frac{(\\pi/2)^{r+1}}{r+1}\n\\]\nwhile since $\\sin x \\geq 2x/\\pi$ for $x \\leq \\pi/2$,\n\\[\nf(r) > \\int_0^{\\pi/2} \\frac{2x^{r+1}}{\\pi} \\,dx = \\frac{(\\pi/2)^{r+1}}{r+2}.\n\\]\nIt follows that\n\\[\n\\lim_{r\\to\\infty} r \\left(\\frac{2}{\\pi}\\right)^{r+1} f(r) = 1,\n\\]\nwhence\n\\[\n\\lim_{r\\to\\infty} \\frac{f(r)}{f(r+1)} = \\lim_{r\\to\\infty}\n\\frac{r(2/\\pi)^{r+1}f(r)}{(r+1)(2/\\pi)^{r+2}f(r+1)} \\cdot\n\\frac{2(r+1)}{\\pi r} = \\frac{2}{\\pi}.\n\\]\n\nNow by integration by parts, we have\n\\[\n\\int_0^{\\pi/2} x^r\\cos x\\,dx = \\frac{1}{r+1} \\int_0^{\\pi/2} x^{r+1} \\sin x\\,dx\n    = \\frac{f(r+1)}{r+1}.\n\\]\nThus setting $c = -1$ in the given limit yields\n\\[\n\\lim_{r\\to\\infty} \\frac{(r+1)f(r)}{r f(r+1)} =\n\\frac{2}{\\pi},\n\\]\nas desired."
  },
  {
    "year": 2011,
    "label": "A4",
    "difficulty": "4",
    "problem": "For which positive integers $n$ is there an $n \\times n$ matrix\nwith integer entries such that every dot product of a row with itself is\neven, while every dot product of two different rows is odd?",
    "solution": "The answer is $n$ odd. Let $I$ denote the $n\\times n$ identity\nmatrix, and let $A$ denote the $n\\times n$ matrix all of whose entries\nare $1$. If $n$ is odd, then the matrix $A-I$ satisfies the conditions of\nthe problem: the dot product of any row with itself is $n-1$, and the dot\nproduct of any two distinct rows is $n-2$.\n\nConversely, suppose $n$ is even, and suppose that the matrix $M$ satisfied\nthe conditions of the problem. Consider all matrices and vectors mod\n$2$. Since the dot product of a row with itself is equal mod $2$ to the\nsum of the entries of the row, we have $M v = 0$ where $v$ is the vector\n$(1,1,\\ldots,1)$, and so $M$ is singular. On the other hand, $M M^T =\nA-I$; since\n\\[\n(A-I)^2 = A^2-2A+I = (n-2)A+I = I,\n\\]\nwe have $(\\det M)^2 = \\det(A-I) = 1$ and $\\det M = 1$, contradicting the\nfact that $M$ is singular."
  },
  {
    "year": 2011,
    "label": "A5",
    "difficulty": "5",
    "problem": "Let $F : \\RR^2 \\to \\RR$ and $g : \\RR \\to \\RR$ be twice\ncontinuously differentiable functions with the following properties:\n\\begin{itemize}\n\\item $F(u,u) = 0$ for every $u \\in \\RR$;\n\\item for every $x \\in \\RR$, $g(x) > 0$ and $x^2 g(x) \\leq 1$;\n\\item for every $(u,v) \\in \\RR^2$, the vector $\\nabla F(u,v)$ is either $\\mathbf{0}$ or parallel to the vector $\\langle g(u), -g(v) \\rangle$.\n\\end{itemize}\nProve that there exists a constant $C$ such that for every $n\\geq 2$ and any $x_1,\\dots,x_{n+1} \\in \\RR$, we have\n\\[\n\\min_{i \\neq j} |F(x_i,x_j)| \\leq \\frac{C}{n}.\n\\]",
    "solution": "(by Abhinav Kumar) Define $G : \\RR \\to \\RR$ by $G(x) = \\int_0^x\ng(t)\\,dt$. By assumption, $G$ is a strictly increasing, thrice continuously\ndifferentiable function. It is also bounded: for $x>1$, we have\n\\[\n0 < G(x)-G(1) = \\int_1^x g(t)\\,dt \\leq \\int_1^x dt/t^2 = 1,\n\\]\nand similarly, for $x<-1$, we have $0 > G(x)-G(-1) \\geq -1$.\nIt follows that the image of $G$ is some open interval $(A,B)$\nand that $G^{-1}: (A,B) \\to \\RR$ is also thrice continuously differentiable.\n\nDefine $H: (A,B) \\times (A,B) \\to \\RR$ by $H(x,y) = F(G^{-1}(x), G^{-1}(y))$;\nit is twice continuously differentiable since $F$ and $G^{-1}$ are.\nBy our assumptions about $F$,\n\\begin{multline*}\n\\frac{\\partial H}{\\partial x} + \\frac{\\partial H}{\\partial y} =\n    \\frac{\\partial F}{\\partial x}(G^{-1}(x), G^{-1}(y))\n    \\cdot \\frac{1}{g(G^{-1}(x))}\\\\\n    + \\frac{\\partial F}{\\partial y}(G^{-1}(x), G^{-1}(y))\n    \\cdot \\frac{1}{g(G^{-1}(y))} = 0.\n\\end{multline*}\nTherefore $H$ is constant along any line parallel to the vector $(1,1)$,\nor equivalently, $H(x,y)$ depends only on $x-y$. We may thus write $H(x,y) =\nh(x-y)$ for some function $h$ on $(-(B-A), B-A)$, and we then have $F(x,y)\n= h(G(x) - G(y))$.  Since $F(u,u) = 0$, we have $h(0) = 0$. Also, $h$\nis twice continuously differentiable (since it can be written as $h(x)\n= H((A+B+x)/2,(A+B-x)/2)$), so $|h'|$ is bounded on the closed interval $[-(B-A)/2,\n(B-A)/2]$, say by $M$.\n\nGiven $x_1,\\dots,x_{n+1} \\in \\RR$ for some $n \\geq 2$, the numbers\n$G(x_1),\\dots,G(x_{n+1})$ all belong to $(A,B)$, so we can choose indices\n$i$ and $j$ so that $|G(x_i) - G(x_j)| \\leq (B-A)/n \\leq (B-A)/2$.  By the\nmean value theorem,\n\n\\[\n|F(x_i, x_j)| = |h(G(x_i) - G(x_j))| \\leq M \\frac{B-A}{n},\n\\]\nso the claim holds with $C = M(B-A)$."
  },
  {
    "year": 2011,
    "label": "A6",
    "difficulty": "6",
    "problem": "Let $G$ be an abelian group with $n$ elements, and let\n\\[ \\{g_1=e,g_2,\\dots,g_k\\} \\subsetneqq G \\]\nbe a (not necessarily minimal) set of distinct generators of $G$. A special\ndie, which randomly selects one of the elements $g_1,g_2,...,g_k$ with equal\nprobability, is rolled $m$ times and the selected elements are multiplied\nto produce an element $g \\in G$.  Prove that there exists a real number\n$b \\in (0,1)$ such that\n\n\\[ \\lim_{m\\to\\infty} \\frac{1}{b^{2m}} \\sum_{x\\in G} \\left(\\mathrm{Prob}(g=x)\n    - \\frac{1}{n}\\right)^2 \\]\nis positive and finite.",
    "solution": "Choose some ordering $h_1,\\dots, h_n$ of the elements of $G$ with $h_1 = e$.\nDefine an $n \\times n$ matrix $M$\nby settting $M_{ij} = 1/k$ if $h_j = h_i g$ for some $g \\in \\{g_1,\\dots,g_k\\}$ and $M_{ij} = 0$ otherwise.\nLet $v$ denote the column vector $(1,0,\\dots,0)$. The probability\nthat the product of $m$ random elements of $\\{g_1,\\dots,g_k\\}$\nequals $h_i$ can then be interpreted as the $i$-th component of the vector\n$M^m v$.\n\nLet $\\hat{G}$ denote the dual group of $G$, i.e., the group of complex-valued characters of $G$.\nLet $\\hat{e} \\in \\hat{G}$ denote the trivial character.\nFor each $\\chi \\in \\hat{G}$, the vector $v_\\chi = (\\chi(h_i))_{i=1}^n$ is an eigenvector of $M$\nwith eigenvalue $\\lambda_\\chi = (\\chi(g_1) + \\cdots + \\chi(g_k))/k$.\nIn particular, $v_{\\hat{e}}$ is the all-ones vector and $\\lambda_{\\hat{e}} = 1$.\nPut\n\\[\nb = \\max\\{|\\lambda_\\chi|: \\chi \\in \\hat{G} - \\{\\hat{e}\\}\\};\n\\]\nwe show that $b \\in (0,1)$ as follows.\nFirst suppose $b=0$; then\n\\[\n1 = \\sum_{\\chi \\in \\hat{G}} \\lambda_\\chi\n= \\frac{1}{k} \\sum_{i=1}^k \\sum_{\\chi \\in \\hat{G}} \\chi(g_i) = \\frac{n}{k}\n\\]\nbecause $\\sum_{\\chi \\in \\hat(G)} \\chi(g_i)$ equals $n$ for $i=1$ and $0$ otherwise.\nHowever, this contradicts the hypothesis that $\\{g_1, \\dots, g_k\\}$ is not all of $G$.\nHence $b > 0$. Next suppose $b=1$, and choose $\\chi \\in \\hat{G} - \\{\\hat{e}\\}$ with $|\\lambda_\\chi| = 1$.\nSince each of\n$\\chi(g_1), \\dots, \\chi(g_k)$ is a complex number of norm 1, the triangle inequality forces them all to be equal.\nSince $\\chi(g_1) = \\chi(e) = 1$, $\\chi$ must map each of $g_1,\\dots, g_k$ to 1, but this is impossible because\n$\\chi$ is a nontrivial character and $g_1,\\dots,g_k$ form a set of generators of $G$.\nThis contradiction yields $b < 1$.\n\nSince $v = \\frac{1}{n} \\sum_{\\chi \\in \\hat{G}} v_\\chi$\nand $M v_\\chi = \\lambda_\\chi v_\\chi$, we have\n\\[\nM^m v - \\frac{1}{n} v_{\\hat{e}}\n= \\frac{1}{n} \\sum_{\\chi \\in \\hat{G} - \\{\\hat{e}\\}} \\lambda_\\chi^m v_\\chi.\n\\]\nSince the vectors $v_\\chi$ are pairwise orthogonal,\nthe limit we are interested in can be written as\n\\[\n\\lim_{m \\to \\infty} \\frac{1}{b^{2m}} (M^m v - \\frac{1}{n} v_{\\hat{e}}) \\cdot (M^m v - \\frac{1}{n} v_{\\hat{e}}).\n\\]\nand then rewritten as\n\\[\n\\lim_{m \\to \\infty} \\frac{1}{b^{2m}} \\sum_{\\chi \\in \\hat{G} - \\{\\hat{e}\\}} |\\lambda_\\chi|^{2m}\n= \\#\\{\\chi \\in \\hat{G}: |\\lambda_\\chi| = b\\}.\n\\]\nBy construction, this last quantity is nonzero and finite.\n\n\n\\textbf{Remark.}\nIt is easy to see that the result fails if we do not assume $g_1 = e$: take $G = \\ZZ/2\\ZZ$,\n$n=1$, and $g_1 = 1$.\n\n\\textbf{Remark.}\nHarm Derksen points out that a similar argument applies even if $G$ is not assumed to be abelian,\nprovided that the operator $g_1 + \\cdots + g_k$ in the group algebra $\\ZZ[G]$ is \\emph{normal},\ni.e., it commutes with the operator $g_1^{-1} + \\cdots + g_k^{-1}$.\nThis includes the cases where the set $\\{g_1,\\dots,g_k\\}$ is closed under taking inverses\nand where it is a union of conjugacy classes (which in turn includes the case of $G$ abelian).\n\n\\textbf{Remark}.\nThe matrix $M$ used above has nonnegative entries with row sums equal to 1 (i.e., it corresponds to a Markov chain), and there exists a positive integer $m$ such that $M^m$ has positive entries. For any such matrix,\nthe Perron-Frobenius theorem implies that\nthe sequence of vectors $M^m v$ converges to a limit $w$, and there exists $b \\in [0,1)$\nsuch that\n\\[\n\\limsup_{m \\to \\infty} \\frac{1}{b^{2m}} \\sum_{i=1}^n ((M^m v - w)_i)^2\n\\]\nis nonzero and finite. (The intended interpretation in case $b=0$ is that $M^m v = w$ for all large $m$.)\nHowever, the limit need not exist in general."
  },
  {
    "year": 2011,
    "label": "B1",
    "difficulty": "1",
    "problem": "Let $h$ and $k$ be positive integers. Prove that for every\n$\\epsilon > 0$, there are positive integers $m$ and $n$ such that\n\\[ \\epsilon < |h \\sqrt{m} - k \\sqrt{n}| < 2\\epsilon.  \\]",
    "solution": "Since the rational numbers are dense in the reals, we can find positive integers $a,b$\nsuch that\n\\[\n\\frac{3\\epsilon}{hk} < \\frac{b}{a}\n< \\frac{4\\epsilon}{hk}.\n\\]\nBy multiplying $a$ and $b$ by a suitably large positive integer, we can also ensure that $3a^2 > b$. We then have\n\\[\n\\frac{\\epsilon}{hk} < \\frac{b}{3a} < \\frac{b}{\\sqrt{a^2+b} + a} = \\sqrt{a^2+b} - a\n\\]\nand\n\\[\n\\sqrt{a^2+b} - a = \\frac{b}{\\sqrt{a^2+b} + a} \\leq \\frac{b}{2a} < 2 \\frac{\\epsilon}{hk}.\n\\]\nWe may then take $m = k^2 (a^2+b), n = h^2 a^2$."
  },
  {
    "year": 2011,
    "label": "B2",
    "difficulty": "2",
    "problem": "Let $S$ be the set of all ordered triples $(p,q,r)$ of prime\nnumbers for which at least one rational number $x$ satisfies $px^2 + qx +\nr =0$. Which primes appear in seven or more elements of $S$?",
    "solution": "Only the primes 2 and 5 appear seven or more times.\nThe fact that these primes appear is demonstrated by the examples\n\\[\n(2,5,2), (2, 5, 3),  (2, 7, 5), (2, 11, 5)\n\\]\nand their reversals.\n\nIt remains to show that if either $\\ell=3$ or $\\ell$ is a prime greater than 5, then $\\ell$ occurs at most six times\nas an element of a triple in $S$.\nNote that $(p,q,r) \\in S$ if and only if\n$q^2 - 4pr = a^2$ for some integer $a$; in particular, since $4pr \\geq 16$, this forces $q \\geq 5$.\nIn particular, $q$ is odd, as then is $a$, and so $q^2 \\equiv a^2 \\equiv 1 \\pmod{8}$;\nconsequently, one of $p,r$ must equal 2. If $r=2$, then $8p = q^2-a^2 = (q+a)(q-a)$; since both factors\nare of the same sign and their sum is the positive number $2q$, both factors are positive.\nSince they are also both even, we have $q+a \\in \\{2, 4, 2p, 4p\\}$ and so\n$q \\in \\{2p+1, p+2\\}$. Similarly, if $p=2$, then $q \\in \\{2r+1, r+2\\}$.\nConsequently, $\\ell$ occurs at most twice as many times as there are prime numbers in the list\n\\[\n2\\ell+1, \\ell+2, \\frac{\\ell-1}{2}, \\ell-2.\n\\]\nFor $\\ell = 3$,$\\ell-2= 1$ is not prime.\nFor $\\ell \\geq 7$, the numbers $\\ell-2, \\ell, \\ell+2$ cannot all be prime,\nsince one of them is always a nontrivial multiple of 3.\n\n\\textbf{Remark.}\nThe above argument shows that the cases listed for 5 are the only ones that can occur. By contrast,\nthere are infinitely many cases where 2 occurs if either the twin prime conjecture holds or there are\ninfinitely many Sophie Germain primes (both of which are expected to be true)."
  },
  {
    "year": 2011,
    "label": "B3",
    "difficulty": "3",
    "problem": "Let $f$ and $g$ be (real-valued) functions defined on an open\ninterval containing $0$, with $g$ nonzero and continuous at $0$.  If $fg$\nand $f/g$ are differentiable at $0$, must $f$ be differentiable at 0?",
    "solution": "Yes, it follows that $f$ is differentiable.\n\n\\noindent\n\\textbf{First solution.}\nNote first that at $0$, $f/g$ and $g$ are both continuous, as then is their product $f$.\nIf $f(0) \\neq 0$, then in some neighborhood of $0$, $f$ is either always positive or always\nnegative. We can thus choose $\\epsilon \\in \\{\\pm 1\\}$ so that\n$\\epsilon f$ is the composition of the differentiable function\n$(fg)\\cdot (f/g)$ with the square root function. By the chain rule, $f$ is differentiable at $0$.\n\nIf $f(0) = 0$, then $(f/g)(0) = 0$, so we have\n\\[\n(f/g)'(0) = \\lim_{x \\to 0}\n\\frac{f(x)}{x g(x)}.\n\\]\nSince $g$ is continuous at 0, we may multiply limits to deduce that $\\lim_{x \\to 0} f(x)/x$ exists.\n\n\\noindent\n\\textbf{Second solution.}\nChoose a neighborhood $N$ of $0$ on which $g(x) \\neq 0$.\nDefine the following functions on $N \\setminus \\{0\\}$:\n$h_1(x) = \\frac{f(x)g(x)-f(0)g(0)}{x}$;\n$h_2(x) = \\frac{f(x)g(0)-f(0)g(x)}{xg(0)g(x)}$;\n$h_3(x) = g(0)g(x)$;\n$h_4(x) = \\frac{1}{g(x)+g(0)}$. Then\nby assumption, $h_1,h_2,h_3,h_4$ all have limits as $x \\to 0$. On the\nother hand,\n\\[\n\\frac{f(x)-f(0)}{x} = (h_1(x)+h_2(x)h_3(x))h_4(x),\n\\]\nand it follows that $\\lim_{x\\to 0} \\frac{f(x)-f(0)}{x}$ exists, as desired."
  },
  {
    "year": 2011,
    "label": "B4",
    "difficulty": "4",
    "problem": "In a tournament, 2011 players meet 2011 times to play a\nmultiplayer game. Every game is played by all 2011 players together and\nends with each of the players either winning or losing. The standings\nare kept in two $2011 \\times 2011$ matrices, $T = (T_{hk})$ and $W =\n(W_{hk})$. Initially, $T=W=0$. After every game, for every $(h,k)$ (including\nfor $h=k$), if players $h$ and $k$ tied (that is, both won or both lost),\nthe entry $T_{hk}$ is increased by 1, while if player $h$ won and player $k$\nlost, the entry $W_{hk}$ is increased by 1 and $W_{kh}$ is decreased by 1.\n\nProve that at the end of the tournament, $\\det(T+iW)$ is a non-negative\ninteger divisible by $2^{2010}$.",
    "solution": "Number the games $1,\\ldots,2011$, and let $A = (a_{jk})$ be the $2011 \\times 2011$ matrix whose $jk$ entry is $1$ if player $k$ wins game $j$ and $i = \\sqrt{-1}$ if player $k$ loses game $j$. Then $\\overline{a_{hj}}a_{jk}$ is $1$ if players $h$ and $k$ tie in game $j$; $i$ if player $h$ wins and player $k$ loses in game $j$; and $-i$ if $h$ loses and $k$ wins. It follows that $T + i W = \\overline{A}^T A$.\n\nNow the determinant of $A$ is unchanged if we subtract the first row of $A$ from each of the other rows, producing a matrix whose rows, besides the first one, are $(1-i)$ times a row of integers. Thus we can write $\\det A = (1-i)^{2010}(a+bi)$ for some integers $a,b$. But then\n$\\det(T+iW) = \\det(\\overline{A}^T A) = 2^{2010}(a^2+b^2)$ is a nonnegative integer multiple of $2^{2010}$, as desired."
  },
  {
    "year": 2011,
    "label": "B5",
    "difficulty": "5",
    "problem": "Let $a_1, a_2, \\dots$ be real numbers. Suppose that there is\na constant $A$ such that for all $n$,\n\\[\n\\int_{-\\infty}^\\infty \\left( \\sum_{i=1}^n \\frac{1}{1 + (x-a_i)^2} \\right)^2\\,dx \\leq An.\n\\]\nProve there is a constant $B>0$ such that for all $n$,\n\\[\n\\sum_{i,j=1}^n (1 + (a_i - a_j)^2) \\geq Bn^3.\n\\]",
    "solution": "Define the function\n\\[\nf(y) =\n\\int_{-\\infty}^\\infty \\frac{dx}{(1+x^2)(1+(x+y)^2)}.\n\\]\nFor $y \\geq 0$, in the range $-1 \\leq x \\leq 0$,\nwe have\n\\begin{align*}\n(1+x^2)(1+(x+y)^2) &\\leq (1+1)(1+(1+y)^2) = 2y^2+4y+4 \\\\\n&\\leq 2y^2+4+2(y^2+1) \\leq 6+6y^2.\n\\end{align*}\nWe thus have the lower bound\n\\[\nf(y) \\geq \\frac{1}{6(1+y^2)};\n\\]\nthe same bound is valid for $y \\leq 0$ because $f(y) = f(-y)$.\n\nThe original hypothesis can be written as\n\\[\n\\sum_{i,j=1}^n f(a_i - a_j) \\leq An\n\\]\nand thus\nimplies that\n\\[\n\\sum_{i,j=1}^n \\frac{1}{1 + (a_i-a_j)^2} \\leq 6An.\n\\]\nBy the Cauchy-Schwarz inequality, this implies\n\\[\n\\sum_{i,j=1}^n (1 + (a_i-a_j)^2) \\geq Bn^3\n\\]\nfor $B = 1/(6A)$.\n\n\\textbf{Remark.}\nOne can also compute explicitly (using partial fractions, Fourier transforms, or contour integration)\nthat $f(y) = \\frac{2\\pi}{4 + y^2}$.\n\n\\textbf{Remark.}\nPraveen Venkataramana points out that the lower bound can be improved to $Bn^4$\nas follows. For each $z \\in \\ZZ$, put $Q_{z,n} = \\{i\\in \\{1,\\dots,n\\}: a_i \\in [z, z+1)\\}$ and $q_{z,n} = \\#Q_{z,n}$. Then\n$\\sum_z q_{z,n} = n$ and\n\\[\n6An \\geq \\sum_{i,j=1}^n \\frac{1}{1 + (a_i-a_j)^2} \\geq \\sum_{z \\in \\ZZ} \\frac{1}{2} q_{z,n}^2.\n\\]\nIf exactly $k$ of the $q_{z,n}$ are nonzero, then $\\sum_{z \\in \\ZZ} q_{z,n}^2 \\geq n^2/k$ by Jensen's inequality\n(or various other methods), so we must have $k \\geq n/(6A)$. Then\n\\begin{align*}\n\\sum_{i,j=1}^n (1 + (a_i-a_j)^2) &\\geq\nn^2 + \\sum_{i,j=1}^k \\max\\{0, (|i-j|-1)^2\\} \\\\\n&\\geq\nn^2 + \\frac{k^4}{6}-\\frac{2k^3}{3}+\\frac{5k^2}{6}-\\frac{k}{3}.\n\\end{align*}\nThis is bounded below by $Bn^4$ for some $B>0$.\n\nIn the opposite direction, one can weaken the initial upper bound to $An^{4/3}$ and still\nderive a lower bound of $Bn^3$. The argument is similar."
  },
  {
    "year": 2011,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $p$ be an odd prime. Show that for at least $(p+1)/2$ values of $n$ in $\\{0,1,2,\\dots,p-1\\}$,\n\\[\n\\sum_{k=0}^{p-1} k! n^k \\qquad \\mbox{is not divisible by $p$.}\n\\]\n\n\\end{itemize}\n\n\\end{document}",
    "solution": "In order to interpret the problem statement, one must choose a convention for the value of $0^0$; we will take\nit to equal 1. (If one takes $0^0$ to be 0, then the problem fails for $p=3$.)\n\n\\textbf{First solution.}\nBy Wilson's theorem,\n\\[\nk! (p-1-k)! \\equiv (-1)^{k} (p-1)! \\equiv (-1)^{k+1} \\pmod{p},\n\\]\nso we have a congruence of Laurent polynomials\n\\begin{align*}\n\\sum_{k=0}^{p-1} k! x^k &\\equiv \\sum_{k=0}^{p-1} \\frac{(-1)^{k+1} x^k}{(p-1-k)!} \\pmod{p} \\\\\n&\\equiv -x^{p-1} \\sum_{k=0}^{p-1} \\frac{(-x)^{-k}}{k!} \\pmod{p}.\n\\end{align*}\nReplacing $x$ with $-1/x$, we reduce the original problem to showing that the polynomial\n\\[\ng(x) = \\sum_{k=0}^{p-1} \\frac{x^k}{k!}\n\\]\nover $\\FF_p$ has at most $(p-1)/2$ nonzero roots in $\\FF_p$. To see this, write\n\\[\nh(x) = x^p - x + g(x)\n\\]\nand note that by Wilson's theorem again,\n\\[\nh'(x) = 1 + \\sum_{k=1}^{p-1} \\frac{x^{k-1}}{(k-1)!} = x^{p-1} - 1 + g(x).\n\\]\nIf $z \\in \\FF_p$ is such that $g(z) = 0$, then $z \\neq 0$ because $g(0) = 1$.\nTherefore, $z^{p-1} = 1$, so $h(z) = h'(z) = 0$ and so $z$ is at least a double root of $h$.\nSince $h$ is a polynomial of degree $p$, there can be at most $(p-1)/2$ zeroes of $g$ in $\\FF_p$, as desired.\n\n\\noindent\n\\textbf{Second solution.} (By Noam Elkies)\nDefine the polynomial $f$ over $\\FF_p$ by\n\\[\nf(x) = \\sum_{k=0}^{p-1} k! x^k.\n\\]\nPut $t = (p-1)/2$; the problem statement is that $f$\nhas at most $t$ roots modulo $p$.\nSuppose the contrary; since $f(0) = 1$,\nthis means that $f(x)$ is nonzero for at most $t-1$ values of $x \\in \\FF_p^*$.\nDenote these values by $x_1,\\dots,x_m$, where by assumption $m < t$, and define the polynomial\n$Q$ over $\\FF_p$ by\n\\[\nQ(x) =\n\\prod_{k=1}^m (x - x_m) = \\sum_{k=0}^{t-1} Q_k x^k.\n\\]\nThen we can write\n\\[\nf(x) = \\frac{P(x)}{Q(x)} (1-x^{p-1})\n\\]\nwhere $P(x)$ is some polynomial of degree at most $m$.\nThis means that the power series expansions of $f(x)$ and $P(x)/Q(x)$ coincide modulo $x^{p-1}$,\nso the coefficients of $x^t, \\dots, x^{2t-1}$ in $f(x) Q(x)$ vanish.\nIn other words, the product of the square matrix\n\\[\nA = ((i+j+1)!)_{i,j=0}^{t-1}\n\\]\nwith the nonzero column vector $(Q_{t-1}, \\dots, Q_0)$ is zero.\nHowever, by the following lemma, $\\det(A)$ is nonzero modulo $p$, a contradiction.\n\n\\begin{lemma}\nFor any nonnegative integer $m$ and any integer $n$,\n\\[\n\\det((i+j+n)!)_{i,j=0}^m = \\prod_{k=0}^m k! (k+n)!.\n\\]\n\\end{lemma}\n\\begin{proof}\nDefine the $(m+1) \\times (m+1)$ matrix $A_{m,n}$ by $(A_{m,n})_{i,j} = \\binom{i+j+n}{i}$;\nthe desired result is then that $\\det(A_{m,n}) = 1$. Note that\n\\[\n(A_{m,n-1})_{ij} = \\begin{cases}\n(A_{m,n})_{ij} & i=0 \\\\\n(A_{m,n})_{ij} - (A_{m,n})_{(i-1)j} & i > 0;\n\\end{cases}\n\\]\nthat is, $A_{m,n-1}$ can be obtained from $A_{m,n}$ by elementary row operations.\nTherefore, $\\det(A_{m,n}) = \\det(A_{m,n-1})$, so $\\det(A_{m,n})$ depends only on $m$.\nThe claim now follows by observing that $A_{0,0}$ is the $1 \\times 1$ matrix with entry 1\nand that $A_{m,-1}$ has the block representation $\\begin{pmatrix} 1 & * \\\\ 0 & A_{m-1,0} \\end{pmatrix}$.\n\\end{proof}\n\n\\noindent\n\\textbf{Remark.}\nElkies has given a more detailed discussion of the origins of this solution in the theory of orthogonal\npolynomials; see \\texttt{http://mathoverflow.net/questions/82648}.\n\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2012,
    "label": "A1",
    "difficulty": "1",
    "problem": "Let $d_1, d_2, \\dots, d_{12}$ be real numbers in the open\ninterval $(1, 12)$. Show that there exist distinct indices $i, j, k$\nsuch that $d_i, d_j, d_k$ are the side lengths of an acute triangle.",
    "solution": "Without loss of generality, assume $d_1\\leq d_2\\leq \\cdots \\leq d_{12}$.\nIf $d_{i+2}^2 < d_i^2+d_{i+1}^2$ for some $i\\leq 10$, then\n$d_i,d_{i+1},d_{i+2}$ are the side lengths of an acute triangle, since\nin this case $d_i^2 < d_{i+1}^2+d_{i+2}^2$ and $d_{i+1}^2 <\nd_i^2+d_{i+2}^2$ as well. Thus we may assume $d_{i+2}^2 \\geq d_i^2 +\nd_{i+1}^2$ for all $i$. But then by induction, $d_i^2 \\geq F_i d_1^2$\nfor all $i$, where $F_i$ is the $i$-th Fibonacci number (with\n$F_1=F_2=1$): $i=1$ is clear, $i=2$ follows from $d_2\\geq d_1$, and the\ninduction step follows from the assumed inequality. Setting $i=12$ now\ngives $d_{12}^2 \\geq 144 d_1^2$, contradicting $d_1>1$ and $d_{12}<12$.\n\n\\noindent\n\\textbf{Remark.} A materially equivalent problem appeared on the 2012\nUSA Mathematical Olympiad and USA Junior Mathematical Olympiad."
  },
  {
    "year": 2012,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $*$ be a commutative and associative binary operation on a set $S$. Assume that for every $x$\nand $y$ in $S$, there exists $z$ in $S$ such that $x * z = y$. (This $z$ may depend on $x$ and $y$.)\nShow that if $a,b,c$ are in $S$ and $a*c = b*c$, then $a=b$.",
    "solution": "Write $d$ for $a * c = b * c \\in S$. For some $e\\in S$, $d * e = a$, and\nthus for $f = c * e$, $a * f = a * c * e = d * e = a$ and $b * f = b * c\n* e = d * e = a$. Let $g \\in S$ satisfy $g * a = b$; then $b = g * a = g\n* (a * f) = (g * a) * f = b * f = a$, as desired.\n\n\\noindent\n\\textbf{Remark.} With slightly more work, one can show that $S$ forms an abelian group\nwith the operation $*$."
  },
  {
    "year": 2012,
    "label": "A3",
    "difficulty": "3",
    "problem": "Let $f: [-1, 1] \\to \\RR$ be a continuous function such that\n\\begin{itemize}",
    "solution": "We will prove that $f(x) = \\sqrt{1-x^2}$ for all $x \\in [-1,1]$. Define\n$g :\\thinspace (-1,1) \\to \\mathbb{R}$ by\n$g(x) = f(x)/\\sqrt{1-x^2}$. Plugging $f(x) = g(x)\\sqrt{1-x^2}$ into\nequation (i) and simplifying yields\n\\begin{equation} \\label{eq:g}\ng(x) = g\\left(\\frac{x^2}{2-x^2}\\right)\n\\end{equation}\n  for all $x \\in (-1,1)$. Now fix $x \\in (-1,1)$ and define a sequence\n$\\{a_n\\}_{n=1}^\\infty$ by $a_1=x$ and $a_{n+1} = \\frac{a_n^2}{2-a_n^2}$.\nThen\n  $a_n \\in (-1,1)$ and thus $|a_{n+1}| \\leq |a_n|^2$ for all $n$. It\nfollows that $\\{|a_n|\\}$ is a decreasing sequence with $|a_n| \\leq\n|x|^n$ for all $n$, and so $\\lim_{n\\to\\infty} a_n = 0$. Since $g(a_n) =\ng(x)$ for all $n$ by \\eqref{eq:g} and $g$ is continuous at $0$, we\nconclude that $g(x) = g(0) = f(0) = 1$. This holds for all $x \\in\n(-1,1)$ and thus for $x=\\pm 1$ as well by continuity. The result follows.\n\n\\noindent\n\\textbf{Remark.} As pointed out by Noam Elkies, condition (iii) is unnecessary.\nHowever, one can use it to derive a slightly different solution by running the recursion\nin the opposite direction."
  },
  {
    "year": 2012,
    "label": "A4",
    "difficulty": "4",
    "problem": "Let $q$ and $r$ be integers with $q > 0$, and let $A$ and $B$ be intervals on the real line.\nLet $T$ be the set of all $b+mq$ where $b$ and $m$ are integers with $b$ in $B$,\nand let $S$ be the set of all integers $a$ in $A$ such that $ra$ is in $T$. Show that if the\nproduct of the lengths of $A$ and $B$ is less than $q$, then $S$ is the intersection of $A$\nwith some arithmetic progression.",
    "solution": "We begin with an easy lemma.\n\\setcounter{lemma}{0}\n\\begin{lemma*}\nLet $S$ be a finite set of integers with the following property: for all $a,b,c \\in S$ with\n$a \\leq b \\leq c$, we also have $a+c-b \\in S$. Then $S$ is an arithmetic progression.\n\\end{lemma*}\n\\begin{proof}\nWe may assume $\\# S \\geq 3$, as otherwise $S$ is trivially an arithmetic progression.\nLet $a_1, a_2$ be the smallest and second-smallest elements of $S$, respectively, and put\n$d = a_2 - a_1$. Let $m$ be the smallest positive integer such that $a_1 + md \\notin S$.\nSuppose that there exists an integer $n$ contained in $S$ but not in\n$\\{a_1, a_1 + d, \\dots, a_1 + (m-1)d\\}$, and choose the least such $n$.\nBy the hypothesis applied with $(a,b,c) = (a_1, a_2, n)$, we see that $n-d$ also has the property,\na contradiction.\n\\end{proof}\n\nWe now return to the original problem.\nBy dividing $B, q, r$ by $\\gcd(q,r)$ if necessary, we may reduce to the case where $\\gcd(q,r) = 1$.\nWe may assume $\\#S \\geq 3$, as otherwise $S$ is trivially an arithmetic progression.\nLet $a_1, a_2, a_3$ be any three distinct elements of $S$, labeled so that $a_1 < a_2 < a_3$,\nand write $ra_i = b_i + m_i q$ with $b_i, m_i \\in \\ZZ$ and $b_i \\in B$. Note that $b_1, b_2, b_3$ must also be distinct, so the differences $b_2 - b_1, b_3 - b_1, b_3 - b_2$ are all nonzero; consequently, two of them have the same sign. If $b_i - b_j$ and $b_k - b_l$ have the same sign, then\nwe must have\n\\[\n(a_i - a_j)(b_k - b_l) =  (b_i - b_j)(a_k - a_l)\n\\]\nbecause both sides are of the same sign, of absolute value less than $q$,\nand congruent to each other modulo $q$. In other words, the points $(a_1, b_1), (a_2, b_2), (a_3, b_3)$\nin $\\RR^2$ are collinear.\nIt follows that $a_4 = a_1 + a_3 - a_2$ also belongs to $S$ (by taking $b_4 = b_1 + b_3 - b_2$),\nso $S$ satisfies the conditions of the lemma. It is therefore an\narithmetic progression.\n\n\\noindent\n\\textbf{Reinterpretations.}\nOne can also interpret this argument geometrically using cross products (suggested by Noam Elkies),\nor directly in terms of congruences (suggested by Karl Mahlburg).\n\n\\noindent\n\\textbf{Remark.} The problem phrasing is somewhat confusing: to say that ``$S$ is the intersection of\n[the interval] $A$ with an arithmetic progression'' is the same thing as saying that ``$S$ is the empty set or an arithmetic progression'' unless it is implied that arithmetic progressions are necessarily infinite.\nUnder that interpretation, however, the problem becomes false; for instance, for\n\\[\nq=5, r=1, A = [1,3], B = [0,2],\n\\]\nwe have\n\\[\nT = \\{\\cdots, 0,1,2,5,6,7,\\dots\\}, S = \\{1,2\\}.\n\\]"
  },
  {
    "year": 2012,
    "label": "A5",
    "difficulty": "5",
    "problem": "Let $\\FF_p$ denote the field of integers modulo a prime $p$, and let $n$ be a positive integer.\nLet $v$ be a fixed vector in $\\FF_p^n$, let $M$ be an $n \\times n$ matrix with entries of $\\FF_p$,\nand define $G: \\FF_p^n \\to \\FF_p^n$ by $G(x) = v + Mx$. Let $G^{(k)}$ denote the $k$-fold\ncomposition of $G$ with itself, that is, $G^{(1)}(x) = G(x)$ and $G^{(k+1)}(x) = G(G^{(k)}(x))$.\nDetermine all pairs $p, n$ for which there exist $v$ and $M$ such that the $p^n$ vectors\n$G^{(k)}(0)$, $k=1,2,\\dots,p^n$ are distinct.",
    "solution": "The pairs $(p,n)$ with the specified property are those pairs with $n=1$, together with the single pair\n$(2,2)$. We first check that these do work. For $n=1$, it is clear that taking $v = (1)$ and $M = (0)$\nhas the desired effect. For $(p,n) = (2,2)$, we take $v = \\begin{pmatrix} 0 & 1 \\end{pmatrix}$\nand $M = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$ and then observe that\n\\[\nG^{(k)}(0) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix},\n\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix},\n\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix},\n\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\,\nk=0,1,2,3.\n\\]\nWe next check that no other pairs work, keeping in mind that the desired condition means that\n$G$ acts on $\\FF_p^n$ as a cyclic permutation. Assume by way of contradiction that $(p,n)$ has the desired\nproperty but does not appear in our list. In particular, we have $n \\geq 2$.\n\nLet $I$ be the $n \\times n$ identity matrix over $\\FF_p$.\nDecompose $\\FF_p^n$ as a direct sum of two subspaces $V,W$ such that\n$M-I$ is nilpotent on $V$ and invertible on $W$. Suppose that $W \\neq 0$.\nSplit $v$ as $v_1 + v_2$ with $v_1 \\in V$, $v_2 \\in W$. Since $M-I$ is invertible on $W$, there exists a\nunique $w \\in W$ such that $(M-I)w = -v_2$. Then $G^{(k)}(w) - w \\in V$ for all nonnegative integers $k$.\nLet $k$ be the least positive integer such that $G^{(k)}(w) = w$; then $k$ is at most the cardinality of $V$,\nwhich is strictly less than $p^n$ because $W \\neq 0$. This gives a contradiction and thus forces $W = 0$.\n\nIn other words, the matrix $N = M-I$ is nilpotent; consequently, $N^n = 0$.\nFor any positive integer $k$, we have\n\\begin{align*}\nG^{(k)}(0) &= v + Mv + \\cdots + M^{k-1}v \\\\\n&=  \\sum_{j=0}^{k-1}  \\sum_{i=0}^{n-1} \\binom{j}{i} N^i v \\\\\n&= \\sum_{i=0}^{n-1} \\binom{k}{i+1} N^i v.\n\\end{align*}\nIf $n \\geq 2$ and $(p,n) \\neq (2,2)$, then $p^{n-1} > n$ and so $G^{k}(0) = 0$ for $k = p^{n-1}$ (because all\nof the binomial coefficients are divisible by $p$). This contradiction\ncompletes the proof."
  },
  {
    "year": 2012,
    "label": "A6",
    "difficulty": "6",
    "problem": "Let $f(x,y)$ be a continuous, real-valued function on $\\RR^2$. Suppose that, for every\nrectangular region $R$ of area $1$, the double integral of $f(x,y)$ over $R$ equals $0$.\nMust $f(x,y)$ be identically 0?",
    "solution": "\\textbf{First solution.}\nYes, $f(x,y)$ must be identically 0. We proceed using a series of lemmas.\n\n\\setcounter{lemma}{0}\n\\begin{lemma}\nLet $R$ be a rectangular region of area $1$ with corners $A,B,C,D$ labeled in counterclockwise order. Then\n$f(A) + f(C) = f(B) + f(D)$.\n\\end{lemma}\n\\begin{proof}\nWe may choose coordinates so that for some $c>0$,\n\\[\nA = (0,0), B = (c,0), C = (c,1/c), D = (0, 1/c).\n\\]\nDefine the functions\n\\begin{align*}\ng(x,y) &= \\int_x^{x+c} f(t,y)\\,dt \\\\\nh(x,y) &= \\int_0^y g(x,u)\\,du.\n\\end{align*}\nFor any $x,y \\in \\RR$,\n\\[\nh(x,y+1/c) - h(x,y) = \\int_x^{x+c} \\int_y^{y+1/c} f(t,u)\\,dt\\,du = 0\n\\]\nby hypothesis, so $h(x,y+1/c) = h(x,y)$. By the fundamental theorem of calculus,\nwe may differentiate both sides of this identity with respect to $y$ to deduce that\n$g(x,y+1/c) = g(x,y)$. Differentiating this new identity with respect to $x$ yields the desired equality.\n\\end{proof}\n\n\\begin{lemma}\nLet $C$ be a circle whose diameter $d$ is at least $\\sqrt{2}$, and let $AB$ and $A'B'$ be two diameters of $C$. Then\n$f(A) + f(B) = f(A') + f(B')$.\n\\end{lemma}\n\\begin{proof}\nBy continuity, it suffices to check the case where $\\alpha = \\arcsin \\frac{2}{d^2}$\nis an irrational multiple of $2\\pi$.\nLet $\\beta$ be the radian measure of the counterclockwise arc from $A$ to $A'$.\nBy Lemma~1, the claim holds when $\\beta = \\alpha$. By induction, the claim also holds when $\\beta \\equiv n\\alpha\n\\pmod{2\\pi}$ for any positive integer $n$. Since $\\alpha$ is an irrational multiple of $2\\pi$, the positive multiples of $\\alpha$ fill out a dense subset of the real numbers modulo $2\\pi$,\nso by continuity the claim holds for all $\\beta$.\n\\end{proof}\n\n\\begin{lemma}\nLet $R$ be a rectangular region of arbitrary (positive) area with corners $A,B,C,D$ labeled in counterclockwise order. Then\n$f(A) + f(C) = f(B) + f(D)$.\n\\end{lemma}\n\\begin{proof}\nLet $EF$ be a segment such that $AEFD$ and $BEFC$ are rectangles whose diagonals have length at least $\\sqrt{2}$. By Lemma~2,\n\\begin{align*}\nf(A) + f(F) &= f(D) + f(E) \\\\\nf(C) + f(E) &= f(B) + f(F),\n\\end{align*}\nyielding the claim.\n\\end{proof}\n\n\\begin{lemma}\nThe restriction of $f$ to any straight line is constant.\n\\end{lemma}\n\\begin{proof}\nWe may choose coordinates so that the line in question is the $x$-axis.\nDefine the function $g(y)$ by\n\\[\ng(y) = f(0,y) - f(0,0).\n\\]\nBy Lemma~3, for all $x \\in \\RR$,\n\\[\nf(x,y) = f(x,0) + g(y).\n\\]\nFor any $c>0$, by the original hypothesis we have\n\\begin{align*}\n0 &= \\int_x^{x+c} \\int_y^{y+1/c} f(u,v)\\,du\\,dv \\\\\n&= \\int_x^{x+c} \\int_y^{y+1/c} (f(u,0) + g(v))\\,du\\,dv \\\\\n&= \\frac{1}{c} \\int_x^{x+c} f(u,0)\\,du + c \\int_y^{y+1/c} g(v)\\,dv.\n\\end{align*}\nIn particular, the function $F(x) = \\int_x^{x+c} f(u,0)\\,du$ is constant.\nBy the fundamental theorem of calculus, we may differentiate to conclude that\n$f(x+c,0) = f(x,0)$ for all $x \\in \\RR$. Since $c$ was also arbitrary, we deduce the claim.\n\\end{proof}\n\nTo complete the proof, note that\nsince any two points in $\\RR^2$ are joined by a straight line, Lemma~4 implies that $f$ is constant.\nThis constant equals the integral of $f$ over any rectangular region of area 1, and hence must be 0\nas desired.\n\n\\noindent\n\\textbf{Second solution} (by Eric Larson, communicated by Noam Elkies).\nIn this solution, we fix coordinates and\nassume only that the double integral vanishes on each rectangular region of area 1\nwith sides parallel to the coordinate axes, and still conclude that $f$ must be identically 0.\n\n\\setcounter{lemma}{0}\n\\begin{lemma*}\nLet $R$ be a rectangular region of area $1$ with sides parallel to the coordinate axes.\nThen the averages of $f$ over any two adjacent sides of $R$ are equal.\n\\end{lemma*}\n\\begin{proof}\nWithout loss of generality, we may take $R$ to have corners $(0, 0), (c,0), (c,1/c), (0,1/c)$ and consider\nthe two sides adjacent to $(c,1/c)$. Differentiate the equality\n\\[\n0 = \\int_x^{x+c} \\int_y^{y+1/c} f(u,v)\\,du\\,dv\n\\]\nwith respect to $c$ to obtain\n\\[\n0 = \\int_y^{y+1/c} f(x+c,v)\\,dv - \\frac{1}{c^2} \\int_x^{x+c} f(u,y+1/c)\\,du.\n\\]\nRearranging yields\n\\[\nc \\int_y^{y+1/c} f(x+c,v)\\,dv = \\frac{1}{c} \\int_x^{x+c} f(u,y+1/c)\\,du,\n\\]\nwhich asserts the desired result.\n\\end{proof}\n\nReturning to the original problem, given any $c>0$, we can tile the plane with rectangles of area 1 whose\nvertices lie in the lattice $\\{(mc, n/c): m,n \\in \\ZZ\\}$. By repeated application of the lemma,\nwe deduce that for any positive integer $n$,\n\\[\n\\int_0^c f(u,0)\\,du = \\int_{nc}^{(n+1)c} f(u,0)\\,du.\n\\]\nReplacing $c$ with $c/n$, we obtain\n\\[\n\\int_0^{c/n} f(u,0)\\,du = \\int_{c}^{c+1/n} f(u,0)\\,du.\n\\]\nFixing $c$ and taking the limit as $n \\to \\infty$ yields $f(0,0) = f(c,0)$. By similar reasoning,\n$f$ is constant on any horizontal line and on any vertical line, and as in the first solution the constant\nvalue is forced to equal 0.\n\n\\noindent\n\\textbf{Third solution.} (by Sergei Artamoshin) We retain the weaker hypothesis of the second solution. Assume by way of contradiction that $f$ is not identically zero.\n\nWe first exhibit a vertical segment $PQ$ with $f(P) > 0$ and $f(Q) < 0$.\nIt cannot be the case that $f(P) \\leq 0$ for all $P$, as otherwise the vanishing of the zero over any rectangle would force $f$ to vanish identically. By continuity, there must exist an open disc $U$ such that $f(P) > 0$ for all $P \\in U$. Choose a rectangle $R$ of area $1$ with sides parallel to the coordinate axes with one horizontal edge contained in $U$. Since the integral of $f$ over $R$ is zero, there must exist a point $Q \\in R$ such that $f(Q) < 0$. Take $P$ to be the vertical projection of $Q$ onto the edge of $R$ contained in $U$.\n\nBy translating coordinates, we may assume that $P = (0,0)$ and\n$Q = (0,a)$ for some $a>0$.\nFor $s$ sufficiently small, $f$ is positive on the square of side length $2s$ centered at $P$, which we call $S$, and negative on the square of side length $2s$ centered at $Q$, which we call $S'$. Since the ratio $2s/(1-4s^2)$ tends to 0 as $s$ does, we can choose $s$ so that\n$2s/(1-4s^2) = a/n$ for some positive integer $n$.\n\nFor $i \\in \\ZZ$, let $A_i$ be the rectangle\n\\begin{multline*}\n\\left\\{(x,y): s \\leq x \\leq s + \\frac{1-4s^2}{2s},\\right. \\\\\n\\qquad \\left. -s+i \\frac{2s}{1-4s^2} \\leq y \\leq s + i \\frac{2s}{1-4s^2} \\right\\}\n\\end{multline*}\nand let $B_i$ be the rectangle\n\\begin{multline*}\n\\left\\{(x,y): s \\leq x \\leq s + \\frac{1-4s^2}{2s}, \\right.  \\\\\n\\qquad \\left. s+i \\frac{2s}{1-4s^2} \\leq y \\leq -s + (i+1) \\frac{2s}{1-4s^2} \\right\\}.\n\\end{multline*}\nThen for all $i \\in \\ZZ$,\n\\[\nS \\cup A_0, A_n \\cup S', A_i \\cup B_i, B_i \\cup A_{i+1}\n\\]\nare all rectangles of area 1 with sides parallel to the coordinate axes,\nso the integral over $f$ over each of these rectangles is zero.\nSince the integral over $S$ is positive, the integral over $A_0$ must be negative; by induction, for all $i \\in \\ZZ$ the integral over $A_i$ is negative and the integral over $B_i$ is positive. But this forces the integral over $S'$ to be positive whereas $f$ is negative everywhere on $S'$, a contradiction."
  },
  {
    "year": 2012,
    "label": "B1",
    "difficulty": "1",
    "problem": "Let $S$ be a class of functions from $[0, \\infty)$ to $[0, \\infty)$ that satisfies:\n\\begin{itemize}",
    "solution": "Each of the following functions belongs to $S$ for the reasons indicated.\n\\begin{center}\n\\begin{tabular}{ll}\n$f(x), g(x)$ & given \\\\\n$\\ln(x+1)$ & (i) \\\\\n$\\ln(f(x)+1), \\ln(g(x)+1)$ & (ii) plus two previous lines\\\\\n$\\ln(f(x)+1) + \\ln(g(x)+1)$ & (ii) \\\\\n$e^x - 1$ & (i) \\\\\n$(f(x)+1)(g(x)+1) - 1$ & (ii) plus two previous lines \\\\\n$f(x)g(x) + f(x) + g(x)$ & previous line \\\\\n$f(x) + g(x)$ & (ii) plus first line \\\\\n$f(x) g(x)$ & (iii) plus two previous lines\n\\end{tabular}\n\\end{center}"
  },
  {
    "year": 2012,
    "label": "B2",
    "difficulty": "2",
    "problem": "Let $P$ be a given (non-degenerate) polyhedron. Prove that there is a constant $c(P) > 0$\nwith the following property: If a collection of $n$ balls whose volumes sum to $V$ contains\nthe entire surface of $P$, then $n > c(P) / V^2$.",
    "solution": "Fix a face $F$ of the polyhedron with area $A$. Suppose $F$ is completely covered by balls of radii\n$r_1, \\dots, r_n$ whose volumes sum to $V$. Then on one hand,\n\\[\n\\sum_{i=1}^n \\frac{4}{3} \\pi r_i^3 = V.\n\\]\nOn the other hand, the intersection of a ball of radius $r$ with the plane containing $F$ is a\ndisc of radius at most $r$, which covers a piece of $F$ of area at most $\\pi r^2$; therefore\n\\[\n\\sum_{i=1}^n \\pi r_i^2 \\geq A.\n\\]\nBy writing $n$ as $\\sum_{i=1}^n 1$ and applying H\\\"older's inequality,\nwe obtain\n\\[\nn V^2 \\geq \\left( \\sum_{i=1}^n \\left( \\frac{4}{3} \\pi r_i^3 \\right)^{2/3} \\right)^3\n\\geq \\frac{16}{9\\pi} A^3.\n\\]\nConsequently, any value of $c(P)$ less than $\\frac{16}{9\\pi} A^3$ works."
  },
  {
    "year": 2012,
    "label": "B3",
    "difficulty": "3",
    "problem": "A round-robin tournament of $2n$ teams lasted for $2n-1$ days, as follows.\nOn each day, every team played one game against another team, with one team winning\nand one team losing in each of the $n$ games. Over the course of the tournament,\neach team played every other team exactly once. Can one necessarily choose\none winning team from each day without choosing any team more than once?",
    "solution": "The answer is yes. We first note that for any collection of $m$\ndays with $1\\leq m\\leq 2n-1$, there are at least $m$ distinct teams that\nwon a game on at least one of those days. If not, then any of the teams\nthat lost games on all of those days must in particular have lost to $m$\nother teams, a contradiction.\n\nIf we now construct a bipartite graph whose vertices are the $2n$ teams\nand the $2n-1$ days, with an edge linking a day to a team if that team\nwon their game on that day, then any collection of $m$ days is connected\nto a total of at least $m$ teams. It follows from Hall's Marriage Theorem\nthat one can match the $2n-1$ days with $2n-1$ distinct teams that won on\ntheir respective days, as desired."
  },
  {
    "year": 2012,
    "label": "B4",
    "difficulty": "4",
    "problem": "Suppose that $a_0 = 1$ and that $a_{n+1} = a_n + e^{-a_n}$ for $n=0,1,2,\\dots$. Does $a_n - \\log n$\nhave a finite limit as $n \\to \\infty$? (Here $\\log n = \\log_e n = \\ln n$.)",
    "solution": "\\textbf{First solution.}\nWe will show that the answer is yes. First note that for all $x>-1$,\n$e^x \\geq 1+x$ and thus\n\\begin{equation} \\label{eq:log}\nx \\geq \\log(1+x).\n\\end{equation}\nWe next claim that $a_n > \\log(n+1)$ (and in particular that $a_n-\\log\nn > 0$) for all $n$, by induction on $n$. For $n=0$ this follows\nfrom $a_0=1$. Now suppose that $a_n > \\log(n+1)$, and define $f(x)\n= x+e^{-x}$, which is an increasing function in $x>0$; then\n\\begin{align*}\na_{n+1} &= f(a_n) > f(\\log(n+1)) \\\\\n&= \\log(n+1) + 1/(n+1) \\geq \\log(n+2),\n\\end{align*}\nwhere the last inequality is \\eqref{eq:log} with $x=1/(n+1)$. This completes\nthe induction step.\n\nIt follows that $a_n-\\log n$ is a decreasing function in $n$: we have\n\\begin{align*}\n&(a_{n+1} - \\log(n+1)) - (a_n - \\log n) \\\\\n&\\,= e^{-a_n} + \\log(n/(n+1)) \\\\\n&\\,< 1/(n+1) + \\log(n/(n+1)) \\leq 0,\n\\end{align*}\nwhere the final inequality is \\eqref{eq:log} with $x = -1/(n+1)$. Thus\n$\\{a_n-\\log n\\}_{n=0}^\\infty$ is a decreasing sequence of positive numbers,\nand so it has a limit as $n\\to\\infty$.\n\n\\noindent\n\\textbf{Second solution.}\nPut $b_n = e^{a_n}$, so that $b_{n+1} = b_n e^{1/b_n}$.  In terms of the\n$b_n$, the problem is to prove that $b_n/n$ has a limit as $n \\to \\infty$;\nwe will show that the limit is in fact equal to 1.\n\nExpanding $e^{1/b_n}$ as a Taylor series in $1/b_n$, we have\n\\[\nb_{n+1} = b_n + 1 + R_n\n\\]\nwhere $0 \\leq R_n \\leq c/b_n$ for some absolute constant $c>0$.\nBy writing\n\\[\nb_n = n+e + \\sum_{i=0}^{n-1} R_i,\n\\]\nwe see first that $b_n \\geq n+e$. We then see that\n\\begin{align*}\n0 &\\leq \\frac{b_n}{n} - 1 \\\\\n&\\leq \\frac{e}{n} + \\sum_{i=0}^{n-1} \\frac{R_i}{n}  \\\\\n&\\leq \\frac{e}{n} + \\sum_{i=0}^{n-1} \\frac{c}{n b_i}  \\\\\n&\\leq \\frac{e}{n} + \\sum_{i=0}^{n-1} \\frac{c}{n (i+e)}  \\\\\n&\\leq \\frac{e}{n} + \\frac{c \\log n}{n}.\n\\end{align*}\nIt follows that $b_n/n \\to 1$ as $n \\to \\infty$.\n\n\\noindent\n\\textbf{Remark.}\nThis problem is an example of the general principle that one can often predict the asymptotic behavior of a recursive\nsequence by studying solutions of a sufficiently similar-looking differential equation. In this case, we\nstart with the equation $a_{n+1} - a_n = e^{-a_n}$, then replace $a_n$ with a function $y(x)$\nand replace the difference $a_{n+1} - a_n$ with the derivative $y'(x)$ to obtain the differential equation\n$y' = e^{-y}$, which indeed has the solution $y = \\log x$."
  },
  {
    "year": 2012,
    "label": "B5",
    "difficulty": "5",
    "problem": "Prove that, for any two bounded functions $g_1, g_2: \\RR \\to [1, \\infty)$,\nthere exist functions $h_1, h_2: \\RR \\to \\RR$ such that, for every $x \\in \\RR$,\n\\[\n\\sup_{s \\in \\RR} (g_1(s)^x g_2(s))  = \\max_{t \\in \\RR} (x h_1(t) + h_2(t)).\n\\]",
    "solution": "Define the function\n\\[\nf(x) = \\sup_{s \\in \\RR} \\{x \\log g_1(s) + \\log g_2(s)\\}.\n\\]\nAs a function of $x$, $f$ is the supremum of a collection of affine functions, so it is convex.\nThe function $e^{f(x)}$ is then also convex, as may be checked directly from the definition:\nfor $x_1, x_2 \\in \\RR$ and $t \\in [0,1]$, by the weighted AM-GM inequality\n\\begin{align*}\nt e^{f(x_1)} + (1-t) e^{f(x_2)}&\\geq e^{t f(x_1) + (1-t)f(x_2)} \\\\\n&\\geq e^{f(t x_1 + (1-t)x_2)}.\n\\end{align*}\nFor each $t \\in \\RR$, draw a supporting line to the graph of $e^{f(x)}$ at $x=t$;\nit has the form $y = x h_1(t) + h_2(t)$ for some $h_1(t), h_2(t) \\in \\RR$. For all $x$, we then have\n\\[\n\\sup_{s \\in \\RR} \\{g_1(s)^x g_2(s) \\} \\geq x h_1(t) + h_2(t)\n\\]\nwith equality for $x = t$. This proves the desired equality (including the fact that the maximum on the right side is achieved).\n\n\\noindent\n\\textbf{Remark.}\nThis problem demonstrates an example of \\emph{duality} for convex functions."
  },
  {
    "year": 2012,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $p$ be an odd prime number such that $p \\equiv 2 \\pmod{3}$. Define a permutation $\\pi$ of the\nresidue classes modulo $p$ by $\\pi(x) \\equiv x^3 \\pmod{p}$. Show that $\\pi$ is an even permutation\nif and only if $p \\equiv 3 \\pmod{4}$.\n\n\\end{itemize}\n\n\\end{document}",
    "solution": "\\textbf{First solution.}\nSince fixed points do not affect the signature of a permutation, we may\nignore the residue class of $0$ and consider $\\pi$ as a permutation on the\nnonzero residue classes modulo $p$. These form a cyclic group of order $p-1$,\nso the signature of $\\pi$ is also the signature of multiplication by 3 as\na permutation $\\sigma$ of the residue classes modulo $p-1$. If we identify\nthese classes with the integers $0,\\dots,p-2$, then the signature equals\nthe parity of the number of \\emph{inversions}: these are the pairs $(i,j)$\nwith $0 \\leq i < j \\leq p-2$ for which $\\sigma(i) > \\sigma(j)$. We may write\n\\[\n\\sigma(i) = 3i - (p-1) \\left\\lfloor \\frac{3i}{p-1} \\right\\rfloor\n\\]\nfrom which we see that $(i,j)$ cannot be an inversion unless $\\lfloor \\frac{3j}{p-1} \\rfloor > \\lfloor \\frac{3i}{p-1} \\rfloor$. In particular, we only obtain inversions when $i < 2(p-1)/3$.\n\nIf $i < (p-1)/3$, the elements $j$ of $\\{0,\\dots,p-2\\}$ for which $(i,j)$ is an inversion correspond to the elements of $\\{0,\\dots,3i\\}$ which are not multiples of $3$, which are $2i$ in number.\nThis contributes a total of $0 + 2 + \\cdots + 2(p-2)/3 = (p-2)(p+1)/9$ inversions.\n\nIf $(p-1)/3 < i < 2(p-1)/3$, the elements $j$ of $\\{0,\\dots,p-2\\}$ for which $(i,j)$ is an inversion correspond\nto the elements of $\\{0, \\dots, 3i-p+1\\}$ congruent to 1 modulo 3, which are\n$(3i-p+2)/3 = i - (p-2)/3$ in number. This contributes a total of\n$1 + \\cdots + (p-2)/3 = (p-2)(p+1)/18$ inversions.\n\nSumming up, the total number of inversions is $(p-2)(p+1)/6$, which is even if and only if\n$p \\equiv 3 \\pmod{4}$. This proves the claim.\n\n\\noindent\n\\textbf{Second solution} (by Noam Elkies).\nRecall that the sign of $\\pi$ (which is $+1$ if $\\pi$ is even and $-1$ if $\\pi$ is odd)\ncan be computed as\n\\[\n\\prod_{0 \\leq x < y < p} \\frac{\\pi(x) - \\pi(y)}{x - y}\n\\]\n(because composing $\\pi$ with a transposition changes the sign of the product).\nReducing modulo $p$, we get a congruence with\n\\[\n\\prod_{0 \\leq x < y < p} \\frac{x^3-y^3}{x-y} = \\prod_{0 \\leq x < y < p} (x^2 + xy + y^2).\n\\]\nIt thus suffices to count the number of times each possible value of $x^2+xy+y^2$ occurs.\nEach nonzero value $c$ modulo $p$ occurs $p+1$ times as $x^2+xy+y^2$ with $0 \\leq x, y < p$\nand hence $(p + \\chi(c/3))/2$ times with $0 \\leq x < y < p$, where $\\chi$ denotes the quadratic character\nmodulo $p$. Since $p \\equiv 2 \\pmod{3}$, by the law of quadratic reciprocity we have\n$\\chi(-3) = +1$, so $\\chi(c/3) = \\chi(-c)$.\nIt thus remains to evaluate the product $\\prod_{c=1}^{p-1} c^{(p+\\chi(-c))/2}$ modulo $p$.\n\nIf $p \\equiv 3 \\pmod{4}$, this is easy: each factor is a quadratic residue (this is clear if $c$ is a residue,\nand otherwise $\\chi(-c) = +1$ so $p+\\chi(-c)$ is divisible by $4$) and $-1$ is not, so we must get $+1$\nmodulo $p$.\n\nIf $p \\equiv 1 \\pmod{4}$, we must do more work: we\nchoose a primitive root $g$ modulo $p$ and rewrite the product as\n\\[\n\\prod_{i=0}^{p-2} g^{i(p+(-1)^i)/2}.\n\\]\nThe sum of the exponents, split into sums over $i$ odd and $i$ even, gives\n\\[\n\\sum_{j=0}^{(p-3)/2} \\left( j(p+1) + \\frac{(2j+1)(p-1)}{2}\\right)\n\\]\nwhich simplifies to\n\\[\n\\frac{(p-3)(p-1)(p+1)}{8} + \\frac{(p-1)^3}{8} = \\frac{p-1}{2} \\left( \\frac{p^2 - 1}{2} - p \\right).\n\\]\nHence the product we are trying to evaluate is congruent to $g^{(p-1)/2} \\equiv -1$ modulo $p$.\n\n\\noindent\n\\textbf{Third solution} (by Mark van Hoeij).\nWe compute the parity of $\\pi$ as the parity of the number of cycles of even length\nin the cycle decomposition of $\\pi$.\nFor $x$ a nonzero residue class modulo $p$ of multiplicative order $d$, the elements of the orbit of $x$\nunder $\\pi$ also have order $d$ (because $d$ divides $p-1$ and hence is coprime to $3$). Since the group\nof nonzero residue classes modulo $p$ is cyclic of order $p-1$, the elements of order $d$ fall into\n$\\varphi(d)/f(d)$ orbits under $\\pi$, where $\\varphi$ is the Euler phi function and $f(d)$ is the\nmultiplicative order of 3 modulo $d$. The parity of $\\pi$ is then the parity of the sum of $\\varphi(d)/f(d)$\nover all divisors $d$ of $p-1$ for which $f(d)$ is even.\n\nIf $d$ is odd, then $\\varphi(d)/f(d) = \\varphi(2d)/f(2d)$, so the summands corresponding to $d$ and $2d$\ncoincide. It thus suffices to consider those $d$ divisible by $4$. If $p \\equiv 3 \\pmod{4}$, then there are no\nsuch summands, so the sum is trivially even.\n\nIf $p \\equiv 1 \\pmod{4}$, then $d=4$ contributes a summand of $\\varphi(4)/f(4) = 2/2 = 1$.\nFor each $d$ which is a larger multiple of 4, the group $(\\ZZ/d\\ZZ)^*$ is isomorphic to the product of\n$\\ZZ/2\\ZZ$ with another group of even order, so the maximal power of 2 dividing $f(d)$ is strictly smaller\nthan the maximal power of 2 dividing $d$. Hence $\\varphi(d)/f(d)$ is even, and so the overall sum is odd.\n\n\\noindent\n\\textbf{Remark.}\nNote that the second proof uses quadratic reciprocity, whereas the first and third proofs are similar to several classical\nproofs of quadratic reciprocity. Abhinav Kumar notes that the problem itself is a special case\nof the Duke-Hopkins quadratic reciprocity law for abelian groups (Quadratic reciprocity in a finite group,\n\\textit{Amer. Math. Monthly} \\textbf{112} (2005), 251--256; see also\n\\url{http://math.uga.edu/~pete/morequadrec.pdf}).\n\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2013,
    "label": "A1",
    "difficulty": "1",
    "problem": "Recall that a regular icosahedron is a convex polyhedron\nhaving 12 vertices and 20 faces;\nthe faces are congruent equilateral triangles.\nOn each face of a regular icosahedron is written a nonnegative integer\nsuch that the sum of all 20 integers is 39. Show that there are \ntwo faces that share a vertex and have the same integer written on them.",
    "solution": "Suppose otherwise. Then each vertex $v$ is a vertex for five faces, all of which have different labels, and so the sum of the labels of the five faces incident to $v$ is at least $0+1+2+3+4 = 10$. Adding this sum over all vertices $v$ gives $3 \\times 39 = 117$, since each face's label is counted three times. Since there are $12$ vertices, we conclude that $10 \\times 12 \\leq 117$, contradiction.\n\n\\noindent\n\\textbf{Remark:}\nOne can also obtain the desired result by showing that any collection of five faces must contain two faces that share a vertex; it then follows that each label can appear at most $4$ times, and so the sum of all labels is at least $4(0+1+2+3+4) = 40 > 39$, contradiction."
  },
  {
    "year": 2013,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $S$ be the set of all positive integers that are \\emph{not} perfect squares. For $n$ in $S$, consider choices of integers\n$a_1, a_2, \\dots, a_r$ such that $n < a_1<  a_2 < \\cdots < a_r$\nand $n \\cdot a_1 \\cdot a_2 \\cdots a_r$ is a perfect square, and\nlet $f(n)$ be the minumum of $a_r$ over all such choices. For example,\n$2 \\cdot 3 \\cdot 6$ is a perfect square, while $2 \\cdot 3$, $2 \\cdot 4$, \n$2 \\cdot 5$, $2 \\cdot 3 \\cdot 4$, $2 \\cdot 3 \\cdot 5$, $2 \\cdot 4 \\cdot 5$, and $2 \\cdot 3 \\cdot 4 \\cdot 5$ are not, and so $f(2) = 6$.\nShow that the function $f$ from $S$ to the integers is one-to-one.",
    "solution": "Suppose to the contrary that $f(n) = f(m)$ with $n<m$, and let $n\\cdot a_1\\cdots a_r$, $m\\cdot b_1\\cdots b_s$ be perfect squares where $n < a_1 < \\cdots < a_r$, $m < b_1 < \\cdots < b_s$, $a_r,b_s$ are minimal and $a_r=b_s$. Then $(n\\cdot a_1\\cdots a_r)\\cdot (m\\cdot b_1\\cdots b_s)$ is also a perfect square. Now eliminate any factor in this product that appears twice (i.e., if $a_i = b_j$ for some $i,j$, then delete $a_i$ and $b_j$ from this product). The product of what remains must also be a perfect square, but this is now a product of distinct integers, the smallest of which is $n$ and the largest of which is strictly smaller than $a_r = b_s$. This contradicts the minimality of $a_r$.\n\n\\noindent\n\\textbf{Remark:}\nSequences whose product is a perfect square occur naturally in the \\emph{quadratic sieve} algorithm for factoring large integers. However,\nthe behavior of the function $f(n)$ seems to be somewhat erratic. \nKarl Mahlburg points out the upper bound $f(n) \\leq 2n$ for $n \\geq 5$, which holds because the interval $(n, 2n)$ contains an integer of the form $2m^2$. A trivial lower bound is $f(n) \\geq n+p$ where $p$ is the least prime factor of $n$. For $n = p$ prime, the bounds agree and we have $f(p) = 2p$. For more discussion, see \n\\url{https://oeis.org/A006255}."
  },
  {
    "year": 2013,
    "label": "A3",
    "difficulty": "3",
    "problem": "Suppose that the real numbers $a_0, a_1, \\dots, a_n$ and\n$x$, with $0 < x < 1$, satisfy\n\\[\n\\frac{a_0}{1-x} + \\frac{a_1}{1-x^2} + \\cdots + \\frac{a_n}{1 - x^{n+1}} = 0.\n\\]\nProve that there exists a real number $y$ with $0 < y < 1$ such that\n\\[\na_0 + a_1 y + \\cdots + a_n y^n = 0.\n\\]",
    "solution": "Suppose on the contrary that $a_0 + a_1 y + \\cdots + a_n y^n$ is nonzero for $0 < y < 1$. By the intermediate value theorem, this is only possible if $a_0 + a_1 y + \\cdots + a_n y^n$ has the same sign for $0 < y < 1$; without loss of generality, we may assume that $a_0 + a_1 y + \\cdots + a_n y^n > 0$ for $0 < y < 1$. For the given value of $x$, we then have\n\\[\na_0 x^m + a_1 x^{2m} + \\cdots + a_n x^{(n+1)m} \\geq 0\n\\]\nfor $m=0,1,\\dots$, with strict inequality for $m>0$.\nTaking the sum over all $m$ is absolutely convergent and hence valid; this yields\n\\[\n\\frac{a_0}{1-x} + \\frac{a_1}{1-x^2} + \\cdots + \\frac{a_n}{1-x^{n+1}} > 0,\n\\]\na contradiction."
  },
  {
    "year": 2013,
    "label": "A4",
    "difficulty": "4",
    "problem": "A finite collection of digits $0$ and $1$ is written around a circle.\nAn \\emph{arc} of length $L \\geq 0$ consists of $L$ consecutive digits around the circle. For each arc $w$, let $Z(w)$ and $N(w)$ denote the number of $0$'s in $w$ and the number of $1$'s in $w$, respectively.\nAssume that $\\left| Z(w) - Z(w') \\right| \\leq 1$ for any two arcs $w, w'$ of the same length. Suppose that some arcs $w_1,\\dots,w_k$ have the property that\n\\[\nZ = \\frac{1}{k} \\sum_{j=1}^k Z(w_j) \\mbox{ and }\nN = \\frac{1}{k} \\sum_{j=1}^k N(w_j)\n\\]\nare both integers. Prove that there exists an arc $w$ with $Z(w) = Z$\nand $N(w) = N$.",
    "solution": "Let $w_1',\\ldots,w_k'$ be arcs such that: $w_j'$ has the same length as $w_j$; $w_1'$ is the same as $w_1$; and $w_{j+1}'$ is adjacent to $w_j'$ (i.e., the last digit of $w_j'$ comes right before the first digit of $w_{j+1}'$). Since $w_j$ has length $Z(w_j)+N(w_j)$, the sum of the lengths of $w_1,\\ldots,w_k$ is $k(Z+N)$, and so the concatenation of $w_1',\\ldots,w_k'$ is a string of $k(Z+N)$ consecutive digits around the circle. (This string may wrap around the circle, in which case some of these digits may appear more than once in the string.) Break this string into $k$ arcs $w_1'',\\ldots,w_k''$ each of length $Z+N$, each adjacent to the previous one. (Note that if the number of digits around the circle is $m$, then $Z+N \\leq m$ since $Z(w_j)+N(w_j) \\leq m$ for all $j$, and thus each of $w_1'',\\ldots,w_k''$ is indeed an arc.)\n\nWe claim that for some $j=1,\\ldots,k$, $Z(w_j'')=Z$ and $N(w_j'')=N$ (where the second equation follows from the first since $Z(w_j'')+N(w_j'')=Z+N$). Otherwise, since all of the $Z(w_j'')$ differ by at most $1$, either $Z(w_j'') \\leq Z-1$ for all $j$ or $Z(w_j'') \\geq Z+1$ for all $j$. In either case,\n$|kZ - \\sum_j Z(w_j')| = |kZ-\\sum_j Z(w_j'')| \\geq k$. But since $w_1=w_1'$, we have\n$|kZ - \\sum_j Z(w_j')| = |\\sum_{j=1}^k (Z(w_j)-Z(w_j'))| = |\\sum_{j=2}^k (Z(w_j)-Z(w_j'))| \\leq \\sum_{j=2}^k |Z(w_j)-Z(w_j')| \\leq k-1$, contradiction."
  },
  {
    "year": 2013,
    "label": "A5",
    "difficulty": "5",
    "problem": "For $m \\geq 3$, a list of $\\binom{m}{3}$ real numbers $a_{ijk}$ ($1 \\leq i < < j < k \\leq m$) is said to be \\emph{area definite} for $\\mathbb{R}^n$ if the inequality\n\\[\n\\sum_{1 \\leq i < j < k \\leq m} a_{ijk} \\cdot \\mathrm{Area}(\\Delta A_i A_j A_k) \\geq 0\n\\]\nholds for every choice of $m$ points $A_1,\\dots,A_m$ in $\\mathbb{R}^n$.\nFor example, the list of four numbers $a_{123} = a_{124} = a_{134} = 1$, $a_{234} = -1$ is area definite for $\\mathbb{R}^2$. Prove that if a list of $\\binom{m}{3}$ numbers is area definite for $\\mathbb{R}^2$,\nthen it is area definite for $\\mathbb{R}^3$.",
    "solution": "Let $A_1,\\ldots,A_m$ be points in $\\mathbb{R}^3$, and let $\\hat{n}_{ijk}$ denote a unit vector normal to $\\Delta A_iA_jA_k$ (unless $A_i,A_j,A_k$ are collinear, there are two possible choices for $\\hat{n}_{ijk}$). If $\\hat{n}$ is a unit vector in $\\mathbb{R}^3$, and $\\Pi_{\\hat{n}}$ is a plane perpendicular to $\\hat{n}$, then the area of the orthogonal projection of $\\Delta A_iA_jA_k$ onto $\\Pi_{\\hat{n}}$ is $\\text{Area}(\\Delta A_iA_jA_k) |\\hat{n}_{ijk} \\cdot \\hat{n}|$. Thus if $\\{a_{ijk}\\}$ is area definite for $\\mathbb{R}^2$, then for any $\\hat{n}$,\n\\[\n\\sum a_{ijk} \\text{Area}(\\Delta A_iA_jA_k) |\\hat{n}_{ijk} \\cdot \\hat{n}| \\geq 0.\n\\]\nNote that integrating $|\\hat{n}_{ijk} \\cdot \\hat{n}|$ over $\\hat{n} \\in S^2$, the unit sphere in $\\mathbb{R}^3$, with respect to the natural measure on $S^2$ gives a positive number $c$, which is independent of $\\hat{n}_{ijk}$ since the measure on $S^2$ is rotation-independent. Thus integrating the above inequality over $\\hat{n}$ gives\n$c \\sum a_{ijk} \\text{Area}(\\Delta A_iA_jA_k) \\geq 0$. It follows that $\\{a_{ijk}\\}$ is area definite for $\\mathbb{R}^3$, as desired. \n\n\\noindent\n\\textbf{Remark:}\nIt is not hard to check (e.g., by integration in spherical coordinates) that the constant $c$ occurring above is equal to $2\\pi$. It follows that for any convex body $C$ in $\\mathbb{R}^3$, the average over $\\hat{n}$ of the area of the projection of $C$ onto $\\Pi_{\\hat{n}}$ equals $1/4$ of the surface area of $C$. \n\nMore generally, let $C$ be a convex body in $\\mathbb{R}^n$.\nFor $\\hat{n}$ a unit vector, let $\\Pi_{\\hat{n}}$ denote the hyperplane through the origin perpendicular to $\\hat{n}$. Then the average over $\\hat{n}$ of the volume of the projection of $C$ onto $\\Pi_{\\hat{n}}$ equals a constant (depending only on $n$) times the $(n-1)$-dimensional surface area of $C$. \n\nStatements of this form inhabit the field of \\emph{inverse problems}, in which one attempts to reconstruct information about a geometric object from low-dimensional samples. This field has important applications in imaging and tomography."
  },
  {
    "year": 2013,
    "label": "A6",
    "difficulty": "6",
    "problem": "Define a function $w: \\mathbb{Z} \\times \\mathbb{Z} \\to \\mathbb{Z}$\nas follows. For $\\left| a \\right|, \\left| b \\right| \\leq 2$,\nlet $w(a,b)$ be as in the table shown; otherwise, let $w(a,b) = 0$.\n\\begin{center}\n\\begin{tabular}{|cc|r|r|r|r|r|}\n\\hline\n\\multicolumn{2}{|c|}{\\multirow{2}{*}{$w(a,b)$}} & \\multicolumn{5}{|c|}{$b$} \\\\\n&  & -2 & -1 & 0 & 1 & 2 \\\\\n\\hline\n& -2 & -1 & -2 & 2 & -2 & -1 \\\\\n& -1 & -2 & 4 & -4 & 4 & -2 \\\\\n$a$ & 0 & 2 & -4 & 12 & -4 & 2 \\\\\n& 1 & -2 & 4 & -4 & 4 & -2 \\\\ \n& 2 &  -1 & -2 & 2 & -2 & -1 \\\\\n\\hline\n\\end{tabular}\n\\end{center}\nFor every finite subset $S$ of $\\mathbb{Z} \\times \\mathbb{Z}$,\ndefine\n\\[\nA(S) = \\sum_{(\\mathbf{s}, \\mathbf{s}') \\in S \\times S} w(\\mathbf{s} - \\mathbf{s}').\n\\]\nProve that if $S$ is any finite nonempty subset of $\\mathbb{Z} \\times \\mathbb{Z}$, then $A(S) > 0$.\n(For example, if $S = \\{(0,1), (0,2), (2,0), (3,1)\\}$, then the terms in $A(S)$ are $12, 12, 12, 12, 4, 4, 0, 0, 0,0,-1,-1,-2,-2,-4,-4$.)",
    "solution": "(by Harm Derksen)\nConsider the generating functions\n\\begin{align*}\nf(x,y) &= \\sum_{(a,b) \\in S} x^a y^b, \\\\\ng(x,y) &= \\sum_{(a,b) \\in \\mathbb{Z}^2} w(a,b) x^a y^b.\n\\end{align*}\nThen $A(S)$ is the constant coefficient of the Laurent polynomial\n$h(x,y) = f(x,y) f(x^{-1}, y^{-1}) g(x,y)$. We may compute this coefficient by averaging over unit circles:\n\\begin{align*}\n(2 \\pi)^2 A(S) &= \\int_0^{2\\pi} \\int_0^{2\\pi} h(e^{is}, e^{it})\\,dt\\,ds \\\\\n&= \\int_0^{2\\pi} \\int_0^{2\\pi} \\left| f(e^{is}, e^{it}) \\right|^2 g(e^{is}, e^{it}) \\,dt\\,ds.\n\\end{align*}\nConsequently, it is enough to check that $g(e^{is}, e^{it})$ is a nonnegative real number for all $s,t \\in \\mathbb{R}$. But\n$g(e^{is}, e^{it}) = 16 G(\\cos s,\\cos t)$ for\n\\[\nG(z,w) = zw + z^2 + w^2 - z^2 w - zw^2 - z^2w^2.\n\\]\nIf $z,w \\in [-1,1]$ and $zw \\geq 0$, then\n\\[\nG(z,w) = zw(1-zw) + z^2(1-w) + w^2(1-z) \\geq 0.\n\\]\nIf $z,w \\in [-1,1]$ and $zw \\leq 0$, then\n\\[\nG(z,w) = (z+w)^2 - zw(1+z)(1+w) \\geq 0.\n\\]\nHence $g(e^{is},e^{it}) \\geq 0$ as desired."
  },
  {
    "year": 2013,
    "label": "B1",
    "difficulty": "1",
    "problem": "For positive integers $n$, let the numbers $c(n)$ be determined by \nthe rules $c(1) = 1$, $c(2n) = c(n)$, and $c(2n+1) = (-1)^n c(n)$.\nFind the value of \n\\[\n\\sum_{n=1}^{2013} c(n) c(n+2).\n\\]",
    "solution": "Note that \n\\begin{align*}\nc(2k+1)c(2k+3) &= (-1)^k c(k) (-1)^{k+1} c(k+1) \\\\\n&= -c(k)c(k+1) \\\\ \n&= -c(2k)c(2k+2).\n\\end{align*}\nIt follows that $\\sum_{n=2}^{2013} c(n)c(n+2) = \\sum_{k=1}^{1006} (c(2k)c(2k+2)+c(2k+1)c(2k+3)) = 0$,\nand so the desired sum is $c(1)c(3) = -1$. \n\n\\textbf{Remark}: Karl Mahlburg points out the general formula\n$c(n) = (-1)^{b_0 b_1 + b_1 b_2 + \\dots + b_{k-1} b_k}$\nfor $n$ having binary representation $b_k \\cdots b_0$."
  },
  {
    "year": 2013,
    "label": "B2",
    "difficulty": "2",
    "problem": "Let $C = \\bigcup_{N=1}^\\infty C_N$, where $C_N$ denotes the set of those `cosine polynomials' of the form\n\\[\nf(x) = 1 + \\sum_{n=1}^N a_n \\cos(2 \\pi n x)\n\\]\nfor which:\n\\begin{enumerate}",
    "solution": "We claim that the maximum value of $f(0)$ is $3$. This is attained for\n$N=2$, $a_1=\\frac{4}{3}$, $a_2=\\frac{2}{3}$: in this case $f(x) = 1+\\frac{4}{3} \\cos(2\\pi x)+\\frac{2}{3} \\cos(4\\pi x) =\n1+\\frac{4}{3} \\cos(2\\pi x)+\\frac{2}{3}(2\\cos^2(2\\pi x)-1) = \\frac{1}{3} (2\\cos(2\\pi x)+1)^2$ is always nonnegative.\n\nNow suppose that $f = 1 + \\sum_{n=1}^N a_n \\cos(2\\pi nx) \\in C$. When $n$ is an integer, $\\cos(2\\pi n/3)$ equals $0$ if $3|n$ and $-1/2$ otherwise. Thus $a_n \\cos(2\\pi n/3) = -a_n/2$ for all $n$, and\n$f(1/3) = 1-\\sum_{n=1}^N (a_n/2)$. Since $f(1/3) \\geq 0$, $\\sum_{n=1}^N a_n \\leq 2$, whence $f(0) = 1 + \\sum_{n=1}^N a_n \\leq 3$."
  },
  {
    "year": 2013,
    "label": "B3",
    "difficulty": "3",
    "problem": "Let $\\mathcal{P}$ be a nonempty collection of subsets of $\\{1,\\dots, n\\}$ such that:\n\\begin{enumerate}",
    "solution": "Yes, such numbers must exist. To define them, we make the following observations.\n\n\\setcounter{lemma}{0}\n\\begin{lemma}\nFor any $i \\in \\{1,\\dots,n\\}$, if there exists any $S \\in P$ containing $i$, then there exist $S,T \\in P$ such that $S$ is the disjoint union of $T$ with $\\{i\\}$.\n\\end{lemma}\n\\begin{proof}\nLet $S$ be an element of $P$ containing $i$ of minimum cardinality.\nBy (ii), there must be a subset $T \\subset S$ containing $P$ with exactly one fewer element than $S$. These sets have the desired form.\n\\end{proof}\n\n\\begin{lemma}\nSuppose $S_1, S_2, T_1, T_2 \\in P$ have the property that for some $i \\in \\{1,\\dots,n\\}$, $S_1$ is the disjoint union of $T_1$ with $\\{i\\}$ and $S_2$ is the disjoint union of $T_2$ with $\\{i\\}$. Then \n\\[\nf(S_1) - f(T_1) = f(S_2) - f(T_2).\n\\]\n\\end{lemma}\n\\begin{proof}\nBy (i) we have\n\\begin{align*}\nf(T_1 \\cup T_2 \\cup \\{i\\}) &= f(S_1) + f(T_2) - f(T_1 \\cap T_2) \\\\\nf(T_1 \\cup T_2 \\cup \\{i\\}) &= f(T_1) + f(S_2) - f(T_1 \\cap T_2),\n\\end{align*}\nfrom which the claim follows immediately.\n\\end{proof}\n\nWe now define $f_1,\\dots,f_n$ as follows. If $i$ does not appear in any element of $P$, we put $f_i = 0$. Otherwise, by Lemma~1, we can find \n$S, T \\in P$ such that $S$ is the disjoint union of $T$ with $\\{i\\}$. We then set $f_i = f(S) - f(T)$; by Lemma~2, this does not depend on the choice of $S,T$.\n\nTo check that $f(S) = \\sum_{i \\in S} f_i$ for $S \\in P$, note first that $\\emptyset \\in P$ by repeated application of (ii) and that $f(\\emptyset) = 0$ by hypothesis. This provides the base case for an induction on the cardinality of $S$; for any nonempty $S \\in P$, we may apply (ii) to find $T \\subset S$ such that $S$ is the disjoint union of $T$ and some singleton set $\\{j\\}$. By construction and the induction hypothesis, we have $f(S) = f(T) + f_j = j + \\sum_{i \\in T} f_i = \\sum_{i \\in S} f_i$ as desired."
  },
  {
    "year": 2013,
    "label": "B4",
    "difficulty": "4",
    "problem": "For any continuous real-valued function $f$ defined on the interval $[0,1]$, let\n\\begin{gather*}\n\\mu(f) = \\int_0^1 f(x)\\,dx, \\,\n\\mathrm{Var}(f) = \\int_0^1 (f(x) - \\mu(f))^2\\,dx, \\\\\nM(f) = \\max_{0 \\leq x \\leq 1} \\left| f(x) \\right|.\n\\end{gather*}\nShow that if $f$ and $g$ are continuous real-valued functions\ndefined on the interval $[0,1]$,\nthen\n\\[\n\\mathrm{Var}(fg) \\leq 2 \\mathrm{Var}(f) M(g)^2 + 2 \\mathrm{Var}(g) M(f)^2.\n\\]",
    "solution": "\\newcommand{\\Var}{\\mathrm{Var}}\n\nWrite $f_0(x) = f(x)-\\mu(f)$ and $g_0(x) = g(x)-\\mu(g)$, so that $\\int_0^1 f_0(x)^2\\,dx = \\Var(f)$, $\\int_0^1 g_0(x)^2\\,dx = \\Var(g)$, and $\\int_0^1 f_0(x)\\,dx = \\int_0^1 g_0(x)\\,dx = 0$. Now since $|g(x)| \\leq M(g)$ for all $x$, $0\\leq \\int_0^1 f_0(x)^2(M(g)^2-g(x)^2)\\,dx = \\Var(f) M(g)^2-\\int_0^1 f_0(x)^2g(x)^2\\,dx$, and similarly $0 \\leq \\Var(g)M(f)^2-\\int_0^1 f(x)^2g_0(x)^2\\,dx$. Summing gives\n\\begin{equation}\n\\Var(f)M(g)^2+\\Var(g)M(f)^2\n\\label{eq:1}\n\\geq \\int_0^1 (f_0(x)^2g(x)^2+f(x)^2g_0(x)^2)\\,dx.\n\\end{equation}\nNow\n\\begin{align*}\n&\\int_0^1 (f_0(x)^2g(x)^2+f(x)^2g_0(x)^2)\\,dx-\\Var(fg) \\\\&= \\int_0^1 (f_0(x)^2g(x)^2+f(x)^2g_0(x)^2-(f(x)g(x)-\\int_0^1 f(y)g(y)\\,dy)^2)\\,dx;\n\\end{align*}\nsubstituting $f_0(x)+\\mu(f)$ for $f(x)$ everywhere and $g_0(x)+\\mu(g)$ for $g(x)$ everywhere, and using the fact that $\\int_0^1 f_0(x)\\,dx = \\int_0^1 g_0(x)\\,dx = 0$, we can expand and simplify the right hand side of this equation to obtain\n\\begin{align*}\n&\\int_0^1 (f_0(x)^2g(x)^2+f(x)^2g_0(x)^2)\\,dx-\\Var(fg) \\\\\n&= \\int_0^1 f_0(x)^2g_0(x)^2\\,dx \\\\\n&-2\\mu(f)\\mu(g)\\int_0^1 f_0(x)g_0(x)\\,dx +(\\int_0^1 f_0(x)g_0(x)\\,dx)^2 \\\\\n&\\geq -2\\mu(f)\\mu(g)\\int_0^1 f_0(x)g_0(x)\\,dx.\n\\end{align*}\nBecause of \\eqref{eq:1}, it thus suffices to show that\n\\begin{equation}\n2\\mu(f)\\mu(g)\\int_0^1 f_0(x)g_0(x)\\,dx\n\\label{eq:3} \\leq \\Var(f)M(g)^2+\\Var(g)M(f)^2.\n\\end{equation}\nNow since $(\\mu(g) f_0(x)-\\mu(f) g_0(x))^2 \\geq 0$ for all $x$, we have\n\\begin{align*}\n2\\mu(f)\\mu(g) \\int_0^1 f_0(x)g_0(x)\\,dx\n& \\leq \\int_0^1 (\\mu(g)^2 f_0(x)^2 + \\mu(f)^2 g_0(x)^2) dx \\\\\n& = \\Var(f) \\mu(g)^2 + \\Var(g) \\mu(f)^2 \\\\\n& \\leq \\Var(f) M(g)^2 + \\Var(g) M(f)^2,\n\\end{align*}\nestablishing \\eqref{eq:3} and completing the proof."
  },
  {
    "year": 2013,
    "label": "B5",
    "difficulty": "5",
    "problem": "Let $X = \\{1, 2, \\dots, n\\}$, and let $k \\in X$. Show that there are exactly $k \\cdot n^{n-1}$ functions $f: X \\to X$ such that for every $x \\in X$ there is a $j \\geq 0$ such that $f^{(j)}(x) \\leq k$.\n[Here $f^{(j)}$ denotes the $j$\\textsuperscript{th} iterate of $f$, so that $f^{(0)}(x) = x$ and $f^{(j+1)}(x) = f(f^{(j)}(x))$.]",
    "solution": "\\setcounter{lemma}{0}\n\\textbf{First solution:}\nWe assume $n \\geq 1$ unless otherwise specified.\nFor $T$ a set and $S_1, S_2$ two subsets of $T$, we say that a function $f: T \\to T$ \\emph{iterates $S_1$ into $S_2$} if for each $x \\in S_1$, there is a $j \\geq 0$ such that $f^{(j)}(x) \\in S_2$.\n\n\\begin{lemma}\nFix $k \\in X$. Let $f,g: X \\to X$ be two functions such that $f$ iterates $X$ into $\\{1,\\dots,k\\}$ and $f(x) = g(x)$ for $x \\in \\{k+1,\\dots,n\\}$. Then $g$ also iterates $X$ into $\\{1,\\dots,k\\}$.\n\\end{lemma}\n\\begin{proof}\nFor $x \\in X$, by hypothesis there exists a nonnegative integer $j$ such that $f^{(j)}(x) \\in \\{1,\\dots,k\\}$. Choose the integer $j$ as small as possible; then $f^{(i)}(x) \\in \\{k+1,\\dots,n\\}$ for $0 \\leq i<j$. By induction on $i$, we have $f^{(i)}(x) = g^{(i)}(x)$ for $i=0,\\dots,j$, so in particular $g^{(j)}(x) \\in \\{1,\\dots,k\\}$. This proves the claim.\n\\end{proof}\n\nWe proceed by induction on $n-k$, the case $n-k=0$ being trivial.\nFor the induction step, we need only confirm that the number $x$ of functions $f: X \\to X$ which iterate $X$ into $\\{1,\\dots,k+1\\}$ but not into $\\{1,\\dots,k\\}$ is equal to $n^{n-1}$. These are precisely the functions for which there is a unique cycle $C$ containing only numbers in $\\{k+1,\\dots,n\\}$ and said cycle contains $k+1$. Suppose $C$ has length $\\ell \\in \\{1,\\dots,n-k\\}$. For a fixed choice of $\\ell$, we may choose the underlying set of $C$ in\n$\\binom{n-k-1}{\\ell-1}$ ways and the cycle structure in $(\\ell-1)!$ ways. Given $C$, the functions $f$ we want are the ones that act on $C$ as specified and iterate $X$ into\n$\\{1,\\dots,k\\} \\cup C$.\nBy Lemma~1, the number of such functions is\n$n^{-\\ell}$ times the total number of functions that iterate $X$ into\n$\\{1,\\dots,k\\} \\cup C$.\nBy the induction hypothesis,\nwe compute the number of functions  which iterate $X$ into $\\{1,\\dots,k+1\\}$ but not into $\\{1,\\dots,k\\}$ to be\n\\[\n\\sum_{\\ell=1}^{n-k} (n-k-1)\\cdots(n-k-\\ell+1)\n(k+\\ell) n^{n-\\ell-1}\n\\]\nBy rewriting this as a telescoping sum, we get\n\\begin{align*}\n&\\sum_{\\ell=1}^{n-k} (n-k-1)\\cdots(n-k-\\ell+1)\n(n) n^{n-\\ell-1} \\\\\n&- \\sum_{\\ell=1}^{n-k} (n-k-1)\\cdots(n-k-\\ell+1)\n(n-k-\\ell) n^{n-\\ell-1} \\\\\n&=\\sum_{\\ell=0}^{n-k-1} (n-k-1)\\cdots(n-k-\\ell) n^{n-\\ell-1} \\\\\n&- \\sum_{\\ell=1}^{n-k} (n-k-1)\\cdots\n(n-k-\\ell) n^{n-\\ell-1} \\\\\n&= n^{n-1}.\n\\end{align*}\nas desired.\n\n\\textbf{Second solution:}\nFor $T$ a set, $f: T \\to T$ a function, and $S$ a subset of $T$,\nwe define the \\emph{contraction} of $f$ at $S$ as the function $g: \\{* \\} \\cup (T-S) \\to \\{*\\}  \\cup (T-S)$\ngiven by\n\\[\ng(x) = \\begin{cases} * & x = *  \\\\\n* & x \\neq *, f(x) \\in S \\\\\nf(x) & x \\neq *, f(x) \\notin S.\n\\end{cases}\n\\]\n\\begin{lemma}\nFor $S \\subseteq X$ of cardinality $\\ell \\geq 0$,\nthere are $\\ell n^{n-\\ell-1}$ functions $f: \\{*\\} \\cup X \\to \\{*\\} \\cup X$ with $f^{-1}(*) = \\{*\\} \\cup S$\nwhich iterate $X$ into $\\{*\\}$.\n\\end{lemma}\n\\begin{proof}\nWe induct on $n$. If $\\ell = n$ then there is nothing to check.\nOtherwise, put $T = f^{-1}(S)$, which must be nonempty.\nThe contraction $g$ of $f$ at $\\{*\\} \\cup S$ is then a function on $\\{*\\} \\cup (X-S)$ with $f^{-1}(*) = \\{*\\} \\cup T$ which iterates $X-S$ into $\\{*\\}$. Moreover, for given $T$, each such $g$ arises from\n$\\ell^{\\# T}$ functions of the desired form.\nSumming over $T$ and invoking the induction hypothesis, we see that the number of functions $f$ is \n\\begin{align*}\n&\\sum_{k=1}^{n-\\ell} \\binom{n-\\ell}{k} \\ell^k \\cdot k (n-\\ell)^{n-\\ell-k-1} \\\\\n&=\\sum_{k=1}^{n-\\ell} \\binom{n-\\ell-1}{k-1} \\ell^k (n-\\ell)^{n-\\ell-k} \n= \\ell n^{n-\\ell-1}\n\\end{align*}\nas claimed.\n\\end{proof}\n\nWe now count functions $f: X \\to X$ which iterate $X$ into $\\{1,\\dots,k\\}$ as follows. By Lemma~1 of the first solution, this count equals $n^k$ times the number of functions with $f(1) = \\cdots = f(k) = 1$  which iterate $X$ into $\\{1,\\dots,k\\}$. For such a function $f$, put $S = \\{k+1,\\dots,n\\} \\cap f^{-1}(\\{1,\\dots,k\\})$ and let $g$ be the contraction of $f$\nat $\\{1,\\dots,k\\}$; then $g^{-1}(*) = * \\cup \\{S\\}$ and $g$ iterates \nits domain into $*$. By Lemma~2, for $\\ell = \\#S$, there are\n$\\ell (n-k)^{n-k-\\ell-1}$ such functions $g$.\nFor given $S$, each such $g$ gives rise to $k^{\\ell}$ functions $f$ with $f(1) = \\cdots = f(k) = 1$  which iterate $X$ into $\\{1,\\dots,k\\}$.\nThus the number of such functions $f$ is\n\\begin{align*}\n&\\sum_{\\ell=0}^{n-k} \\binom{n-k}{\\ell} k^{\\ell} \\ell (n-k)^{n-k-\\ell-1} \\\\\n&= \\sum_{\\ell=0}^{n-k} \\binom{n-k-1}{\\ell-1} k^{\\ell} (n-k)^{n-k-\\ell}\\\\\n&= k n^{n-k-1}.\n\\end{align*}\nThe desired count is this times $n^k$, or $k n^{n-1}$ as desired.\n\n\\textbf{Remark:}\nFunctions of the sort counted in Lemma~2 can be identified with rooted trees on the vertex set $\\{*\\} \\cup X$ with root $*$. Such trees can be counted using \\emph{Cayley's formula}, a special case of \\emph{Kirchoff's matrix tree theorem}. The matrix tree theorem can also be used to show directly that the number of rooted forests on $n$ vertices with $k$ fixed roots is $k n^{n-k-1}$; the desired count follows immediately from this formula plus Lemma~1. (One can also use Pr\\\"ufer sequences for a more combinatorial interpretation.)"
  },
  {
    "year": 2013,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $n \\geq 1$ be an odd integer. Alice and Bob play the following game,\ntaking alternating turns, with Alice playing first. \nThe playing area consists of $n$ spaces, arranged in a line.\nInitially all spaces are empty.\nAt each turn, a player either\n\\begin{itemize}\n\\item\nplaces a stone in an empty space, or\n\\item\nremoves a stone from a nonempty space $s$, \nplaces a stone in the nearest empty space to the left of $s$\n(if such a space exists),\nand places a stone in the nearest empty space to the right of $s$\n(if such a space exists).\n\\end{itemize}\nFurthermore, a move is permitted only if the resulting position has not occurred previously in the game. A player loses if he or she is unable to move. Assuming that both players play optimally throughout the game, what moves may Alice make on her first turn?\n\n\\end{itemize}\n\n\\end{document}",
    "solution": "We show that the only winning first move for Alice is to place a stone in the central space. We start with some terminology.\n\n%Divide the playing area into the \\emph{left half}, the \\emph{central %space}, and the \\emph{right half}.\nBy a \\emph{block} of stones, we mean a (possibly empty) sequence of stones occupying consecutive spaces. By the \\emph{extremal blocks}, we mean the (possibly empty) maximal blocks adjacent to the left and right ends of the playing area.\n\nWe refer to a legal move consisting of placing a stone in an empty space as a move of \\emph{type 1}, and any other legal move as being of \\emph{type 2}.\nFor $i=0,\\dots,n$, let $P_i$ be the collection of positions containing $i$ stones. Define the \\emph{end zone} as the union $Z = P_{n-1} \\cup P_n$. In this language, we make the following observations.\n\\begin{itemize}\n\\item\nAny move of type 1 from $P_i$ ends in $P_{i+1}$.\n\\item\nAny move of type 2 from $P_n$ ends in $P_{n-1}$.\n\\item\nFor $i < n$, any move of type 2 from $P_i$ ends in $P_i \\cup P_{i+1}$.\n\\item\nAt this point, we see that  the number of stones cannot decrease until we reach the end zone.\n\\item\nFor $i < n-1$, if we start at a position in $P_i$ where the extremal blocks have length $a,b$, then the only possible moves to $P_i$ decrease one of $a,b$ while leaving the other unchanged (because they are separated by at least two empty spaces). In particular, no repetition is possible within $P_i$, so the number of stones must eventually increase to $i+1$.\n\\item\nFrom any position in the end zone, the legal moves are precisely to the other positions in the end zone which have not previously occurred. Consequently, after the first move into the end zone, the rest of the game consists of enumerating all positions in the end zone in some order.\n\\item\nAt this point, we may change the rules without affecting the outcome by eliminating the rule on repetitions and declaring that the first player to move into the end zone loses (because $\\# Z = n+1$ is even).\n\\end{itemize}\n\nTo determine who wins in each position, number the spaces of the board $1,\\dots,n$ from left to right. Define the \\emph{weight} of a position to be the sum of the labels of the occupied spaces, reduced modulo $n+1$. For any given position outside of the end zone, \nfor each $s=1,\\dots,n$ there is a unique move that adds $s$ to the weight:\nif $s$ is empty that a move of type 1 there does the job.\nOtherwise, $s$ inhabits a block running from $i+1$ to $j-1$ with $i$ and $j$ empty (or equal to $0$ or $n+1$), so the type 2 move at $i+j-s$ (which belongs to the same block) does the job.\n\nWe now verify that a position of weight $s$ outside of the end zone is a win for the player to move if and only if $s \\neq (n+1)/2$. We check this for positions in $P_i$ for $i = n-2, \\dots, 0$ by descending induction. For positions in $P_{n-2}$, the only safe moves are in the extremal blocks; we may thus analyze these positions as two-pile Nim with pile sizes equal to the lengths of the extremal blocks. In particular, a position is a win for the player to move if and only if the extremal blocks are unequal, in which case the winning move is to equalize the blocks. In other words, a position is a win for the player to move unless the empty spaces are at $s$ and $n+1-s$ for some $s \\in \\{1,\\dots,(n-1)/2\\}$, and indeed these are precisely the positions for which the weight equals $(1 + \\cdots + n) - (n+1) \\equiv (n+1)/2 \\pmod{n+1}$.\nGiven the analysis of positions in $P_{i+1}$ for some $i$, it is clear that if a position in $P_i$ has weight $s \\neq (n+1)/2$, there is a winning move of weight $t$ where $s+t \\equiv (n+1)/2 \\pmod{n}$,\nwhereas if $s = (n+1)/2$ then no move leads to a winning position.\n\nIt thus follows that the unique winning move for Alice at her first turn is to move at the central space, as claimed.\n\n\\textbf{Remark:}\nDespite the existence of a simple description of the winning positions, it is nonetheless necessary to go through the preliminary analysis in order to establish the nature of the end zone and to ensure that the repetition clause does not affect the availability of moves outside of the end zone. However, it is not strictly necessary to study $P_{n-2}$ separately: none of the positions in $P_{n-1}$ has weight $(n+1)/2$, so following the strategy of forcing the weight to equal $(n+1)/2$ cannot force a first move into the end zone.\n\n\\textbf{Remark:}\nIt is easy to see that Alice's winning strategy is to ensure that after each of her moves, the stones are placed symmetrically and the central space is occupied. However, it is somewhat more complicated to describe Bob's winning strategy without the modular interpretation. \n\n\\textbf{Remark:}\nTo resolve a mild ambiguity in the problem statement, it should be clarified that the initial position (with no stones placed) should be treated as having occurred previously once the first move has been made. This only affects the case $n=1$.\n\n\\textbf{Remark:}\nFor the analogous problem with $n$ even, David Savitt has conjectured (based on the cases $n=2$ and $n=4$) that Alice has a winning strategy, and her possible winning moves at her first turn are to place a stone in one of the two central spaces. We give a partial analysis based on an argument from Art of Problem Solving user \\texttt{gnayijoag}, with some clarification from Savitt.\n\nWe first revise the endgame analysis from the original solution. Define the sets $P_i$ and the end zone $Z$ as before. The first six observations from the previous solution remain correct; however, now the number of positions in $Z$ is odd, so the first player to move into $Z$ wins. That is, every position in $P_{n-2}$ is a winning position for the player to move. Consequently, the positions in $P_{n-3}$ can be identified with two-player Nim on the extremal blocks (the subdivision between the two internal blocks being immaterial).\n\nThis suggests that if we want to introduce a numerical invariant that detects the difference between winning and losing positions for the player to move, we must consider a formula that selectively discards some information about some of the stones. To this end, for a position $x \\in P_{n-k}$ for $k \\geq 2$ with vacant spaces at $a_0 > \\cdots > a_{k-1}$\n(or $a_0(x) > \\cdots > a_{k-1}(x)$ if this needs to be clarified),\ndefine\n\\begin{align*}\nA(x) &= a_0 + \\cdots + a_{k-1} \\\\\nf(x,t) &= A - a_t - t(n+1) \\quad (t=0,\\dots,k-1);\n\\end{align*}\nnote that $f(x,0) > \\cdots > f(x,k-1)$. We say that $x$ is \\emph{balanced} if $f(x,t) = 0$ for some (necessarily unique) choice of $t$, in which case we refer to $a_t$ as the \\emph{balance point} of $x$; otherwise, we say that\n$x$ is \\emph{unbalanced}.\nThis definition then has the following properties. \n\\begin{itemize}\n\\item\nThe property of being balanced is invariant under left-right symmetry. This will permit some simplification in the following arguments.\n\\item\nEvery position in $P_{n-2}$ is unbalanced, because $a_0 < a_0 + a_1 < a_1 + (n+1)$.\n\\item\nFor a position $x \\in P_1$ to be balanced,\nin order to have $f(x,t) \\equiv 0 \\pmod{n+1}$ for some $t$,\nthe unique occupied space must be $n+1-t$. We must then have\n$A(x) - t = 1 + \\cdots + n - (n+1) = (n/2  -1)(n+1)$,\nso $x$ is balanced if and only if $f(x, n/2 - 1) = 0$.\nThis occurs if and only if the occupied space is $n/2$ or $n/2 + 1$.\n\\item\nFrom every balanced position $x \\in P_{n-k}$ for $k \\geq 3$, every move leads to an unbalanced position.\nTo check this, we need only consider moves at or to the left of the balance point $a_t$ of $x$.\nLet $y$ be the result of a move from $x$. If the move is at $a_t$,\nthen\n\\[\nf(y,t') \\equiv f(x,t) - a_{t'}(y) = -a_{t'}(y) \\pmod{n+1}\n\\]\nand the latter is not a nonzero residue because $a_{t'} \\in \\{1,\\dots,n\\}$.\nFor a move to the left of $a_t$, the vacant spaces to the right of $a_t$ remain at $a_0,\\dots,a_{t-1}$\nand $0 < A(x) - A(y) < a_t$; consequently, \n\\begin{align*}\nf(y,t-1) &= f(x,t-1) - (A(x)-A(y)) \\\\\n&\\geq (f(x,t) + a_t - a_{t-1} + (n+1)) - (a_t - 1) \\\\\n&= n+2 - a_{t-1} > 0.\n\\end{align*}\nMeanwhile, either $a_t$ remains vacant, or $a_{t}$ and $a_{t+1}$ are filled while some space $b$ in between becomes vacant; in either case, we have $f(y,t) <f(x,t) = 0$.\nSince $f(y,t) < 0 < f(y,t-1)$, $y$ is unbalanced.\n\\end{itemize}\n\nTo complete the analysis, one would need to show that from \nevery unbalanced position in $P_{n-k}$ for $k \\geq 3$, there is a move to some balanced position;\nthis would then show that a position in the game is a win for the player to move if and only if it is unbalanced,\nfrom which the conjecture of Savitt would follow.\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2014,
    "label": "A1",
    "difficulty": "1",
    "problem": "Prove that every nonzero coefficient of the Taylor series of\n\\[\n(1 - x + x^2)e^x\n\\]\nabout $x=0$ is a rational number whose numerator (in lowest terms) is either $1$ or a prime number.",
    "solution": "The coefficient of $x^n$ in the Taylor series of $(1-x+x^2)e^x$ for \n$n=0,1,2$ is $1,0,\\frac{1}{2}$, respectively. For $n\\geq 3$, the coefficient of \n$x^n$ is\n\\begin{align*}\n\\frac{1}{n!} - \\frac{1}{(n-1)!} + \\frac{1}{(n-2)!}\n&= \\frac{1-n+n(n-1)}{n!} \\\\\n&= \\frac{n-1}{n(n-2)!}.\n\\end{align*}\nIf $n-1$ is prime, then the lowest-terms numerator is clearly either 1 or the prime $n-1$ (and in fact the latter, since $n-1$ is relatively prime to $n$ and to $(n-2)!$).\n If $n-1$ is composite,\neither it can be written as $ab$ for some $a \\neq b$, in which case both $a$ and $b$ appear separately in $(n-2)!$ and so the numerator is $1$,\nor $n-1 = p^2$ for some prime $p$, in which case $p$ appears in $(n-2)!$\nand so the numerator is either 1 or $p$. (In the latter case, the numerator is actually 1 unless $p=2$, as in all other cases both $p$ and $2p$ appear in $(n-2)!$.)"
  },
  {
    "year": 2014,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $A$ be the $n \\times n$ matrix whose entry in the $i$-th row and $j$-th column is\n\\[\n\\frac{1}{\\min(i,j)}\n\\]\nfor $1 \\leq i,j \\leq n$. Compute $\\det(A)$.",
    "solution": "Let $v_1,\\ldots,v_n$ denote the rows of $A$. The determinant is \nunchanged if we replace $v_n$ by $v_n-v_{n-1}$, and then $v_{n-1}$ by \n$v_{n-1}-v_{n-2}$, and so forth, eventually replacing $v_k$ by \n$v_k-v_{k-1}$ for $k\\geq 2$. Since $v_{k-1}$ and $v_k$ agree in their \nfirst $k-1$ entries, and the $k$-th entry of $v_k-v_{k-1}$ is \n$\\frac{1}{k} - \\frac{1}{k-1}$, the result of these row operations is an upper triangular \nmatrix with diagonal entries $1,\\frac{1}{2}-1,\\frac{1}{3}-\\frac{1}{2},\\ldots,\\frac{1}{n}-\\frac{1}{n-1}$. The \ndeterminant is then\n\\begin{align*}\n\\prod_{k=2}^n \\left( \\frac{1}{k} - \\frac{1}{k-1}\\right) &= \\prod_{k=2}^n \\left(\\frac{-1}{k(k-1)} \\right) \\\\\n&= \n\\frac{(-1)^{n-1}}{(n-1)!n!}.\n\\end{align*}\nNote that a similar calculation can be made whenever $A$ has the form $A_{ij} = \\min\\{a_i, a_j\\}$ for any monotone sequence $a_1,\\dots,a_n$. Note also that the standard Gaussian elimination algorithm leads to the same upper triangular matrix, but the nonstandard order of operations used here makes the computations somewhat easier.\n\n\\noindent\n\\textbf{Remark:}\nThe inverse of $A$ can be identified explicitly: for $n \\geq 2$, it is the matrix $B$ given by\n\\[\nB_{ij} = \\begin{cases} -1 & i=j=1 \\\\\n-2i^2 & 1 < i=j< n \\\\\n-(n-1)n & i=j=n \\\\\nij & |i-j|=1 \\\\\n0 & \\mbox{otherwise.} \\end{cases}\n\\]\nFor example, for $n=5$,\n\\[\nB = \\begin{pmatrix}\n-1 & 2 & 0 & 0 & 0 \\\\\n2 & -8 & 6 & 0 & 0 \\\\\n0 & 6 & -18 & 12 & 0 \\\\\n0 & 0 & 12 & -32 & 20 \\\\\n0 & 0 & 0 & 20 & -20\n\\end{pmatrix}.\n\\]\nLet $C$ denote the matrix obtained from $B$ by replacing the bottom-right entry with $-2n^2$ (for consistency with the rest of the diagonal).\nExpanding in minors along the bottom row produces a second-order recursion for $\\det(C)$ solving to $\\det(C) = (-1)^n (n!)^2$; a similar expansion then yields $\\det(B) = (-1)^{n-1} n! (n-1)!$.\n\n\\noindent\n\\textbf{Remark:}\nThis problem and solution are due to one of us (Kedlaya). The statement appears in the comments on sequence A010790 (i.e., the sequence $(n-1)! n!$)\nin the On-Line Encyclopedia of Integer Sequences (\\url{http://oeis.org}),\nattributed to Benoit Cloitre in 2002."
  },
  {
    "year": 2014,
    "label": "A3",
    "difficulty": "3",
    "problem": "Let $a_0 = 5/2$ and $a_k = a_{k-1}^2 - 2$ for $k \\geq 1$. Compute\n\\[\n\\prod_{k=0}^\\infty \\left(1 - \\frac{1}{a_k} \\right)\n\\]\nin closed form.",
    "solution": "\\textbf{First solution:}\nUsing the identity\n\\[\n(x + x^{-1})^2 - 2 = x^2 + x^{-2},\n\\]\nwe may check by induction on $k$ that $a_k = 2^{2^k} + 2^{-2^k}$; in particular, the product is absolutely convergent.\nUsing the identities\n\\begin{align*}\n\\frac{x^2 + 1 + x^{-2}}{x + 1 + x^{-1}} &= x  - 1 + x^{-1}, \\\\\n\\frac{x^2 - x^{-2}}{x - x^{-1}} &= x + x^{-1},\n\\end{align*}\nwe may telescope the product to obtain\n\\begin{align*}\n\\prod_{k=0}^\\infty \\left( 1 - \\frac{1}{a_k} \\right)\n&= \\prod_{k=0}^\\infty \\frac{2^{2^k} - 1 + 2^{-2^k}}{2^{2^k} + 2^{-2^k}} \\\\\n&= \\prod_{k=0}^\\infty \\frac{2^{2^{k+1}} + 1 + 2^{-2^{k+1}}}{2^{2^k} + 1 + 2^{-2^k}} \\cdot\n \\frac{2^{2^k} - 2^{-2^k}}{2^{2^{k+1}} - 2^{2^{-k-1}}} \\\\\n&= \\frac{2^{2^0} - 2^{-2^0}}{2^{2^0}+1 + 2^{-2^0}} = \\frac{3}{7}.\n\\end{align*}\n\n\\textbf{Second solution:}\n(by Catalin Zara)\nIn this solution, we do not use the explicit formula for $a_k$.\nWe instead note first that the $a_k$ form an increasing sequence which cannot approach a finite limit (since the equation $L = L^2 - 2$ has no real solution $L>2$), and is thus \nunbounded. Using the identity\n\\[\na_{k+1} + 1 = (a_k - 1)(a_k + 1),\n\\]\none checks by induction on $n$ that\n\\[\n\\prod_{k=0}^n \\left( 1 - \\frac{1}{a_k} \\right)\n= \\frac{2}{7} \\frac{a_{n+1} + 1}{a_0 a_1 \\cdots a_n}.\n\\]\nUsing the identity\n\\[\na_{n+2}^2 - 4 = a_{n+1}^4 - 4 a_{n+1}^2,\n\\]\none also checks by induction on $n$ that\n\\[\na_0 a_1 \\cdots a_n = \\frac{2}{3} \\sqrt{a_{n+1}^2 - 4}.\n\\]\nHence\n\\[\n\\prod_{k=0}^n \\left( 1 - \\frac{1}{a_k} \\right)\n= \\frac{3}{7} \\frac{a_{n+1} + 1}{\\sqrt{a_{n+1}^2 - 4}}\n\\]\ntends to $\\frac{3}{7}$ as $a_{n+1}$ tends to infinity, hence as $n$ tends to infinity."
  },
  {
    "year": 2014,
    "label": "A4",
    "difficulty": "4",
    "problem": "Suppose $X$ is a random variable that takes on only nonnegative integer values,\nwith $E\\left[ X \\right] = 1$, $E\\left[ X^2 \\right] = 2$, and $E \\left[ X^3 \\right] = 5$.\n(Here $E\\left[ y \\right]$ denotes the expectation of the random variable $Y$.)\nDetermine the smallest possible value of the probability of the event $X=0$.",
    "solution": "The answer is $\\frac{1}{3}$.\n\n\\textbf{First solution:}\nLet $a_n = P(X=n)$; we want the minimum value for $a_0$. If we write \n$S_k = \\sum_{n=1}^\\infty n^k a_n$, then the given expectation values \nimply that $S_1 = 1$, $S_2 = 2$, $S_3 = 5$. Now\ndefine $f(n) = 11n-6n^2+n^3$, and note that $f(0) = 0$, $f(1)=f(2)=f(3)=6$, and \n$f(n)>6$ for $n\\geq 4$; thus\n$4 = 11S_1-6S_2+S_3 = \\sum_{n=1}^\\infty f(n)a_n \\geq 6 \\sum_{n=1}^{\\infty} a_n$. \nSince $\\sum_{n=0}^\\infty a_n = 1$, it \nfollows that $a_0 \\geq \\frac{1}{3}$. Equality is achieved \nwhen $a_0=\\frac{1}{3}$, $a_1=\\frac{1}{2}$, $a_3=\\frac{1}{6}$, and $a_n = 0$ for all other $n$, \nand so the answer is $\\frac{1}{3}$.\n\n\\textbf{Second solution:}\n(by Tony Qiao)\nDefine the \\emph{probability generating function} of $P$ as the power series\n\\[\nG(z) = \\sum_{n=0}^\\infty P(x = n) z^n.\n\\]\nWe compute that $G(1) = G'(1) = G''(1) = G'''(1) = 1$. By Taylor's theorem with remainder,\nfor any $x \\in [0,1]$, there exists $c \\in [x,1]$ such that\n\\[\nG(x) = 1 + (x-1) + \\frac{(x-1)^2}{2!} + \\frac{(x-1)^3}{3!} + \\frac{G''''(c)}{4!} (x-1)^4.\n\\]\nIn particular, $G(0) = \\frac{1}{3} + \\frac{1}{24} G''''(c)$ for some $c \\in [0,1]$.\nHowever, since $G$ has nonnegative coefficients and $c \\geq 0$, we must have $G''''(c) \\geq 0$,\nand so $G(0) \\geq \\frac{1}{3}$. As in the first solution, we see that this bound is best possible."
  },
  {
    "year": 2014,
    "label": "A5",
    "difficulty": "5",
    "problem": "Let\n\\[\nP_n(x) = 1 + 2 x  + 3 x^2 + \\cdots + n x^{n-1}.\n\\]\nProve that the polynomials $P_j(x)$\nand $P_k(x)$ are relatively prime\nfor all positive integers $j$ and $k$ with $j \\neq k$.",
    "solution": "\\textbf{First solution:}\nSuppose to the contrary that there exist positive integers $i \\neq j$ and a complex number $z$ such that $P_i(z) = P_j(z) = 0$. Note that $z$ cannot be a nonnegative real number or else $P_i(z), P_j(z) > 0$; we may put $w = z^{-1} \\neq 0,1$. For $n \\in \\{i+1,j+1\\}$ we compute that\n\\[\nw^n = n w - n + 1,\n\\qquad \\overline{w}^n =  n \\overline{w} - n + 1;\n\\]\nnote crucially that these equations also hold for $n \\in \\{0,1\\}$.\nTherefore, the function $f: [0, +\\infty) \\to \\RR$ given by\n\\[\nf(t) = \\left| w \\right|^{2t} - t^2 \\left| w \\right|^2 + 2t(t-1)\\mathrm{Re}(w) - (t-1)^2\n\\]\nsatisfies $f(t) = 0$ for $t \\in \\{0,1,i+1,j+1\\}$. On the other hand, for all $t \\geq 0$ we have\n\\[\nf'''(t) = (2 \\log \\left| w \\right|)^3 \\left| w \\right|^{2t} > 0,\n\\]\nso by Rolle's theorem, the equation $f^{(3-k)}(t) = 0$ has at most $k$ distinct solutions for $k=0,1,2,3$. This yields the desired contradiction.\n\n\\noindent\n\\textbf{Remark:}\nBy similar reasoning, an equation of the form $e^{x} = P(x)$ in which $P$ is a real polynomial of degree $d$ has at most $d+1$ real solutions. This turns out to be closely related to a concept in mathematical logic known as \\emph{o-minimality}, which in turn has deep consequences for the solution of Diophantine equations.\n\n\\noindent\n\\textbf{Second solution:}\n\\setcounter{lemma}{0}\n(by Noam Elkies)\nWe recall a result commonly known as the \\emph{Enestr\\\"om-Kakeya theorem}.\n\\begin{lemma}\nLet \n\\[\nf(x) = a_0 + a_1 x + \\cdots + a_n x^n\n\\]\nbe a polynomial with real coefficients such that $0 < a_0 \\leq a_1 \\leq \\cdots \\leq a_n$.\nThen every root $z \\in \\CC$ of $f$ satisfies $|z| \\leq 1$.\n\\end{lemma}\n\\begin{proof}\nIf $f(z) = 0$, then we may rearrange the equality $0 = f(z)(z-1)$ to obtain\n\\[\na_n z^{n+1} = (a_n - a_{n-1}) z^n + \\cdots + (a_1 - a_0)z + a_0.\n\\]\nBut if $|z| > 1$, then \n\\[\n|a_n z^{n+1}| \\leq (|a_n - a_{n-1}| + \\cdots + |a_1 - a_0|) |z|^{n}\n\\leq |a_n z^{n}|,\n\\]\ncontradiction.\n\\end{proof}\n\\begin{cor}\nLet \n\\[\nf(x) = a_0 + a_1 x + \\cdots + a_n x^n\n\\]\nbe a polynomial with positive real coefficients. Then every root $z \\in \\CC$ of $f$ satisfies $r \\leq |z| \\leq R$ for\n\\begin{align*}\nr &= \\min\\{a_0/a_1, \\dots, a_{n-1}/a_n\\} \\\\\nR &= \\max\\{a_0/a_1, \\dots, a_{n-1}/a_n\\}.\n\\end{align*}\n\\end{cor}\n\\begin{proof}\nThe bound $|z| \\leq R$ follows by applying the lemma to the polynomial $f(x/R)$.\nThe bound $|z| \\geq r$ follows by applying the lemma to the reverse of the polynomial $f(x/r)$.\n\\end{proof}\nSuppose now that $P_i(z) = P_j(z) = 0$ for some $z \\in \\CC$ and some integers $i < j$. \nWe clearly cannot have $j = i+1$, as then $P_i(0) \\neq 0$ and so $P_j(z) - P_i(z) = (i+1) z^i \\neq 0$; we thus have $j-i \\geq 2$.\nBy applying Corollary~2 to $P_i(x)$, we see that $|z| \\leq 1 - \\frac{1}{i}$. On the other hand, by applying Corollary~2 to $(P_j(x) - P_i(x))/x^{i-1}$, we see that $|z| \\geq 1 - \\frac{1}{i+2}$, contradiction.\n\n\\noindent\n\\textbf{Remark:} Elkies also reports that this problem is his submission, dating back to 2005 and arising from work of Joe Harris.\nIt dates back further to Example 3.7 in: Hajime Kaji,\nOn the tangentially degenerate curves,\n\\textit{J. London Math. Soc. (2)} \\textbf{33} (1986), 430--440, in which the second solution is given.\n\n\\noindent\n\\textbf{Remark:}\nElkies points out a mild generalization which may be treated using the first solution but not the second: for integers $a<b<c<d$ and $z \\in \\CC$\nwhich is neither zero nor a root of unity, the matrix\n\\[\n\\begin{pmatrix}\n1 & 1 & 1 & 1 \\\\\na & b & c & d \\\\\nz^a & z^b & z^c & z^d\n\\end{pmatrix}\n\\]\nhas rank 3 (the problem at hand being the case $a=0, b=1, c=i+1, d=j+1$).\n\n\\noindent\n\\textbf{Remark:}\nIt seems likely that the individual polynomials $P_k(x)$ are all irreducible, but this appears difficult to prove.\n\n\\noindent\n\\textbf{Third solution:}\n(by David Feldman)\nNote that\n\\[\nP_n(x)(1-x) = 1 + x + \\cdots + x^{n-1} - nx^n.\n\\]\nIf $|z| \\geq 1$, then\n\\[\nn|z|^n \\geq |z|^{n-1} + \\cdots + 1 \\geq |z^{n-1} + \\cdots + 1|,\n\\]\nwith the first equality occurring only if $|z| = 1$ and the second equality occurring only if $z$ is a positive real number. Hence the equation $P_n(z)(1-z) = 0$ has no solutions  with $|z| \\geq 1$ other than the trivial solution $z=1$. Since\n\\[\nP_n(x)(1-x)^2 = 1 - (n+1) x^n + nx^{n+1},\n\\]\nit now suffices to check that the curves\n\\[\nC_n = \\{ z \\in \\CC: 0 < |z| < 1, \\left| z \\right|^n \\left| n+1 - zn \\right| = 1 \\}\n\\]\nare pairwise disjoint as $n$ varies over positive integers.\n\nWrite $z = u+iv$; we may assume without loss of generality that $v \\geq 0$.\nDefine the function\n\\[\nE_z(n) = n \\log |z| + \\log |n+1-zn|.\n\\]\nOne computes that for $n \\in \\RR$, $E_z''(n) < 0$ if and only if\n\\[\n\\frac{u-v-1}{(1-u)^2 + v^2} < n <\n\\frac{u+v-1}{(1-u)^2 + v^2}.\n\\]\nIn addition, $E_z(0) = 0$ and \n\\[\nE_z'(0) = \\frac{1}{2} \\log (u^2+v^2) + (1-u) \\geq \\log (u) + 1 - u \\geq 0\n\\]\nsince $\\log(u)$ is concave. From this, it follows that the equation $E_z(n) = 0$\ncan have at most one solution with $n>0$.\n\n\\noindent\n\\textbf{Remark:}\nThe reader may notice a strong similarity between this solution and the first solution. The primary difference is we compute that $E'_z(0) \\geq 0$ instead of discovering that $E_z(-1) = 0$.\n\n\\noindent\n\\textbf{Remark:}\nIt is also possible to solve this problem using a $p$-adic valuation on the field of algebraic numbers in place of the complex absolute value; however, this leads to a substantially more complicated solution. In lieu of including such a solution here,\nwe refer to the approach described by Victor Wang \nhere: \\url{http://www.artofproblemsolving.com/Forum/viewtopic.php?f=80&t=616731}."
  },
  {
    "year": 2014,
    "label": "A6",
    "difficulty": "6",
    "problem": "Let $n$ be a positive integer. What is the largest $k$ for which there exist $n \\times n$ matrices $M_1, \\dots, M_k$ and $N_1, \\dots, N_k$ with real entries such that for all $i$ and $j$, the matrix product $M_i N_j$ has a zero entry somewhere on its diagonal if and only if $i \\neq j$?",
    "solution": "The largest such $k$ is $n^n$. We first show that this value can be achieved by an explicit construction.\nLet $e_1,\\dots,e_n$ be the standard basis of $\\RR^n$.\nFor $i_1,\\dots,i_n \\in \\{1,\\dots,n\\}$, let $M_{i_1,\\dots,i_n}$ be the matrix with row vectors $e_{i_1},\\dots,e_{i_n}$, and let $N_{i_1,\\dots,i_n}$ be the transpose of $M_{i_1,\\dots,i_n}$. Then $M_{i_1,\\dots,i_n} N_{j_1,\\dots,j_n}$ has $k$-th diagonal entry $e_{i_k} \\cdot e_{j_k}$, proving the claim.\n\nWe next show that for any families of matrices $M_i, N_j$ as described, we must have $k \\leq n^n$.\nLet $V$ be the \\emph{$n$-fold tensor product} of $\\RR^n$, i.e., the vector space with  orthonormal basis\n$e_{i_1} \\otimes \\cdots \\otimes e_{i_n}$ for $i_1,\\dots,i_n \\in \\{1,\\dots,n\\}$.\nLet $m_i$ be the tensor product of the rows of $M_i$; that is,\n\\[\nm_i = \\sum_{i_1,\\dots,i_n=1}^n (M_i)_{1,i_1} \\cdots (M_i)_{n,i_n} e_{i_1} \\otimes \\cdots \\otimes e_{i_n}.\n\\]\nSimilarly, let $n_j$ be the tensor product of the columns of $N_j$. One computes easily that $m_i \\cdot n_j$ equals the product of the diagonal entries of $M_i N_j$,\nand so vanishes if and only if $i \\neq j$. For any $c_i \\in \\RR$ such that $\\sum_i c_i m_i = 0$, for each $j$ we have \n\\[\n0 = \\left(\\sum_i c_i m_i\\right) \\cdot n_j = \\sum_i c_i (m_i \\cdot n_j) = c_j.\n\\]\nTherefore the vectors $m_1,\\dots,m_k$ in $V$ are linearly independent, implying $k \\leq n^n$ as desired.\n\n\\noindent\n\\textbf{Remark:}\nNoam Elkies points out that similar argument may be made in the case that the $M_i$ are $m \\times n$ matrices and the $N_j$ are $n \\times m$ matrices."
  },
  {
    "year": 2014,
    "label": "B1",
    "difficulty": "1",
    "problem": "A \\emph{base $10$ over-expansion} of a positive integer $N$ is an expression of the form\n\\[\nN = d_k 10^k + d_{k-1} 10^{k-1} + \\cdots + d_0 10^0\n\\]\nwith $d_k \\neq 0$ and $d_i \\in \\{0,1,2,\\dots,10\\}$ for all $i$.\nFor instance, the integer $N = 10$ has two base 10 over-expansions: $10 = 10 \\cdot 10^0$\nand the usual base 10 expansion $10 = 1 \\cdot 10^1 + 0 \\cdot 10^0$.\nWhich positive integers have a unique base 10 over-expansion?",
    "solution": "These are the integers with no $0$'s in their usual base $10$ expansion. If the usual base $10$ expansion of $N$ is $d_k 10^k + \\cdots + d_0 10^0$ and one of the digits is $0$, then there exists an $i \\leq k-1$ such that $d_i = 0$ and $d_{i+1} > 0$; then we can replace $d_{i+1} 10^{i+1} + (0) 10^i$ by $(d_{i+1}-1) 10^{i+1} + (10) 10^i$ to obtain a second base $10$ over-expansion.\n\nWe claim conversely that if $N$ has no $0$'s in its usual base $10$ expansion, then this standard form is the unique base $10$ over-expansion for $N$. This holds by induction on the number of digits of $N$: if $1\\leq N\\leq 9$, then the result is clear. Otherwise, any base $10$ over-expansion $N = d_k 10^k + \\cdots + d_1 10 + d_0 10^0$ must have $d_0 \\equiv N \\pmod{10}$, which uniquely determines $d_0$ since $N$ is not a multiple of $10$; then $(N-d_0)/10$ inherits the base $10$ over-expansion $d_k 10^{k-1} + \\cdots + d_1 10^0$, which must be unique by the induction hypothesis.\n\n\\noindent\n\\textbf{Remark:}\nKarl Mahlburg suggests an alternate proof of uniqueness (due to Shawn Williams):\nwrite the usual expansion $N = d_k 10^k + \\cdots + d_0 10^0$ and suppose $d_i \\neq 0$ for all $i$. Let $M = c_l 10^l + \\cdots + c_0 10^0$ be an over-expansion with at least one 10. To have $M = N$, we must have $l \\leq k$; we may pad the expansion of $M$ with zeroes to force $l=k$. Now define $e_i = c_i - d_i$; since $1 \\leq d_i \\leq 9$ and $0 \\leq c_i \\leq 10$,\nwe have $0 \\leq |e_i| \\leq 9$. Moreover, there exists at least one index $i$ with $e_i \\neq 0$, since any index for which $c_i = 10$ has this property. But if $i$ is the largest such index, we have \n\\begin{align*}\n10^i &\\leq \\left| e_i 10^i \\right| = \\left| -\\sum_{j=0}^{i-1} e_i 10^i \\right| \\\\\n&\\leq \\sum_{j=0}^{i-1} \\left| e_i| 10^i \\right| \\leq 9 \\cdot 10^{i-1} + \\cdots + 9 \\cdot 10^0,\n\\end{align*}\na contradiction."
  },
  {
    "year": 2014,
    "label": "B2",
    "difficulty": "2",
    "problem": "Suppose that $f$ is a function on the interval $[1,3]$ such that $-1 \\leq f(x) \\leq 1$ for all $x$ and $\\int_1^3 f(x)\\,dx = 0$. How large can $\\int_1^3 \\frac{f(x)}{x}\\,dx$ be?\n\n\\,",
    "solution": "In all solutions, we assume that the function $f$ is integrable.\n\n\\textbf{First solution:}\nLet $g(x)$ be $1$ for $1\\leq x\\leq 2$ and $-1$ for $2<x\\leq 3$, and \ndefine $h(x)=g(x)-f(x)$. Then $\\int_1^3 h(x)\\,dx = 0$ and $h(x) \\geq 0$ \nfor $1\\leq x\\leq 2$, $h(x) \\leq 0$ for $2<x\\leq 3$. Now\n\\begin{align*}\n\\int_1^3 \\frac{h(x)}{x}\\,dx & = \\int_1^2 \\frac{|h(x)|}{x}\\,dx - \\int_2^3 \n\\frac{|h(x)|}{x}\\,dx\\\\\n&\\geq \\int_1^2 \\frac{|h(x)|}{2}\\,dx - \\int_2^3 \\frac{|h(x)|}{2}\\,dx = 0,\n\\end{align*}\nand thus $\\int_1^3 \\frac{f(x)}{x}\\,dx \\leq \\int_1^3 \\frac{g(x)}{x}\\,dx = \n2\\log 2-\\log 3 = \\log \\frac{4}{3}$. Since $g(x)$ achieves the upper bound, the answer is \n$\\log \\frac{4}{3}$.\n\n\\noindent\n\\textbf{Reformulation:}\n(by Karl Mahlburg and Karthik Adimurthi) \nSince $f$ is integrable, it can be expressed in terms of the Hadamard basis\n\\begin{align*}\nH_0(x) &= \\begin{cases} 1 & x \\in [1,2) \\\\\n-1 & x \\in [2,3] \\\\\n0 & x \\notin [1,3] \\end{cases} \\\\\nH_{n+1}(x) &= H_n( 2(x-1) + 1) + H_n( 2(x-2) + 1).\n\\end{align*}\nMore precisely, we have $f(x) = \\sum_n c_n H_n(x)$ for some $c_n$ \nwith $|c_0| + |c_1| + |\\cdots| \\leq 1$. Let $g_n = \\int_1^3 (H_n(x) / x)\\,dx$; \nit is easy to show that the $g_n$ are strictly decreasing in $n$. \nThus \\[\n\\int_1^3 (f(x) / x) dx = c_0 g_0 +\nc_1 g_1 + \\cdots \\leq 1 \\cdot g_0 = \\log \\frac{4}{3}.\n\\] \n\n\\noindent\n\\textbf{Second solution:}\n(Art of Problem Solving, user \\verb+libra_gold+)\nDefine the function $F(x) = \\int_1^x f(t)\\,dt$ for $1 \\leq x \\leq 3$; then $F(1) = F(3) = 0$ and $F(x) \\leq \\min\\{x-1,3-x\\}$. Using integration by parts, we obtain\n\\begin{align*}\n\\int_1^3 \\frac{f(x)}{x}\\,dx &= \\int_1^3 \\frac{F(x)}{x^2}\\,dx \\\\\n&\\leq \\int_1^2 \\frac{x-1}{x^2}\\,dx + \\int_2^3 \\frac{3-x}{x^2}\\,dx \\\\\n&= \\log \\frac{4}{3}.\n\\end{align*}\n(Some minor adjustment is needed to make this completely rigorous, e.g., approximating $f$ uniformly by continuous functions.)"
  },
  {
    "year": 2014,
    "label": "B3",
    "difficulty": "3",
    "problem": "Let $A$ be an $m \\times n$ matrix with rational entries.\nSuppose that there are at least $m+n$ distinct prime numbers among the absolute values of the entries of $A$. Show that the rank of $A$ is at least 2.",
    "solution": "\\textbf{First solution:}\nAssume by way of contradiction that $A$ has rank at most 1;\nin this case, we can find rational numbers $a_1,\\dots,a_m$, $b_1,\\dots,b_n$ such that\n$A_{ij} = a_i b_j$ for all $i,j$. By deleting rows or columns, we may reduce to the case where the $a_i$'s and $b_j$'s are all nonzero.\n\nRecall that any nonzero rational number $q$ has a unique prime factorization\n\\[\nq = \\pm 2^{c_1} 3^{c_2} 5^{c_3} \\cdots\n\\]\nwith exponents in $\\ZZ$. Set\n\\[\nc(q) = (c_1, c_2, c_3, \\dots).\n\\]\nNote that $|a_i b_j|$ is prime if and only if $c(a_i) + c(b_j)$ has one entry equal to 1 and all others equal to 0. The condition that $m+n$ distinct primes appear in the matrix implies that the vector space \n\\[\n\\left\\{ \\sum_i x_i c(a_i) + \\sum_j y_i c(b_j) : x_i, y_j \\in \\RR, \\sum_i x_i = \\sum_j y_j \\right\\} \n\\]\ncontains a linearly independent set of size $m+n$. But that space evidently has dimension at most $m+n-1$, contradiction.\n\n\\textbf{Second solution:}\nIn this solution, we use standard terminology of graph theory, considering only simple undirected graphs (with no self-loops or multiple edges).\nWe first recall the quick induction proof that that a graph on $k$ vertices\n with no cycles contains at most $k-1$ edges: for $k=1$, the claim is trivially true because there can be no edges.\nFor $k>1$, choose any vertex $v$ and let $d$ be its degree. Removing the vertex $v$ and the edges incident to it leaves a disjoint union of $d$ different graphs, each having no cycles. If the numbers of vertices in these graphs are $k_1,\\dots,k_d$, by induction the total number of edges in the original graph is at most $(k_1 - 1) + \\cdots + (k_d - 1) + d = k - 1$.\n\nReturning to the original problem, suppose that $A$ has rank at most 1.\nDraw a bipartite graph whose vertices correspond to the rows and columns of $A$, with an edge joining a particular row and column if the entry where they intersect has prime absolute value. By the previous paragraph, this graph must contain a cycle. Since the graph is bipartite, this cycle must be of length $2k$ for some integer $k \\geq 2$ (we cannot have $k=1$ because the graph has no repeated edges). Without loss of generality, we may assume that the cycle consists of row 1, column 1, row 2, column 2, and so on. There must then exist distinct prime numbers $p_1, \\dots, p_{2k}$ such that\n\\[\n\\left| A_{11} \\right| = p_1, \\left| A_{21} \\right| = p_2, \\dots,\n\\left| A_{kk} \\right| = p_{2k-1}, \\left| A_{1k} \\right| = p_{2k}.\n\\]\nHowever, since $A$ has rank 1, the $2 \\times 2$ minor $A_{11} A_{ij} - A_{i1} A_{1j}$ must vanish for all $i,j$. If we put $r_i = \\left|A_{i1} \\right|$ and $c_j = \\left| A_{ij}/A_{11} \\right|$, we have\n\\begin{align*}\np_1 \\cdots p_{2k} &= (r_1 c_1)(r_2 c_1) \\cdots (r_k c_k) (r_1 c_k) \\\\\n&= (r_1 c_1 \\cdots r_k c_k)^2,\n\\end{align*}\nwhich contradicts the existence of unique prime factorizations for positive rational numbers: the prime $p_1$ occurs with exponent 1 on the left, but with some even exponent on the right. This contradiction completes the proof."
  },
  {
    "year": 2014,
    "label": "B4",
    "difficulty": "4",
    "problem": "Show that for each positive integer $n$, all the roots of the polynomial\n\\[\n\\sum_{k=0}^n 2^{k(n-k)} x^k\n\\]\nare real numbers.",
    "solution": "Define the polynomial $f_n(x) = \\sum_{k=0}^n 2^{k(n-k)} x^k$.\nSince\n\\[\nf_1(x) = 1+x, f_2(x) = 1 + 2x + x^2 = (1+x)^2,\n\\]\nthe claim holds for for $n=1,2$. For $n \\geq 3$, we show that the quantities\n\\[\nf_n(-2^{-n}), f_n(-2^{-n+2}), \\dots, f_n(-2^n)\n\\]\nalternate in sign; by the intermediate value theorem, this will imply that $f_n$ has a root in each of the $n$ intervals $(- 2^{-n}, - 2^{-n+2}), \\dots, (- 2^{n-2}, -2^n)$,\nforcing $f_n$ to have as many distinct real roots as its degree.\n\nFor $j \\in \\{0,\\dots,n\\}$, group the terms of $f_n(x)$ as\n\\begin{align*}\n&\\cdots \\\\\n&+ 2^{(j-5)(n-j+5)} x^{j-5} + 2^{(j-4)(n-j+4)} x^{j-4} \\\\\n&+ 2^{(j-3)(n-j+3)} x^{j-3} + 2^{(j-2)(n-j+2)} x^{j-2} \\\\\n&+ 2^{(j-1)(n-j+1)} x^{j-1} + 2^{j(n-j)} x^j + 2^{(j+1)(n-j-1)} x^{j+1} \\\\\n&+  2^{(j+2)(n-j-2)} x^{j+2} + 2^{(j+3)(n-j-3)} x^{j+3} \\\\\n&+2^{(j+4)(n-j-4)} x^{j+4} + 2^{(j+5)(n-j-5)} x^{j+5} \\\\\n& \\cdots.\n\\end{align*}\n\nDepending on the parity of $j$ and of $n-j$, there may be a single monomial left on each end. When evaluating at $x =- 2^{-n+2j}$,\nthe trinomial evaluates to $0$. In the binomials preceding the trinomial, the right-hand term dominates, so each of these binomials contributes with the sign of $x^{j-2k}$, which is $(-1)^j$. In the binomials following the trinomial, the left-hand term dominates, so again the contribution has sign $(-1)^j$.\n\nAny monomials which are left over on the ends also contribute with sign $(-1)^j$. Since $n \\geq 3$, there exists at least one contribution other than the trinomial, so $f_n(- 2^{-n+2j})$ has overall sign $(-1)^j$, proving the claimed alternation.\n\n\\noindent\n\\textbf{Remark:} Karl Mahlburg suggests an alternate interpretation of the preceding algebra: write $2^{-j^2} f_n(2^{-n+2j})$ as\n\\begin{align*}\n&2^{-j^2} - 2^{-(j-1)^2} + \\cdots + (-1)^{j-1} 2^{-1} + (-1)^j 2^{-1}\\\\\n+ &(-1)^j 2^{-1} + (-1)^{j+1} 2^{-1} + (-1)^{j+2} 2^{-2} + \\cdots,\n\\end{align*}\nwhere the two central terms $(-1)^j 2^{-1}$ arise from splitting the term arising from $x^j$. Then each row is an alternating series whose sum carries the sign of $(-1)^j$ unless it has only two terms. Since $n \\geq 3$, one of the two sums is forced to be nonzero.\n\n\\noindent\n\\textbf{Remark:} One of us (Kedlaya) received this problem and solution from David Speyer in 2009 and submitted it to the problem committee."
  },
  {
    "year": 2014,
    "label": "B5",
    "difficulty": "5",
    "problem": "In the 75th annual Putnam Games, participants compete at mathematical games.\nPatniss and Keeta play a game in which they take turns choosing an element \nfrom the group of invertible $n \\times n$ matrices with entries in the field\n$\\mathbb{Z}/p \\mathbb{Z}$ of integers modulo $p$, where $n$ is a fixed positive integer and $p$ is a fixed prime number. The rules of the game are:\n\\begin{enumerate}",
    "solution": "We show that Patniss wins if $p=2$ and Keeta wins if $p>2$ (for all $n$).\nWe first analyze the analogous game played using an arbitrary finite group $G$.\nRecall that for any subset $S$ of $G$, the set of elements $g \\in G$ which commute with all elements of $S$ forms a subgroup $Z(S)$ of $G$, called the \\emph{centralizer} (or \\emph{commutant}) of $S$. \nAt any given point in the game, the set $S$ of previously chosen elements is contained in $Z(S)$. Initially $S = \\emptyset$ and $Z(S) = G$;\nafter each turn, $S$ is increased by one element and $Z(S)$ is replaced by a subgroup.\nIn particular, if the order of $Z(S)$ is odd at some point, it remains odd thereafter;\nconversely, if $S$ contains an element of even order, then the order of $Z(S)$ remains even thereafter. Therefore, any element $g \\in G$ for which $Z(\\{g\\})$ has odd order is a winning first move for Patniss, while any other first move by Patniss loses if Keeta responds with some $h \\in Z(\\{g\\})$ of even order (e.g., an element of a 2-Sylow subgroup of $Z(\\{g\\})$). In both cases, the win is guaranteed no matter what moves follow.\n\nNow let $G$ be the group of invertible $n \\times n$ matrices with entries in $\\ZZ/p\\ZZ$.\nIf $p>2$, then $Z(S)$ will always contain the scalar matrix $-1$ of order 2, so the win for Keeta is guaranteed. (An explicit winning strategy is to answer any move $g$ with the move $-g$.)\n\nIf $p=2$, we establish the existence of $g \\in G$ such that $Z(\\{g\\})$ has odd order\nusing the existence of an irreducible polynomial $P(x)$ of degree $n$ over $\\ZZ/p\\ZZ$ (see remark). We construct an $n \\times n$ matrix over $\\ZZ/p\\ZZ$ with characteristic polynomial $P(x)$ by taking the \\emph{companion matrix} of $P(x)$: write $P(x) = x^n + P_{n-1} x^{n-1} + \\cdots + P_0$ and set\n\\[\ng = \\begin{pmatrix}\n0 & 0 & \\cdots & 0 & -P_0 \\\\\n1 & 0 & \\cdots & 0 & -P_1 \\\\\n0 & 1 & \\cdots & 0 & -P_2 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n0 & 0 & \\cdots & 1 & -P_{n-1}\n\\end{pmatrix}.\n\\]\nIn particular, $\\det(g) = (-1)^n P_0 \\neq 0$, so $g \\in G$.\nOver an algebraic closure of $\\ZZ/p \\ZZ$, $g$ becomes diagonalizable with distinct eigenvalues, so any matrix commuting with $g$ must also be diagonalizable, and hence of odd order. In particular, $Z(\\{g\\})$ is of odd order, so Patniss has a winning strategy.\n\n\\noindent\n\\textbf{Remark:}\nIt can be shown that in the case $p=2$, the only elements $g \\in G$ for which $Z(\\{g\\})$ has odd order are those for which $g$ has distinct eigenvalues: in any other case, $Z(\\{g\\})$ contains a subgroup isomorphic to the group of $k \\times k$ invertible matrices over $\\ZZ/2\\ZZ$ for some $k>1$, and this group has order $(2^k-1)(2^k-2) \\cdots(2^k - 2^{k-1})$.\n\n\\noindent\n\\textbf{Remark:}\nWe sketch two ways to verify the existence of an irreducible polynomial of degree $n$ over $\\ZZ/p\\ZZ$ for any positive integer $n$ and any prime number $p$. One is to use M\\\"obius inversion to count the number of irreducible polynomials of degree $n$ over $\\ZZ/p\\ZZ$ and then give a positive lower bound for this count. The other is to first establish the existence of a finite field $\\FF$ of cardinality $p^n$, e.g., as the set of roots of the polynomial $x^{p^n}-1$ inside a splitting field, and then take the minimal polynomial of a nonzero element of $\\FF$ over $\\ZZ/p\\ZZ$ which is a primitive $(p^n-1)$-st root of unity in $\\FF$ (which exist because the multiplicative group of $\\FF$ contains at most one cyclic subgroup of any given order). One might be tempted to apply the primitive element theorem for $\\FF$ over $\\ZZ/p\\ZZ$, but in fact one of the preceding techniques is needed in order to verify this result for finite fields, as the standard argument that ``most'' elements of the upper field are primitive breaks down for finite fields.\n\nOne may also describe the preceding analysis in terms of an identification of $\\FF$ as a $\\ZZ/p\\ZZ$-vector space with the space of column vectors of length $n$. Under such an identification, if we take $g$ to be an element of $\\FF - \\{0\\}$ generating this group, then any element of $Z(\\{g\\})$ commutes with all of $\\FF- \\{0\\}$ and hence must define an $\\FF$-linear endomorphism of $\\FF$. Any such endomorphism is itself multiplication by an element of $\\FF$, so $Z(\\{g\\})$ is identified with the multiplicative group of $\\FF$, whose order is the odd number $2^n-1$."
  },
  {
    "year": 2014,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $f: [0,1] \\to \\mathbb{R}$ be a function for which there exists a constant $K>0$\nsuch that $\\left| f(x) - f(y) \\right| \\leq K \\left| x - y \\right|$ for all $x,y \\in [0,1]$.\nSuppose also that for each rational number $r \\in [0,1]$, there exist integers $a$ and $b$\nsuch that $f(r) = a + br$. Prove that there exist finitely many intervals $I_1, \\dots, I_n$\nsuch that $f$ is a linear function on each $I_i$ and $[0,1] = \\bigcup_{i=1}^n I_i$. \n\n\\end{itemize}\n\n\\end{document}",
    "solution": "Let us say that a linear function $g$ on an interval is \\emph{integral} if it has the form\n$g(x) = a + bx$ for some $a,b \\in \\ZZ$, and that a piecewise linear function is \\emph{integral} if on every interval where it is linear, it is also integral.\n\nFor each positive integer $n$, define the $n$-th \\emph{Farey sequence} $F_n$ as the sequence of rational numbers in $[0,1]$ with denominators at most $n$.\nIt is easily shown by induction on $n$ that any two consecutive elements $\\frac{r}{s}, \\frac{r'}{s'}$ of $F_n$, written in lowest terms, satisfy $\\gcd(s,s') = 1$, $s+s' > n$, and $r's - r s' = 1$. Namely, this is obvious for $n=1$ because $F_1 = \\frac{0}{1}, \\frac{1}{1}$. To deduce the claim for $F_n$ from the claim for $F_{n-1}$, let $\\frac{r}{s}, \\frac{r'}{s'}$ be consecutive elements of $F_{n-1}$. If $s+s' = n$, then for $m = r+r'$ we have $\\frac{r}{s} < \\frac{m}{n} < \\frac{r'}{s'}$ and the pairs $\\frac{r}{s},\\frac{m}{n}$ and $\\frac{m}{n}, \\frac{r'}{s'}$ \nsatisfy the desired conditions. Conversely, if $s+s' > n$, then we cannot have $\\frac{r}{s} < \\frac{m}{n} < \\frac{r'}{s'}$ for $a \\in \\ZZ$, as this yields the contradiction\n\\[\nn =(ms - nr)s' + (r'n - ms') \\geq s+s' > n;\n\\]\nhence $\\frac{r}{s}, \\frac{r'}{s'}$ remain consecutive in $F_n$. \n\nLet $f_n: [0,1] \\to \\RR$ be the piecewise linear function which agrees with $f$ at each element of $F_n$ and is linear between any two consecutive elements of $F_n$.\nBetween any two consecutive elements $\\frac{r}{s}, \\frac{r'}{s'}$ of $F_n$,\n$f_n$ coincides with some linear function $a+bx$. Since $s f(\\frac{r}{s}), s' f(\\frac{r'}{s'}) \\in \\ZZ$, we deduce first that\n\\[\nb = ss' (f(\\frac{r'}{s'}) - f(\\frac{r}{s}))\n\\]\nis an integer of absolute value at most $K$,\nand second that both $as = s f(\\frac{r}{s}) - br$ and $as' = s' f(\\frac{r'}{s'}) - br'$ are integral. It follows that $f_n$ is integral.\n\nWe now check that if $n > 2K$, then $f_n = f_{n-1}$. \nFor this, it suffices to check that for any consecutive elements $\\frac{r}{s}, \\frac{m}{n}, \\frac{r'}{s'}$ in $F_n$, the linear function $a_0 + b_0 x$ matching $f_{n-1}$ from $\\frac{r}{s}$ to $\\frac{r'}{s'}$ has the property that $f(\\frac{m}{n}) = a_0 + b_0 \\frac{m}{n}$. Define the integer $t = nf(\\frac{m}{n}) - a_0 n - b_0 m$. \nWe then compute that the slope of $f_n$ from $\\frac{r}{s}$ to $\\frac{m}{n}$ is $b_0+st$,\nwhile the slope of $f_n$ from $\\frac{m}{n}$ to $\\frac{r'}{s'}$ is at most $b_0 -s't$.\nIn order to have $\\left| b_0 + s t\\right|, \\left| b_0 - s' t\\right| \\leq K$, we must have\n$(s+s') \\left| t \\right| \\leq 2K$; since $s+s' = n > 2K$, this is only possible if $t=0$.\nHence $f_n = f_{n-1}$, as claimed.\n\nIt follows that for any $n > 2K$, we must have $f_n = f_{n+1} = \\cdots$. Since the condition on $f$ and $K$ implies that $f$ is continuous, we must also have $f_n = f$, completing the proof.\n\n\\noindent\n\\textbf{Remark:}\nThe condition on $f$ and $K$ is called \\emph{Lipschitz continuity}.\n\n\\noindent\n\\textbf{Remark:}\nAn alternate approach is to prove that for each $x  \\in [0,1)$, there exists $\\epsilon  \\in (0, 1-x)$ such that the restriction of $f$ to $[x, x+\\epsilon)$ is linear;\none may then deduce the claim using the compactness of $[0,1]$. In this approach, the role of the Farey sequence may also be played by the convergents of the continued fraction of $x$ (at least in the case where $x$ is irrational).\n\n\\noindent\n\\textbf{Remark:} This problem and solution are due to one of us (Kedlaya). Some related results can be proved with the Lipschitz continuity condition replaced by suitable convexity conditions.\n See for example: Kiran S. Kedlaya and Philip Tynan,\nDetecting integral polyhedral functions, \\textit{Confluentes Mathematici}\n\\textbf{1} (2009), 87--109.\nSuch results arise in the theory of $p$-adic differential equations; see for example:\nKiran S. Kedlaya and Liang Xiao, Differential modules on $p$-adic polyannuli, \\textit{J. Inst. Math. Jusssieu} \\textbf{9} (2010), 155--201 (errata, \\textit{ibid.}, 669--671).\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2015,
    "label": "A1",
    "difficulty": "1",
    "problem": "Let $A$ and $B$ be points on the same branch of the hyperbola $xy=1$. Suppose that $P$ is a point lying between $A$ and $B$ on this hyperbola, such that the area of the triangle $APB$ is as large as possible. Show that the region bounded by the hyperbola and the chord $AP$ has the same area as the region bounded by the hyperbola and the chord $PB$.",
    "solution": "\\textbf{First solution:}\nWithout loss of generality, assume that $A$ and $B$ lie in the first quadrant with $A = (t_1,1/t_1)$, $B = (t_2,1/t_2)$, and $t_1<t_2$. If $P = (t,1/t)$ with $t_1 \\leq t \\leq t_2$, then the area of triangle $APB$ is\n\\[\n\\frac{1}{2} \\left| \\begin{matrix} 1 & 1 & 1 \\\\ t_1 & t & t_2 \\\\ 1/t_1 & 1/t & 1/t_2 \\end{matrix} \\right| = \\frac{t_2-t_1}{2t_1t_2} (t_1+t_2-t-t_1t_2/t).\n\\]\nWhen $t_1,t_2$ are fixed, this is maximized when $t+t_1t_2/t$ is minimized, which by AM-GM exactly holds when $t = \\sqrt{t_1t_2}$.\n\nThe line $AP$ is given by $y = \\frac{t_1+t-x}{tt_1}$, and so the area of the region bounded by the hyperbola and $AP$ is\n\\[\n\\int_{t_1}^t \\left( \\frac{t_1+t-x}{tt_1} - \\frac{1}{x} \\right) \\,dx = \\frac{t}{2t_1}-\\frac{t_1}{2t}-\\log \\left(\\frac{t}{t_1} \\right),\n\\]\nwhich at $t = \\sqrt{t_1t_2}$ is equal to $\\frac{t_2-t_1}{2\\sqrt{t_1t_2}} - \\log(\\sqrt{t_2/t_1})$. Similarly, the area of the region bounded by the hyperbola and $PB$ is $\\frac{t_2}{2t}-\\frac{t}{2t_2}-\\log \\frac{t_2}{t}$, which at $t = \\sqrt{t_1t_2}$ is also $\\frac{t_2-t_1}{2\\sqrt{t_1t_2}} - \\log(\\sqrt{t_2/t_1})$, as desired.\n\n\\noindent\n\\textbf{Second solution:}\nFor any $\\lambda > 0$, the map $(x,y) \\mapsto (\\lambda x, \\lambda^{-1} y)$ preserves both areas and the hyperbola $xy=1$. We may thus rescale the picture so that\n$A,B$ are symmetric across the line $y=x$, with $A$ above the line. As $P$ moves from $A$ to $B$, the area of $APB$ increases until $P$ passes through the point $(1,1)$, then decreases. Consequently, $P = (1,1)$ achieves the maximum area, and the desired equality is obvious by symmetry.\nAlternatively, since the hyperbola is convex, the maximum is uniquely achieved at the point where the tangent line is parallel to $AB$, and by symmetry that point is $P$."
  },
  {
    "year": 2015,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $a_0=1$, $a_1=2$, and $a_n=4a_{n-1}-a_{n-2}$ for $n\\geq 2$. Find an odd prime factor of $a_{2015}$.",
    "solution": "\\noindent\n\\textbf{First solution:}\nOne possible answer is $181$.\nBy induction, we have $a_n = ((2+\\sqrt{3})^n+(2-\\sqrt{3})^n)/2 = (\\alpha^n+\\beta^n)/2$ for all $n$, where $\\alpha = 2+\\sqrt{3}$ and $\\beta = 2-\\sqrt{3}$. Now note that if $k$ is an odd positive integer and $a_n \\neq 0$, then\n$\\frac{a_{kn}}{a_n} = \\frac{\\alpha^{kn}+\\beta^{kn}}{\\alpha^n+\\beta^n}\n= \\alpha^{(k-1)n}-\\alpha^{(k-2)n}\\beta^n+\\cdots-\\alpha^n\\beta^{(k-2)n}+\\beta^{(k-1)n}$.\nThis expression is both rational (because $a_n$ and $a_{kn}$ are integers) and of the form $a+b\\sqrt{3}$ for some integers $a,b$ by the expressions for $\\alpha,\\beta$; it follows that it must be an integer, and so $a_{kn}$ is divisible by $a_n$. Applying this to $n=5$ and $k=403$, we find that $a_{2015}$ is divisible by $a_5 = 362$ and thus by $181$.\n\n\\noindent\n\\textbf{Second solution:}\nBy rewriting the formula for $a_n$ as $a_{n-2} = 4a_{n-1} - a_n$, we may extend the sequence backwards to define $a_n$ for all integers $n$. Since $a_{-1} = 2$, we may see by induction that $a_{-n} = a_n$ for all $n$. For any integer $m$ and any prime $p$ dividing $a_m$,\n$p$ also divides $a_{-m}$; on the other hand, $p$ cannot divide $a_{-m+1}$, as otherwise $p$ would also divide $a_{-m+2}, \\dots, a_0 = 1$, a contradiction. We can thus find an integer $k$ such that $a_{m+1} \\equiv k a_{-m+1} \\pmod{p}$; by induction on $n$, we see that\n$a_n \\equiv k a_{n-2m} \\pmod{p}$ for all $n$. In particular, if $k$ is odd, then $p$ also divides $a_{km}$; we thus conclude (again) that $a_{2015}$ is divisible by $a_5 = 362$ and thus by $181$.\n\n\\noindent\n\\textbf{Remark:}\nAlthough it was not needed in the solution, we note in passing that if $a_n \\equiv 0 \\pmod{p}$, then $a_{2n+k} \\equiv -a_{k} \\pmod{p}$ for all $k$.\n\n\\noindent\n\\textbf{Remark:} One can find other odd prime factors of $a_{2015}$ in the same manner. For example, $a_{2015}$ is divisible by each of the following quantities. (The prime factorizations were computed using\nthe \\texttt{Magma} computer algebra system.)\n\\begin{align*}\na_{13} &= 2 \\times 6811741 \\\\\na_{31} &= 2 \\times 373 \\times 360250962984637 \\\\\na_{5 \\cdot 13} &= 2 \\times 181 \\times 6811741 \\\\\n&\\quad \\times 3045046274679316654761356161 \\\\\na_{5 \\cdot 31} &= 1215497709121 \\times 28572709494917432101 \\\\\n&\\quad \\times\n13277360555506179816997827126375881581 \\\\\na_{13 \\cdot 31} &= 2 \\times 373 \\times 193441 \\times 6811741 \\times 360250962984637 \\\\\n&\\quad \\times 16866100753000669 \\\\\n&\\quad \\times 79988387992470656916594531961 \\times p_{156}\n\\end{align*}\nwhere $p_{156}$ is a prime of 156 decimal digits. Dividing $a_{2015}$ by the product of the primes appearing in this list yields a number $N$ of 824 decimal digits which is definitely not prime, because $2^N \\not\\equiv 2 \\pmod{N}$, but whose prime factorization we have been unable to establish. Note that $N$ is larger than a 2048-bit RSA modulus, so the difficulty of factoring it is not surprising.\n\nOne thing we can show is that each prime factor of $N$ is %divisible by \ncongruent to $1$ modulo \n$6 \\times 2015 = 12090$, thanks to the following lemma.\n\n\\begin{lemma*}\nLet $n$ be an odd integer. Then any odd prime factor $p$ of $a_n$ which does not divide $a_m$ for any divisor $m$ of $n$ is congruent to $1$ modulo $\\lcm(6,n)$. (By either solution of the original problem, $p$ also does not divide $a_m$ for any positive integer $m<n$.)\n\\end{lemma*}\n\\begin{proof}\nWe first check that $p \\equiv 1 \\pmod{3}$.\nIn $\\FF_q = \\FF_p(\\sqrt{3})$ we have $(\\alpha/\\beta)^n \\equiv -1$. If $p \\equiv 2 \\pmod{3}$,\nthen $q = p^2$ and $\\alpha$ and $\\beta$ are conjugate in $p$; consequently, the equality\n$\\alpha^n = -\\beta^n$ in $\\FF_{q^2}$ means that $\\alpha^n = c \\sqrt{3}$, $\\beta^n = - c \\sqrt{3}$ for some $c \\in \\FF_p$. But then $-3c^2 = \\alpha^n \\beta^n = 1$ in $\\FF_q$ and hence in $\\FF_p$, which contradicts $p \\equiv 2 \\pmod{3}$ by quadratic reciprocity.\n\nBy the previous paragraph, $\\alpha$ and $\\beta$ may be identified with elements of $\\FF_p$, and we have $(\\alpha/\\beta)^n \\equiv -1$, but the same does not hold with $n$ replaced by any smaller value. Since $\\FF_p^\\times$ is a cyclic group of order $p-1$, this forces $p \\equiv 1 \\pmod{n}$ as claimed.\n\\end{proof}"
  },
  {
    "year": 2015,
    "label": "A3",
    "difficulty": "3",
    "problem": "Compute\n\\[\n\\log_2 \\left( \\prod_{a=1}^{2015} \\prod_{b=1}^{2015} (1+e^{2\\pi i a b/2015}) \\right)\n\\]\nHere $i$ is the imaginary unit (that is, $i^2=-1$).",
    "solution": "The answer is $13725$.\nWe first claim that if $n$ is odd, then $\\prod_{b=1}^{n} (1+e^{2\\pi i ab/n}) = 2^{\\gcd(a,n)}$. To see this, write $d = \\gcd(a,n)$ and $a = da_1$, $n=dn_1$ with $\\gcd(a_1,n_1) = 1$. Then\n$a_1, 2a_1,\\dots,n_1 a_1$ modulo $n_1$ is a permutation of $1,2,\\dots,n_1$ modulo $n_1$, and so $\\omega^{a_1},\\omega^{2a_1},\\dots,\\omega^{n_1 a_1}$ is a permutation of $\\omega,\\omega^2,\\ldots,\\omega^{n_1}$;  it follows that for $\\omega = e^{2\\pi i/n_1}$,\n\\[\n\\prod_{b=1}^{n_1} (1+e^{2\\pi i a b/n}) =\n\\prod_{b=1}^{n_1} (1+e^{2\\pi i a_1 b/n_1}) = \\prod_{b=1}^{n_1} (1+\\omega^b).\n\\]\nNow since the roots of $z^{n_1}-1$ are $\\omega,\\omega^2,\\ldots,\\omega^{n_1}$, it follows that\n$z^{n_1}-1 = \\prod_{b=1}^{n_1} (z-\\omega^b)$. Setting $z=-1$ and using the fact that $n_1$ is odd gives $\\prod_{b=1}^{n_1} (1+\\omega^b) = 2$. \n\nFinally,\n$\\prod_{b=1}^{n} (1+e^{2\\pi i ab/n}) = (\\prod_{b=1}^{n_1} (1+e^{2\\pi i ab/n}))^d = 2^d$, and we have proven the claim.\n\nFrom the claim, we find that\n\\begin{align*}\n&\\log_2 \\left( \\prod_{a=1}^{2015} \\prod_{b=1}^{2015} (1+e^{2\\pi i a b/2015}) \\right) \\\\\n&= \\sum_{a=1}^{2015} \\log_2 \\left(\\prod_{b=1}^{2015} (1+e^{2\\pi i a b/2015}) \\right) \\\\\n&= \\sum_{a=1}^{2015} \\gcd(a,2015).\n\\end{align*}\nNow for each divisor $d$ of $2015$, there are $\\phi(2015/d)$ integers between $1$ and $2015$ inclusive whose $\\gcd$ with $2015$ is $d$. Thus\n\\[\n\\sum_{a=1}^{2015} \\gcd(a,2015) = \\sum_{d|2015} d\\cdot \\phi(2015/d).\n\\]\nWe factor $2015 = pqr$ with $p=5$, $q=13$, and $r=31$, and calculate\n\\begin{align*}\n&\\sum_{d|pqr} d\\cdot \\phi(pqr/d) \\\\\n&= 1 \\cdot (p-1)(q-1)(r-1) + p \\cdot (q-1)(r-1) \\\\\n&\\quad + q\\cdot (p-1)(r-1) + r\\cdot (p-1)(q-1) + pq \\cdot (r-1) \\\\\n& \\quad + pr\\cdot (q-1) + qr\\cdot (p-1) + pqr \\cdot 1 \\\\\n&\\quad = (2p-1)(2q-1)(2r-1).\n\\end{align*}\nWhen $(p,q,r) = (5,13,31)$, this is equal to $13725$.\n\n\\noindent\n\\textbf{Remark:}\nNoam Elkies suggests the following similar but shorter derivation of the equality\n$\\prod_{b=1}^{n_1} (1 + \\omega^b) = 2$: write\n\\[\n\\prod_{b=1}^{n_1-1} (1 + \\omega^b) = \\frac{\\prod_{b=1}^{n_1 - 1} (1 - \\omega^{2b})}{\\prod_{b=1}^{n_1-1} (1 - \\omega^b)}\n\\]\nand note (as above) that $\\omega^2, \\omega^{4}, \\dots, \\omega^{2(n_1-1)}$ is a permutation of $\\omega, \\dots, \\omega^{n_1-1}$, so the two products in the fraction are equal.\n\n\\noindent\n\\textbf{Remark:}\nThe function $f(n) = \\sum_{d|n} d\\cdot \\phi(n/d)$ is multiplicative: for any two coprime positive integers $m,n$, we have $f(mn) = f(m) f(n)$. This follows from the fact that $f(n)$ is the convolution of the two multiplicative functions $n \\mapsto n$ and $n \\mapsto \\phi(n)$; it can also be seen directly using the Chinese remainder theorem."
  },
  {
    "year": 2015,
    "label": "A4",
    "difficulty": "4",
    "problem": "For each real number $x$, let\n\\[\nf(x) = \\sum_{n\\in S_x} \\frac{1}{2^n},\n\\]\nwhere $S_x$ is the set of positive integers $n$ for which $\\lfloor nx \\rfloor$ is even. What is the largest real number $L$ such that $f(x) \\geq L$ for all $x \\in [0,1)$? (As usual, $\\lfloor z \\rfloor$ denotes the greatest integer less than or equal to $z$.)",
    "solution": "The answer is $L = 4/7$. For $S \\subset \\mathbb{N}$, let $F(S) = \\sum_{n\\in S} 1/2^n$, so that $f(x) = F(S_x)$. Note that for $T = \\{1,4,7,10,\\ldots\\}$, we have $F(T) = 4/7$.\n\nWe first show by contradiction that for any $x \\in [0,1)$, $f(x) \\geq 4/7$.\nSince each term in the geometric series $\\sum_n 1/2^n$ is equal to the sum of all subsequent terms, if $S,S'$ are different subsets of $\\mathbb{N}$ and the smallest positive integer in one of $S,S'$ but not in the other is in $S$, then $F(S) \\geq F(S')$. Assume $f(x) < 4/7$; then the smallest integer in one of $S_x,T$ but not in the other is in $T$. Now $1 \\in S_x$ for any $x \\in [0,1)$, and we conclude that there are three consecutive integers $n,n+1,n+2$ that are not in $S_x$: that is, $\\lfloor nx\\rfloor$, $\\lfloor (n+1)x\\rfloor$, $\\lfloor (n+2)x\\rfloor$ are all odd. Since the difference between consecutive terms in $nx$, $(n+1)x$, $(n+2)x$ is $x<1$, we conclude that $\\lfloor nx\\rfloor = \\lfloor (n+1)x\\rfloor = \\lfloor (n+2)x\\rfloor$ and so $x<1/2$. But then $2\\in S_x$ and so $f(x) \\geq 3/4$, contradicting our assumption.\n\nIt remains to show that $4/7$ is the greatest lower bound for $f(x)$, $x\\in [0,1)$.\nFor any $n$, choose $x = 2/3-\\epsilon$ with $0<\\epsilon<1/(9n)$; then for $1\\leq k\\leq n$, we have $0<m\\epsilon<1/3$ for $m \\leq 3n$, and so\n\\begin{align*}\n\\lfloor (3k-2)x \\rfloor &= \\lfloor (2k-2)+2/3-(3k-2)\\epsilon \\rfloor = 2k-2 \\\\\n\\lfloor (3k-1)x \\rfloor &= \\lfloor (2k-1)+1/3-(3k-1)\\epsilon \\rfloor = 2k-1 \\\\\n\\lfloor (3k)x \\rfloor &= \\lfloor (2k-1)+1-3k\\epsilon \\rfloor = 2k-1.\n\\end{align*}\nIt follows that $S_x$ is a subset of $S = \\{1,4,7,\\ldots,3n-2,3n+1,3n+2,3n+3,\\ldots\\}$, and so\n$f(x) = F(S_x) \\leq f(S) = (1/2+1/2^4+\\cdots+1/2^{3n+1})+1/2^{3n+1}$. This last expression tends to $4/7$ as $n\\to\\infty$, and so no number greater than $4/7$ can be a lower bound for $f(x)$ for all $x\\in [0,1)$."
  },
  {
    "year": 2015,
    "label": "A5",
    "difficulty": "5",
    "problem": "Let $q$ be an odd positive integer, and let $N_q$ denote the number of integers $a$ such that $0 < a < q/4$ and $\\gcd(a,q) = 1$. Show that $N_q$ is odd if and only if $q$ is of the form $p^k$ with $k$ a positive integer and $p$ a prime congruent to $5$ or $7$ modulo $8$.",
    "solution": "\\textbf{First solution:}\nBy inclusion-exclusion, we have\n\\begin{align*}\nN_q    &= \\sum_{d|q} \\mu(d) \\left\\lfloor \\frac{\\lfloor q/4\\rfloor}{d} \\right\\rfloor \\\\\n       &= \\sum_{d|q} \\mu(d) \\left\\lfloor \\frac{q/d}{4} \\right\\rfloor \\\\\n  &\\equiv \\sum_{d|q \\mbox{\\, \\small squarefree}} \\left\\lfloor \\frac{q/d}{4}  \\right\\rfloor  \\pmod{2},\n\\end{align*}\nwhere $\\mu$ is the M\\\"obius function.\nNow\n\\[\n\\left\\lfloor \\frac{q/d}{4} \\right\\rfloor \\equiv \\begin{cases} 0 \\pmod{2} & \\mbox{if } q/d\\equiv 1, 3 \\pmod{8} \\\\\n1 \\pmod{2} & \\mbox{if } q/d\\equiv 5, 7 \\pmod{8}.\n\\end{cases}\n\\]\nSo $N_q$ is odd if and only if $q$ has an odd number of squarefree factors $q/d$ congruent to $5$ or $7$ (mod~8).\n\nIf $q$ has a prime factor $p$ congruent to 1 or 3 (mod~8), then the squarefree factors $d$ of $q$ occur in pairs $c,pc$, which are either both 1 or 3 (mod~8) or both 5 or 7 (mod~8).  Hence $q$ must have an even number of factors that are congruent to $5$ or $7$ (mod~8), and so $N_q$ is even in this case.\n\nIf $q$ has two prime factors $p_1$ and $p_2$, each congruent to either 5 or 7 (mod~8), then the squarefree factors $d$ of $q$ occur in quadruples $d,p_1d,q_1d,p_1q_1d$, which are then congruent respectively to some permutation of 1,3,5,7 (mod~8) (if $p_1$ and $p_2$ are distinct mod 8) or are congruent respectively to $d,p_1d,p_1d,d$ (mod~8). Either way, we see that exactly two of the four residues are congruent to $5$ or $7$ (mod~8).  Thus again $q$ must have an even number of factors that are $5$ or $7$ (mod~8), and so $N_q$ is even in this case as well.\n\nIf $q=1$, then $N_q=0$ is even.  The only case that remains is that $q=p^k$ is a positive power of a prime $p$ congruent to 5 or 7 (mod~8).  In this case, $q$ has two squarefree factors, $1$ and $p$, of which exactly one is congruent to $5$ or $7$ (mod~8).  We conclude that $N_q$ is odd in this case, as desired.\n\n\\noindent\n\\textbf{Second solution:}\n\nConsider the set $S$ of all integers in $\\{1,\\ldots,q-1\\}$ that are even and relatively prime to $q$.  Then the product of all elements in $S$ is\n\\[\n2^{\\phi(q)/2}\\prod_{{1\\leq a\\leq (q-1)/2}\\atop{(a,q)=1}} a.\n\\]\nOn the other hand, we can rewrite the set of elements in $S \\pmod{q}$ as a set $T$ of residues in the interval $[-(q-1)/2,(q-1)/2]$.  Then for each $1\\leq a\\leq (q-1)/2$ with $(a,q)=1$, $T$ contains exactly one element from $\\{a,-a\\}$: if $-2r \\equiv 2s \\pmod{q}$ for some $r,s\\in\\{1,\\ldots,(q-1)/2\\}$, then $r \\equiv -s \\pmod{q}$, which is impossible given the ranges of $r$ and $s$.  Thus the product of all elements in $T$ is\n\\[\n(-1)^n \\prod_{{1\\leq a\\leq (q-1)/2}\\atop{(a,q)=1}} a,\n\\]\nwhere $n$ denotes the number of elements of $S$ greater than $(q-1)/2$.\nWe conclude that $(-1)^n \\equiv 2^{\\phi(q)/2} \\pmod{q}$.\n\nHowever, note that the number of elements of $S$ less than $(q-1)/2$ is equal to $N_q$, since dividing these numbers by 2 gives exactly the numbers counted by $N_q$. Hence the total cardinality of $S$ is $N_q + n$; however, this cardinality also equals $\\phi(q)/2$ because the numbers in $\\{1,\\dots,q-1\\}$ relatively prime to $q$ come in pairs\n$\\{a,q-a\\}$ in each of which exactly one member is even. We thus obtain\n\\begin{align*}\n(-1)^{N_q} &= (-1)^{\\phi(q)/2 + n} \\\\\n&\\equiv (-1)^{\\phi(q)/2} 2^{\\phi(q)/2} = (-2)^{\\phi(q)/2} \\pmod{q}.\n\\end{align*}\nIf $q=1$, then $N_q$ is even.  If $q$ has more than one prime factor, then the group $(\\mathbb{Z}/q\\mathbb{Z})^\\times$ has exponent dividing $\\phi(q)/2$, so $(-1)^{N_q}\\equiv (-2)^{\\phi(q)/2} \\equiv 1 \\pmod{q}$, and thus $N_q$ must be even in this case as well.  Finally, suppose that $q$ is a prime power $p^k$ with $p$ odd and $k$ positive.  Since $(\\mathbb{Z}/q\\mathbb{Z})^\\times$ is a cyclic group of order $\\phi(q)=p^{k-1}(p-1)$, in which the only square roots of unity are $\\pm 1$, it follows that $(-2)^{\\phi(q)/2}\\equiv \\pm 1 \\pmod{q}$ in accordance with whether $(-2)^{(p-1)/2} \\equiv \\pm 1 \\pmod{p}$, i.e., whether $-2$ is a quadratic residue or nonresidue.  But recall that $-2$ is a quadratic residue modulo $p$ if and only if $p\\equiv 1, 3 \\pmod{8}$. Thus $N_q$ is odd in this case if and only if $p\\equiv 5$ or $7 \\pmod{8}$.\n\nWe conclude that for any odd integer $q\\geq 1$, the quantity $N_q$ is odd if and only if $q=p^k$ with $k$ positive and $p$ a prime that is 5 or 7 (mod~8).\n\n\\noindent\n\\textbf{Remark:} The combination of the two solutions recovers Gauss's criterion for when $-2$ is a quadratic residue modulo $p$, with essentially the original proof."
  },
  {
    "year": 2015,
    "label": "A6",
    "difficulty": "6",
    "problem": "Let $n$ be a positive integer. Suppose that $A$, $B$, and $M$ are $n\\times n$ matrices with real entries such that $AM = MB$, and such that $A$ and $B$ have the same characteristic polynomial. Prove that $\\det(A-MX) = \\det(B-XM)$ for every $n\\times n$ matrix $X$ with real entries.",
    "solution": "\\textbf{First solution:}\n(by Noam Elkies)\nUsing row and column operations, we may construct invertible matrices $U,V$ such that\n$U^{-1} M V$ is a block diagonal matrix of the form\n\\[\n\\begin{pmatrix} I & 0 \\\\ 0 & 0 \\end{pmatrix}.\n\\]\nPut $A' = U^{-1} A U, M' = U^{-1} M V, B' = V^{-1} B V$, $X' = V^{-1} X U$,\nso that $A' M' = M' B'$,\n$\\det(A-MX) = \\det(U^{-1}(A-MX)U) = \\det(A' - M'X')$,\nand\n$\\det(B-XM) = \\det(V^{-1}(B-XM)V) = \\det(B' - X'M')$.\nForm the corresponding block decompositions\n\\[\nA' = \\begin{pmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{pmatrix},\nB' = \\begin{pmatrix} B_{11} & B_{12} \\\\ B_{21} & B_{22} \\end{pmatrix},\nX' = \\begin{pmatrix} X_{11} & X_{12} \\\\ X_{21} & X_{22} \\end{pmatrix}.\n\\]\nWe then have\n\\[\nA' M' = \\begin{pmatrix} A_{11} & 0 \\\\ A_{21} & 0 \\end{pmatrix}, \\qquad\nM' B' = \\begin{pmatrix} B_{11} & B_{12} \\\\ 0 & 0 \\end{pmatrix},\n\\]\nso we must have $A_{11} = B_{11}$ and $A_{21} = B_{12} = 0$;\nin particular, the characteristic polynomial of $A$ is the product of the characteristic polynomials of $A_{11}$ and $A_{22}$, and the characteristic polynomial of $B$ is the product of the characteristic polynomials of $B_{11}$ and $B_{22}$. Since $A_{11} = B_{11}$, it follows that $A_{22}$ and $B_{22}$ have the same characteristic polynomial.\nSince\n\\[\nX' M' = \\begin{pmatrix} X_{11} & 0 \\\\ X_{21} & 0 \\end{pmatrix}, \\qquad\nM' X' = \\begin{pmatrix} X_{11} & X_{12} \\\\ 0 & 0 \\end{pmatrix},\n\\]\nwe conclude that\n\\begin{align*}\n\\det(A-MX) &= \\det(A'-M'X') \\\\\n&= \\det \\begin{pmatrix} A_{11}-X_{11} & A_{12} - X_{12} \\\\ 0 & A_{22} \\end{pmatrix} \\\\\n&= \\det(A_{11}-X_{11}) \\det(A_{22}) \\\\\n&= \\det(B_{11}-X_{11}) \\det(B_{22}) \\\\\n&= \\det \\begin{pmatrix} B_{11}-X_{11} & 0 \\\\ B_{21}-X_{21} & B_{22} \\end{pmatrix} \\\\\n&= \\det(B'-X'M') \\\\\n&= \\det(B-XM),\n\\end{align*}\nas desired. (By similar arguments, $A-MX$ and $B-XM$ have the same characteristic polynomial.)\n\n\\noindent\n\\textbf{Second solution:}\nWe prove directly that $A-MX$ and $B-XM$ have the same characteristic polynomial, i.e., for any $t \\in \\mathbb{R}$, writing $A_t = A-tI$, $B_t = B-tI$, we have\n\\[\n\\det(A_t - MX) = \\det(B_t - XM).\n\\]\nFor fixed $A,B,M$, the stated result is a polynomial identity in $t$ and the entries of $X$. It thus suffices to check it assuming that $A_t,B_t, X$ are all invertible.\nSince $AM = MB$, we also have $A_t M = M B_t$, so $A_tMB_t^{-1} = M$.\nSince $\\det(A_t) = \\det(B_t)$ by hypothesis,\n\\begin{align*}\n\\det(A_t - MX) &= \\det (A_t - A_tM B_t^{-1} X)\\\\\n&= \\det(A_t) \\det(1 - M B_t^{-1} X) \\\\\n&= \\det(A_t) \\det(X) \\det(B_t)^{-1} \\det(X^{-1} B_t - M) \\\\\n&= \\det(X) \\det(X^{-1} B_t - M) \\\\\n&= \\det(B_t - XM).\n\\end{align*}\n\n\\noindent\n\\textbf{Remark:}\nOne can also assert directly that\n$\\det(1 - M B_t^{-1} X) = \\det(1 - X M B_t^{-1})$ using the fact that for any square matrices $U$ and $V$, $UV$ and $VU$ have the same characteristic polynomial; \nthe latter is again proved by reducing to the case where one of the two matrices is invertible, in which case the two matrices are similar.\n\n\\noindent\n\\textbf{Third solution:}\n(by Lev Borisov)\nWe will check that for each positive integer $k$,\n\\[\n\\Trace((A-MX)^k) = \\Trace((B- XM)^k).\n\\]\nThis will imply that $A-MX$ and $B-XM$ have the same characteristic polynomial, yielding the desired result.\n\nWe establish the claim by expanding both sides and comparing individual terms.\nBy hypothesis, $A^k$ and $B^k$ have the same characteristic polynomial, so\n$\\Trace(A^k) = \\Trace(B^k)$. \nTo compare the other terms, it suffices to check that for any sequence $i_1, i_2,\\dots, i_m$ of nonnegative integers,\n\\begin{align*}\n& \\Trace(A^{i_1} MX A^{i_2} MX \\cdots A^{i_{m-1}} MX A^{i_m})\\\\\n&\\quad =\n\\Trace(B^{i_1} XM B^{i_2} XM \\cdots B^{i_{m-1}} XM B^{i_m}).\n\\end{align*}\nTo establish this equality, first apply the remark following the previous solution to write\n\\begin{align*}\n& \\Trace(A^{i_1} MX A^{i_2} MX \\cdots A^{i_{m-1}} MX A^{i_m})\\\\\n&\\quad =\n\\Trace(A^{i_m + i_1} MX A^{i_2} MX \\cdots A^{i_{m-1}} MX).\n\\end{align*}\nThen apply the relation $AM = MB$ repeatedly to commute $M$ past $A$, to obtain\n\\[\n\\Trace(M B^{i_m + i_1} X M B^{i_2} XM \\cdots XM B^{i_{m-1}} X).\n\\]\nFinally, apply the remark again to shift $MB^{i_m}$ from the left end to the right end.\n\n\\noindent\n\\textbf{Remark:}\nThe conclusion holds with $\\RR$ replaced by an arbitrary field.\nIn the second solution, one must reduce to the case of an infinite field, e.g., by replacing the original field with an algebraic closure. The third solution only applies to fields of characteristic 0 or positive characteristic greater than $n$.\n\n\\noindent\n\\textbf{Remark:}\nIt is tempting to try to reduce to the case where $M$ is invertible, as in this case $A-MX$ and $B-XM$ are in fact similar. However, it is not clear how to make such an argument work."
  },
  {
    "year": 2015,
    "label": "B1",
    "difficulty": "1",
    "problem": "Let $f$ be a three times differentiable function (defined on $\\mathbb{R}$ and real-valued) such that $f$ has at least five distinct real zeros. Prove that $f + 6f' + 12f'' + 8f'''$ has at least two distinct real zeros.",
    "solution": "Let $g(x) = e^{x/2} f(x)$. Then $g$ has at least $5$ distinct real zeroes,\nand by repeated applications of Rolle's theorem, $g', g'', g'''$ have at least $4,3,2$ distinct real zeroes, respectively. But\n\\[\ng'''(x) = \\frac{1}{8} e^{x/2} (f(x) + 6 f'(x) + 12 f''(x) + 8 f'''(x))\n\\]\nand $e^{x/2}$ is never zero, so we obtain the desired result."
  },
  {
    "year": 2015,
    "label": "B2",
    "difficulty": "2",
    "problem": "Given a list of the positive integers $1,2,3,4,\\dots$, take the first three numbers\n$1,2,3$ and their sum $6$ and cross all four numbers off the list. Repeat with the three \nsmallest remaining numbers $4,5,7$ and their sum $16$. Continue in this way, crossing off the three smallest remaining numbers and their sum, and consider the sequence of sums produced: $6, 16, 27, 36, \\dots$. Prove or disprove that there is some number in the sequence whose base 10 representation ends with $2015$.\n\n\\,",
    "solution": "We will prove that 42015 is such a number in the sequence.\nLabel the sequence of sums $s_0, s_1, \\dots$, and let $a_n, b_n, c_n$ be the summands of $s_n$ in ascending order. We prove the following two statements for each nonnegative integer $n$: \\begin{enumerate}"
  },
  {
    "year": 2015,
    "label": "B3",
    "difficulty": "3",
    "problem": "Let $S$ be the set of all $2 \\times 2$ real matrices\n\\[\nM = \\begin{pmatrix} a & b \\\\\nc & d \\end{pmatrix}\n\\]\nwhose entries $a,b,c,d$ (in that order) form an arithmetic progression. Find all matrices $M$ in $S$ for which there is some integer $k>1$ such that $M^k$ is also in $S$.",
    "solution": "\\textbf{First solution:}\nAny element of $S$ can be written as $M = \\alpha A + \\beta B$, where $A = \\left( \\begin{smallmatrix} 1 & 1 \\\\ 1 & 1 \\end{smallmatrix} \\right)$, $B = \\left( \\begin{smallmatrix} -3 & -1 \\\\ 1 & 3 \\end{smallmatrix} \\right)$, and $\\alpha,\\beta \\in \\mathbb{R}$. Note that $A^2 = \\left( \\begin{smallmatrix} 4 & 4 \\\\ 4 & 4 \\end{smallmatrix} \\right)$ and\n$B^3 = \\left( \\begin{smallmatrix} -24 & -8 \\\\ 8 & 24 \\end{smallmatrix} \\right)$ are both in $S$, and so any matrix of the form $\\alpha A$ or $\\beta B$, $\\alpha,\\beta\\in\\mathbb{R}$, satisfies the given condition.\n\nWe claim that these are also the only matrices in $S$ satisfying the given condition. Indeed, suppose $M = \\alpha A + \\beta B$ where $\\alpha,\\beta \\neq 0$. Let $C = \\left( \\begin{smallmatrix} 1 & 1/\\sqrt{2} \\\\ -1 & 1/\\sqrt{2} \\end{smallmatrix} \\right)$ with inverse\n$C^{-1} = \\left( \\begin{smallmatrix} 1/2 & -1/2 \\\\ 1/\\sqrt{2} & 1/\\sqrt{2} \\end{smallmatrix} \\right)$. If we define $D = C^{-1}MC$, then $D = 2\\alpha \\left( \\begin{smallmatrix} 0 & \\gamma \\\\ \\gamma & 1 \\end{smallmatrix} \\right)$ where $\\gamma = -\\frac{\\beta\\sqrt{2}}{\\alpha}$. Now suppose that $M^k$ is in $S$ with $k\\geq 2$. Since $\\left( \\begin{smallmatrix} 1 & -1 \\end{smallmatrix} \\right) A \\left( \\begin{smallmatrix} 1 \\\\ -1 \\end{smallmatrix} \\right) = \\left( \\begin{smallmatrix} 1 & -1 \\end{smallmatrix} \\right) B \\left( \\begin{smallmatrix} 1 \\\\ -1 \\end{smallmatrix} \\right) = 0$,\nwe have $\\left( \\begin{smallmatrix} 1 & -1 \\end{smallmatrix} \\right) M^k \\left( \\begin{smallmatrix} 1 \\\\ -1 \\end{smallmatrix} \\right) = 0$, and so the upper left entry of $C^{-1} M^k C = D^k$ is $0$. On the other hand, from the expression for $D$, an easy induction on $k$ shows that\n$D^k = (2\\alpha)^k \\left( \\begin{smallmatrix} \\gamma^2 p_{k-1} & \\gamma p_k \\\\\n\\gamma p_k & p_{k+1} \\end{smallmatrix} \\right)$, where $p_k$ is defined inductively by $p_0 = 0$, $p_1 = 1$, $p_{k+2} = \\gamma^2 p_k + p_{k+1}$. In particular, it follows from the inductive definition that $p_k > 0$ when $k \\geq 1$, whence the upper left entry of $D^k$ is nonzero when $k \\geq 2$, a contradiction.\n\n\\noindent\n\\textbf{Remark:}\nA variant of this solution can be obtained by diagonalizing the matrix $M$.\n\n\\textbf{Second solution:}\nIf $a,b,c,d$ are in arithmetic progression, then we may write\n\\[\na = r-3s, b=r-s, c=r+s, d=r+3s\n\\]\nfor some $r,s$. If $s=0$, then clearly all powers of $M$ are in $xS$. Also, if $r=0$, then one easily checks that $M^3$ is in $S$.\n\nWe now assume $rs\\neq 0$, and show that in that case $M$ cannot be in $S$. First, note that the characteristic polynomial of $M$ is $x^2-2rx-8s^2$, and since $M$ is nonsingular (as $s\\neq 0$), this is also the minimal polynomial of $M$ by the Cayley-Hamilton theorem.  By repeatedly using the relation $M^2=2rM+8s^2I$, we see that for each positive integer, we have $M^k = t_k M + u_k I$ for unique real constants $t_k, u_k$ (uniqueness follows from the independence of $M$ and $I$).  Since $M$ is in $S$, we see that $M^k$ lies in $S$ only if $u_k=0$.\n\nOn the other hand, we claim that if $k>1$, then $rt_k>0$ and $u_k>0$ if $k$ is even, and $t_k>0$ and $ru_k>0$ if $k$ is odd (in particular, $u_k$ can never be zero).  The claim is true for $k=2$ by the relation $M^2=2rM+8s^2I$. Assuming the claim for $k$, and multiplying both sides of the relation $M^k = t_k M + u_k I$ by $M$, yields\n\\[\nM^{k+1} = t_k (2rM+8s^2I) + u_k M = (2rt_k+u_k) M + 8s^2t_k I,\n\\]\nimplying the claim for $k+1$.\n\n\\noindent\n\\textbf{Remark:}\n(from \\url{artofproblemsolving.com}, user \\texttt{hoeij})\nOnce one has $u_k = 0$, one can also finish using the relation $M \\cdot M^k = M^k \\cdot M$."
  },
  {
    "year": 2015,
    "label": "B4",
    "difficulty": "4",
    "problem": "Let $T$ be the set of all triples $(a,b,c)$ of positive integers for which there exist triangles with side lengths $a,b,c$. Express\n\\[\n\\sum_{(a,b,c) \\in T} \\frac{2^a}{3^b 5^c} \n\\]\nas a rational number in lowest terms.",
    "solution": "\\textbf{First solution:}\nThe answer is $17/21$. For fixed $b,c$, there is a triangle of side lengths $a,b,c$ if and only if $|b-c|<a<b+c$. It follows that the desired sum is\n\\[\nS = \\sum_{b,c} \\frac{1}{3^b5^c} \\left(\\sum_{a=|b-c|+1}^{b+c-1} 2^a \\right) = \\sum_{b,c} \\frac{2^{b+c}-2^{|b-c|+1}}{3^b5^c}.\n\\]\nWe write this as $S = S_1+S_2$ where $S_1$ sums over positive integers $b,c$ with $b\\leq c$ and $S_2$ sums over $b>c$. Then\n\\begin{align*}\nS_1 &= \\sum_{b=1}^\\infty \\sum_{c=b}^\\infty \\frac{2^{b+c}-2^{c-b+1}}{3^b 5^c} \\\\\n&= \\sum_{b=1}^\\infty \\left( \\left( \\left(\\frac{2}{3}\\right)^b-\\frac{2}{6^b} \\right) \\sum_{c=b}^\\infty \\left(\\frac{2}{5} \\right)^c \\right) \\\\\n&= \\sum_{b=1}^\\infty \\left( \\left(\\frac{2}{3}\\right)^b-\\frac{2}{6^b} \\right) \\frac{5}{3} \\left( \\frac{2}{5} \\right)^b \\\\\n&= \\sum_{b=1}^\\infty \\left( \\frac{5}{3} \\left(\\frac{4}{15}\\right)^b - \\frac{10}{3} \\left(\\frac{1}{15}\\right)^b \\right) \\\\\n&= \\frac{85}{231}.\n\\end{align*}\nSimilarly,\n\\begin{align*}\nS_2 &= \\sum_{c=1}^\\infty \\sum_{b=c+1}^\\infty \\frac{2^{b+c}-2^{b-c+1}}{3^b 5^c} \\\\\n&= \\sum_{c=1}^\\infty \\left( \\left( \\left(\\frac{2}{5}\\right)^c-\\frac{2}{10^c} \\right) \\sum_{b=c+1}^\\infty \\left(\\frac{2}{3} \\right)^b \\right) \\\\\n&= \\sum_{c=1}^\\infty \\left( \\left(\\frac{2}{5}\\right)^c-\\frac{2}{10^c} \\right) 3 \\left( \\frac{2}{3} \\right)^{c+1} \\\\\n&= \\sum_{c=1}^\\infty \\left( 2 \\left(\\frac{4}{15}\\right)^c - 4 \\left(\\frac{1}{15}\\right)^c \\right) \\\\\n&= \\frac{34}{77}.\n\\end{align*}\nWe conclude that $S = S_1+S_2 = \\frac{17}{21}$.\n\n\\noindent\n\\textbf{Second solution:}\nRecall that the real numbers $a,b,c$ form the side lengths of a triangle if and only if\n\\[\ns-a, s-b, s-c > 0 \\qquad s = \\frac{a+b+c}{2},\n\\]\nand that if we put $x = 2(s-a), y = 2(s-b), z = 2(s-c)$,\n\\[\na = \\frac{y+z}{2}, b = \\frac{z+x}{2}, c = \\frac{x+y}{2}.\n\\]\nTo generate all \\emph{integer} triples $(a,b,c)$ which form the side lengths of a triangle, we must also assume that $x,y,z$ are either all even or all odd. We may therefore write the original sum as\n\\[\n%\\sum_{(a,b,c) \\in T} \\frac{2^a}{3^b 5^c}\n%=\n\\sum_{x,y,z >0 \\mbox{\\small \\,odd}} \\frac{2^{(y+z)/2}}{3^{(z+x)/2} 5^{(x+y)/2}}\n+ \\sum_{x,y,z >0 \\mbox{\\small \\,even}} \\frac{2^{(y+z)/2}}{3^{(z+x)/2} 5^{(x+y)/2}}.\n\\]\nTo unify the two sums, we substitute in the first case  $x = 2u+1, y = 2v+1, z = 2w+1$ and in the second case $x = 2u+2, y = 2v+2, z = 2w+2$ to obtain\n\\begin{align*}\n\\sum_{(a,b,c) \\in T} \\frac{2^a}{3^b 5^c}\n&= \\sum_{u,v,w=1}^\\infty \\frac{2^{v+w}}{3^{w+u} 5^{u+v}} \\left( 1 + \\frac{2^{-1}}{3^{-1} 5^{-1}} \\right) \\\\\n&= \\frac{17}{2} \\sum_{u=1}^\\infty \\left( \\frac{1}{15} \\right)^u \\sum_{v=1}^\\infty\n\\left( \\frac{2}{5} \\right)^v \\sum_{w=1}^\\infty \\left( \\frac{2}{3} \\right)^w \\\\\n&= \\frac{17}{2} \\frac{1/15}{1-1/15} \\frac{2/5}{1-2/5} \\frac{2/3}{1-2/3} \\\\\n&= \\frac{17}{21}.\n\\end{align*}"
  },
  {
    "year": 2015,
    "label": "B5",
    "difficulty": "5",
    "problem": "Let $P_n$ be the number of permutations $\\pi$ of $\\{1,2,\\dots,n\\}$ such that\n\\[\n|i-j| = 1 \\mbox{ implies } |\\pi(i) -\\pi(j)| \\leq 2\n\\]\nfor all $i,j$ in $\\{1,2,\\dots,n\\}$. Show that for $n \\geq 2$, the quantity\n\\[\nP_{n+5} - P_{n+4} - P_{n+3} + P_n\n\\]\ndoes not depend on $n$, and find its value.",
    "solution": "The answer is 4.\n\nAssume $n \\geq 3$ for the moment.\nWe write the permutations $\\pi$ counted by $P_n$ as sequences $\\pi(1),\\pi(2),\\ldots,\\pi(n)$.  Let $U_n$ be the number of permutations counted by $P_n$ that end with $n-1,n$; let $V_n$ be the number ending in $n,n-1$; let $W_n$ be the number starting with $n-1$ and ending in $n-2,n$; let $T_n$ be the number ending in $n-2,n$ but not starting with $n-1$; and let $S_n$ be the number which has $n-1,n$ consecutively in that order, but not at the beginning or end.\nIt is clear that every permutation $\\pi$ counted by $P_n$ either lies in exactly one of the sets counted by $U_n, V_n, W_n, T_n, S_n$, or is the reverse of such a permutation.  Therefore\n\\[\nP_n = 2 (U_n + V_n + W_n+ T_n+ S_n).\n\\]\nBy examining how each of the elements in the sets counted by $U_{n+1}, V_{n+1}, W_{n+1}, T_{n+1}, S_{n+1}$ can be obtained from a (unique) element in one of the sets counted by $U_n, V_n, W_n, T_n, S_n$ by suitably inserting the element $n+1$, we obtain the recurrence relations\n\\begin{align*}\nU_{n+1} &= U_n+W_n+T_n, \\\\\nV_{n+1}&=U_n, \\\\\nW_{n+1}&=W_n, \\\\\nT_{n+1}&=V_n, \\\\\nS_{n+1}&=S_n+V_n.\n\\end{align*}\nAlso, it is clear that $W_n=1$ for all $n$. \n\nSo far we have assumed $n \\geq 3$, but it is straightforward to extrapolate the sequences $P_n,U_n,V_n,W_n,T_n,S_n$ back to $n=2$ to preserve the preceding identities. Hence for all $n \\geq 2$,\n\\begin{align*}\nP_{n+5} &= 2(U_{n+5}+V_{n+5}+W_{n+5}+T_{n+5}+S_{n+5}) \\\\\n&= 2((U_{n+4}+W_{n+4}+T_{n+4})+U_{n+4}\\\\\n& \\qquad + W_{n+4}+V_{n+4}+(S_{n+4}+V_{n+4})) \\\\\n&= P_{n+4} + 2(U_{n+4}+W_{n+4}+V_{n+4}) \\\\\n&= P_{n+4} + 2((U_{n+3}+W_{n+3}+T_{n+3})+W_{n+3}+U_{n+3}) \\\\\n&= P_{n+4} + P_{n+3} + 2(U_{n+3}-V_{n+3}+W_{n+3}-S_{n+3}) \\\\\n&= P_{n+4} + P_{n+3} + 2((U_{n+2}+W_{n+2}+T_{n+2})-U_{n+2}\\\\\n&\\qquad +W_{n+2}-(S_{n+2}-V_{n+2})) \\\\\n&= P_{n+4} + P_{n+3} + 2(2W_{n+2}+T_{n+2}-S_{n+2}-V_{n+2}) \\\\\n&= P_{n+4} + P_{n+3} + 2(2W_{n+1}+V_{n+1}\\\\\n&\\qquad -(S_{n+1}+V_{n+1})-U_{n+1}) \\\\\n&= P_{n+4} + P_{n+3} + 2(2W_n+U_n-(S_n+V_n)-U_n\\\\\n&\\qquad -(U_n+W_n+T_n)) \\\\\n&= P_{n+4} + P_{n+3} - P_n + 4,\n\\end{align*}\nas desired.\n\n\\noindent\n\\textbf{Remark:}\nThere are many possible variants of the above solution obtained by dividing the permutations up according to different features. For example, Karl Mahlburg suggests \nwriting \n\\[\nP_n = 2P'_n, \\qquad P'_n = Q'_n + R'_n\n\\]\nwhere $P'_n$ counts those permutations counted by $P_n$ for which $1$ occurs before 2,\nand $Q'_n$ counts those permutations counted by $P'_n$ for which $\\pi(1) = 1$. One then has the recursion\n\\[\nQ'_n = Q'_{n-1} + Q'_{n-3} + 1\n\\]\ncorresponding to the cases where $\\pi(1), \\pi(2) = 1,2$; where $\\pi(1), \\pi(2), \\pi(3) = 1,3,2$;  and the unique case $1,3,5,\\dots,6,4,2$. Meanwhile, one has\n\\[\nR'_n = R'_{n-1} + Q'_{n-2}\n\\]\ncorresponding to the cases containing $3,1,2,4$ (where removing 1 and reversing gives a permutation counted by $R'_{n-1}$); and where $4$ occurs before $3, 1, 2$ (where removing $1,2$ and reversing gives a permutation counted by $Q'_{n-2}$).\n\n\\noindent\n\\textbf{Remark:}\nThe permutations counted by $P_n$ are known as {\\it key permutations}, and have been studied by E.S. Page, Systematic generation of ordered sequences using recurrence relations, {\\it The Computer Journal} {\\bf 14} (1971), no. 2, 150--153.  We have used the same notation for consistency with the literature. The sequence of the $P_n$ also appears as entry A003274 in the On-line Encyclopedia of Integer Sequences (\\url{http://oeis.org})."
  },
  {
    "year": 2015,
    "label": "B6",
    "difficulty": "6",
    "problem": "For each positive integer $k$, let $A(k)$ be the number of odd divisors of $k$ in the interval $[1, \\sqrt{2k})$. Evaluate\n\\[\n\\sum_{k=1}^\\infty (-1)^{k-1} \\frac{A(k)}{k}.\n\\]\n\n\\end{itemize}\n\n\\end{document}",
    "solution": "(from \\url{artofproblemsolving.com})\nWe will prove that the sum converges to $\\pi^2/16$.\nNote first that the sum does not converge absolutely, so we are not free to rearrange it arbitrarily. For that matter, the standard alternating sum test does not apply because the absolute values of the terms does not decrease to 0, so even the convergence of the sum must be established by hand.\n\nSetting these issues aside momentarily, note that\nthe elements of the set counted by $A(k)$ are those odd positive integers $d$ for which $m = k/d$ is also an integer and $d < \\sqrt{2dm}$; if we write $d = 2\\ee-1$, then the condition on $m$ reduces to $m \\geq \\ee$. In other words, the original sum equals\n\\[\nS_1 := \\sum_{k=1}^\\infty \\sum_{{\\ee \\geq 1, m \\geq \\ee}\\atop{k = m(2\\ee-1)}} \\frac{(-1)^{m-1}}{m(2\\ee-1)},\n\\]\nand we would like to rearrange this to\n\\[\nS_2 := \\sum_{\\ee=1}^\\infty \\frac{1}{2\\ee-1} \\sum_{m=\\ee}^\\infty \\frac{(-1)^{m-1}}{m},\n\\]\nin which both sums converge by the alternating sum test. In fact a bit more is true:\nwe have\n\\[\n\\left| \\sum_{m=\\ee}^\\infty \\frac{(-1)^{m-1}}{m} \\right| < \\frac{1}{\\ee},\n\\]\nso the outer sum converges absolutely.\nIn particular, $S_2$ is the limit of the truncated sums\n\\[\nS_{2,n} = \\sum_{\\ee(2\\ee-1) \\leq n} \\frac{1}{2\\ee-1} \\sum_{m=\\ee}^\\infty \\frac{(-1)^{m-1}}{m}.\n\\]\nTo see that $S_1$ converges to the same value as $S_2$, write\n\\[\nS_{2,n} - \\sum_{k=1}^n (-1)^{k-1} \\frac{A(k)}{k} =\n\\sum_{\\ee(2\\ee-1) \\leq n} \\frac{1}{2\\ee-1} \\sum_{m=\\lfloor \\frac{n}{2\\ee-1}+1 \\rfloor}^\\infty\n\\frac{(-1)^{m-1}}{m}.\n\\]\nThe expression on the right is bounded above in absolute value by the sum $\\sum_{\\ee(2\\ee-1) \\leq n} \\frac{1}{n}$, in which the number of summands is\n%at most $\\sqrt{n/2}$ and so the total is bounded by $1/\\sqrt{2n}$.\nat most $\\sqrt{n}$ (since $\\sqrt{n}(2\\sqrt{n}-1)\\geq n$), and so the total is bounded above by $1/\\sqrt{n}$.\nHence the difference converges to zero as $n \\to \\infty$; that is, $S_1$ converges and equals $S_2$.\n\nWe may thus focus hereafter on computing $S_2$. We begin by writing\n\\[\nS_2 = \\sum_{\\ee=1}^\\infty \\frac{1}{2\\ee-1} \\sum_{m=\\ee}^\\infty (-1)^{m-1} \\int_0^1 t^{m-1}\\,dt.\n\\]\nOur next step will be to interchange the inner sum and the integral, but again this requires some justification.\n\\begin{lemma}\nLet $f_0, f_1, \\dots$ be a sequence of continuous functions on $[0,1]$ such that for each $x \\in [0,1]$, we have\n\\[\nf_0(x) \\geq f_1(x) \\geq \\cdots \\geq 0.\n\\]\nThen\n\\[\n\\sum_{n=0}^\\infty (-1)^n \\int_0^1 f_n(t)\\,dt = \\int_0^1 \\left( \\sum_{n=0}^\\infty (-1)^n f_n(t) \\right)\\,dt\n\\]\nprovided that both sums converge.\n\\end{lemma}\n\\begin{proof}\nPut $g_n(t) = f_{2n}(t) - f_{2n+1}(t) \\geq 0$; we may then rewrite the desired equality as\n\\[\n\\sum_{n=0}^\\infty \\int_0^1 g_n(t) \\,dt = \\int_0^1 \\left( \\sum_{n=0}^\\infty g_n(t) \\right)\\,dt,\n\\]\nwhich is a case of the Lebesgue monotone convergence theorem.\n\\end{proof}\nBy Lemma~1, we have\n\\begin{align*}\nS_2 &= \\sum_{\\ee=1}^\\infty \\frac{1}{2\\ee-1} \\int_0^1 \\left( \\sum_{m=\\ee}^\\infty (-1)^{m-1} t^{m-1} \\right) \\,dt \\\\\n&=  \\sum_{\\ee=1}^\\infty \\frac{1}{2\\ee-1} \\int_0^1 \\frac{(-t)^{\\ee-1}}{1+t}  \\,dt.\n\\end{align*}\nSince the outer sum is absolutely convergent, we may freely interchange it with the integral:\n\\begin{align*}\nS_2 &=  \\int_0^1 \\left(\n\\sum_{\\ee=1}^\\infty \\frac{1}{2\\ee-1}  \\frac{(-t)^{\\ee-1}}{1+t} \\right)\\,dt \\\\\n&= \\int_0^1 \\frac{1}{\\sqrt{t}(1+t)} \\left( \\sum_{\\ee=1}^\\infty \\frac{(-1)^{\\ee-1} t^{\\ee-1/2}}{2\\ee-1} \\right) \\,dt \\\\\n&= \\int_0^1 \\frac{1}{\\sqrt{t}(1+t)} \\arctan(\\sqrt{t})\\,dt \\\\\n&= \\int_0^1 \\frac{2}{1+u^2} \\arctan(u)\\,du \\qquad (u = \\sqrt{t}) \\\\\n&= \\arctan(1)^2 - \\arctan(0)^2 = \\frac{\\pi^2}{16}.\n\\end{align*}\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2016,
    "label": "A1",
    "difficulty": "1",
    "problem": "Find the smallest positive integer $j$ such that for every polynomial $p(x)$ with integer coefficients and for every integer $k$, the integer\n\\[\np^{(j)}(k) = \\left. \\frac{d^j}{dx^j} p(x) \\right|_{x=k} \n\\] \n(the $j$-th derivative of $p(x)$ at $k$) is divisible by 2016.",
    "solution": "The answer is $j=8$. First suppose that $j$ satisfies the given condition. For $p(x) = x^j$, we have $p^{(j)}(x) = j!$ and thus $j!$ is divisible by $2016$. Since $2016$ is divisible by $2^5$ and $7!$ is not, it follows that $j \\geq 8$. Conversely, we claim that $j=8$ works. Indeed, let $p(x) = \\sum_{m=0}^n a_m x^m$ be a polynomial with integer coefficients; then if $k$ is any integer, \n\\begin{align*}\np^{(8)}(k) &= \\sum_{m=8}^n m(m-1)\\cdots (m-7) a_m k^{m-8} \\\\\n&= \\sum_{m=8}^n {m\\choose 8} 8! a_m k^{m-8}\n\\end{align*}\nis divisible by $8! = 20 \\cdot 2016$, and so $p^{(8)}(k)$ is divisible by $2016$.\n\n\\noindent\n\\textbf{Remark:}\nBy the same reasoning, if one replaces $2016$ in the problem by a general integer $N$,\nthen the minimum value of $j$ is the smallest one for which $N$ divides $j!$.\nThis can be deduced from P\\'olya's observation that the set of integer-valued polynomials is the free $\\ZZ$-module generated by the binomial polynomials $\\binom{x}{n}$ for $n=0,1,\\dots$. That statement can be extended to polynomials evaluated on a subset of a Dedekind domain using Bhargava's method of \\emph{$P$-orderings}; we do not know if this generalization can be adapted to the analogue of this problem, where one considers polynomials whose $j$-th derivatives take integral values on a prescribed subset."
  },
  {
    "year": 2016,
    "label": "A2",
    "difficulty": "2",
    "problem": "Given a positive integer $n$, let $M(n)$ be the largest integer $m$ such that \n\\[\n\\binom{m}{n-1} > \\binom{m-1}{n}.\n\\]\nEvaluate \n\\[\n\\lim_{n \\to \\infty} \\frac{M(n)}{n}.\n\\]",
    "solution": "The answer is $\\frac{3+\\sqrt{5}}{2}$. Note that for $m > n+1$, both binomial coefficients are nonzero and their ratio is\n\\begin{align*}\n{m\\choose n-1}/{m-1\\choose n} &= \\frac{m!n!(m-n-1)!}{(m-1)!(n-1)!(m-n+1)!} \\\\\n&= \\frac{mn}{(m-n+1)(m-n)}.\n\\end{align*}\nThus the condition ${m\\choose{n-1}} > {{m-1}\\choose n}$ is equivalent to $(m-n+1)(m-n)-mn < 0$. The left hand side of this last inequality is a quadratic function of $m$ with roots\n\\begin{align*}\n\\alpha(n) &= \\frac{3n-1+\\sqrt{5n^2-2n+1}}{2}, \\\\\n\\beta(n) &= \\frac{3n-1-\\sqrt{5n^2-2n+1}}{2},\n\\end{align*}\nboth of which are real since $5n^2-2n+1 = 4n^2+(n-1)^2 > 0$; it follows that $m$ satisfies the given inequality if and only if $\\beta(n) < m < \\alpha(n)$. (Note in particular that since $\\alpha(n)-\\beta(n) = \\sqrt{5n^2-2n+1} > 1$, there is always some integer $m$ between $\\beta(n)$ and $\\alpha(n)$.)\n\n\nWe conclude that $M(n)$ is the greatest integer strictly less than $\\alpha(n)$, and thus that \n$\\alpha(n)-1 \\leq M(n) < \\alpha(n)$. Now\n\\[\n\\lim_{n\\to\\infty} \\frac{\\alpha(n)}{n} = \\lim_{n\\to\\infty} \\frac{3-\\frac{1}{n}+\\sqrt{5-\\frac{2}{n}+\\frac{1}{n^2}}}{2}\n= \\frac{3+\\sqrt{5}}{2}\n\\]\nand similarly $\\lim_{n\\to\\infty} \\frac{\\alpha(n)-1}{n} = \\frac{3+\\sqrt{5}}{2}$, and so by the sandwich theorem, $\\lim_{n\\to\\infty} \\frac{M(n)}{n} = \\frac{3+\\sqrt{5}}{2}$."
  },
  {
    "year": 2016,
    "label": "A3",
    "difficulty": "3",
    "problem": "Suppose that $f$ is a function from $\\mathbb{R}$ to $\\mathbb{R}$ such that\n\\[\nf(x) + f\\left( 1 - \\frac{1}{x} \\right) = \\arctan x\n\\]\nfor all real $x \\neq 0$. (As usual, $y = \\arctan x$ means $-\\pi/2 < y < \\pi/2$ and $\\tan y = x$.) Find \n\\[\n\\int_0^1 f(x)\\,dx.\n\\]",
    "solution": "The given functional equation, along with the same equation but with $x$ replaced by $\\frac{x-1}{x}$ and $\\frac{1}{1-x}$ respectively, yields:\n\\begin{align*}\nf(x) + f\\left(1-\\frac{1}{x}\\right) &= \\tan^{-1}(x) \\\\\nf\\left(\\frac{x-1}{x}\\right) + f\\left(\\frac{1}{1-x}\\right) &= \\tan^{-1}\\left(\\frac{x-1}{x}\\right) \\\\\nf\\left(\\frac{1}{1-x}\\right) + f(x) &= \\tan^{-1}\\left(\\frac{1}{1-x}\\right).\n\\end{align*}\nAdding the first and third equations and subtracting the second gives:\n\\[\n2f(x) = \\tan^{-1}(x) + \\tan^{-1}\\left(\\frac{1}{1-x}\\right) - \\tan^{-1}\\left(\\frac{x-1}{x}\\right).\n\\]\nNow $\\tan^{-1}(t) + \\tan^{-1}(1/t)$ is equal to $\\pi/2$ if $t>0$ and $-\\pi/2$ if $t<0$; it follows that for $x \\in (0,1)$,\n\\begin{align*}\n2(f(x)+f(1-x)) &= \\left(\\tan^{-1}(x)+\\tan^{-1}(1/x)\\right)\\\\\n&\\,\\, + \\left(\\tan^{-1}(1-x)+\\tan^{-1}\\left(\\frac{1}{1-x}\\right)\\right) \\\\\n&\\,\\,- \n\\left(\\tan^{-1}\\left(\\frac{x-1}{x}\\right) + \\tan^{-1}\\left(\\frac{x}{x-1}\\right) \\right) \\\\\n&= \\frac{\\pi}{2} + \\frac{\\pi}{2} + \\frac{\\pi}{2} \\\\\n&= \\frac{3\\pi}{2}.\n\\end{align*}\nThus\n\\[\n4\\int_0^1 f(x)\\,dx = 2\\int_0^1 (f(x)+f(1-x))dx = \\frac{3\\pi}{2}\n\\]\nand finally $\\int_0^1 f(x)\\,dx = \\frac{3\\pi}{8}$.\n\n\\noindent\n\\textbf{Remark:}\nOnce one has the formula for $f(x)$, one can also (with some effort) directly evaluate the integral of each summand over $[0,1]$ to obtain the same result. A much cleaner variant of this approach (suggested on AoPS, user \\texttt{henrikjb}) is to write\n\\[\n\\tan^{-1}(x) = \\int_0^y \\frac{1}{1+y^2}\\,dy\n\\]\nand do a change of variable on the resulting double integral."
  },
  {
    "year": 2016,
    "label": "A4",
    "difficulty": "4",
    "problem": "Consider a $(2m-1) \\times (2n-1)$ rectangular region, where $m$ and $n$ are integers such that $m, n \\geq 4$. This region is to be tiled using tiles of the two types shown:\n\\[\n\\setlength{\\unitlength}{4144sp}%\n%\n\\begingroup\\makeatletter\\ifx\\SetFigFont\\undefined%\n\\gdef\\SetFigFont#1#2#3#4#5{%\n  \\reset@font\\fontsize{#1}{#2pt}%\n  \\fontfamily{#3}\\fontseries{#4}\\fontshape{#5}%\n  \\selectfont}%\n\\fi\\endgroup%\n\\begin{picture}(2724,924)(1339,-1423)\n\\thinlines\n{\\put(1351,-511){\\line( 0,-1){900}}\n\\put(1351,-1411){\\line( 1, 0){450}}\n\\put(1801,-1411){\\line( 0, 1){450}}\n\\put(1801,-961){\\line( 1, 0){450}}\n\\put(2251,-961){\\line( 0, 1){450}}\n\\put(2251,-511){\\line(-1, 0){900}}\n}%\n{\\multiput(1351,-961)(128.57143,0.00000){4}{\\line( 1, 0){ 64.286}}\n\\multiput(1801,-961)(0.00000,128.57143){4}{\\line( 0, 1){ 64.286}}\n}%\n{\\put(2701,-961){\\line( 0,-1){450}}\n\\put(2701,-1411){\\line( 1, 0){900}}\n\\put(3601,-1411){\\line( 0, 1){450}}\n\\put(3601,-961){\\line( 1, 0){450}}\n\\put(4051,-961){\\line( 0, 1){450}}\n\\put(4051,-511){\\line(-1, 0){900}}\n\\put(3151,-511){\\line( 0,-1){450}}\n\\put(3151,-961){\\line(-1, 0){450}}\n}%\n{\\multiput(3151,-1411)(0.00000,128.57143){4}{\\line( 0, 1){ 64.286}}\n\\multiput(3151,-961)(128.57143,0.00000){4}{\\line( 1, 0){ 64.286}}\n\\multiput(3601,-961)(0.00000,128.57143){4}{\\line( 0, 1){ 64.286}}\n}%\n\\end{picture}%\n\\]\n(The dotted lines divide the tiles into $1 \\times 1$ squares.)\nThe tiles may be rotated and reflected, as long as their sides are parallel to the sides\nof the rectangular region. They must all fit within the region, and they must cover it completely without overlapping.\n\nWhat is the minimum number of tiles required to tile the region?",
    "solution": "The minimum number of tiles is $mn$. To see that this many are required, label the squares $(i,j)$ with $1\\leq i\\leq 2m-1$ and $1\\leq j\\leq 2n-1$, and for each square with $i,j$ both odd, color the square red; then no tile can cover more than one red square, and there are $mn$ red squares.\n\nIt remains to show that we can cover any $(2m-1) \\times (2n-1)$ rectangle with $mn$ tiles when $m,n \\geq 4$. First note that we can tile any $2 \\times (2k-1)$ rectangle with $k\\geq 3$ by $k$ tiles: one of the first type, then $k-2$ of the second type, and finally one of the first type. Thus if we can cover a $7\\times 7$ square with $16$ tiles, then we can do the general $(2m-1) \\times (2n-1)$ rectangle, by decomposing this rectangle into a $7\\times 7$ square in the lower left corner, along with $m-4$ $(2\\times 7)$ rectangles to the right of the square, and $n-4$ $((2m-1)\\times 2)$ rectangles above, and tiling each of these rectangles separately, for a total of $16+4(m-4)+m(n-4) = mn$ tiles.\n\nTo cover the $7 \\times 7$ square, note that the tiling must consist of 15 tiles of the first type and 1 of the second type, and that any $2 \\times 3$ rectangle can be covered using 2 tiles of the first type. We may thus construct a suitable covering by covering all but the center square with eight $2 \\times 3$ rectangles, in such a way that we can attach the center square to one of these rectangles to get a shape that can be covered by two tiles. An example of such a covering, with the remaining $2 \\times 3$ rectangles left intact for visual clarity, is depicted below. (Many other solutions are possible.)\n\\[\n\\setlength{\\unitlength}{4144sp}%\n%\n\\begingroup\\makeatletter\\ifx\\SetFigFont\\undefined%\n\\gdef\\SetFigFont#1#2#3#4#5{%\n  \\reset@font\\fontsize{#1}{#2pt}%\n  \\fontfamily{#3}\\fontseries{#4}\\fontshape{#5}%\n  \\selectfont}%\n\\fi\\endgroup%\n\\begin{picture}(3174,3174)(1339,-7723)\n\\thinlines\n{\\put(1351,-7711){\\framebox(3150,3150){}}\n}%\n{\\put(1351,-5911){\\line( 1, 0){945}}\n\\put(2296,-5911){\\line( 0, 1){1350}}\n}%\n{\\put(2296,-5911){\\line( 1, 0){405}}\n\\put(2701,-5911){\\line( 0,-1){1800}}\n}%\n{\\put(1351,-6811){\\line( 1, 0){1350}}\n}%\n{\\put(2701,-6361){\\line( 1, 0){1800}}\n}%\n{\\put(3601,-6361){\\line( 0,-1){1350}}\n}%\n{\\put(3151,-6361){\\line( 0, 1){1800}}\n}%\n{\\put(3151,-5461){\\line( 1, 0){1350}}\n}%\n{\\multiput(2296,-5011)(128.57143,0.00000){4}{\\line( 1, 0){ 64.286}}\n\\multiput(2746,-5011)(0.00000,-128.57143){4}{\\line( 0,-1){ 64.286}}\n\\multiput(2746,-5461)(115.71429,0.00000){4}{\\line( 1, 0){ 57.857}}\n}%\n\\end{picture}%\n\\]"
  },
  {
    "year": 2016,
    "label": "A5",
    "difficulty": "5",
    "problem": "Suppose that $G$ is a finite group generated by the two elements $g$ and $h$, where the order of $g$ is odd. Show that every element of $G$ can be written in the form\n\\[\ng^{m_1} h^{n_1} g^{m_2} h^{n_2} \\cdots g^{m_r} h^{n_r}\n\\]\nwith $1 \\leq r \\leq |G|$ and $m_1, n_1, m_2, n_2, \\ldots, m_r, n_r \\in \\{-1, 1\\}$. \n(Here $|G|$ is the number of elements of $G$.)\n\n\\,",
    "solution": "\\noindent\n\\textbf{First solution:}\nFor $s \\in G$ and $r$ a positive integer, define a \\emph{representation of $s$ of length $r$}\nto be a sequence of values $m_1, n_1, \\ldots, m_r, n_r \\in \\{-1, 1\\}$ for which\n\\[\ns = g^{m_1} h^{n_1} \\cdots g^{m_r} h^{n_r}.\n\\]\nWe first check that every $s \\in G$ admits at least one representation of some length; this is equivalent to saying that the set $S$ of $s \\in G$ which admit representations of some length\nis equal to $G$ itself. \nSince $S$ is closed under the group operation and $G$ is finite, $S$ is also closed under formation of inverses and contains the identity element; that is, $S$ is a subgroup of $G$.\nIn particular, $S$ contains not only $gh$ but also its inverse $h^{-1} g^{-1}$; since $S$ also contains $g^{-1} h$, we deduce that $S$ contains $g^{-2}$. \nSince $g$ is of odd order in $G$, $g^{-2}$ is also a generator of the cyclic subgroup containing $g$; it follows that $g \\in S$ and hence $h \\in S$. Since we assumed that $g,h$ generate $G$,\nwe now conclude that $S = G$, as claimed.\n\nTo complete the proof, we must now check that for each $s \\in G$, the smallest possible length of a representation of $s$ cannot exceed $|G|$. Suppose the contrary, and let\n\\[\ns = g^{m_1} h^{n_1} \\cdots g^{m_r} h^{n_r}\n\\]\nbe a representation of the smallest possible length. Set\n\\[\ns_i = g^{m_1} h^{n_1} \\cdots g^{m_i} h^{n_i} \\qquad (i=0,\\dots,r-1),\n\\]\ninterpreting $s_0$ as $e$; since $r>|G|$ by hypothesis, by the pigeonhole principle there must exist indices $0 \\leq i < j \\leq r-1$ such that $s_i = s_j$. Then\n\\[\ns = g^{m_1} h^{n_1} \\cdots g^{m_i} h^{n_i} g^{m_{j+1}} h^{n_{j+1}} \\cdots g^{m_r} h^{n_r} \n\\]\nis another representation of $s$ of length strictly less than $r$, a contradiction.\n\n\\noindent\n\\textbf{Remark:}\nIf one considers $s_1,\\dots,s_r$ instead of $s_0,\\dots,s_{r-1}$, then the case $s=e$ must be handled separately: otherwise, one might end up with a representation of length 0 which is disallowed by the problem statement.\n\n\\noindent\n\\textbf{Reinterpretation:} \nNote that the elements $gh, gh^{-1}, g^{-1} h, g^{-1} h^{-1}$ generate $gh(g^{-1}h)^{-1} = g^2$ and hence all of $G$ (again using the hypothesis that $g$ has odd order, as above). Form the Cayley digraph on the set $G$, i.e., the directed graph with an edge from $s_1$ to $s_2$ whenever $s_2 = s_1 *$ for $* \\in \\{gh, gh^{-1}, g^{-1} h, g^{-1} h^{-1}\\}$. Since $G$ is finite, this digraph is strongly connected: there exists at least one path from any vertex to any other vertex (traveling all edges in the correct direction). The shortest such path cannot repeat any vertices (except the starting and ending vertices in case they coincide), and so has length at most $|G|$.\n\n\\noindent\n\\textbf{Second solution:}\nFor $r$ a positive integer, let $S_r$ be the set of $s \\in G$ which admit a representation of length at most $r$ (terminology as in the first solution); obviously $S_r \\subseteq S_{r+1}$.\nWe will show that $S_r \\neq S_{r+1}$ unless $S_r = G$; this will imply by induction on $r$ that $\\#S_r \\geq \\min\\{r, |G|\\}$ and hence that $S_r = G$ for some $r \\leq |G|$.\n\nSuppose that $S_r = S_{r+1}$.\nThen the map $s \\mapsto sgh$ defines an injective map $S_r \\to S_{r+1} = S_r$,\nso $S_r$ is closed under right multiplication by $gh$. By the same token, $S_r$ is closed under right multiplication by each of $gh^{-1}, g^{-1}h, g^{-1}h^{-1}$.\nSince $gh, gh^{-1}, g^{-1}h, g^{-1}h^{-1}$ generate $G$ as in the first solution, it follows that $S_r = G$ as claimed.\n\n\\noindent\n\\textbf{Remark:} The condition on the order of $g$ is needed to rule out the case where $G$ admits a (necessarily normal) subgroup $H$ of index 2 not containing either $g$ or $h$; in this case, all products of the indicated form belong to $H$.\nOn the other hand, if one assumes that both $g$ and $h$ have odd order, then one can say a bit more: there exists some positive integer $r$ with $1 \\leq r \\leq |G|$ such that every element of $G$ has a representation of length exactly $r$. (Namely, the set of such elements for a given $r$ strictly increases in size until it is stable under right multiplication by both\n$gh(g^{-1}h)^{-1} = g^2$ and $gh(gh^{-1})^{-1} = gh^2g^{-1}$, but under the present hypotheses these generate $G$.)"
  },
  {
    "year": 2016,
    "label": "A6",
    "difficulty": "6",
    "problem": "Find the smallest constant $C$ such that for every real polynomial $P(x)$ of degree 3 that has a root in the interval $[0,1]$,\n\\[\n\\int_0^1 \\left| P(x) \\right|\\,dx \\leq C \\max_{x \\in [0,1]} \\left| P(x) \\right|.\n\\]",
    "solution": "We prove that the smallest such value of $C$ is $5/6$.\n\n\\noindent\n\\textbf{First solution:}\n(based on a suggestion of Daniel Kane)\n\nWe first reduce to the case where $P$ is nonnegative in $[0,1]$ and $P(0) = 0$.\nTo achieve this reduction, suppose that a given value $C$ obeys the inequality for such $P$.\nFor $P$ general,\ndivide the interval $[0,1]$ into subintervals $I_1,\\dots,I_k$ at the roots of $P$.\nWrite $\\ell(I_i)$ for the length of the interval $I_i$; since each interval is bounded by a root of $P$, we may make a linear change of variable to see that\n\\[\n\\int_{I_i} |P(x)|\\,dx \\leq C \\ell(I_i) \\max_{x \\in I_i} |P(x)| \\quad (i=1,\\dots,k).\n\\]\nSumming over $i$ yields the desired inequality.\n\nSuppose now that $P$ takes nonnegative values on $[0,1]$, $P(0) = 0$, and $\\max_{x \\in [0,1]} P(x) = 1$. Write $P(x) = ax^3 + bx^2 + cx$ for some $a,b,c \\in \\RR$; then\n\\begin{align*}\n\\int_0^1 P(x)\\,dx &= \\frac{1}{4} a + \\frac{1}{3} b + \\frac{1}{2} c \\\\\n&= \\frac{2}{3} \\left( \\frac{1}{8} a + \\frac{1}{4} b + \\frac{1}{2} c \\right)\n+ \\frac{1}{6} (a+b+c) \\\\\n&= \\frac{2}{3} P\\left( \\frac{1}{2} \\right) + \\frac{1}{6} P(1) \\\\\n&\\leq \\frac{2}{3} + \\frac{1}{6} = \\frac{5}{6}.\n\\end{align*}\nConsequently, the originally claimed inequality holds with $C = 5/6$. To prove that this value is best possible, it suffices to exhibit a polynomial $P$ as above with $\\int_0^1 P(x)\\,dx = 5/6$; we will verify that\n\\[\nP(x) = 4x^3 - 8x^2 + 5x\n\\]\nhas this property. It is apparent that $\\int_0^1 P(x)\\, dx =5/6$.\nSince $P'(x) = (2x-1)(6x-5)$ and \n\\[\nP(0) = 0, \\,P\\left( \\frac{1}{2} \\right) = 1, \\,\nP\\left( \\frac{5}{6} \\right) = \\frac{25}{27}, P(1) = 1,\n\\]\nit follows that $P$ increases from 0 at $x=0$ to 1 at $x=1/2$, then decreases to a positive value at $x=5/6$, then increases to 1 at $x=1$. Hence $P$ has the desired form.\n\n\\noindent\n\\textbf{Remark:}\nHere is some conceptual motivation for the preceding solution.\nLet $V$ be the set of polynomials of degree at most 3 vanishing at 0, viewed as a three-dimensional vector space over $\\RR$.\nLet $S$ be the subset of $V$ consisting of those polynomials $P(x)$ for which\n$0 \\leq P(x) \\leq 1$ for all $x \\in [0,1]$; this set is convex and compact. We may then compute the minimal $C$ as the maximum value of $\\int_0^1 P(x)\\,dx$ over all $P \\in S$, provided that the maximum is achieved for some polynomial of degree exactly 3. (Note that any extremal polynomial must satisfy\n$\\max_{x \\in [0,1]} P(x) = 1$, as otherwise we could multiply it by some constant $c>1$ so as to increase $\\int_0^1 P(x)\\,dx$.)\n\nLet $f: V \\to \\RR$ be the function taking $P(x)$ to $\\int_0^1 P(x)\\,dx$. This function is linear, so we can characterize its extrema on $S$ easily: there exist exactly two level surfaces for $f$ which are supporting planes for $S$, and the intersections of these two planes\nwith $S$ are the minima and the maxima. It is obvious that the unique minimum is achieved by the zero polynomial, so this accounts for one of the planes.\n\nIt thus suffices to exhibit a single polynomial $P(x) \\in S$ such that the level plane of $f$ through $P$ is a supporting plane for $S$. \nThe calculation made in the solution amounts to verifying that\n\\[\nP(x) = 4x^3 - 8x^2 + 5x\n\\]\nhas this property, by interpolating between the constraints $P(1/2) \\leq 1$ and $P(1) \\leq 1$.\n\nThis still leaves the matter of correctly guessing the optimal polynomial. If one supposes that it should be extremized both at $x=1$ and at an interval value of the disc, it is forced to have the form $P(x) = 1 + (x-1)(cx-1)^2$ for some $c>0$; the interpolation property then pins down $c$ uniquely.\n\n\\noindent\n\\textbf{Second solution:}\n(by James Merryfield, via AoPS)\nAs in the first solution, we may assume that $P$ is nonnegative on $[0,1]$ and $P(0)= 0$.\nSince $P$ has degree at most 3, Simpson's rule for approximating $\\int_0^1 P(x)\\,dx$ is an exact formula:\n\\[\n\\int_0^1 P(x)\\,dx = \\frac{1}{6}( P(0) + 4 P\\left( \\frac{1}{2} \\right) + P(1)).\n\\]\nThis immediately yields the claimed inequality for $C = 5/6$. Again as in the first solution,\nwe obtain an example showing that this value is best possible."
  },
  {
    "year": 2016,
    "label": "B1",
    "difficulty": "1",
    "problem": "Let $x_0,x_1,x_2,\\dots$ be the sequence such that $x_0=1$ and for $n \\geq 0$,\n\\[\nx_{n+1} = \\ln(e^{x_n} - x_n)\n\\]\n(as usual, the function $\\ln$ is the natural logarithm). Show that the infinite series\n\\[\nx_0 + x_1 + x_2 + \\cdots\n\\]\nconverges and find its sum.",
    "solution": "Note that the function $e^x - x$ is strictly increasing for $x>0$ (because its derivative is $e^x - 1$, which is positive because $e^x$ is strictly increasing), and its value at 0 is 1.\nBy induction on $n$, we see that $x_n > 0$ for all $n$.\n\nBy exponentiating the equation defining $x_{n+1}$, we obtain the expression\n\\[\nx_n = e^{x_n} - e^{x_{n+1}}.\n\\]\nWe use this equation repeatedly to acquire increasingly precise information about the sequence $\\{x_n\\}$.\n\\begin{itemize}\n\\item\nSince $x_n > 0$, we have $e^{x_n} > e^{x_{n+1}}$, so $x_n > x_{n+1}$.\n\\item\nSince the sequence $\\{x_n\\}$ is decreasing and bounded below by 0, it converges to some limit $L$.\n\\item\nTaking limits in the equation yields $L = e^L - e^L$, whence $L = 0$.\n\\item\nSince $L = 0$, the sequence $\\{e^{x_n}\\}$ converges to 1.\n\\end{itemize}\n\nWe now have a telescoping sum:\n\\begin{align*}\nx_0 + \\cdots + x_n &= (e^{x_0} - e^{x_1}) + \\cdots + (e^{x_n} - e^{x_{n+1}}) \\\\\n&=e^{x_0} - e^{x_{n+1}} = e - e^{x_{n+1}}.\n\\end{align*}\nBy taking limits, we see that the sum $x_0 + x_1 + \\cdots$ converges to the value\n$e-1$."
  },
  {
    "year": 2016,
    "label": "B2",
    "difficulty": "2",
    "problem": "Define a positive integer $n$ to be \\emph{squarish} if either $n$ is itself a perfect square or the distance from $n$ to the nearest perfect square is a perfect square. For example, 2016 is squarish, because the nearest perfect square to 2016 is $45^2 = 2025$ and $2025-2016=9$ is a perfect square. (Of the positive integers between 1 and 10, only 6 and 7 are not squarish.)\n\nFor a positive integer $N$, let $S(N)$ be the number of squarish integers between 1 and $N$,\ninclusive. Find positive constants $\\alpha$ and $\\beta$ such that\n\\[\n\\lim_{N \\to \\infty} \\frac{S(N)}{N^\\alpha} = \\beta,\n\\]\nor show that no such constants exist.",
    "solution": "We prove that the limit exists for $\\alpha = \\frac{3}{4}$, $\\beta =\\frac{4}{3}$. \n\nFor any given positive integer $n$, the integers which are closer to $n^2$ than to any other perfect square are the ones in the interval $[n^2 - n - 1, n^2 + n]$. The number of squarish numbers in this interval is $1 + \\lfloor \\sqrt{n-1} \\rfloor + \\lfloor \\sqrt{n} \\rfloor$.\nRoughly speaking, this means that \n\\[\nS(N) \\sim \\int_0^{\\sqrt{N}} 2 \\sqrt{x} \\,dx = \\frac{4}{3} N^{3/4}.\n\\]\nTo make this precise, we use the bounds $x-1 \\leq \\lfloor x \\rfloor \\leq x$,\nand the upper and lower Riemann sum estimates for the integral of $\\sqrt{x}$,\nto derive upper and lower bounds on $S(N)$:\n\\begin{align*}\nS(N) &\\geq \\sum_{n=1}^{\\lfloor \\sqrt{N} \\rfloor - 1} \n(2 \\sqrt{n-1}-1) \\\\\n&\\geq \\int_0^{\\lfloor \\sqrt{N} \\rfloor - 2} 2\\sqrt{x} \\,dx - \\sqrt{N} \\\\\n&\\geq \\frac{4}{3} (\\sqrt{N} - 3)^{3/2} - \\sqrt{N}\n\\end{align*}\n\n\\begin{align*}\nS(N) &\\leq \\sum_{n=1}^{\\lceil \\sqrt{N} \\rceil} (2 \\sqrt{n} + 1) \\\\\n&\\leq \\int_0^{\\lceil \\sqrt{N}\\rceil + 1} 2 \\sqrt{x}\\,dx  + \\sqrt{N} + 1\\\\\n&\\leq \\frac{4}{3} (\\sqrt{N} + 2)^{3/2} + \\sqrt{N} + 1.\n\\end{align*}\n\n\\noindent\n\\textbf{Remark:}\nJohn Rickert points out that when $N = n^4$, one can turn the previous estimates into exact calculations to obtain the formula\n\\[\nS(N) = \\frac{4}{3}\\left( n^3 + \\frac{n}{2} \\right) = \\frac{4}{3} N^{3/4} + \\frac{2}{3} N^{1/4}.\n\\]\nFor general $N$, one can then use the estimates\n\\begin{align*}\n\\frac{4}{3} (N-1)^{3/4} + \\frac{2}{3} (N-1)^{1/4}\n&\\leq\nS(\\lfloor N^{1/4} \\rfloor^4) \\\\\n&\\leq S(N) \\\\\n&\\leq S(\\lceil N^{1/4} \\rceil^4) \\\\\n&\\leq \\frac{4}{3} (N+1)^{3/4} + \\frac{2}{3} (N+1)^{1/4}\n\\end{align*}\nto obtain the desired limit."
  },
  {
    "year": 2016,
    "label": "B3",
    "difficulty": "3",
    "problem": "Suppose that $S$ is a finite set of points in the plane such that the area of triangle\n$\\triangle ABC$ is at most 1 whenever $A$, $B$, and $C$ are in $S$. Show that there exists a triangle of area 4 that (together with its interior) covers the set $S$.",
    "solution": "Since $S$ is finite, we can choose three points $A,B,C$ in $S$ so as to maximize the area of the triangle $ABC$. Let $A', B', C'$ be the points in the plane such that $A,B,C$ are the midpoints of the segments $B'C', C'A', A'B'$; the triangle $A'B'C'$ is similar to $ABC$ with sides twice as long, so its area is 4 times that of $ABC$ and hence no greater than 4.\n\nWe claim that this triangle has the desired effect; that is, every point $P$ of $S$ is contained within the triangle $A'B'C'$. \n(To be precise, the problem statement requires a triangle of area exactly 4, which need not be the case for $A'B'C'$, but this is trivially resolved by scaling up by a homothety.)\nTo see this, note that since the area of the triangle $PBC$ is no more than that of $ABC$, $P$ must lie in the half-plane bounded by $B'C'$ containing $B$ and $C$. Similarly, $P$ must lie in the half-plane bounded by $C'A'$ containing\n$C$ and $A$, and the half-plane bounded by $A'B'$ containing $A$ and $B$. These three half-planes intersect precisely in the region bounded by the triangle $A'B'C'$, proving the claim."
  },
  {
    "year": 2016,
    "label": "B4",
    "difficulty": "4",
    "problem": "Let $A$ be a $2n \\times 2n$ matrix, with entries chosen independently at random. Every entry is chosen to be 0 or 1, each with probability $1/2$. Find the expected value of $\\det(A-A^t)$ (as a function of $n$), where $A^t$ is the transpose of $A$.",
    "solution": "The expected value equals\n\\[\n\\frac{(2n)!}{4^n n!}.\n\\]\n\\noindent\n\\textbf{First solution:}\n\nWrite the determinant of $A-A^t$ as the sum over permutations $\\sigma$ of $\\{1,\\dots,2n\\}$ of the product\n\\[\n\\sgn(\\sigma)\n\\prod_{i=1}^{2n}\n(A-A^t)_{i \\sigma(i)} \n=\n\\sgn(\\sigma) \\prod_{i=1}^{2n} (A_{i \\sigma(i)} - A_{\\sigma(i) i});\n\\]\nthen the expected value of the determinant is the sum over $\\sigma$ of the expected value of this product, which we denote by $E_\\sigma$. \n\nNote that if we partition $\\{1,\\dots,2n\\}$ into orbits for the action of $\\sigma$, then partition the factors of the product accordingly, then no entry of $A$ appears in more than one of these factors; consequently, these factors are independent random variables. This means that we can compute $E_\\sigma$ as the product of the expected values of the individual factors.\n\nIt is obvious that any orbit of size 1 gives rise to the zero product, and hence the expected value of the corresponding factor is zero. For an orbit of size $m \\geq 3$, the corresponding factor contains $2m$ distinct matrix entries, so again we may compute the expected value of the factor as the product of the expected values of the individual terms $A_{i \\sigma(i)} - A_{\\sigma(i) i}$. However, the distribution of this term is symmetric about 0, so its expected value is 0.\n\nWe conclude that $E_\\sigma = 0$ unless $\\sigma$ acts with $n$ orbits of size 2. To compute $E_\\sigma$ in this case, assume without loss of generality that the orbits of $\\sigma$ are\n$\\{1,2\\}, \\dots, \\{2n-1,2n\\}$; note that $\\sgn(\\sigma) = (-1)^n$. Then $E_\\sigma$ is the expected value of\n$\\prod_{i=1}^n -(A_{(2i-1)2i} - A_{2i(2i-1)})^2$, which is $(-1)^n$ times the $n$-th power\nof the expected value of $(A_{12} - A_{21})^2$. Since $A_{12} - A_{21}$ takes the values $-1, 0, 1$ with probabilities $\\frac{1}{4}, \\frac{1}{2}, \\frac{1}{4}$, its square takes the values\n$0,1$ with probabilities $\\frac{1}{2}, \\frac{1}{2}$; we conclude that\n\\[\nE_\\sigma = 2^{-n}.\n\\]\nThe permutations $\\sigma$ of this form correspond to unordered partitions of $\\{1,\\dots,2n\\}$ into $n$ sets of size 2, so there are\n\\[\n\\frac{(2n)!}{n!(2!)^n}\n\\]\nsuch permutations. Putting this all together yields the claimed result.\n\n\\noindent\n\\textbf{Second solution:}\n(by Manjul Bhargava)\nNote that the matrix $A-A^t$ is skew-symmetric: \n\\[\n(A-A^t)^t = A^t-A = -(A-A^t).\n\\]\nThe determinant of a $2n \\times 2n$ skew-symmetric matrix $M$ is the square of the {\\it Pfaffian} of $M$, which is a polynomial of degree $n$ in the entries of $M$ defined as follows. Define a {\\it perfect matching} of $\\{1,\\ldots,2n\\}$ to be a permutation of $\\{1,\\ldots,2n\\}$ that is the product of $n$ disjoint transpositions. Then the Pfaffian of $M$ is given by\n\\begin{equation}\\label{pfaffeq}\n\\sum_{\\alpha} \\sgn(\\alpha) M_{i_1,j_1}\\cdots M_{i_n,j_n}\n\\end{equation}\nwhere the sum is over perfect matchings $\\alpha=(i_1,j_1)\\cdots(i_n,j_n)$,\nand $\\sgn(\\alpha)$ denotes the sign of the permutation\n$\\left(\\begin{smallmatrix}\n1&2&3&4&\\cdots & (2n-1)&2n \\\\\ni_1&j_1&i_2&j_2& \\cdots & i_n & j_n\n\\end{smallmatrix} \\right)$.\nThe determinant of $M$ is then the square of \\eqref{pfaffeq}, i.e.,\n\\begin{equation}\\label{deteq} \\det(M)=\\sum_{\\alpha,\\beta} \\sgn(\\alpha)\\sgn(\\beta) M_{i_1,j_1}\\cdots M_{i_n,j_n}M_{i'_1,j'_1}\\cdots M_{i'_n,j'_n}\n\\end{equation}\nwhere the sum is now over ordered pairs $$(\\alpha=(i_1,j_1)\\cdots(i_n,j_n),\\beta=(i'_1,j'_1)\\cdots(i'_n,j'_n))$$ of perfect matchings.\n\nTaking $M = A - A^t$, so that $M_{ij} = A_{ij} - A_{ji}$,\nwe wish to find the expected value of \\eqref{deteq}; again, this is the sum of the expected values of each summand in \\eqref{deteq}. Note that each $M_{ij}$ with $i < j$ is an independent random variable taking the values $-1,0,1$ with probabilities $\\frac14,\\frac12,\\frac14$, respectively.\n\nConsider first a summand in \\eqref{deteq} with $\\alpha\\neq \\beta$. Then some factor $M_{ij}$  occurs with exponent 1; since the distribution of $M_{ij}$ is symmetric about 0, any such summand has expected value 0.\n\nConsider next a summand in \\eqref{deteq} with $\\alpha= \\beta$. This summand is a product of distinct factors of the form $M_{ij}^2$; from the distributions of the $M_{ij}$, we see that the expected value of each of these terms is $1/2^n$.\n\nSince the total number of perfect matchings $\\alpha$ is $(2n)!/(2^nn!)$, the expected value of $(\\ref{deteq})$ is therefore $(2n)!/(2^nn!)\\cdot 1/2^n=(2n)!/(4^nn!)$, as desired."
  },
  {
    "year": 2016,
    "label": "B5",
    "difficulty": "5",
    "problem": "Find all functions $f$ from the interval $(1, \\infty)$ to $(1, \\infty)$ with the following property:\nif $x,y \\in (1, \\infty)$ and $x^2 \\leq y \\leq x^3$, then $(f(x))^2 \\leq f(y) \\leq (f(x))^3$.",
    "solution": "It is obvious that for any $c>0$, the function $f(x) = x^c$ has the desired property; we will prove that conversely, any function with the desired property has this form for some $c$.\n\nDefine the function $g: (0, \\infty) \\to (0, \\infty)$ given by\n$g(x) = \\log f(e^x)$; this function has the property that if $x,y \\in (0, \\infty)$\nand $2x \\leq y \\leq 3x$, then $2g(x) \\leq g(y) \\leq 3g(x)$. \nIt will suffice to show that there exists $c>0$ such that $g(x) = cx$ for all $x >0$.\n\nSimilarly, define the function $h: \\RR \\to \\RR$ given by\n$h(x) = \\log g(e^x)$; this function has the property that if $x,y \\in \\RR$\nand $x + \\log 2 \\leq y \\leq x + \\log 3$, then $h(x) + \\log 2 \\leq h(y) \\leq h(x) + \\log 3$. \nIt will suffice to show that there exists $c>0$ such that $h(x) = x + c$ for all $x \\in \\RR$\n(as then $h(x) = e^c x$ for all $x>0$).\n\nBy interchanging the roles of $x$ and $y$, we may restate the condition on $h$ as follows:\nif $x - \\log 3 \\leq y \\leq x - \\log 2$, then $h(x) - \\log 3 \\leq h(y) \\leq h(x) - \\log 2$. \nThis gives us the cases $a+b=0,1$ of the following statement, which we will establish in full by induction on $a+b$: for any nonnegative integers $a,b$, for all $x,y \\in \\RR$ such that\n\\[\nx + a \\log 2 - b \\log 3 \\leq y \\leq x + a \\log 3 - b \\log 2,\n\\]\nwe have\n\\[\nh(x) + a \\log 2 - b \\log 3 \\leq h(y) \\leq h(x) + a \\log 3 - b \\log 2.\n\\]\nTo this end, suppose that $a+b>0$ and that the claim is known for all smaller values of $a+b$. In particular, either $a>0$ or $b>0$; the two cases are similar, so we treat only the first one. Define the function\n\\[\nj(t) = \\frac{(a+b-1)t - b(\\log 2 + \\log 3)}{a+b},\n\\]\nso that\n\\begin{gather*}\nj(a \\log 2 - b \\log 3) = (a-1) \\log 2 - b \\log 3, \\\\\nj(a \\log 3 - b \\log 2) = (a-1) \\log 3 - b \\log 2.\n\\end{gather*}\nFor $t \\in [a \\log 2 - b \\log 3, a \\log 3 - b \\log 2]$ and $y = x+t$,\nwe have $\\log 2 \\leq t-j(t) \\leq \\log 3$ and hence\n\\begin{gather*}\n(a-1) \\log 2 - b \\log 3 \\leq h(x+j(t)) - h(x) \\leq (a-1) \\log 3 - b \\log 2 \\\\\n\\log 2 \\leq h(y)-h(x+j(t)) \\leq \\log 3; \n\\end{gather*}\nthis completes the induction.\n\nNow fix two values $x,y \\in \\RR$ with $x \\leq y$. Since $\\log 2$ and $\\log 3$ are linearly independent over $\\QQ$, the fractional parts of the nonnegative integer multiples of $\\log 3/\\log 2$ are dense in $[0,1)$. (This result is due to Kronecker; a stronger result of Weyl shows that the fractional parts are uniformly distributed in $[0,1)$.)\nIn particular, for any $\\epsilon > 0$ and any $N > 0$, we can find integers $a,b > N$ such that\n\\[\ny-x < a \\log 3 - b \\log 2 < y-x + \\epsilon.\n\\]\nBy writing\n\\begin{align*}\na \\log 2 - b \\log 3& = \\frac{\\log 2}{\\log 3}(a \\log 3 - b \\log 2) \\\\\n&\\,\\,- b \\frac{(\\log 3)^2 - (\\log 2)^2}{\\log 3},\n\\end{align*}\nwe see that this quantity tends to $-\\infty$ as $N \\to \\infty$; in particular, for $N$ sufficiently large we have that $a \\log 2 - b \\log 3 < y-x$. We thus have\n$h(y) \\leq h(x) + a \\log 2 - b \\log 3 < y-x + \\epsilon$; since $\\epsilon>0$ was chosen arbitrarily, we deduce that $h(y)-h(x) \\leq y-x$. A similar argument shows that $h(y)-h(x) \\geq y-x$; we deduce that $h(y) - h(x) = y-x$, or equivalently $h(y)-y = h(x) - x$. In other words, the function $x \\mapsto h(x) - x$ is constant, as desired."
  },
  {
    "year": 2016,
    "label": "B6",
    "difficulty": "6",
    "problem": "Evaluate\n\\[\n\\sum_{k=1}^\\infty \\frac{(-1)^{k-1}}{k} \\sum_{n=0}^\\infty \\frac{1}{k2^n + 1}.\n\\]\n\\end{itemize}\n\n\\end{document}",
    "solution": "Let $S$ denote the desired sum. We will prove that $S=1$.\n\n\\noindent\n\\textbf{First solution:}\nWrite\n\\[\n\\sum_{n=0}^\\infty \\frac{1}{k2^n+1} = \\frac{1}{k+1} + \\sum_{n=1}^\\infty \\frac{1}{k2^n+1}; \n\\]\nthen we may write $S = S_1+S_2$ where \n\\begin{align*} \nS_1 &= \\sum_{k=1}^\\infty \\frac{(-1)^{k-1}}{k(k+1)} \\\\\nS_2 &= \\sum_{k=1}^\\infty \\frac{(-1)^{k-1}}{k} \\sum_{n=1}^\\infty \\frac{1}{k2^n+1}.\n\\end{align*}\nThe rearrangement is valid because both $S_1$ and $S_2$ converge absolutely in $k$, by comparison to $\\sum 1/k^2$.\n\nTo compute $S_1$, note that \n\\begin{align*}\n\\sum_{k=1}^N \\frac{(-1)^{k-1}}{k(k+1)} &= \\sum_{k=1}^N  (-1)^{k-1}\\left(\\frac{1}{k}-\\frac{1}{k+1} \\right) \\\\\n&= -1+\\frac{(-1)^N}{N+1}+2\\sum_{k=1}^N \\frac{(-1)^{k-1}}{k}\n\\end{align*}\nconverges to $2\\ln 2-1$ as $N\\to\\infty$, and so $S_1 = 2\\ln 2-1$.\n\nTo compute $S_2$, write $\\frac{1}{k2^n+1} = \\frac{1}{k2^n}\\cdot \\frac{1}{1+1/(k2^n)}$ as the geometric series $\\sum_{m=0}^\\infty \\frac{(-1)^m}{k^{m+1} 2^{mn+n}}$, whence\n\\[\nS_2 = \\sum_{k=1}^\\infty \\sum_{n=1}^\\infty \\sum_{m=0}^\\infty \\frac{(-1)^{k+m-1}}{k^{m+2} 2^{mn+n}}.\n\\]\n(This step requires $n \\geq 1$, as otherwise the geometric series would not converge for $k=0$.)\nNow note that this triple sum converges absolutely: we have\n\\begin{align*}\n\\sum_{m=0}^\\infty \\frac{1}{k^{m+2} 2^{mn+n}} &= \n\\frac{1}{k^2 2^n} \\cdot \\frac{1}{1-\\frac{1}{k 2^n}} \\\\\n&= \\frac{1}{k(k2^n-1)} \\leq \\frac{1}{k^2 2^{n-1}}\n\\end{align*}\nand so\n\\begin{align*}\n\\sum_{k=1}^\\infty \\sum_{n=1}^\\infty \\sum_{m=0}^\\infty \\frac{1}{k^{m+2} 2^{mn+n}} &\\leq\n\\sum_{k=1}^\\infty \\sum_{n=1}^\\infty  \\frac{1}{k^2 2^{n-1}}\\\\\n &= \\sum_{k=1}^\\infty \\frac{2}{k^2} < \\infty.\n \\end{align*}\n\nThus we can rearrange the sum to get\n\\[\nS_2 = \\sum_{m=0}^\\infty (-1)^m \\left( \\sum_{n=1}^\\infty \\frac{1}{2^{mn+n}}\\right) \\left(\\sum_{k=1}^\\infty \n\\frac{(-1)^{k-1}}{k^{m+2}} \\right).\n\\]\nThe sum in $n$ is the geometric series \n\\[\n\\frac{1}{2^{m+1}(1-\\frac{1}{2^{m+1}})} = \\frac{1}{2^{m+1}-1}.\n\\]\nIf we write the sum in $k$ as $S_3$, then note that\n\\[\n\\sum_{k=1}^\\infty \\frac{1}{k^{m+2}} = S_3 + 2 \\sum_{k=1}^\\infty \\frac{1}{(2k)^{m+2}}\n= S_3 + \\frac{1}{2^{m+1}} \\sum_{k=1}^\\infty \\frac{1}{k^{m+2}}\n\\]\n(where we can rearrange terms in the first equality because all of the series converge absolutely), and so \n\\[\nS_3 = \\left(1-\\frac{1}{2^{m+1}}\\right)  \\sum_{k=1}^\\infty \\frac{1}{k^{m+2}}.\n\\]\nIt follows that\n\\begin{align*}\nS_2 &= \\sum_{m=0}^\\infty \\frac{(-1)^m}{2^{m+1}} \\sum_{k=1}^\\infty \\frac{1}{k^{m+2}} \\\\\n&= \\sum_{k=1}^\\infty \\frac{1}{2k^2} \\sum_{m=0}^\\infty \\left(-\\frac{1}{2k}\\right)^m \\\\\n&= \\sum_{k=1}^\\infty \\frac{1}{k(2k+1)} \\\\\n&= 2 \\sum_{k=1}^\\infty \\left( \\frac{1}{2k} - \\frac{1}{2k+1} \\right) = 2(1-\\ln 2).\n\\end{align*}\nFinally, we have $S = S_1 + S_2 = 1$.\n\n\\noindent\n\\textbf{Second solution:}\n(by Tewodros Amdeberhan)\nSince $\\int_0^1 x^t\\,dx = \\frac{1}{1+t}$ for any $t \\geq 1$, we also have\n\\[\nS = \\sum_{k=1}^\\infty  \\sum_{n=0}^\\infty \\frac{(-1)^{k-1}}{k} \\int_0^1 x^{k2^n}\\,dx.\n\\]\nAgain by absolute convergence, we are free to permute the integral and the sums:\n\\begin{align*}\nS &= \\int_0^1 dx\\, \\sum_{n=0}^\\infty \\sum_{k=1}^\\infty \\frac{(-1)^{k-1}}{k} x^{k2^n} \\\\\n&= \\int_0^1 dx\\, \\sum_{n=0}^\\infty \\log (1 + x^{2^n}).\n\\end{align*}\nDue to the uniqueness of binary expansions of nonnegative integers, we have the identity\nof formal power series\n\\[\n\\frac{1}{1 - x} = \\prod_{n=0}^\\infty (1 + x^{2^n});\n\\]\nthe product converges absolutely for $0 \\leq x < 1$. We thus have\n\\begin{align*}\nS &= -\\int_0^1 \\log (1-x)\\,dx \\\\\n&= \\left((1-x) \\log (1-x) - (1-x)\\right)_0^1 \\\\\n&= 1.\n\\end{align*}\n\n\\noindent\n\\textbf{Third solution:}\n(by Serin Hong)\nAgain using absolute convergence, we may write\n\\[\nS = \\sum_{m=2}^\\infty \\frac{1}{m} \\sum_{k} \\frac{(-1)^{k-1}}{k}\n\\]\nwhere $k$ runs over all positive integers for which $m = k2^n+1$ for some $n$.\nIf we write $e$ for the 2-adic valuation of $m-1$ and $j = (m-1)2^{-e}$ for the odd part of $m-1$, then the values of $k$ are $j 2^i$ for $i=0,\\dots,e$. The inner sum can thus be evaluated as\n\\[\n\\frac{1}{j} - \\sum_{i=1}^e \\frac{1}{2^i j}\n= \\frac{1}{2^e j} = \\frac{1}{m-1}.\n\\]\nWe thus have\n\\[\nS = \\sum_{m=2}^\\infty \\frac{1}{m(m-1)} \\\\\n= \\sum_{m=2}^\\infty \\left( \\frac{1}{m-1} - \\frac{1}{m} \\right) \\\\\n= 1.\n\\]\n\n\\noindent\n\\textbf{Fourth solution:}\n(by Liang Xiao)\nLet $S_0$ and $S_1$ be the sums $\\sum_k \\frac{1}{k} \\sum_{n=0}^\\infty \\frac{1}{k2^n+1}$\nwith $k$ running over all odd and all even positive integers, respectively, so that \n\\[\nS = S_0 - S_1.\n\\]\nIn $S_1$, we may write $k = 2\\ell$ to obtain\n\\begin{align*}\nS_1 &= \\sum_{\\ell=1}^\\infty \\frac{1}{2\\ell} \\sum_{n=0}^\\infty \\frac{1}{\\ell 2^{n+1} + 1} \\\\\n&= \\frac{1}{2} (S_0 + S_1) - \\sum_{\\ell=1}^\\infty \\frac{1}{2\\ell(\\ell+1)} \\\\\n&= \\frac{1}{2} (S_0 + S_1) - \\frac{1}{2}\n\\end{align*}\nbecause the last sum telescopes; this immediately yields $S = 1$.\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2017,
    "label": "A1",
    "difficulty": "1",
    "problem": "Let $S$ be the smallest set of positive integers such that\n\\begin{enumerate}",
    "solution": "We claim that the positive integers not in $S$ are $1$ and all multiples of $5$. If $S$ consists of all other natural numbers, then $S$ satisfies the given conditions: note that the only perfect squares not in $S$ are $1$ and numbers of the form $(5k)^2$ for some positive integer $k$, and it readily follows that both (b) and (c) hold.\n\n\nNow suppose that $T$ is another set of positive integers satisfying (a), (b), and (c). Note from (b) and (c) that if $n \\in T$ then $n+5 \\in T$, and so $T$ satisfies the following property: \n\\begin{itemize}"
  },
  {
    "year": 2017,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $Q_0(x) = 1$, $Q_1(x) = x$, and\n\\[\nQ_n(x) = \\frac{(Q_{n-1}(x))^2 - 1}{Q_{n-2}(x)}\n\\]\nfor all $n \\geq 2$. Show that, whenever $n$ is a positive integer, $Q_n(x)$ is equal to a polynomial with integer coefficients.",
    "solution": "\\textbf{First solution.}\nDefine $P_n(x)$ for $P_0(x) = 1$, $P_1(x) = x$, and $P_n(x) = x \nP_{n-1}(x)-P_{n-2}(x)$. We claim that $P_n(x) = Q_n(x)$ for all $n \\geq 0$;\nsince $P_n(x)$ clearly is a polynomial \nwith integer coefficients for all $n$, this will imply the desired result.\n\n Since $\\{P_n\\}$ and $\\{Q_n\\}$ are \nuniquely determined by their respective recurrence relations and the \ninitial conditions $P_0,P_1$ or $Q_0,Q_1$, it suffices to check that \n$\\{P_n\\}$ satisfies the same recurrence as $Q$: that is, \n$(P_{n-1}(x))^2-P_n(x)P_{n-2}(x) = 1$ for all $n \\geq 2$. Here is one \nproof of this: for $n \\geq 1$, define the $2\\times 2$ matrices \n\\[\nM_n = \n\\begin{pmatrix} P_{n-1}(x) & P_n (x) \\\\ P_{n-2}(x) & \nP_{n-1}(x) \\end{pmatrix}, \\quad T = \\begin{pmatrix} x & -1 \\\\ 1 & 0 \\end{pmatrix}\n\\]\nwith $P_{-1}(x) = 0$ (this value being consistent with the recurrence).\nThen $\\det(T) = 1$ and $T M_{n} = M_{n+1}$, so by induction on $n$ we have\n\\[\n(P_{n-1}(x))^2-P_n(x)P_{n-2}(x) = \\det(M_n) = \n\\det(M_1) = 1.\n\\]\n\n\\noindent\n\\textbf{Remark:}\nA similar argument shows that any second-order linear recurrent sequence also satisfies a quadratic second-order recurrence relation.\nA familiar example is the identity $F_{n-1} F_{n+1} - F_n^2 = (-1)^{n}$ for $F_n$ the $n$-th Fibonacci number. \nMore examples come from various classes of \\emph{orthogonal polynomials}, including the Chebyshev polynomials mentioned below.\n\n\\noindent\n\\textbf{Second solution.}\nWe establish directly that $Q_n(x) = x \nQ_{n-1}(x)-Q_{n-2}(x)$, which again suffices. \nFrom the equation\n\\[\n1 = Q_{n-1}(x)^2 - Q_n(x) Q_{n-2}(x) = Q_n(x)^2 - Q_{n+1}(x) Q_{n-1}(x)\n\\]\nwe deduce that\n\\[\nQ_{n-1}(x)(Q_{n-1}(x) + Q_{n+1}(x)) = Q_n(x) (Q_n(x) + Q_{n-2}(x)).\n\\]\nSince $\\deg(Q_n(x)) = n$ by an obvious induction, the polynomials $Q_n(x)$ are all nonzero. We may thus rewrite the previous equation as\n\\[\n\\frac{Q_{n+1}(x) + Q_{n-1}(x)}{Q_n(x)} = \\frac{Q_n(x) + Q_{n-2}(x)}{Q_{n-1}(x)},\n\\]\nmeaning that the rational functions $\\frac{Q_n(x) + Q_{n-2}(x)}{Q_{n-1}(x)}$\nare all equal to a constant value. By taking $n=2$ and computing from the definition that $Q_2(x) = x^2-1$,\nwe find the constant value to be $x$; this yields the desired recurrence.\n\n\\noindent\n\\textbf{Remark:}\nBy induction, one may also obtain the explicit formula\n\\[\nQ_n(x) = \\sum_{k=0}^{\\lfloor n/2 \\rfloor} (-1)^k \\binom{n-k}{k} x^{n-2k}.\n\\]\n\n\\noindent\n\\textbf{Remark:}\nIn light of the explicit formula for $Q_n(x)$,\nKarl Mahlburg suggests the following bijective interpretation of the identity\n$Q_{n-1}(x)^2 - Q_n(x) Q_{n-2}(x) = 1$.\nConsider the set $C_n$ of integer compositions of $n$ with all parts 1 or 2; \nthese are ordered tuples $(c_1, \\dots, c_k)$ such that $c_1 + \\cdots + c_k = n$ and $c_i  \\in \\{1,2\\}$ for all $i$.\nFor a given composition $c$, let $o(c)$ and $d(c)$ denote the number of 1's and 2's, respectively.\nDefine the generating function\n\\[\nR_n(x) = \\sum_{c \\in C_n} x^{o(c)};\n\\]\nthen $R_n(x) = \\sum_{j} \\binom{n-j}{j} x^{n-2j}$, so that $Q_n(x) = i^{-n/2} R_n(ix)$.\n(The polynomials $R_n(x)$ are sometimes called \\emph{Fibonacci polynomials}; they satisfy $R_n(1) = F_n$.\nThis interpretation of $F_n$ as the cardinality of $C_n$ first arose in the study of Sanskrit prosody, specifically the analysis of a line of verse as a sequence of long and short syllables, at least 500 years prior to\nthe work of Fibonacci.)\n\nThe original identity is equivalent to the identity\n\\[\nR_{n+1}(x) R_{n-1}(x) - R_n(x)^2 = (-1)^{n-1}.\n\\]\nThis follows because if we identify the composition $c$ with a tiling of a $1 \\times n$ rectangle by $1 \\times 1$ squares and $1 \\times 2$ dominoes, it is \\emph{almost} a bijection to place two tilings of length $n$ on top of each other, offset by one square, and hinge at the first possible point (which is the first square in either). This only fails when both tilings are all dominoes, which gives the term $(-1)^{n-1}$.\n\n\\noindent\n\\textbf{Remark:}\nThis problem appeared on the 2012 India National Math Olympiad; see\n\\url{https://artofproblemsolving.com/community/c6h1219629}.\nAnother problem based on the same idea is problem A2 from the 1993 Putnam."
  },
  {
    "year": 2017,
    "label": "A3",
    "difficulty": "3",
    "problem": "Let $a$ and $b$ be real numbers with $a<b$, and let $f$ and $g$ be continuous functions from $[a,b]$ to $(0, \\infty)$\nsuch that $\\int_a^b f(x)\\,dx = \\int_a^b g(x)\\,dx$ but $f \\neq g$. For every positive integer $n$, define\n\\[\nI_n = \\int_a^b \\frac{(f(x))^{n+1}}{(g(x))^n}\\,dx.\n\\]\nShow that $I_1, I_2, I_3, \\dots$ is an increasing sequence with $\\lim_{n \\to \\infty} I_n = \\infty$.",
    "solution": "\\textbf{First solution.}\nExtend the definition of $I_n$ to $n=0$, so that $I_0 = \\int_a^b f(x)\\,dx > 0$. Since $\\int_a^b (f(x)-g(x))\\,dx = 0$, we have\n\\begin{align*}\nI_1-I_0 &= \\int_a^b \\frac{f(x)}{g(x)}(f(x)-g(x)) \\, dx \\\\\n&= \\int_a^b \\frac{(f(x)-g(x))^2}{g(x)} \\,dx > 0,\n\\end{align*}\nwhere the inequality follows from the fact that the integrand is a nonnegative continuous function on $[a,b]$ that is not identically $0$. Now for $n \\geq 0$, the Cauchy--Schwarz inequality gives\n\\begin{align*}\nI_n I_{n+2} &= \\left( \\int_a^b \\frac{(f(x))^{n+1}}{(g(x))^n}\\,dx \\right) \\left( \\int_a^b \\frac{(f(x))^{n+3}}{(g(x))^{n+2}}\\,dx \\right) \\\\\n&\\geq \\left(\\int_a^b \\frac{(f(x))^{n+2}}{(g(x))^{n+1}}\\,dx \\right)^2 = I_{n+1}^2.\n\\end{align*}\nIt follows that the sequence $\\{I_{n+1}/I_n\\}_{n=0}^\\infty$ is nondecreasing. Since $I_1/I_0>1$, this implies that $I_{n+1}>I_n$ for all $n$; also,\n$I_n/I_0 = \\prod_{k=0}^{n-1} (I_{k+1}/I_k) \\geq (I_1/I_0)^n$, and so $\\lim_{n\\to\\infty} I_n = \\infty$ since $I_1/I_0>1$ and $I_0 > 0$.\n\n\\noindent\n\\textbf{Remark:}\nNoam Elkies suggests the following variant of the previous solution,\nwhich eliminates the need to separately check that $I_1 > I_0$.\nFirst, the proof that $I_n I_{n+2} \\geq I_{n+1}^2$ applies also for $n=-1$ under the convention that $I_{-1} = \\int_a^b g(x)\\,dx$ (as in the fourth solution below).\nSecond, this equality must be strict for each $n \\geq -1$: \notherwise, the equality condition in Cauchy--Schwarz would imply that \n$g(x) = c f(x)$ identically for some $c>0$, and the equality $\\int_a^b f(x)\\,dx = \\int_a^b g(x)\\,dx$ would then force $c=1$, contrary to assumption. Consequently, the sequence $I_{n+1}/I_n$ is strictly increasing; since\n$I_0/I_{-1} = 1$, it follows that for $n \\geq 0$, we again have $I_{n+1}/I_n \\geq I_1/I_0 > 1$ and so on.\n\n\\textbf{Second solution.}\n(from Art of Problem Solving, user \\texttt{MSTang})\nSince $\\int_a^b (f(x) - g(x))\\,dx = 0$,\nwe have\n\\begin{align*}\nI_{n+1} - I_n &= \\int_a^b \\left( \\frac{(f(x))^{n+2}}{(g(x))^{n+1}} - \\frac{(f(x))^{n+1}}{(g(x))^{n}} \\right)\\,dx \\\\\n&= \\int_a^b \\frac{(f(x))^{n+1}}{(g(x))^{n+1}} (f(x)-g(x))\\,dx \\\\\n&= \\int_a^b \\left(\\frac{(f(x))^{n+1}}{(g(x))^{n+1}} - 1 \\right) (f(x)-g(x))\\,dx \\\\\n&= \\int_a^b \\frac{(f(x)-g(x))^2 ((f(x))^n + \\cdots + g(x)^n)}{(g(x))^{n+1}}\\,dx.\n\\end{align*}\nThe integrand is continuous, nonnegative, and not identically zero; hence $I_{n+1} - I_n > 0$.\n\nTo prove that $\\lim_{n \\to \\infty} I_n = \\infty$, note that we cannot have $f(x) \\leq g(x)$ identically, as then\nthe equality $\\int_a^b f(x)\\,dx = \\int_a^b g(x)\\,dx$ would imply $f(x) = g(x)$ identically. That is, there exists\nsome $t \\in [a,b]$ such that $f(t) > g(t)$. By continuity, there exist a quantity $c > 1$\nand an interval $J = [t_0, t_1]$ in $[a,b]$ such that $f(x) \\geq c g(x)$ for all $x \\in J$. We then have\n\\[\nI_n \\geq \\int_{t_0}^{t_1} \\frac{(f(x))^{n+1}}{(g(x))^n}\\,dx \\\\\n\\geq c^n \\int_{t_0}^{t_1} f(x)\\,dx;\n\\]\nsince $f(x) > 0$ everywhere, we have $\\int_{t_0}^{t_1} f(x)\\,dx > 0$\nand hence $I_n$ is bounded below by a quantity which tends to $\\infty$.\n\n\\noindent\n\\textbf{Remark:}\nOne can also give a variation of the second half of the solution which shows directly that\n$I_{n+1} - I_n \\geq c^n d$ for some $c > 1, d>0$, thus proving both assertions at once.\n\n%\\textbf{Third solution.}\n%(from Art of Problem Solving, user \\texttt{kybard})\n%Write\n%\\begin{align*}\n%I_n - I_{n-1} &= \\int_a^b (1 + (f(x)-g(x))/g(x))^n (f(x)-g(x))\\,dx \\\\\n%&\\geq (1 + n (f(x)-g(x))/g(x)) (f(x)-g(x))\\,dx \\\\\n%&= n \\int_a^b \\frac{(f(x)-g(x))^2}{g(x)}\\,dx.\n%\\end{align*}\n%The integrand is nonnegative and not identically zero, so\n%$I_n - I_{n-1}$ is bounded below by $n$ times a positive constant. This proves both assertions at once.\n\n\\textbf{Third solution.}\n(from David Savitt, via Art of Problem Solving)\nExtend the definition of $I_n$ to all \\emph{real} $n$,\nand note that \n\\[\nI_{-1} = \\int_a^b g(x)\\,dx = \\int_a^b f(x)\\,dx = I_0.\n\\]\nBy writing\n\\[\nI_n = \\int_a^b \\exp((n+1)\\log f(x) - n \\log g(x))\\,dx,\n\\]\nwe see that the integrand is a strictly convex function of $n$, as then is $I_n$.\nIt follows that $I_n$ is strictly increasing and unbounded for $n \\geq 1$.\n\n\\textbf{Fourth solution.}\n(by David Rusin)\nAgain, extend the definition of $I_n$ to $n=-1$.\nNow note that for $n \\geq 0$ and $x \\in [a,b]$, we have\n\\[\n(f(x) - g(x)) \\left( \\left( \\frac{f(x)}{g(x)} \\right)^{n+1}  - \\left( \\frac{f(x)}{g(x)} \\right)^{n}  \\right) \\geq 0\n\\]\nbecause both factors have the same sign (depending on the comparison between $f(x)$ and $g(x)$);\nmoreover, equality only occurs when $f(x) = g(x)$. Since $f$ and $g$ are not identically equal, we deduce that\n\\[\nI_{n+1} - I_n > I_n - I_{n-1}\n\\]\nand so in particular\n\\[\nI_{n+1} - I_n \\geq I_1 - I_0 > I_0 - I_{-1} = 0.\n\\]\nThis proves both claims.\n\n\\textbf{Remark:}\nThis problem appeared in 2005 on an undergraduate math olympiad in Brazil.\nSee \\url{https://artofproblemsolving.com/community/c7h57686p354392} for discussion."
  },
  {
    "year": 2017,
    "label": "A4",
    "difficulty": "4",
    "problem": "A class with $2N$ students took a quiz, on which the possible scores were $0,1,\\dots,10$. Each of these scores\noccurred at least once, and the average score was exactly $7.4$. Show that the class can be divided into two groups of $N$ students in such a way that the average score for each group was exactly $7.4$.",
    "solution": "\\textbf{First solution.}\nLet $a_1,\\dots,a_{2N}$ be the scores in nondecreasing order, and define the sums\n$s_i = \\sum_{j=i+1}^{i+N} a_j$ for $i=0,\\dots,N$.\nThen $s_0 \\leq \\cdots \\leq s_{N}$\nand\n$s_0 + s_{N} = \\sum_{j=1}^{2N} a_j = 7.4(2N)$,\nso $s_0 \\leq 7.4N \\leq s_N$. Let $i$ be the largest index for which $s_i \\leq 7.4N$;\nnote that we cannot have $i = N$, as otherwise $s_0 = s_N = 7.4N$ and hence \n$a_1 = \\cdots = a_{2N} = 7.4$, contradiction.\nThen $7.4N - s_i < s_{i+1} - s_i = a_{i+N+1} - a_i$ and so\n\\[\na_i < s_i + a_{i+N+1} - 7.4N \\leq a_{i+N+1};\n\\]\nsince all possible scores occur, this means that we can find $N$ scores with sum $7.4N$\nby taking $a_{i+1}, \\dots, a_{i+N+1}$ and omitting one occurrence of the value $s_i + a_{i+N+1} - 7.4N$.\n\n\\noindent\n\\textbf{Remark:}\nDavid Savitt (via Art of Problem Solving) points out that a similar argument applies provided that\nthere are an even number of students, the total score is even, and the achieved scores form a block of consecutive integers.\n\n\\noindent\n\\textbf{Second solution.}\nWe first claim that for any integer $m$ with $15 \\leq m \\leq 40$, we can find five distinct elements of the set $\\{1,2,\\ldots,10\\}$ whose sum is $m$. Indeed, for $0 \\leq k \\leq 4$ and $1 \\leq \\ell \\leq 6$, we have\n\\[\n\\left(\\sum_{j=1}^k j \\right) + (k+\\ell) + \\left(\\sum_{j=k+7}^{10} j \\right) = 34-5k+\\ell,\\]\nand for fixed $k$ this takes all values from $35-5k$ to $40-5k$ inclusive; then as $k$ ranges from $0$ to $4$, this takes all values from $15$ to $40$ inclusive.\n\nNow suppose that the scores are $a_1,\\ldots,a_{2N}$, where we order the scores so that $a_k=k$ for $k \\leq 10$ and the subsequence $a_{11},a_{12},\\ldots,a_{2N}$ is nondecreasing. For $1 \\leq k \\leq N-4$, define $S_k = \\sum_{j=k+10}^{k+N+4} a_j$. Note that for each $k$, $S_{k+1}-S_k = a_{k+N+5}-a_{k+10}$ and so $0 \\leq S_{k+1}-S_k \\leq 10$. Thus $S_1,\\ldots,S_{N-4}$ is a nondecreasing sequence of integers where each term is at most $10$ more than the previous one. On the other hand, we have \n\\begin{align*}\nS_1 + S_{N-4} &= \\sum_{j=11}^{2N} a_j \\\\\n&= (7.4)(2N)-\\sum_{j=1}^{10} a_j \\\\\n&= (7.4)(2N)-55,\n\\end{align*}\nwhence $S_1 \\leq 7.4N-27.5 \\leq S_{N-4}$. It follows that there is some $k$ such that $S_k \\in [7.4N-40, 7.4N-15]$, since this interval has length $25$ and $7.4N-27.5$ lies inside it.\n\n\nFor this value of $k$, note that both $S_k$ and $7.4N$ are integers (the latter since the sum of all scores in the class is the integer $(7.4)(2N)$ and so $N$ must be divisible by $5$). Thus there is an integer $m$ with $15 \\leq m \\leq 40$ for which $S_k = 7.4N-m$. By our first claim, we can choose five scores from $a_1,\\ldots,a_{10}$ whose sum is $m$. When we add these to the sum of the $N-5$ scores $a_{k+10},\\ldots,a_{k+N+4}$, we get precisely $7.4N$. We have now found $N$ scores whose sum is $7.4N$ and thus whose average is $7.4$.\n\n\\noindent\n\\textbf{Third solution.}\nIt will suffices to show that given any partition of the students into two groups of $N$, if the sums are not equal we can bring them closer together by swapping one pair of students between the two groups. To state this symbolically,\nlet $S$ be the set of students and, for any subset $T$ of $S$, let $\\Sigma T$ denote the sum of the scores of the students in $T$; we then show that if $S = A \\cup B$ is a partition into two $N$-element sets with\n$\\Sigma A > \\Sigma B$, then there exist students $a \\in A, B \\in B$ such that the sets\n\\[\nA' = A \\setminus \\{a\\} \\cup \\{b\\}, \\qquad\nB' = A \\setminus \\{b\\} \\cup \\{a\\}\n\\]\nsatisfy\n\\[\n0 \\leq \\Sigma A' - \\Sigma B' < \\Sigma A - \\Sigma B.\n\\]\nIn fact, this argument will apply at the same level of generality as in the remark following the first solution.\n\nTo prove the claim, let \n$a_1,\\dots,a_n$ be the scores in $A$ and let $b_1,\\dots,b_n$ be the scores in $B$ (in any order).\nSince $\\Sigma A - \\Sigma B \\equiv \\Sigma S \\pmod{2}$ and the latter is even, we must have\n$\\Sigma A - \\Sigma B \\geq 2$.\nIn particular, there must exist indices $i,j \\in \\{1,\\dots,n\\}$ such that $a_i > b_j$.\nConsequently, if we sort the sequence $a_1,\\dots,a_n,b_1,\\dots,b_n$ into nondecreasing order,\nit must be the case that some term $b_j$ is followed by some term $a_i$.\nMoreover, since the achieved scores form a range of consecutive integers, we must in fact have\n$a_i = b_j + 1$. Consequently, if we take $a = a_i$, $b = b_j$, we then have\n$\\Sigma A' - \\Sigma' B = \\Sigma A - \\Sigma B - 2$, which proves the claim."
  },
  {
    "year": 2017,
    "label": "A5",
    "difficulty": "5",
    "problem": "Each of the integers from $1$ to $n$ is written on a separate card, and then the cards are combined into a deck and shuffled. Three players, $A$, $B$, and $C$, take turns in the order $A,B,C,A,\\dots$ choosing one card at random from the deck. (Each card in the deck is equally likely to be chosen.) After a card is chosen, that card and all higher-numbered cards are removed from the deck, and the remaining cards are reshuffled before the next turn. Play continues until one of the three players wins the game by drawing the card numbered $1$.\n\nShow that for each of the three players, there are arbitrarily large values of $n$ for which that player has the highest probability among the three players of winning the game.",
    "solution": "\\textbf{First solution.}\nLet $a_n, b_n, c_n$ be the probabilities that players $A$, $B$, $C$, respectively, will win the game.\nWe compute these by induction on $n$, starting with the values\n\\[\na_1 = 1, \\qquad b_1 = 0, \\qquad c_1 = 0.\n\\]\nIf player $A$ draws card $k$, then the resulting game state is that of a deck of $k-1$ cards with the players taking turns in the order $B,C,A,B,\\dots$. In this state, the probabilities that players $A, B, C$ will win are\n$c_{k-1}, a_{k-1}, b_{k-1}$ provided that we adopt the convention that\n\\[\na_0 = 0, \\qquad b_0 = 0, \\qquad c_0 = 1.\n\\]\nWe thus have\n\\[\na_n = \\frac{1}{n} \\sum_{k=1}^{n} c_{k-1}, \\quad\nb_n = \\frac{1}{n} \\sum_{k=1}^{n} a_{k-1}, \\quad\nc_n = \\frac{1}{n} \\sum_{k=1}^{n} b_{k-1}.\n\\]\nPut\n\\[\nx_n = a_n - b_n, \\quad y_n = b_n - c_n, \\quad z_n = c_n - a_n;\n\\]\nwe then have\n\\begin{align*}\n x_{n+1} &= \\frac{n}{n+1} x_n + \\frac{1}{n+1}z_n, \\\\\n y_{n+1} &= \\frac{n}{n+1} y_n + \\frac{1}{n+1}x_n, \\\\\n z_{n+1} &= \\frac{n}{n+1} z_n + \\frac{1}{n+1}y_n.\n\\end{align*}\nNote that if $a_{n+1} = b_{n+1} = c_{n+1} = 0$, then\n\\[\nx_n = -nz_n = n^2y_n = -n^3x_n = n^4z_n\n\\]\nand so $x_n = z_n = 0$, or in other words $a_n = b_n = c_n$. By induction on $n$, we deduce that \n$a_n, b_n, c_n$ cannot all be equal. That is, the quantities $x_n, y_n, z_n$ add up to zero and at most one of them\nvanishes; consequently, the quantity $r_n = \\sqrt{x_n^2 + y_n^2 + z_n^2}$ is always positive\nand the quantities\n\\[\nx'_n = \\frac{x_n}{r_n}, \\quad y'_n = \\frac{y_n}{r_n}, \\quad z'_n = \\frac{z_n}{r_n}\n\\]\nform the coordinates of a point $P_n$ on a fixed circle $C$ in $\\mathbb{R}^3$.\n\nLet $P'_n$ be the point $(z_n, x_n, y_n)$ obtained from $P_n$ by a clockwise rotation of angle $\\frac{2\\pi}{3}$.\nThe point $P_{n+1}$ then lies on the ray through the origin passing through the point dividing the chord from $P_n$ to $P'_n$ in the ratio $1:n$. \nThe (clockwise) arc from $P_n$ to $P_{n+1}$ therefore has a measure of\n\\[\n\\arctan \\frac{\\sqrt{3}}{2n-1}\n= \\frac{\\sqrt{3}}{2n-1} + O(n^{-3});\n\\]\nthese measures form a null sequence whose sum diverges. It follows that any arc of $C$ contains infinitely many of the $P_n$; taking a suitably short arc around the point $(\\frac{\\sqrt{2}}{2}, 0, -\\frac{\\sqrt{2}}{2})$, we deduce that for infinitely many $n$, $A$ has the highest winning probability, and similarly for $B$ and $C$.\n\n\\noindent\n\\textbf{Remark:}\nFrom the previous analysis, we also deduce that\n\\[\n\\frac{r_{n+1}}{r_n} = \\frac{\\sqrt{n^2-n+1}}{n+1} = 1 - \\frac{3}{2(n+1)} + O(n^{-2}),\n\\]\nfrom which it follows that $r_n \\sim c n^{-3/2}$ for some $c>0$.\n\n\\noindent\n\\textbf{Second solution.}\n(by Noam Elkies)\nIn this approach, we instead compute the probability $p_n(m)$ that the game ends after exactly $m$ turns\n(the winner being determined by the residue of $m$ mod 3).\nWe use the convention that $p_0(0) = 1$, $p_0(m) = 0$ for $m>0$.\nDefine the generating function $P_n(X) = \\sum_{m=0}^n p_n(m) x^m$.\nWe will establish that\n\\[\nP_n(X) = \\frac{X(X+1)\\cdots(X+n-1)}{n!}\n\\]\n(which may be guessed by computing $p_n(m)$ for small $n$ by hand). There are several ways to do this; for instance,\nthis follows from the recursion\n\\[\nP_n(X) = \\frac{1}{n} X P_{n-1}(X) + \\frac{(n-1)}{n} P_{n-1}(X).\n\\]\n(In this recursion, the first term corresponds to conditional probabilities given that the first card drawn is $n$,\nand the second term corresponds to the remaining cases.)\n\nLet $\\omega$ be a primitive cube root of 1. With notation as in the first solution,\nwe have\n\\[\nP_n(\\omega) = a_n + b_n \\omega + c_n \\omega;\n\\]\ncombining this with the explicit formula for $P_n(X)$ and the observation that\n\\[\n\\mathrm{arg}(w+n) = \\arctan \\frac{\\sqrt{3}}{2n-1}\n\\]\nrecovers the geometric description of $a_n, b_n, c_n$\ngiven in the first solution (as well as the remark following the first solution).\n\n\\noindent\n\\textbf{Third solution.}\nFor this argument, we use the auxiliary quantities\n\\[\na'_n = a_n - \\frac{1}{3}, \\quad b'_n = b_n - \\frac{1}{3}, \\quad c'_n = c_n - \\frac{1}{3};\n\\]\nthese satisfy the relations\n\\[\na'_n = \\frac{1}{n} \\sum_{k=1}^{n} c'_{k-1}, \\quad\nb'_n = \\frac{1}{n} \\sum_{k=1}^{n} a'_{k-1}, \\quad\nc'_n = \\frac{1}{n} \\sum_{k=1}^{n} b'_{k-1}\n\\]\nas well as \n\\begin{align*}\na'_{n+1} &= a'_n + \\frac{1}{n+1} (c'_n-a'_n)  \\\\\nb'_{n+1} &= b'_n + \\frac{1}{n+1} (a'_n-b'_n) \\\\\nc'_{n+1} &= c'_n + \\frac{1}{n+1} (b'_n-c'_n).\n\\end{align*}\nWe now show that $\\sum_{n=1}^\\infty a'_n$ cannot diverge to $+\\infty$\n(and likewise for $\\sum_{n=1}^\\infty b'_n$ and $\\sum_{n=1}^\\infty c'_n$ by similar reasoning).\nSuppose the contrary; then there exists some $\\epsilon > 0$ and some $n_0 > 0$ \nsuch that $\\sum_{k=1}^n a'_k \\geq \\epsilon$ for all $n \\geq n_0$.\nFor $n > n_0$, we have $b'_n \\geq \\epsilon$; this in turn implies that $\\sum_{n=1}^\\infty b'_n$ diverges to $+\\infty$.\nContinuing around the circle, we deduce that for $n$ sufficiently large, all three of $a'_n, b'_n, c'_n$ are positive;\nbut this contradicts the identity $a'_n + b'_n + c'_n = 0$. We thus conclude that $\\sum_{n=1}^\\infty a'_n$ does not diverge to $+\\infty$; in particular, $\\liminf_{n \\to \\infty} a'_n \\leq 0$.\n\nBy the same token, we may see that $\\sum_{n=1}^\\infty a'_n$ cannot converge to a positive limit $L$\n(and likewise for $\\sum_{n=1}^\\infty b'_n$ and $\\sum_{n=1}^\\infty c'_n$ by similar reasoning).\nNamely, this would imply that $b'_n \\geq L/2$ for $n$ sufficiently large, contradicting the previous argument.\n\nBy similar reasoning, $\\sum_{n=1}^\\infty a'_n$ cannot diverge to $-\\infty$ or converge to a negative limit $L$\n(and likewise for $\\sum_{n=1}^\\infty b'_n$ and $\\sum_{n=1}^\\infty c'_n$ by similar reasoning).\n\nWe next establish that there are infinitely many $n$ for which $a'_n > 0$ (and likewise for $b'_n$ and $c'_n$ by similar reasoning).\nSuppose to the contrary that for $n$ sufficiently large, we have $a'_n \\leq 0$. \nBy the previous arguments, the sum $\\sum_{n=1}^\\infty a'_n$ cannot diverge to $\\infty$ or converge to a nonzero limit;\nit must therefore converge to 0. In particular, for $n$ sufficiently large, we have\n$b'_n = \\sum_{k=1}^n a'_{k-1} \\geq 0$. Iterating the construction, we see that for $n$ sufficiently large,\nwe must have $c'_n \\leq 0$, $a'_n \\geq 0$, $b'_n \\leq 0$, and $c'_n \\geq 0$. As a result, for $n$\nsufficiently large we must have $a'_n = b'_n = c'_n = 0$; but we may rule this out as in the original solution.\n\nBy similar reasoning, we may deduce that there are infinitely many $n$ for which $a'_n < 0$ (and likewise for $b'_n$ and $c'_n$ by similar reasoning). We now continue using a suggestion of Jon Atkins.\nDefine the values of the sequence $x_n$ according to the relative comparison of $a'_n, b'_n, c'_n$ (using the fact that these cannot all be equal):\n\\begin{align*}\nx_n = 1: & \\quad a'_n \\leq b'_n < c'_n \\\\\nx_n = 2: & \\quad b'_n \\leq c'_n < a'_n \\\\\nx_n = 3: & \\quad c'_n \\leq a'_n < b'_n \\\\\nx_n = 4: & \\quad a'_n < c'_n \\leq b'_n \\\\\nx_n = 5: & \\quad b'_n < a'_n \\leq c'_n \\\\\nx_n = 6: & \\quad c'_n < b'_n \\leq a'_n.\n\\end{align*}\nWe consider these values as \\emph{states} and say that there is a \\emph{transition} from state $i$ to state $j$,\nand write $i \\Rightarrow j$, if for every $n \\geq 2$ with $x_n = i$ there exists $n' > n$ with $x_{n'} = j$.\n(In all cases when we use this notation, it will in fact be the case that the \\emph{first} value of $n'>n$ for which\n$x_{n'} \\neq i$ satisfes $x_{n'} = j$, but this is not logically necessary for our final conclusion.) \n\nSuppose that $x_n = 1$. By the earlier discussion, we must have $a'_{n'} > 0$ for some $n' > n$, and so we cannot have $x_{n'} = 1$ for all $n' > n$. On the other hand, as long as $x_n = 1$, we have \n\\begin{align*}\nc'_{n+1}-b'_{n+1} &= c'_n - b'_n + \\frac{1}{n+1}(2b'_n  - a'_n - c'_n) \\\\\n&= \\frac{n-1}{n+1} (c'_n - b'_n) + \\frac{1}{n+1}(c'_n - a'_n) > 0 \\\\\nc'_{n+1}-a'_{n+1} &= c'_n - a'_n + \\frac{1}{n+1}(a'_n + b'_n - 2c'_n) \\\\\n&= \\frac{n-1}{n+1} (c'_n - a'_n) + \\frac{1}{n+1}(b'_n - a'_n) > 0.\n\\end{align*}\nConsequently, for $n'$ the smallest value for which $x_{n'} \\neq x_n$, we must have $x_{n'} = 2$. \nBy this and two similar arguments, we deduce that\n\\[\n1 \\Rightarrow 5, \\quad 2 \\Rightarrow 6, \\quad 3 \\Rightarrow 4.\n\\]\nSuppose that $x_n = 4$. By the earlier discussion, we must have $a'_{n'} < 0$ for some $n' > n$, and so we cannot have $x_{n'} = 4$ for all $n' > n$. On the other hand, as long as $x_n = 4$, we have  \n\\begin{align*}\nb'_{n+1}-a'_{n+1} &=b'_n - a'_n + \\frac{1}{n+1} (2a'_n - b'_n - c'_n) \\\\\n&= \\frac{n-1}{n+1} (b'_n - a'_n) + \\frac{1}{n+1}(b'_n - c'_n) > 0 \\\\\nc'_{n+1}-a'_{n+1} &= c'_n - a'_n + \\frac{1}{n+1}(a'_n + b'_n - 2c'_n) \\\\\n&= \\frac{n-1}{n+1} (c'_n - a'_n) + \\frac{1}{n+1}(b'_n - a'_n) > 0.\n\\end{align*}\nConsequently, for $n'$ the smallest value for which $x_{n'} \\neq x_n$, we must have $x_{n'} = 1$. \nBy this and two similar arguments, we deduce that\n\\[\n4 \\Rightarrow 1, \\quad 5 \\Rightarrow 2, \\quad 6 \\Rightarrow 3.\n\\]\nCombining, we obtain\n\\[\n1 \\Rightarrow 5 \\Rightarrow 2 \\Rightarrow 6 \\Rightarrow 3 \\Rightarrow 4 \\Rightarrow 1\n\\]\nand hence the desired result."
  },
  {
    "year": 2017,
    "label": "A6",
    "difficulty": "6",
    "problem": "The 30 edges of a regular icosahedron are distinguished by labeling them $1,2,\\dots,30$. How many different ways \nare there to paint each edge red, white, or blue such that each of the 20 triangular faces of the icosahedron has two edges of the same color and a third edge of a different color? [Note: the top matter on each exam paper included the logo of the Mathematical Association of America, which is itself an icosahedron.]",
    "solution": "The number of such colorings is $2^{20} 3^{10} = 61917364224$.\n\n\\noindent\n\\textbf{First solution:}\nIdentify the three colors red, white, and blue with (in some order) the elements of the field $\\mathbb{F}_3$ of three elements (i.e., the ring of integers mod 3). \nThe set of colorings may then be identified with the $\\mathbb{F}_3$-vector space $\\mathbb{F}_3^E$\ngenerated by the set $E$ of edges. Let $F$ be the set of faces, and let $\\mathbb{F}_3^F$ be the $\\mathbb{F}_3$-vector space on the basis $F$; we may then define a linear transformation\n$T: \\mathbb{F}_3^E \\to \\mathbb{F}_3^F$ taking a coloring to the vector whose component corresponding to a given face equals the sum of the three edges of that face. The colorings we wish to count are the ones whose images under $T$ consist of vectors with no zero components.\n\nWe now show that $T$ is surjective. (There are many possible approaches to this step; for instance, see the following remark.) \nLet $\\Gamma$ be the dual graph of the icosahedron, that is, $\\Gamma$ has vertex set $F$ and two elements of $F$ are adjacent in $\\Gamma$ if they share an edge in the icosahedron. The graph $\\Gamma$ admits a hamiltonian path, that is, there exists an ordering\n$f_1,\\dots,f_{20}$ of the faces such that any two consecutive faces are adjacent in $\\Gamma$. \nFor example, such an ordering can be constructed with $f_1,\\dots,f_5$ being the five faces sharing a vertex of the icosahedron and $f_{16},\\dots,f_{20}$ being the five faces sharing the antipodal vertex.\n\nFor $i=1,\\dots,19$, let $e_i$ be the common edge of $f_i$ and $f_{i+1}$; these are obviously all distinct.\nBy prescribing components for $e_1,\\dots,e_{19}$ in turn and setting the others to zero,\nwe can construct an element of $\\mathbb{F}_3^E$ whose image under $T$ matches any given vector of $\\mathbb{F}_3^F$ in the components of $f_1,\\dots,f_{19}$. The vectors in $\\mathbb{F}_3^F$ obtained in this way thus form a 19-dimensional subspace; this subspace may also be described as the vectors for which the components of $f_1,\\dots,f_{19}$ have the same sum as the components of $f_{2},\\dots,f_{20}$. \n\nBy performing a mirror reflection, we can construct a second hamiltonian path $g_1,\\dots,g_{20}$ with the property that\n\\[\ng_1 = f_1, g_2 = f_5, g_3 = f_4, g_4 = f_3, g_5 = f_2.\n\\]\nRepeating the previous construction, we obtain a \\emph{different} 19-dimensional subspace of $\\mathbb{F}_3^F$ which is contained in the image of $T$. This implies that $T$ is surjective, as asserted earlier.\n\nSince $T$ is a surjective homomorphism from a 30-dimensional vector space to a 20-dimensional vector space, it has a 10-dimensional kernel. Each of the $2^{20}$ elements of $\\mathbb{F}_3^F$ with no zero components is then the image of exactly $3^{10}$ colorings of the desired form, yielding the result.\n\n\\noindent\n\\textbf{Remark:}\nThere are many ways to check that $T$ is surjective. One of the simplest is the following\n(from Art of Problem Solving, user \\texttt{Ravi12346}): form a vector in $\\mathbb{F}^E$ with components $2,1,2,1,2$ at the five edges around some vertex and all other components 0. This maps to a vector in $\\mathbb{F}^F$ with only a single nonzero component; by symmetry, every standard basis vector of $\\mathbb{F}^F$ arises in this way.\n\n\\noindent\n\\textbf{Second solution:}\n(from Bill Huang, via Art of Problem Solving user \\texttt{superpi83})\nLet $v$ and $w$ be two antipodal vertices of the icosahedron. Let $S_v$ (resp.\\ $S_w$) be the set of five edges incident to $v$ (resp.\\ $w$). Let $T_v$ (resp.\\ $T_w$) be the set of five edges of the pentagon formed by the opposite endpoints of the five edges in $S_v$ (resp. $S_w$). Let $U$ be the set of the ten remaining edges of the icosahedron.\n\nConsider any one of the $3^{10}$ possible colorings of $U$. The edges of $T_v \\cup U$ form the boundaries of five faces with no edges in common; thus each edge of $T_v$ can be colored in one of two ways consistent with the given condition,\nand similarly for $T_w$. That is, there are $3^{10} 2^{10}$ possible colorings of $T_v \\cup T_w \\cup U$ consistent with the given condition.\n\nTo complete the count, it suffices to check that there are exactly $2^5$ ways to color $S_v$ consistent with any given coloring of $T_v$. Using the linear-algebraic interpretation from the first solution, this follows by observing that\n(by the previous remark) the map from $\\mathbb{F}_3^{S_v}$ to the $\\mathbb{F}_3$-vector space on the faces incident to $v$ is surjective, and hence an isomorphism for dimensional reasons. A direct combinatorial proof is also possible."
  },
  {
    "year": 2017,
    "label": "B1",
    "difficulty": "1",
    "problem": "Let $L_1$ and $L_2$ be distinct lines in the plane. Prove that $L_1$ and $L_2$ intersect if and only if, for every\nreal number $\\lambda\\neq 0$ and every point $P$ not on $L_1$ or $L_2$, there exist points $A_1$ on $L_1$ and $A_2$\non $L_2$ such that $\\overrightarrow{PA_2} = \\lambda \\overrightarrow{PA_1}$.",
    "solution": "Recall that $L_1$ and $L_2$ intersect if and only if they are not parallel. \nIn one direction, suppose that $L_1$ and $L_2$ intersect. Then for any $P$ and $\\lambda$, the dilation (homothety) of the plane by a factor of $\\lambda$ with center $P$ carries $L_1$ to another line parallel to $L_1$ and hence not parallel to $L_2$. Let $A_2$ be the unique intersection of $L_2$ with the image of $L_1$, and let $A_1$ be the point on $L_1$ whose image under the dilation is $A_2$; then $\\overrightarrow{PA_2} = \\lambda \\overrightarrow{PA_1}$.\n\nIn the other direction, suppose that $L_1$ and $L_2$ are parallel. Let $P$ be any point in the region between $L_1$ and $L_2$ and take $\\lambda = 1$. Then for any point $A_1$ on $L_1$ and any point $A_2$ on $L_2$, the vectors \n$\\overrightarrow{PA_1}$ and $\\overrightarrow{PA_2}$ have components perpendicular to $L_1$ pointing in opposite directions; in particular, the two vectors cannot be equal.\n\n\\noindent\n\\textbf{Reinterpretation:}\n(by Karl Mahlburg)\nIn terms of vectors, we may find vectors $\\vec{v}_1, \\vec{v}_2$ and scalars $c_1, c_2$ such that\n$L_i = \\{\\vec{x} \\in \\mathbb{R}^2: \\vec{v}_i \\cdot \\vec{x} = c_i\\}$.\nThe condition in the problem amounts to finding a vector $\\vec{w}$ and a scalar $t$ such that\n$P + \\vec{w} \\in L_1, P + \\lambda w \\in L_2$; this comes down to solving the linear system\n\\begin{align*}\n\\vec{v}_1 \\cdot (P + \\vec{w}) &= c_1 \\\\\n\\vec{v}_2 \\cdot (P + \\lambda \\vec{w}) &= c_2\n\\end{align*}\nwhich is nondegenerate and solvable for all $\\lambda$ if and only if $\\vec{v}_1, \\vec{v}_2$ are linearly independent."
  },
  {
    "year": 2017,
    "label": "B2",
    "difficulty": "2",
    "problem": "Suppose that a positive integer $N$ can be expressed as the sum of $k$ consecutive positive integers\n\\[\nN = a + (a+1) +(a+2) + \\cdots + (a+k-1)\n\\]\nfor $k=2017$ but for no other values of $k>1$. Considering all positive integers $N$ with this property,\nwhat is the smallest positive integer $a$ that occurs in any of these expressions?",
    "solution": "We prove that the smallest value of $a$ is 16.\n\nNote that the expression for $N$ can be rewritten as $k(2a+k-1)/2$,\nso that $2N = k(2a+k-1)$. In this expression, $k>1$ by requirement;\n$k < 2a+k-1$ because $a>1$; and obviously $k$ and $2a+k-1$ have opposite parity. Conversely, for any factorization $2N = mn$ with $1<m<n$ and $m,n$ of opposite parity, we obtain an expression of $N$ in the desired form by taking\n$k = m$, $a = (n+1-m)/2$.\n\nWe now note that $2017$ is prime. (On the exam, solvers would have had to verify this by hand.\nSince $2017 < 45^2$, this can be done by trial division by the primes up to 43.)\nFor $2N = 2017(2a+2016)$ not to have another expression of the specified form, it must be the case that\n$2a+2016$ has no odd divisor greater than 1; that is, $2a+2016$ must be a power of 2.\nThis first occurs for $2a+2016=2048$, yielding the claimed result.\n\n\\textbf{Reinterpretation:}\n(by Karl Mahlburg)\nTo avoid $N$ having another representation, for $k = 2, \\dots, 2016$, we must have\n\\[\nN \\not\\equiv \\begin{cases} k/2 & k \\equiv 0 \\pmod{2} \\\\\n0 & k \\equiv 1 \\pmod{2}.\n\\end{cases}\n\\]\nConsequently, $N \\not\\equiv 0 \\pmod{p}$ for any odd prime $p<2017$\nand $N \\equiv 0 \\pmod{1024}$. Since $N$ must be divisible by 2017, this again yields the claimed value of $a$."
  },
  {
    "year": 2017,
    "label": "B3",
    "difficulty": "3",
    "problem": "Suppose that $f(x) = \\sum_{i=0}^\\infty c_i x^i$ is a power series for which each coefficient $c_i$ is $0$ or $1$.\nShow that if $f(2/3) = 3/2$, then $f(1/2)$ must be irrational.",
    "solution": "Suppose by way of contradiction that $f(1/2)$ is rational. Then $\\sum_{i=0}^{\\infty} c_i 2^{-i}$ is the binary expansion of a rational number, and hence must be eventually periodic; that is, there exist some integers $m,n$ such that\n$c_i = c_{m+i}$ for all $i \\geq n$. We may then write\n\\[\nf(x) = \\sum_{i=0}^{n-1} c_i x^i + \\frac{x^n}{1-x^m} \\sum_{i=0}^{m-1} c_{n+i} x^i.\n\\]\nEvaluating at $x = 2/3$, we may equate $f(2/3) = 3/2$ with \n\\[\n\\frac{1}{3^{n-1}} \\sum_{i=0}^{n-1} c_i 2^i 3^{n-i-1} + \\frac{2^n 3^m}{3^{n+m-1}(3^m-2^m)} \\sum_{i=0}^{m-1} c_{n+i} 2^i 3^{m-1-i};\n\\]\nsince all terms on the right-hand side have odd denominator, the same must be true of the sum, a contradiction.\n\n\\noindent\n\\textbf{Remark:}\nGreg Marks asks whether the assumption that $f(2/3)=3/2$ further ensures that $f(1/2)$ is transcendental. \nWe do not know of any existing results that would imply this. However, the following result follows from a theorem of T. Tanaka (Algebraic independence of the values of power series generated by linear recurrences, \\textit{Acta Arith.} \\textbf{74} (1996), 177--190), building upon work of Mahler.\nLet $\\{a_n\\}_{n=0}^\\infty$ be a linear recurrent sequence of positive integers with characteristic polynomial $P$.\nSuppose that $P(0), P(1), P(-1) \\neq 0$ and that no two distinct roots of $P$ have ratio which is a root of unity. Then\nfor $f(x) = \\sum_{n=0}^\\infty x^{a_n}$, the values $f(1/2)$ and $f(2/3)$ are algebraically independent over $\\QQ$.\n(Note that for $f$ as in the original problem, the condition on ratios of roots of $P$ fails.)"
  },
  {
    "year": 2017,
    "label": "B4",
    "difficulty": "4",
    "problem": "Evaluate the sum\n\\begin{gather*}\n\\sum_{k=0}^\\infty \\left( 3 \\cdot \\frac{\\ln(4k+2)}{4k+2} - \\frac{\\ln(4k+3)}{4k+3} - \\frac{\\ln(4k+4)}{4k+4} - \\frac{\\ln(4k+5)}{4k+5} \\right) \\\\\n= 3 \\cdot \\frac{\\ln 2}{2} - \\frac{\\ln 3}{3} - \\frac{\\ln 4}{4} - \\frac{\\ln 5}{5}\n+ 3 \\cdot \\frac{\\ln 6}{6} - \\frac{\\ln 7}{7} \\\\ - \\frac{\\ln 8}{8} - \\frac{\\ln 9}{9}\n+ 3 \\cdot \\frac{\\ln 10}{10} - \\cdots .\n\\end{gather*}\n(As usual, $\\ln x$ denotes the natural logarithm of $x$.)",
    "solution": "We prove that the sum equals $ (\\log 2)^2$;\nas usual, we write $\\log x$ for the natural logarithm of $x$ instead of $\\ln x$.\nNote that of the two given expressions of the original sum, the first is absolutely convergent\n(the summands decay as $\\log(x)/x^2$) but the second one is not; we must thus be slightly careful when rearranging terms.\n\n\\noindent\n\\textbf{First solution.}\nDefine $a_k = \\frac{\\log k}{k} - \\frac{\\log(k+1)}{k+1}$. The infinite sum $\\sum_{k=1}^\\infty a_k$ converges to $0$ since $\\sum_{k=1}^n a_k$ telescopes to $-\\frac{\\log(n+1)}{n+1}$ and this converges to $0$ as $n\\to\\infty$. Note that $a_k > 0$ for $k \\geq 3$ since $\\frac{\\log x}{x}$ is a decreasing function of $x$ for $x>e$, and so the convergence of $\\sum_{k=1}^\\infty a_k$ is absolute.\n\nWrite $S$ for the desired sum. Then since $3a_{4k+2}+2a_{4k+3}+a_{4k+4} = (a_{4k+2}+a_{4k+4})+2(a_{4k+2}+a_{4k+3})$, we have\n\\begin{align*}\nS &= \\sum_{k=0}^\\infty (3a_{4k+2}+2a_{4k+3}+a_{4k+4}) \\\\\n&= \\sum_{k=1}^\\infty a_{2k}+\\sum_{k=0}^\\infty 2(a_{4k+2}+a_{4k+3}),\n\\end{align*}\nwhere we are allowed to rearrange the terms in the infinite sum since $\\sum a_k$ converges absolutely. Now\n$2(a_{4k+2}+a_{4k+3}) = \\frac{\\log(4k+2)}{2k+1}-\\frac{\\log(4k+4)}{2k+2} = a_{2k+1}+(\\log 2)(\\frac{1}{2k+1}-\\frac{1}{2k+2})$, and summing over $k$ gives\n\\begin{align*}\n\\sum_{k=0}^\\infty 2(a_{4k+2}+a_{4k+3}) &= \\sum_{k=0}^\\infty a_{2k+1} + (\\log 2) \\sum_{k=1}^\\infty \\frac{(-1)^{k+1}}{k}\\\\\n&= \\sum_{k=0}^\\infty a_{2k+1} +(\\log 2)^2.\n\\end{align*}\nFinally, we have \n\\begin{align*}\nS &= \\sum_{k=1}^\\infty a_{2k} + \\sum_{k=0}^\\infty a_{2k+1} +(\\log 2)^2 \\\\\n&= \\sum_{k=1}^\\infty a_k +(\\log 2)^2 = (\\log 2)^2.\n\\end{align*}\n\n\\noindent\n\\textbf{Second solution.}\nWe start with the following observation: for any positive integer $n$,\n\\[\n\\left. \\frac{d}{ds} n^{-s} \\right|_{s=1} = -(\\log n)n^{-s}.\n\\]\n(Throughout, we view $s$ as a \\emph{real} parameter, but see the remark below.)\nFor $s>0$, consider the absolutely convergent series\n\\[\nL(s) = \\sum_{k=0}^\\infty (3 (4k+2)^{-s} - (4k+3)^{-s} - (4k+4)^{-s} - (4k+5)^{-s});\n\\]\nin the same range we have\n\\begin{align*}\nL'(s) &= \\sum_{k=0}^\\infty \\left( 3 \\frac{\\log(4k+2)}{(4k+2)^s} - \\frac{\\log(4k+3)}{(4k+3)^s} \\right. \\\\\n&\\quad \\left. + \\frac{\\log(4k+4)}{(4k+4)^s} - \\frac{\\log(4k+5)}{(4k+5)^{s}} \\right),\n\\end{align*}\nso we may interchange the summation with taking the limit at $s=1$ to equate the original sum with $-L'(1)$.\n\nTo make further progress, we introduce the Riemann zeta function\n$\\zeta(s) = \\sum_{n=1}^\\infty n^{-s}$, which converges absolutely for $s>1$.\nIn that region, we may freely rearrange sums to write\n\\begin{align*}\nL(s) + \\zeta(s) &= 1 + 4 (2^{-s} + 6^{-s} + 10^{-s} + \\cdots) \\\\\n&= 1 + 2^{2-s} (1 + 3^{-s} + 5^{-s} + \\cdots) \\\\\n&= 1 + 2^{2-s} (\\zeta(s) - 2^{-s} - 4^{-s} - \\cdots) \\\\\n&= 1 + 2^{2-s} \\zeta(s) - 2^{2-2s} \\zeta(s).\n\\end{align*}\nIn other words, for $s > 1$, we have\n\\[\nL(s) = 1 + \\zeta(s) (-1 + 2^{2-s} - 2^{2-2s}).\n\\]\nNow recall that $\\zeta(s) - \\frac{s}{s-1}$ extends to a $C^\\infty$ function\nfor $s>0$, e.g., by applying Abel summation to obtain\n\\begin{align*}\n\\zeta(s) - \\frac{s}{s-1} &= \\sum_{n=1} n (n^{-s} - (n+1)^{-s}) - \\frac{s}{s-1}\\\\\n&= s \\sum_{n=1}^\\infty n \\int_n^{n+1} x^{-s-1}\\,dx  - \\frac{s}{s-1} \\\\\n&= -s \\int_1^\\infty (x - \\lfloor x \\rfloor) x^{-s-1}\\,dx.\n\\end{align*}\nAlso by writing $2^{2-s} = 2 \\exp((1-s) \\log 2$\nand $2^{2-2s} = \\exp(2(1-s)\\log 2)$, we may use the exponential series\nto compute the Taylor expansion of \n\\[\nf(s) = \\frac{-1 + 2^{2-s} - 2^{2-2s}}{s-1}\n\\]\nat $s=1$; we get\n\\[\nf(s) = -(\\log 2)^2 (s-1)^2 + O((s-1)^3).\n\\]\nConsequently, if we rewrite the previous expression for $L(s)$ as\n\\[\nL(s) =  1 + (s-1)\\zeta(s) \\cdot \\frac{-1 + 2^{2-s} - 2^{2-2s}}{s-1},\n\\]\nthen we have an equality of $C^\\infty$ functions for $s>1$, and\nhence (by continuity) an equality of Taylor series about $s=1$. \nThat is,\n\\[\nL(s) = 1 - (\\log 2)^2 (s-1) + O((s-1)^2),\n\\]\nwhich yields the desired result.\n\n\\noindent\n\\textbf{Remark:}\n\nThe use of series $\\sum_{n=1}^\\infty c_n n^{-s}$ as functions of a \\emph{real} parameter $s$\ndates back to Euler, who observed that the divergence of $\\zeta(s)$ as $s \\to 1$ gives a proof of the infinitude of primes distinct from Euclid's approach, and Dirichlet, who upgraded this idea to prove his theorem on the distribution of primes across arithmetic progressions. It was Riemann who introduced the idea of viewing these series as functions of a \\emph{complex} parameter, thus making it possible to use the tools of complex analysis (e.g., the residue theorem) and leading to the original proof of the prime number theorem by Hadamard and de la Vall\\'ee Poussin.\n\nIn the language of complex analysis, one may handle the convergence issues in the second solution \nin a different way: use the preceding calculation to establish the equality\n\\[\nL(s) = 1 + \\zeta(s) (-1 + 2^{2-s} - 2^{2-2s})\n\\]\nfor $\\mathrm{Real}(s) > 1$, then observe that both sides are holomorphic for $\\mathrm{Real}(s) > 0$\nand so the equality extends to that larger domain."
  },
  {
    "year": 2017,
    "label": "B5",
    "difficulty": "5",
    "problem": "A line in the plane of a triangle $T$ is called an \\emph{equalizer} if it divides $T$ into two regions having equal area and equal perimeter. Find positive integers $a>b>c$, with $a$ as small as possible, such that there exists a triangle with side lengths $a, b, c$ that has exactly two distinct equalizers.",
    "solution": "The desired integers are $(a,b,c) = (9,8,7)$.\n\nSuppose we have a triangle $T = \\triangle ABC$ with $BC=a$, $CA=b$, $AB=c$ and $a>b>c$.\nSay that a line is an \\textit{area equalizer} if it divides $T$ into two regions of equal area. A line intersecting $T$ must intersect two of the three sides of $T$. First consider a line intersecting the segments $AB$ at $X$ and $BC$ at $Y$, and let $BX=x$, $BY=y$. This line is an area equalizer if and only if $xy\\sin B = 2\\operatorname{area}(\\triangle XBY) = \\operatorname{area}(\\triangle ABC) = \\frac{1}{2}ac\\sin B$, that is, $2xy=ac$. Since $x \\leq c$ and $y \\leq a$, the area equalizers correspond to values of $x,y$ with $xy=ac/2$ and $x \\in [c/2,c]$. Such an area equalizer is also an equalizer if and only if $p/2=x+y$, where $p=a+b+c$ is the perimeter of $T$. If we write $f(x) = x+ac/(2x)$, then we want to solve $f(x) = p/2$ for $x \\in [c/2,c]$. Now note that $f$ is convex, $f(c/2) = a+c/2 > p/2$, and $f(c) = a/2+c < p/2$; it follows that there is exactly one solution to $f(x)=p/2$ in $[c/2,c]$.\nSimilarly, for equalizers intersecting $T$ on the sides $AB$ and $AC$, we want to solve $g(x) = p/2$ where $g(x) = x+bc/(2x)$ and $x \\in [c/2,c]$; since $g$ is convex and $g(c/2)<p/2$, $g(c) < p/2$, there are no such solutions.\n\n\nIt follows that if $T$ has exactly two equalizers, then it must have exactly one equalizer intersecting $T$ on the sides $AC$ and $BC$. Here we want to solve $h(x) = p/2$ where $h(x) = x+ab/(2x)$ and $x \\in [a/2,a]$. Now $h$ is convex and $h(a/2) > p/2$, $h(a) > p/2$; thus $h(x) = p/2$ has exactly one solution $x \\in [a/2,a]$ if and only if there is $x_0 \\in [a/2,a]$ with $h'(x_0) = 0$ and $h(x_0) = p/2$. The first condition implies $x_0 = \\sqrt{ab/2}$, and then the second condition gives $8ab = p^2$. Note that $\\sqrt{ab/2}$ is in $[a/2,a]$ since $a>b$ and $a<b+c<2b$.\n\n\nWe conclude that $T$ has two equalizers if and only if $8ab=(a+b+c)^2$. Note that $(a,b,c) = (9,8,7)$ works. We claim that this is the only possibility when $a>b>c$ are integers and $a \\leq 9$. Indeed, the only integers $(a,b)$ such that $2 \\leq b < a \\leq 9$ and $8ab$ is a perfect square are $(a,b) = (4,2)$, $(6,3)$, $(8,4)$, $(9,2)$, and $(9,8)$, and the first four possibilities do not produce triangles since they do not satisfy $a<2b$. This gives the claimed result."
  },
  {
    "year": 2017,
    "label": "B6",
    "difficulty": "6",
    "problem": "Find the number of ordered $64$-tuples $(x_0,x_1,\\dots,x_{63})$ such that $x_0,x_1,\\dots,x_{63}$ are distinct elements of $\\{1,2,\\dots,2017\\}$ and \n\\[\nx_0 + x_1 + 2x_2 + 3x_3 + \\cdots + 63 x_{63}\n\\]\nis divisible by 2017.\n\\end{itemize}\n\n\\end{document}",
    "solution": "\\textbf{First solution.}\nThe desired count is $\\frac{2016!}{1953!}- 63! \\cdot 2016$, which we compute using the principle of inclusion-exclusion.\nAs in A2, we use the fact that 2017 is prime; this means that we can do linear algebra over the field $\\mathbb{F}_{2017}$. In particular, every nonzero homogeneous linear equation in $n$ variables over $\\mathbb{F}_{2017}$ has exactly $2017^{n-1}$ solutions.\n\nFor $\\pi$ a partition of $\\{0,\\dots,63\\}$,\nlet $|\\pi|$ denote the number of distinct parts of $\\pi$,\nLet $\\pi_0$ denote the partition of $\\{0,\\dots,63\\}$ into 64 singleton parts.\nLet $\\pi_1$ denote the partition of $\\{0,\\dots,63\\}$ into one 64-element part.\nFor $\\pi, \\sigma$ two partitions of $\\{0,\\dots,63\\}$, write $\\pi | \\sigma$ if $\\pi$ is a refinement of $\\sigma$\n(that is, every part in $\\sigma$ is a union of parts in $\\pi$). By induction on $|\\pi|$, we may construct \na collection of integers $\\mu_\\pi$, one for each $\\pi$, with the properties that\n\\[\n\\sum_{\\pi | \\sigma} \\mu_\\pi = \\begin{cases} 1 & \\sigma = \\pi_0 \\\\ 0 & \\sigma \\neq \\pi_0 \\end{cases}.\n\\]\nDefine the sequence $c_0, \\dots, c_{63}$ by setting $c_0 = 1$ and $c_i = i$ for $i>1$.\nLet $N_\\pi$ be the number of ordered 64-tuples $(x_0,\\dots,x_{63})$ of elements of $\\mathbb{F}_{2017}$\nsuch that  $x_i = x_j$ whenever $i$ and $j$ belong to the same part and\n$\\sum_{i=0}^{63} c_i x_i$ is divisible by 2017. Then $N_\\pi$ equals $2017^{|\\pi|-1}$\nunless for each part $S$ of $\\pi$, the sum $\\sum_{i \\in S} c_i$ vanishes; in that case,\n$N_\\pi$ instead equals $2017^{|\\pi|}$.\nSince $c_0, \\dots, c_{63}$ are positive integers which sum to $1 + \\frac{63 \\cdot 64}{2} = 2017$, the second outcome only occurs for $\\pi = \\pi_1$. By inclusion-exclusion, the desired count may be written as \n\\[\n\\sum_{\\pi} \\mu_\\pi N_\\pi = 2016 \\cdot \\mu_{\\pi_1} + \\sum_{\\pi} \\mu_\\pi 2017^{|\\pi|-1}.\n\\]\nSimilarly, the number of ordered 64-tuples with no repeated elements may be written as\n\\[\n64! \\binom{2017}{64} = \\sum_{\\pi} \\mu_\\pi 2017^{|\\pi|}.\n\\]\nThe desired quantity may thus be written as $\\frac{2016!}{1953!} + 2016 \\mu_{\\pi_1}$.\n\nIt remains to compute $\\mu_{\\pi_1}$. We adopt an approach suggested by David Savitt: apply inclusion-exclusion\nto count distinct 64-tuples in an \\emph{arbitrary} set $A$. As above, this yields\n\\[\n|A|(|A|-1) \\cdots (|A|-63) = \\sum_{\\pi} \\mu_\\pi |A|^{|\\pi|}.\n\\]\nViewing both sides as polynomials in $|A|$ and comparing coefficients in degree 1 yields\n$\\mu_\\pi = -63!$ and thus the claimed answer.\n\n\\noindent\n\\textbf{Second solution.}\n(from Art of Problem Solving, user \\texttt{ABCDE})\nWe first prove an auxiliary result. \n\\begin{lemma*}\nFix a prime $p$ and define the function $f(k)$ on positive integers by the conditions\n\\begin{align*}\nf(1,p) &= 0 \\\\\nf(k,p) &= \\frac{(p-1)!}{(p-k)!} - kf(k-1,p) \\qquad (k>1).\n\\end{align*}\nThen for any positive integers $a_1,\\dots,a_k$ with\n$a_1 + \\cdots + a_k < p$, there are exactly $f(p)$ solutions to the equation $a_1 x_1 + \\cdots + a_k x_k = 0$\nwith $x_1,\\dots,x_k \\in \\mathbb{F}_p$ nonzero and pairwise distinct.\n\\end{lemma*}\n\\begin{proof}\nWe check the claim by induction, with the base case $k=1$ being obvious.\nFor the induction step, assume the claim for $k-1$.\nLet $S$ be the set of $k$-tuples of distinct elements of $\\mathbb{F}_p$;\nit consists of $\\frac{p!}{(p-k)!}$ elements.\nThis set is stable under the action of $i \\in \\mathbb{F}_p$ by translation:\n\\[\n(x_1,\\dots,x_k) \\mapsto (x_1 + i, \\dots, x_k + i).\n\\]\nSince $0 < a_1 \\cdots + a_k < p$, exactly one element of each orbit gives a solution of\n$a_1 x_1 + \\cdots + a_k x_k = 0$. Each of these solutions contributes to $f(k)$ except\nfor those in which $x_i = 0$ for some $i$.\nSince then $x_j \\neq 0$ for all $j \\neq i$, we may apply the induction hypothesis to see that there are\n$f(k-1,p)$ solutions that arise this way for a given $i$ (and these do not overlap).\nThis proves the claim.\n\\end{proof}\n\nTo compute $f(k,p)$ explicitly, it is convenient to work with the auxiliary function\n\\[\ng(k,p) = \\frac{p f(k,p)}{k!};\n\\]\nby the lemma, this satisfies $g(1,p) = 0$ and \n\\begin{align*}\ng(k,p) &= \\binom{p}{k} - g(k-1,p)  \\\\\n&= \\binom{p-1}{k} + \\binom{p-1}{k-1} - g(k-1, p) \\qquad (k>1).\n\\end{align*}\nBy induction on $k$, we deduce that\n\\begin{align*}\ng(k,p) - \\binom{p-1}{k} &= (-1)^{k-1} \\left( g(1,p) - \\binom{p-1}{1} \\right) \\\\\n &= (-1)^k (p-1)\n\\end{align*}\nand hence\n$g(k,p) = \\binom{p-1}{k} + (-1)^k (p-1)$.\n\nWe now set $p=2017$ and count the tuples in question.\nDefine $c_0,\\dots,c_{63}$ as in the first solution. Since $c_0 + \\cdots + c_{63} = p$,\nthe translation action of $\\mathbb{F}_p$ preserves the set of tuples; we may thus assume without loss of generality\nthat $x_0 = 0$ and multiply the count by $p$ at the end. That is, the desired answer is\n\\begin{align*}\n2017 f(63, 2017) &= 63! g(63, 2017) \\\\\n& = 63! \\left( \\binom{2016}{63} - 2016 \\right)\n\\end{align*}\nas claimed.\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2018,
    "label": "A1",
    "difficulty": "1",
    "problem": "Find all ordered pairs $(a,b)$ of positive integers for which\n\\[\n\\frac{1}{a} + \\frac{1}{b} = \\frac{3}{2018}.\n\\]",
    "solution": "By clearing denominators and regrouping, we see that the given equation is equivalent to \n\\[\n(3a-2018)(3b-2018) = 2018^2.\n\\]\nEach of the factors is congruent to $1 \\pmod 3$. There are $6$ positive factors of $2018^2 = 2^2 \\cdot 1009^2$ that are congruent to $1 \\pmod 3$: $1$, $2^2$, $1009$, $2^2 \\cdot 1009$, $1009^2$, $2^2 \\cdot 1009^2$. These lead to the $6$ possible pairs: $(a,b) = (673,1358114)$, $(674,340033)$, $(1009,2018)$, $(2018,1009)$, $(340033,674)$, and $(1358114,673)$.\n\nAs for negative factors, the ones that are congruent to $1 \\pmod 3$ are $-2, -2 \\cdot 1009, -2 \\cdot 1009^2$.\nHowever, all of these lead to pairs where $a \\leq 0$ or $b \\leq 0$."
  },
  {
    "year": 2018,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $S_1, S_2, \\dots, S_{2^n-1}$ be the nonempty subsets of $\\{1,2,\\dots,n\\}$ in some order, and let\n$M$ be the $(2^n-1) \\times (2^n-1)$ matrix whose $(i,j)$ entry is\n\\[\nm_{ij} = \\begin{cases} 0 & \\mbox{if }S_i \\cap S_j = \\emptyset; \\\\\n1 & \\mbox{otherwise.}\n\\end{cases}\n\\]\nCalculate the determinant of $M$.",
    "solution": "The answer is $1$ if $n=1$ and $-1$ if $n>1$. Write $M_n$ for a $(2^n-1) \\times (2^n-1)$ matrix of the given form, and note that $\\det M_n$ does not depend on the ordering of the subsets: transposing two subsets has the effect of transposing two rows and then transposing two columns in $M_n$, and this does not change the determinant.\n\nClearly $\\det M_1 = 1$. We claim that for $n>1$, $\\det M_n = -(\\det M_{n-1})^2$, and the desired answer will follow by induction. Let $S_1',\\ldots,S_{2^{n-1}-1}'$ denote the nonempty subsets of $\\{1,\\ldots,n-1\\}$ in any order, with resulting matrix $M_{n-1}$. Let $m_{ij}'$ denote the $(i,j)$ entry of $M_{n-1}$. Now order the nonempty subsets $S_1,\\ldots,S_{2^n-1}$ of $\\{1,\\ldots,n\\}$ as follows: \n\\[\nS_i= \\begin{cases} S_i' &  i \\leq 2^{n-1}-1 \\\\\nS_{i-2^{n-1}+1}' \\cup \\{n\\} & 2^{n-1} \\leq i \\leq 2^n-2 \\\\\n\\{n\\} & i=2^{n}-1.\n\\end{cases}\n\\]\n(For example, if $S_1', \\dots, S_{2^{n-1}-1}'$ are ordered in lexicographic order\nas binary strings, then so are $S_1,\\dots,S_{2^n-1}$.)\nLet $M_n$ be the resulting matrix. Then we have:\n\\[\nM_n = \\left( \\begin{array}{ccc|ccc|c}\n&&&&&& 0 \\\\\n& M_{n-1} &&& M_{n-1} && \\vdots \\\\\n&&&&&& 0 \\\\ \\hline\n&&&1 & \\cdots & 1 & 1 \\\\\n& M_{n-1} && \\vdots & \\ddots & \\vdots & \\vdots \\\\\n&&&1 &\\cdots & 1 & 1 \\\\ \\hline\n0 & \\cdots & 0 & 1 & \\cdots & 1 & 1\n\\end{array} \\right).\n\\]\n\nIn $M_n$, perform the following operations, which do not change the determinant: subtract the final row from rows $2^{n-1}$ through $2^n-2$, and then subtract the final column from columns $2^{n-1}$ through $2^n-2$. The result is the matrix\n\\[\n\\left( \\begin{array}{ccc|ccc|c}\n&&&&&& 0 \\\\\n& M_{n-1} &&& M_{n-1} && \\vdots \\\\\n&&&&&& 0 \\\\ \\hline\n&&&0 & \\cdots & 0 & 0 \\\\\n& M_{n-1} && \\vdots & \\ddots & \\vdots & \\vdots \\\\\n&&&0 &\\cdots & 0 & 0 \\\\ \\hline\n0 & \\cdots & 0 & 0 & \\cdots & 0 & 1\n\\end{array} \\right).\n\\]\n\nWe can remove the final row and column without changing the determinant. Now swap the first $2^{n-1}-1$ rows with the final $2^{n-1}-1$ rows: this changes the determinant by an overall factor of $(-1)^{(2^{n-1}-1)^2} = -1$. The result is the block-diagonal matrix $\\left( \\begin{matrix} M_{n-1} & 0 \\\\ M_{n-1} & M_{n-1} \\end{matrix} \\right)$, whose determinant is $(\\det M_{n-1})^2$. Thus $\\det M_n = -(\\det M_{n-1})^2$ as desired."
  },
  {
    "year": 2018,
    "label": "A3",
    "difficulty": "3",
    "problem": "Determine the greatest possible value of $\\sum_{i=1}^{10} \\cos(3x_i)$ for real numbers $x_1,x_2,\\dots,x_{10}$\nsatisfying $\\sum_{i=1}^{10} \\cos(x_i) = 0$.",
    "solution": "The maximum value is $480/49$.\nSince $\\cos(3x_i) = 4 \\cos(x_i)^3 - 3 \\cos(x_i)$, it is equivalent to maximize $4 \\sum_{i=1}^{10} y_i^3$\nfor $y_1,\\dots,y_{10} \\in [-1,1]$ with $\\sum_{i=1}^{10} y_i = 0$; \nnote that this domain is compact, so the maximum value is guaranteed to exist.\nFor convenience, we establish something slightly stronger: we maximize $4 \\sum_{i=1}^{n} y_i^3$\nfor $y_1,\\dots,y_{n} \\in [-1,1]$ with $\\sum_{i=1}^{n} y_i = 0$, where $n$ may be any even nonnegative integer up to $10$,\nand show that the maximum is achieved when $n=10$.\n\nWe first study the effect of varying $y_i$ and $y_j$ while fixing their sum. If that sum is $s$,\nthen the function $y \\mapsto y^3 + (s-y)^3$ has constant second derivative $6s$, so it is either everywhere convex or everywhere concave. Consequently, if $(y_1,\\dots,y_{n})$ achieves the maximum, then for any two indices $i<j$,\nat least one of the following must be true:\n\\begin{itemize}\n\\item one of $y_i$, $y_j$ is extremal (i.e., equal to $1$ or $-1$);\n\\item $y_i = y_j < 0$ (in which case $s<0$ and the local maximum is achieved above);\n\\item $y_i = -y_j$ (in which case $s=0$ above).\n\\end{itemize}\nIn the third case, we may discard $y_i$ and $y_j$ and achieve a case with smaller $n$; we may thus assume that this does not occur. In this case, all of the non-extremal values are equal to some common value $y < 0$, and moreover we cannot have both 1 and -1. We cannot omit 1, as otherwise the condition $\\sum_{i=1}^{n} y_i = 0$ cannot be achieved;\nwe must thus have only the terms 1 and $y$, occurring with some positive multiplicities $a$ and $b$ adding up to $n$. \nSince $a+b=n$ and $a+by = 0$, we can solve for $y$ to obtain $y = -a/b$; we then have\n\\[\n4\\sum_{i=1}^n y_i^3 = a + by^3 = 4a \\left( 1 - \\frac{a^2}{b^2} \\right).\n\\]\nSince $y > -1$, we must have $a < b$. For fixed $a$, the target function increases as $b$ increases,\nso the optimal case must occur when $a+b=10$. The possible pairs $(a,b)$ at this point are\n\\[\n(1,9), (2,8), (3,7), (4,6);\n\\]\ncomputing the target function for these values yields respectively\n\\[\n\\frac{32}{9}, \\frac{15}{2}, \\frac{480}{49}, \\frac{80}{9},\n\\]\nyielding $480/49$ as the maximum value.\n\n\\noindent\n\\textbf{Remark.}\nUsing Lagrange multipliers yields a similar derivation, but with a slight detour required to separate local minima and maxima. For general $n$, the above argument shows that the target function is maximized when $a+b=n$."
  },
  {
    "year": 2018,
    "label": "A4",
    "difficulty": "4",
    "problem": "Let $m$ and $n$ be positive integers with $\\gcd(m,n) = 1$, and let\n\\[\na_k = \\left\\lfloor \\frac{mk}{n} \\right\\rfloor - \\left\\lfloor \\frac{m(k-1)}{n} \\right\\rfloor\n\\]\nfor $k=1,2,\\dots,n$.\nSuppose that $g$ and $h$ are elements in a group $G$ and that \n\\[\ngh^{a_1} gh^{a_2} \\cdots gh^{a_n} = e,\n\\]\nwhere $e$ is the identity element. Show that $gh= hg$. (As usual, $\\lfloor x \\rfloor$ denotes the greatest integer\nless than or equal to $x$.)",
    "solution": "\\noindent\n\\textbf{First solution.}\nWe prove the claim by induction on $m+n$.\nFor the base case, suppose that $n=1$; we then have $m=1$ and the given equation becomes $gh=e$. The claim then reduces to the fact that a one-sided inverse in $G$ is also a two-sided inverse. (Because $G$ is a group, $g$ has an inverse $g^{-1}$; since $gh = e$, we have $h = g^{-1}(gh) = g^{-1} e = g^{-1}$, so $hg = e = gh$.)\n\nSuppose now that $n>1$. In case $m>n$, set $\\tilde{g} = g h$, $\\tilde{h} = h$, and\n\\[\nb_k = \\left\\lfloor \\frac{(m-n)k}{n} \\right\\rfloor - \\left\\lfloor \\frac{(m-n)(k-1)}{n} \\right\\rfloor \n\\quad (k=1,\\dots,n).\n\\]\nthen\n\\[\n\\tilde{g} \\tilde{h}^{b_1} \\cdots \\tilde{g} \\tilde{h}^{b_n} = gh^{a_1} \\cdots gh^{a_n} = e,\n\\]\nso the induction hypothesis implies that $\\tilde{g}$ and $\\tilde{h}$ commute; this implies that $g$ and $h$ commute.\n\nIn case $m < n$, note that $a_k \\in \\{0,1\\}$ for all $k$. Set $\\tilde{g} = h^{-1}$, $\\tilde{h} = g^{-1}$, and\n\\[\nb_l = \\left\\lfloor \\frac{n \\ell}{m} \\right\\rfloor - \\left\\lfloor \\frac{n(\\ell-1)}{m} \\right\\rfloor \n\\quad (\\ell=1,\\dots,m);\n\\]\nwe claim that \n\\[\n\\tilde{g}\\tilde{h}^{b_1}\\cdots\\tilde{g}\\tilde{h}^{b_m} = (gh^{a_1}\\cdots gh^{a_n})^{-1} = e,\n\\]\nso the induction hypothesis implies that $\\tilde{h}$ and $\\tilde{g}$ commute; this implies that $g$ and $h$ commute.\n\nTo clarify this last equality, consider a lattice walk starting from $(0,0)$, ending at $(n,m)$, staying below the line\n$y = mx/n$, and keeping as close to this line as possible. If one follows this walk and records the element $g$ for each horizontal step and $h$ for each vertical step, one obtains the word $gh^{a_1}\\cdots gh^{a_n}$. \nNow take this walk, reflect across the line $y = x$, rotate by a half-turn, then translate to put the endpoints at $(0,0)$ and $(m,n)$; this is the analogous walk for the pair $(n,m)$.\n\n\\noindent\n\\textbf{Remark.}\nBy tracing more carefully through the argument, one sees in addition that there exists an element $k$ of $G$\nfor which $g = k^m, h = k^{-n}$.\n\n\\noindent\n\\textbf{Second solution.} (by Greg Martin)\nSince $\\gcd(m,n) = 1$, there exist integers $x,y$ such that $mx + ny = 1$; we may further assume that \n$x \\in \\{1,\\dots,n\\}$. We first establish the identity\n\\[\na_{k-x} = \\begin{cases}\na_k - 1 & \\mbox{if $k \\equiv 0 \\pmod{n}$} \\\\\na_k + 1 & \\mbox{if $k \\equiv 1 \\pmod{n}$} \\\\\na_k & \\mbox{otherwise}.\n\\end{cases}\n\\]\nNamely, by writing $-mx = ny-1$, we see that\n\\begin{align*}\na_{k-x} &= \\left\\lfloor \\frac{m(k-x)}{n} \\right\\rfloor - \\left\\lfloor \\frac{m(k-x-1)}{n} \\right\\rfloor\n\\\\\n&= \\left\\lfloor \\frac{mk+ny-1}{n} \\right\\rfloor - \\left\\lfloor \\frac{m(k-1)+ny-1}{n} \\right\\rfloor \\\\\n&= \\left\\lfloor \\frac{mk-1}{n} \\right\\rfloor - \\left\\lfloor \\frac{m(k-1)-1}{n} \\right\\rfloor\n\\end{align*}\nand so\n\\begin{align*}\na_{k-x} - a_k &= \\left( \\left\\lfloor \\frac{mk-1}{n} \\right\\rfloor - \\left\\lfloor \\frac{mk}{n} \\right\\rfloor \\right)\n\\\\\n&\\quad\n- \\left( \\left\\lfloor \\frac{m(k-1)-1}{n} \\right\\rfloor - \\left\\lfloor \\frac{m(k-1)}{n} \\right\\rfloor \\right).\n\\end{align*}\nThe first parenthesized expression equals 1 if $n$ divides $mk$, or equivalently $n$ divides $k$, and 0 otherwise.\nSimilarly, the second parenthesized expression equals 1 if $n$ divides $k-1$ and 0 otherwise. This proves the stated identity.\n\nWe now use the given relation $g h^{a_1} \\cdots g h^{a_n} = e$ to write\n\\begin{align*}\nghg^{-1}h^{-1} &= gh(h^{a_1} g h^{a_2} \\cdots gh^{a_{n-1}} g h^{a_n})h^{-1} \\\\\n&= gh^{a_1+1} gh^{a_2} \\cdots gh^{a_{n-1}} gh^{a_n-1} \\\\\n&= gh^{a_{1-x}} \\cdots gh^{a_{n-x}} \\\\\n&= (gh^{a_{n+1-x}} \\cdots gh^{a_{n}}) (gh^{a_1} \\cdots gh^{a_{n-x}}).\n\\end{align*}\nThe two parenthesized expressions multiply in the opposite order to $g h^{a_1} \\cdots g h^{a_n} = e$, so they must be\n(two-sided) inverses of each other. We deduce that $ghg^{-1} h^{-1} = e$, meaning that $g$ and $h$ commute.\n\n\\noindent\n\\textbf{Third solution.} (by Sucharit Sarkar)\nLet $T$ denote the torus $\\mathbb{R}^2/\\mathbb{Z}^2$. The line segments from $(0,0)$ to $(1,0)$ and from $(0,0)$ to $(0,1)$ are closed loops in $T$, and we denote them by $g$ and $h$ respectively. Now let $p$ be the (image of the) point $(\\epsilon,-\\epsilon)$ in $T$ for some $0<\\epsilon\\ll 1$. The punctured torus $T \\setminus \\{p\\}$ deformation retracts onto the union of the loops $g$ and $h$, and so $\\pi_1(T\\setminus\\{p\\})$, the fundamental group of $T\\setminus\\{p\\}$ based at $(0,0)$, is the free group on two generators, $\\langle g,h\\rangle$.\n\nLet $\\gamma$ and $\\tilde{\\gamma}$ denote the following loops based at $(0,0)$ in $T$: $\\gamma$ is the image of the line segment from $(0,0)$ to $(n,m)$ under the projection $\\mathbb{R}^2 \\to T$, and $\\tilde{\\gamma}$ is the image of the lattice walk from $(0,0)$ to $(n,m)$, staying just below the line $y=mx/n$, that was described in the first solution. There is a straight-line homotopy with fixed endpoints between the two paths in $\\mathbb{R}^2$ from $(0,0)$ to $(n,m)$, the line segment and the lattice walk, and this homotopy does not pass through any point of the form $(a+\\epsilon,b-\\epsilon)$ for $a,b\\in\\mathbb{Z}$ by the construction of the lattice walk. It follows that $\\gamma$ and $\\tilde{\\gamma}$ are homotopic loops in $T \\setminus \\{p\\}$. Since the class of $\\tilde{\\gamma}$ in $\\pi_1(T\\setminus\\{p\\})$ is evidently $gh^{a_1}gh^{a_2}\\cdots gh^{a_n}$, it follows that the class of $\\gamma$ in $\\pi_1(T\\setminus\\{p\\})$ is the same.\n\nNow since $\\gcd(m,n)=1$, there is an element $\\phi \\in GL_2(\\mathbb{Z})$ sending $(n,m)$ to $(1,0)$, which then sends the line segment from $(0,0)$ to $(n,m)$ to the segment from $(0,0)$ to $(1,0)$. Then $\\phi$ induces a homeomorphism of $T$ sending $\\gamma$ to $g$, which in turn induces an isomorphism $\\phi_* :\\thinspace \\pi_1(T\\setminus \\{p\\}) \\to \\pi_1(T\\setminus \\{\\phi^{-1}(p)\\})$. Both fundamental groups are equal to $\\langle g,h\\rangle$, and we conclude that $\\phi_*$ sends $gh^{a_1}gh^{a_2}\\cdots gh^{a_n}$ to $g$. It follows that $\\phi_*$ induces an isomorphism\n\\[\n\\langle g,h\\,|\\,gh^{a_1}gh^{a_2}\\cdots gh^{a_n} \\rangle \\to \\langle g,h \\,|\\, g\\rangle \\cong \\langle h\\rangle \\cong \\mathbb{Z}.\n\\]\n\nSince $\\mathbb{Z}$ is abelian, $g$ and $h$ must commute in $\\langle g,h\\,|\\,gh^{a_1}gh^{a_2}\\cdots gh^{a_n}\\rangle$, whence they must also commute in $G$."
  },
  {
    "year": 2018,
    "label": "A5",
    "difficulty": "5",
    "problem": "Let $f: \\mathbb{R} \\to \\mathbb{R}$ be an infinitely differentiable function satisfying $f(0) = 0$, $f(1)= 1$,\nand $f(x) \\geq 0$ for all $x \\in \\mathbb{R}$. Show that there exist a positive integer $n$ and a real number $x$\nsuch that $f^{(n)}(x) < 0$.",
    "solution": "\\textbf{First solution.}\nCall a function $f\\colon \\mathbb{R} \\to \\mathbb{R}$ \\textit{ultraconvex} if $f$ is infinitely differentiable and $f^{(n)}(x) \\geq 0$ for all $n \\geq 0$ and all $x \\in \\mathbb{R}$, where $f^{(0)}(x) = f(x)$;\nnote that if $f$ is ultraconvex, then so is $f'$.\nDefine the set\n\\[\nS = \\{ f :\\thinspace \\mathbb{R} \\to \\mathbb{R} \\,|\\,f \\text{ ultraconvex and } f(0)=0\\}.\n\\]\nFor $f \\in S$, we must have $f(x) = 0$ for all $x < 0$: if $f(x_0) > 0$ for some $x_0 < 0$, then\nby the mean value theorem there exists $x \\in (0,x_0)$ for which $f'(x) = \\frac{f(x_0)}{x_0} < 0$.\nIn particular, $f'(0) = 0$, so $f' \\in S$ also.\n\nWe show by induction that for all $n \\geq 0$,\n\\[\nf(x) \\leq \\frac{f^{(n)}(1)}{n!} x^n \\qquad (f \\in S, x \\in [0,1]).\n\\]\nWe induct with base case $n=0$, which holds because any $f \\in S$ is nondecreasing. Given the claim for $n=m$,\nwe apply the induction hypothesis to $f' \\in S$ to see that\n\\[\nf'(t) \\leq \\frac{f^{(n+1)}(1)}{n!} t^n \\qquad (t \\in [0,1]),\n\\]\nthen integrate both sides from $0$ to $x$ to conclude.\n\nNow for $f \\in S$, we have $0 \\leq f(1) \\leq \\frac{f^{(n)}(1)}{n!}$ for all $n \\geq 0$. \nOn the other hand, by Taylor's theorem with remainder,\n\\[\nf(x) \\geq \\sum_{k=0}^n \\frac{f^{(k)}(1)}{k!}(x-1)^k \\qquad (x \\geq 1).\n\\]\nApplying this with $x=2$, we obtain $f(2) \\geq \\sum_{k=0}^n \\frac{f^{(k)}(1)}{k!}$ for all $n$;\nthis implies that $\\lim_{n\\to\\infty}  \\frac{f^{(n)}(1)}{n!} = 0$.\nSince $f(1) \\leq \\frac{f^{(n)}(1)}{n!}$, we must have $f(1) = 0$.\n\nFor $f \\in S$, we proved earlier that $f(x) = 0$ for all $x\\leq 0$, as well as for $x=1$. Since\nthe function $g(x) = f(cx)$ is also ultraconvex for $c>0$, we also have $f(x) = 0$ for all $x>0$;\nhence $f$ is identically zero.\n\nTo sum up, if $f\\colon \\mathbb{R} \\to \\mathbb{R}$ is infinitely differentiable, $f(0)=0$, and $f(1) = 1$,\nthen $f$ cannot be ultraconvex. This implies the desired result.\n\n\\noindent\n\\textbf{Variant.}\n(by Yakov Berchenko-Kogan)\nAnother way to show that any $f \\in S$ is identically zero is to show that for $f \\in S$ and $k$ a positive integer,\n\\[\nf(x) \\leq \\frac{x}{k} f'(x) \\qquad (x \\geq 0).\n\\]\nWe prove this by induction on $k$.\nFor the base case $k=1$, note that $f''(x) \\geq 0$ implies that $f'$ is nondecreasing. For $x \\geq 0$, we thus have\n\\[\nf(x) = \\int_0^x f'(t)\\,dt \\leq \\int_0^x f'(x)\\,dt = x f'(x).\n\\]\nTo pass from $k$ to $k+1$, apply the induction hypothesis to $f'$ and integrate by parts to obtain\n\\begin{align*}\nkf(x) &= \\int_0^x k f'(t)\\,dt \\\\\n&\\leq \\int_0^x t f''(t)\\,dt \\\\\n&= xf'(x) - \\int_0^x f'(t)\\,dt = xf'(x) - f(x).\n\\end{align*}\n\n\n\n\\noindent\n\\textbf{Remark.}\nNoam Elkies points out that one can refine the argument to show that\nif $f$ is ultraconvex, then it is analytic (i.e., it is represented by an entire Taylor series about any point, as opposed to a function like $f(x) = e^{-1/x^2}$ whose Taylor series at $0$ is identically zero);\nhe attributes the following argument to \nPeter Shalen. Let $g_n(x) = \\sum_{k=0}^n \\frac{1}{k!} f^{(k})(0) x^k$ be the $n$-th order Taylor polynomial of $f$.\nBy Taylor's theorem with remainder (a/k/a Lagrange's theorem), $f(x) - g_n(x)$ is everywhere nonnegative;\nconsequently, for all $x \\geq 0$, the Taylor series $\\sum_{n=0}^\\infty \\frac{1}{n!} f^{(n)}(0) x^n$\nconverges and is bounded above by $f$. But since $f^{(n+1)}(x)$ is nondecreasing, Lagrange's theorem \nalso implies that $f(x) - g_n(x) \\leq \\frac{1}{(n+1)!} f^{(n+1)}(x)$; for fixed $x \\geq 0$, the right side \ntends to 0 as $n \\to \\infty$. Hence $f$ is represented by its Taylor series for $x \\geq 0$, and so\nis analytic for $x>0$; by replacing $f(x)$ with $f(x-c)$, we may conclude that $f$ is everywhere analytic.\n\n\\noindent\n\\textbf{Remark.}\nWe record some properties of the class of ultraconvex functions.\n\\begin{itemize}\n\\item\nAny nonnegative constant function is ultraconvex. The exponential function is ultraconvex.\n\\item\nIf $f$ is ultraconvex, then $f'$ is ultraconvex. Conversely, if $f'$ is ultraconvex and\n$\\liminf_{x \\to -\\infty} f(x) \\geq 0$, then $f$ is ultraconvex.\n\\item\nThe class of ultraconvex functions is closed under addition, multiplication, and composition.\n\\end{itemize}\n\n\n\\noindent\n\\textbf{Second solution.} (by Zachary Chase)\nIn this solution, we use \\emph{Bernstein's theorem on monotone functions}.\nTo state this result, we say that a function $f: [0, \\infty) \\to \\mathbb{R}$ is \\emph{totally monotone} if\n$f$ is continuous, $f$ is infinitely differentiable on $(0, \\infty)$, and $(-1)^n f^{(n)}(x)$ is nonnegative\nfor all positive integers $n$ and all $x > 0$. For such a function, Bernstein's theorem asserts that there is a nonnegative finite Borel measure $\\mu$ on $[0, \\infty)$ such that\n\\[\nf(x) = \\int_0^\\infty e^{-tx} d\\mu(t) \\qquad (x \\geq 0).\n\\]\nFor $f$ as in the problem statement, \nfor any $M > 0$, the restriction of $f(M-x)$ to $[0, \\infty)$ is totally monotone, so Bernstein's theorem provides a Borel measure $\\mu$ for which $f(M-x) = \\int_0^\\infty e^{-tx} d\\mu(t)$ for all $x \\geq 0$.\nTaking $x = M$, we see that $\\int_0^\\infty e^{-Mt} d\\mu(t) = f(0) = 0$; since $\\mu$ is a nonnegative measure, it must be identically zero. Hence $f(x)$ is identically zero for $x \\leq M$; varying over all $M$, we deduce the desired result.\n\n\\noindent\n\\textbf{Third solution.}\n(from Art of Problem Solving user \\texttt{chronondecay})\nIn this solution, we only consider the behavior of $f$ on $[0,1]$.\nWe first establish the following result.\nLet $f: (0,1) \\to \\mathbb{R}$ be a function such that for each positive integer $n$, $f^{(n)}(x)$ is nonnegative on $(0,1)$, tends to 0 as $x \\to 0^+$, and tends to some limit as $x \\to 1^-$.\nThen for each nonnegative integer $n$, $f(x) x^{-n}$ is nondecreasing on $(0,1)$.\n\nTo prove the claimed result, we proceed by induction on $n$, the case $n=0$ being a consequence of the assumption that $f'(x)$ is nonnegative on $(0,1)$. Given the claim for some $n \\geq 0$, note that\nsince $f'$ also satisfies the hypotheses of the problem, $f'(x) x^{-n}$ is also nondecreasing on $(0,1)$.\nChoose $c \\in (0,1)$ and consider the function\n\\[\ng(x) = \\frac{f'(c)}{c^n} x^n \\qquad (x \\in [0,1)).\n\\]\nFor $x \\in (0,c)$, $f'(x)x^{-n} \\leq f'(c) c^{-n}$, so $f'(x) \\leq g(x)$;\nsimilarly, for $x \\in (c,1)$, $f'(x) \\geq g(x)$. It follows that if $f'(c) > 0$, then\n\\[\n\\frac{\\int_c^1 f'(x)\\,dx}{\\int_0^c f'(x)\\,dx} \\geq \\frac{\\int_c^1 g(x)\\,dx}{\\int_0^c g(x)\\,dx}\n\\Rightarrow\n\\frac{\\int_0^c f'(x)\\,dx}{\\int_0^1 f'(x)\\,dx} \\leq \\frac{\\int_0^c g(x)\\,dx}{\\int_0^1 g(x)\\,dx}\n\\]\nand so $f(c)/f(1) \\leq c^{n+1}$. (Here for convenience, we extend $f$ continuously to $[0,1]$.)\nThat is, $f(c)/c^{n+1} \\leq f(1)$ for all $c \\in (0,1)$.\nFor any $b \\in (0,1)$, we may apply the same logic to the function $f(bx)$ to deduce that\nif $f'(c) > 0$, then $f(bc)/c^{n+1} \\leq f(b)$, or equivalently \n\\[\n\\frac{f(bc)}{(bc)^{n+1}} \\leq \\frac{f(b)}{b^{n+1}}.\n\\]\nThis yields the claim unless $f'$ is identically 0 on $(0,1)$, but in that case the claim is obvious anyway.\n\nWe now apply the claim to show that for $f$ as in the problem statement, it cannot be the case that\n$f^{(n)}(x)$ is nonnegative on $(0,1)$ for all $n$. Suppose the contrary; then for any fixed $x \\in (0,1)$,\nwe may apply the previous claim with arbitrarily large $n$ to deduce that $f(x) = 0$. By continuity, we also then have\n$f(1) = 0$, a contradiction.\n\n\\noindent\n\\textbf{Fourth solution.}\n(by Alexander Karabegov)\nAs in the first solution, we may see that $f^{(n)}(0) = 0$ for all $n$.\nConsequently, for all $n$ we have\n\\[\nf(x) = \\frac{1}{(n-1)!} \\int_0^x (x-t)^{n-1} f^{(n)}(t)\\,dt \\qquad (x \\in \\mathbb{R})\n\\]\nand hence\n\\[\n\\int_0^1 f(x)\\,dx = \\frac{1}{n!} \\int_0^1 (1-t)^n f^{(n)}(t)\\,dt. \n\\]\nSuppose now that $f$ is infinitely differentiable, $f(1) = 1$, and $f^{(n)}(x) \\geq 0$ for all $n$ and all $x \\in [0,1]$. Then\n\\begin{align*}\n\\int_0^1 f(x)\\,dx &= \\frac{1}{n} \\cdot \\frac{1}{(n-1)!} \\int_0^1 (1-t)^n f^{(n)}(t)\\,dt \\\\\n&\\leq \\frac{1}{n} \\cdot \\frac{1}{(n-1)!} \\int_0^1 (1-t)^{n-1} f^{(n)}(t)\\,dt \\\\\n&= \\frac{1}{n} f(1) = \\frac{1}{n}.\n\\end{align*}\nSince this holds for all $n$, we have $\\int_0^1 f(x)\\,dx = 0$, and so $f(x) = 0$ for $x \\in [0,1]$; this yields the desired contradiction."
  },
  {
    "year": 2018,
    "label": "A6",
    "difficulty": "6",
    "problem": "Suppose that $A,B,C,$ and $D$ are distinct points, no three of which lie on a line,\nin the Euclidean plane. Show\nthat if the squares of the lengths of the line segments $AB$, $AC$, $AD$, $BC$, $BD$, and $CD$\nare rational numbers, then\nthe quotient\n\\[\n\\frac{\\mathrm{area}(\\triangle ABC)}{\\mathrm{area}(\\triangle ABD)}\n\\]\nis a rational number.",
    "solution": "\\textbf{First solution.}\nChoose a Cartesian coordinate system with origin at the midpoint of $AB$ and positive $x$-axis containing $A$.\nBy the condition on $AB$, we have $A = (\\sqrt{a}, 0)$, $B = (-\\sqrt{a}, 0)$ for some positive rational number $a$.\nLet $(x_1, y_1)$ and $(x_2, y_2)$ be the respective coordinates of $C$ and $D$; by computing the lengths\nof the segments $AC, BC, AD, BD, CD$, we see that the quantities\n\\begin{gather*}\n(x_1 - \\sqrt{a})^2 + y_1^2, \\quad (x_1 + \\sqrt{a})^2 + y_1^2, \\\\\n(x_2 - \\sqrt{a})^2 + y_2^2, \\quad (x_2 + \\sqrt{a})^2 + y_2^2, \\\\\n(x_1 - x_2)^2 + (y_1 - y_2)^2\n\\end{gather*}\nare all rational numbers. By adding and subtracting the first two quantities, and similarly for the next two, we see that the quantities\n\\[\nx_1^2 + y_1^2,\\quad x_1 \\sqrt{a}, \\quad x_2^2 + y_2^2, \\quad x_2 \\sqrt{a}\n\\]\nare rational numbers. Since $a$ is a rational number, so then are\n\\begin{align*}\nx_1^2 &= \\frac{(x_1 \\sqrt{a})^2}{a} \\\\\nx_2^2 &= \\frac{(x_2 \\sqrt{a})^2}{a} \\\\\nx_1x_2 &= \\frac{(x_1 \\sqrt{a})(x_2 \\sqrt{a})}{a} \\\\\ny_1^2 &= (x_1^2 + y_1^2) - x_1^2 \\\\\ny_2^2 &= (x_2^2 + y_2^2) - x_2^2.\n\\end{align*}\nNow note that the quantity\n\\[\n(x_1 - x_2)^2 + (y_1 - y_2)^2 = x_1^2 -2x_1 x_2 + x_2^2 + y_1^2 - 2y_1y_2 + y_2^2\n\\]\nis known to be rational, as is every summand on the right except $-2y_1y_2$; thus $y_1y_2$ is also rational.\nSince $y_1^2$ is also rational, so then is $y_1/y_2 = (y_1y_2)/(y_1^2)$;\nsince\n\\[\n\\mathrm{area}(\\triangle ABC) = \\sqrt{a} y_1, \\qquad \\mathrm{area}(\\triangle ABD) = \\sqrt{a} y_2,\n\\]\nthis yields the desired result.\n\n\n\\noindent\n\\textbf{Second solution.} (by Manjul Bhargava)\nLet $\\mathbf{b},\\mathbf{c}, \\mathbf{d}$ be the vectors $AB, AC, AD$ viewed as column vectors.\nThe desired ratio is given by\n\\begin{align*}\n\\frac{\\det(\\mathbf{b},\\mathbf{c})}{\\det(\\mathbf{b},\\mathbf{d})} &= \\frac{\\det(\\mathbf{b},\\mathbf{c})^T \\det(\\mathbf{b},\\mathbf{c}) }{ \\det(\\mathbf{b},\\mathbf{c})^T\\det(\\mathbf{b},\\mathbf{d})} \\\\\n&= \\det \\begin{pmatrix} \\mathbf{b} \\cdot \\mathbf{b} & \\mathbf{b} \\cdot \\mathbf{c} \\\\\n\\mathbf{c} \\cdot \\mathbf{b} & \\mathbf{c} \\cdot \\mathbf{c}\n\\end{pmatrix}\n\\det \\begin{pmatrix}\n\\mathbf{b} \\cdot \\mathbf{b} & \\mathbf{b} \\cdot \\mathbf{d} \\\\\n\\mathbf{c} \\cdot \\mathbf{b} & \\mathbf{c} \\cdot \\mathbf{d}\n\\end{pmatrix}^{-1}.\n\\end{align*}\n\nThe square of the length of $AB$ is $\\mathbf{b} \\cdot \\mathbf{b}$, so this quantity is rational.\nThe square of the lengths of $AC$ and $BC$ are $\\mathbf{c} \\cdot \\mathbf{c}$ and\n$(\\mathbf{c} - \\mathbf{b}) \\cdot (\\mathbf{c} - \\mathbf{b}) = \\mathbf{b} \\cdot \\mathbf{b} + \\mathbf{c} \\cdot \\mathbf{c}\n- 2 \\mathbf{b} \\cdot \\mathbf{c}$, so $\\mathbf{b} \\cdot \\mathbf{c} = \\mathbf{c} \\cdot \\mathbf{b}$ is rational.\nSimilarly, using $AD$ and $BD$, we deduce that $\\mathbf{d} \\cdot \\mathbf{d}$ and $\\mathbf{b} \\cdot \\mathbf{d}$ is rational; then using $CD$, we deduce that $\\mathbf{c} \\cdot \\mathbf{d}$ is rational.\n\n\\noindent\n\\textbf{Third solution.}\n(by David Rusin)\nRecall that Heron's formula (for the area of a triangle in terms of its side length) admits the following three-dimensional analogue due to Piero della Francesca: if $V$ denotes the volume of a tetrahedron with vertices $A,B,C,D \\in \\mathbb{R}^3$, then\n\\[\n288 V^2 = \\det\n\\begin{pmatrix}\n0 & AB^2 & AC^2 & AD^2 & 1 \\\\\nAB^2 & 0 & BC^2 & BD^2 & 1 \\\\\nAC^2 & BC^2 & 0 & CD^2 & 1 \\\\\nAD^2 & BD^2 & CD^2 & 0 & 1 \\\\\n1 & 1 & 1 & 1 & 0\n\\end{pmatrix}\n\\]\nIn particular, the determinant vanishes if and only if $A,B,C,D$ are coplanar. From the identity\n\\begin{gather*}\n64(4 \\mathrm{Area}(\\triangle ABC)^2 \\mathrm{Area}(\\triangle ABD)^2 - 9 AB^2 V^2) \\\\\n= (AB^4 - AB^2(AC^2 + AD^2 + BC^2 + BD^2 - 2CD^2) \\\\ + (AC^2-BC^2)(AD^2-BD^2))^2\n\\end{gather*}\nwe see that $\\mathrm{Area}(\\triangle ABC) \\mathrm{Area}(\\triangle ABD)$ is rational;\nsince each of the areas has rational square, we deduce the claim.\n\n\\noindent\n\\textbf{Fourth solution.}\n(by Greg Martin)\nDefine the signed angles $\\alpha = \\angle BAC, \\beta = \\angle BAD, \\gamma = \\angle CAD$, so that $\\alpha + \\gamma = \\beta$. By the Law of Cosines,\n\\begin{align*}\n2 AB \\cdot AC \\cos \\alpha &= AB^2 + AC^2 - BC^2 \\in \\mathbb{Q} \\\\\n2  AB \\cdot AD \\cos \\beta &= AB^2 + AD^2 - BD^2 \\in \\mathbb{Q} \\\\\n2  AC \\cdot AD \\cos \\gamma &= AC^2 + AD^2 - CD^2 \\in \\mathbb{Q}.\n\\end{align*}\nIn particular, $(2 AB \\cdot AC \\cos \\alpha)^2 \\in \\mathbb{Q}$, and so\n$\\cos^2 \\alpha \\in \\mathbb{Q}$ and $\\sin^2 \\alpha = 1 - \\cos^2 \\alpha \\in \\mathbb{Q}$,\nand similarly for the other two angles.\n\nApplying the addition formula to $\\cos \\beta$, we deduce that\n\\[\n2  AB \\cdot AD \\cos \\alpha \\cos \\gamma - \n2 AB \\cdot AD \\sin \\alpha \\sin \\gamma \\in \\mathbb{Q}. \n\\]\nThe first of these terms equals\n\\[\n\\frac{(2 AB \\cdot AC \\cos \\alpha)(2 AB \\cdot AC \\cos \\alpha)}{AC^2} \\in \\mathbb{Q},\n\\]\nso the second term must also be rational. But now\n\\begin{align*}\n\\frac{\\mathrm{Area}(\\triangle ABC)}{\\mathrm{Area}(\\triangle ACD)}\n&= \\frac{AB \\cdot AC \\sin \\alpha}{AC \\cdot AD \\sin \\gamma} \\\\\n&= \\frac{2 AB \\cdot AD \\sin \\alpha \\sin \\gamma}{2 AD^2 \\sin^2 \\gamma} \\in \\mathbb{Q}\n\\end{align*}\nas desired.\n\n\\noindent\n\\textbf{Remark.}\nDerek Smith observes that this result\nis Proposition 1 of: M. Knopf, J. Milzman, D. Smith, D. Zhu and D. Zirlin,\nLattice embeddings of planar point sets, \\textit{Discrete and Computational Geometry} \\textbf{56} (2016), 693--710.\n\n\\noindent\n\\textbf{Remark.}\nIt is worth pointing out that it is indeed possible to choose points $A,B,C,D$ satisfying the conditions of the problem;\n one can even ensure that the lengths of all four segments are themselves rational.\nFor example, it was originally observed by Euler that one can find an infinite set of points on the unit circle whose pairwise distances are all rational numbers.\nOne way to see this is to apply the linear fractional transformation $f(z) = \\frac{z+i}{z-i}$ to the Riemann sphere to carry the real axis (plus $\\infty$) to the unit circle, then compute that\n\\[\n\\left| f(z_1) - f(z_2) \\right| = \\frac{2|z_1-z_2||}{|(z_1-i)(z_2-i)|}.\n\\]\nLet $S$ be the set of rational numbers $z$ for which $2(z^2 + 1)$ is a perfect square; the set $f(S)$ has the desired property provided that it is infinite. That can be checked in various ways; for instance, the equation\n$2(x^2+1) = (2y)^2$ equates to $x^2-2y^2 = -1$ (a modified Brahmagupta-Pell equation), which has infinitely many solutions even over the integers:\n\\[\nx + y \\sqrt{2} = (1 + \\sqrt{2})^{2n+1}.\n\\]"
  },
  {
    "year": 2018,
    "label": "B1",
    "difficulty": "1",
    "problem": "Let $\\mathcal{P}$ be the set of vectors defined by\n\\[\n\\mathcal{P} = \\left\\{ \\left. \\begin{pmatrix} a \\\\ b \\end{pmatrix} \\right| 0 \\leq a \\leq 2, 0 \\leq b \\leq 100, \\mbox{ and } a,b \\in \\mathbb{Z} \\right\\}.\n\\]\nFind all $\\mathbf{v} \\in \\mathcal{P}$ such that the set $\\mathcal{P} \\setminus \\{ \\mathbf{v} \\}$ obtained by omitting\nvector $\\mathbf{v}$ from $\\mathcal{P}$ can be partitioned into two sets of equal size and equal sum.",
    "solution": "The answer is the collection of vectors $(1,b)$ where $0 \\leq b \\leq 100$ and $b$ is even.\n (For ease of typography, we write tuples instead of column vectors.)\n\nFirst we show that if $\\mathcal{P} \\setminus \\{\\mathbf{v}\\}$ can be partitioned into subsets $S_1$ and $S_2$ of equal size and equal sum, then $\\mathbf{v}$ must be of the form $(1,b)$ where $b$ is even. For a finite nonempty set $S$ of vectors in $\\mathbb{Z}^2$, let $\\Sigma(S)$ denote the sum of the vectors in $S$. \nSince the average $x$- and $y$-coordinates in $\\mathcal{P}$ are $1$ and $50$, respectively, and there are $3\\cdot 101$ elements in $\\mathcal{P}$, we have\n\\[\n\\Sigma(P) = 303 \\cdot (1,50) = (303,15150). \n\\]\nOn the other hand, \n\\[\n\\Sigma(P) = \\mathbf{v}+\\Sigma(S_1)+\\Sigma(S_2) = \\mathbf{v}+2\\Sigma(S_1). \n\\]\nBy parity considerations, the entries of $\\mathbf{v}$ must be odd and even, respectively, and thus $\\mathbf{v}$ is of the claimed form.\n\nNext suppose $\\mathbf{v} = (1,b)$ where $b$ is even. Note that $\\mathcal{P} \\setminus \\{(1,50)\\}$ can be partitioned into $151$ pairs of (distinct) vectors $(x,y)$ and $(2-x,100-y)$, each summing to $(2,100)$. If $b \\neq 50$ then three of these pairs are $\\{(1,b),(1,100-b)\\}$,$\\{(2,b),(0,100-b)\\}$, and $\\{(2,25+b/2),(0,75-b/2)\\}$. Of the remaining $148$ pairs, assign half of them to $S_1$ and half to $S_2$, and then complete the partition of $\\mathcal{P} \\setminus \\{\\mathbf{v}\\}$ by assigning $(0,100-b)$, $(2,25+b/2)$, and $(1,50)$ to $S_1$ and $(1,100-b)$, $(2,b)$, and $(0,75-b/2)$ to $S_2$. (Note that the three vectors assigned to each of $S_1$ and $S_2$ have the same sum $(3,175-b/2)$.) By construction, $S_1$ and $S_2$ have the same number of elements, and $\\Sigma(S_1) = \\Sigma(S_2)$.\n\nFor $b=50$, this construction does not work because $(1,b) = (100-b)$, but a slight variation can be made.\n In this case, three of the pairs in $\\mathcal{P} \\setminus \\{(1,50)\\}$ are $\\{(2,50),(0,50)\\}$, $\\{(1,51),(1,49)\\}$, and $\\{(0,49),(2,51)\\}$. Assign half of the other $148$ pairs to $S_1$ and half to $S_2$, and complete the partition of\n$\\mathcal{P} \\setminus \\{(1,50)\\}$ by assigning $(2,50)$, $(1,51)$, and $(0,49)$ to $S_1$ and $(0,50)$, $(1,49)$, and $(2,51)$ to $S_2$."
  },
  {
    "year": 2018,
    "label": "B2",
    "difficulty": "2",
    "problem": "Let $n$ be a positive integer, and let $f_n(z) = n + (n-1) z + (n-2)z^2 + \\cdots + z^{n-1}$. Prove that\n$f_n$ has no roots in the closed unit disk $\\{z \\in \\mathbb{C}\\colon |z| \\leq 1 \\}$.",
    "solution": "\\textbf{First solution.}\nNote first that $f_n(1) > 0$, so $1$ is not a root of $f_n$.\nNext, note that\n\\[\n(z-1)f_n(z) = z^n + \\cdots + z - n;\n\\]\nhowever, for $\\left| z \\right| \\leq 1$, we have \n$\\left| z^n + \\cdots + z \\right| \\leq n$ by the triangle inequality;\nequality can only occur if $z,\\dots,z^n$ have norm 1 and the same argument, which only happens for $z=1$.\nThus there can be no root of $f_n$ with $|z| \\leq 1$.\n\n\n\\noindent\n\\textbf{Second solution.}\n(by Karl Mahlburg)\nDefine the polynomial\n\\[\ng_n(z) = nz^{n-1} + \\cdots + 2z + 1\n\\]\nand note that $z^{n-1} g_n(z^{-1}) = f_n(z)$.\nSince $f_n(0) \\neq 0$, to prove the claim it is equivalent to show that $g_n$\nhas no roots in the region $|z| \\geq 1$.\n\nNow note that $g_n(z) = h_n'(z)$ for\n\\[\nh_n(z) = z^n + \\cdots + z + 1,\n\\]\na polynomial with roots $e^{2\\pi ij/(n+1)}$ for $j=0,\\dots,n$.\nBy the Gauss-Lucas theorem, the roots of $g_n$ lie in the convex hull of the roots of $h_n$,\nand moreover cannot be vertices of the convex hull because $h_n$ has no repeated roots.\nThis implies the claim.\n\n\\noindent\n\\textbf{Remark.}\nYet another approach is to use the \\emph{Enestr\\\"om-Kakeya theorem}: if $P_n(z) = a_0 + \\cdots + a_n z^n$\nis a polynomial with real coefficients satisfying $|a_n|  \\geq \\cdots \\geq |a_0| > 0$, then the roots of $P_n(z)$\nall satisfy $|z| \\leq 1$. Namely, applying this to the polynomial $g_n(z/c)$ for \n$c = n/(n-1)$ shows that the roots of $g_n$ all satisfy $\\left|z \\right| \\leq 1/c$. \n\n\\noindent\n\\textbf{Remark.}\nFor a related problem, see problem A5 from the 2014 Putnam competition."
  },
  {
    "year": 2018,
    "label": "B3",
    "difficulty": "3",
    "problem": "Find all positive integers $n < 10^{100}$ for which simultaneously $n$ divides $2^n$, $n-1$ divides $2^n-1$,\nand $n-2$ divides $2^n - 2$.",
    "solution": "The values of $n$ with this property are $2^{2^\\ell}$ for $\\ell = 1,2,4,8$.\nFirst, note that $n$ divides $2^n$ if and only if $n$ is itself a power of 2; we may thus write $n = 2^m$ and note that\nif $n<10^{100}$, then\n\\[\n2^m = n < 10^{100} < (10^3)^{34} < (2^{10})^{34} = 2^{340}.\n\\]\nMoreover, the case $m=0$ does not lead to a solution because for $n=1$, $n-1 = 0$ does not divide $2^n-1 = 1$; we \nmay thus assume $1 \\leq m \\leq 340$.\n\nNext, note that modulo $n-1 = 2^m-1$, the powers of $2$ cycle with period $m$ (the terms\n$2^0, \\dots, 2^{m-1}$ remain the same upon reduction, and then the next term repeats the initial 1); consequently,\n$n-1$ divides $2^n-1$ if and only if $m$ divides $n$, which happens if and only if $m$ is a power of 2.\nWrite $m = 2^\\ell$ and note that $2^\\ell < 340 < 512$, so $\\ell < 9$. The case $\\ell=0$ does not lead to a solution because for $n=2$, $n-2 =0$ does not divide $2^n-2 = 2$; we may thus assume $1 \\leq \\ell \\leq 8$.\n\nFinally, note that $n-2 = 2^m-2$ divides $2^n-2$ if and only if $2^{m-1} - 1$ divides $2^{n-1} - 1$.\nBy the same logic as the previous paragraph, this happens if and only if $m-1$ divides $n-1$,\nthat is, if $2^\\ell - 1$ divides $2^m-1$. This in turn happens if and only if $\\ell$ divides $m = 2^\\ell$,\nwhich happens if and only if $\\ell$ is a power of 2. The values allowed by the bound $\\ell < 9$ are\n$\\ell = 1,2,4,8$; for these values, $m \\leq 2^8 = 256$ and\n\\[\nn = 2^m \\leq 2^{256} \\leq (2^3)^{86} < 10^{86} < 10^{100},\n\\]\nso the solutions listed do satisfy the original inequality."
  },
  {
    "year": 2018,
    "label": "B4",
    "difficulty": "4",
    "problem": "Given a real number $a$, we define a sequence by $x_0 = 1$, $x_1 = x_2 = a$, and $x_{n+1} = 2x_n x_{n-1} - x_{n-2}$ for $n \\geq 2$. Prove that if $x_n = 0$ for some $n$, then the sequence is periodic.",
    "solution": "We first rule out the case $|a|>1$. In this case, we prove that $|x_{n+1}| \\geq |x_n|$ for all $n$, meaning that we cannot have $x_n = 0$. We proceed by induction; the claim is true for $n=0,1$ by hypothesis. To prove the claim for  $n \\geq 2$, write\n\\begin{align*}\n|x_{n+1}| &= |2x_nx_{n-1}-x_{n-2}| \\\\\n&\\geq 2|x_n||x_{n-1}|-|x_{n-2}| \\\\\n&\\geq |x_n|(2|x_{n-1}|-1) \\geq |x_n|,\n\\end{align*} \nwhere the last step follows from $|x_{n-1}| \\geq |x_{n-2}| \\geq \\cdots \\geq |x_0| = 1$.\n\nWe may thus assume hereafter that $|a|\\leq 1$. We can then write $a = \\cos b$ for some $b \\in [0,\\pi]$. \nLet $\\{F_n\\}$ be the Fibonacci sequence, defined as usual by $F_1=F_2=1$ and $F_{n+1}=F_n+F_{n-1}$. We show by induction that\n\\[\nx_n = \\cos(F_n b) \\qquad (n \\geq 0).\n\\]\nIndeed, this is true for $n=0,1,2$; given that it is true for $n \\leq m$, then\n\\begin{align*}\n2x_mx_{m-1}&=2\\cos(F_mb)\\cos(F_{m-1}b) \\\\\n&= \\cos((F_m-F_{m-1})b)+\\cos((F_m+F_{m-1})b) \\\\\n&= \\cos(F_{m-2}b)+\\cos(F_{m+1}b)\n\\end{align*}\nand so \n$x_{m+1} = 2x_mx_{m-1}-x_{m-2} = \\cos(F_{m+1}b)$. This completes the induction.\n\n\nSince $x_n = \\cos(F_n b)$, if $x_n=0$ for some $n$ then $F_n b = \\frac{k}{2} \\pi$ for some odd integer $k$. In particular, we can write $b = \\frac{c}{d}(2\\pi)$ where $c = k$ and $d = 4F_n$ are integers.\n\n\nLet $x_n$ denote the pair $(F_n,F_{n+1})$, where each entry in this pair is viewed as an element of $\\mathbb{Z}/d\\mathbb{Z}$. Since there are only finitely many possibilities for $x_n$, there must be some $n_2>n_1$ such that $x_{n_1}=x_{n_2}$. Now $x_n$ uniquely determines both $x_{n+1}$ and $x_{n-1}$, and it follows that the sequence $\\{x_n\\}$ is periodic: for $\\ell = n_2-n_1$, $x_{n+\\ell} = x_n$ for all $n \\geq 0$. In particular, $F_{n+\\ell} \\equiv F_n \\pmod{d}$ for all $n$. But then $\\frac{F_{n+\\ell}c}{d}-\\frac{F_n c}{d}$ is an integer, and so\n\\begin{align*}\nx_{n+\\ell} &= \\cos\\left(\\frac{F_{n+\\ell}c}{d}(2\\pi)\\right)\\\\\n& = \\cos\\left(\\frac{F_n c}{d}(2\\pi)\\right) = x_n\n\\end{align*}\nfor all $n$. Thus the sequence $\\{x_n\\}$ is periodic, as desired.\n\n\\noindent\n\\textbf{Remark.}\nKarl Mahlburg points out that one can motivate the previous solution by computing the terms\n\\[\nx_2 = 2a^2 - 1, x_3 = 4a^3 - 3a, x_4 = 16a^5 - 20a^3 + 5a\n\\]\nand recognizing these as the Chebyshev polynomials $T_2, T_3, T_5$. (Note that $T_3$ was used in the solution of\nproblem A3.)\n\n\\noindent\n\\textbf{Remark.}\nIt is not necessary to handle the case $\\left| a \\right| > 1$ separately; the cosine function extends\nto a surjective analytic function on $\\mathbb{C}$ and continues to satisfy the addition formula,\nso one can write $a = \\cos b$ for some $b \\in \\mathbb{C}$\nand then proceed as above."
  },
  {
    "year": 2018,
    "label": "B5",
    "difficulty": "5",
    "problem": "Let $f = (f_1, f_2)$ be a function from $\\mathbb{R}^2$ to $\\mathbb{R}^2$ with continuous partial derivatives\n$\\frac{\\partial f_i}{\\partial x_j}$ that are positive everywhere. Suppose that\n\\[\n\\frac{\\partial f_1}{\\partial x_1} \\frac{\\partial f_2}{\\partial x_2} - \\frac{1}{4} \\left( \\frac{\\partial f_1}{\\partial x_2}  + \\frac{\\partial f_2}{\\partial x_1} \\right)^2 > 0\n\\]\neverywhere. Prove that $f$ is one-to-one.",
    "solution": "Let $(a_1,a_2)$ and $(a_1',a_2')$ be distinct points in $\\mathbb{R}^2$; we want to show that $f(a_1,a_2) \\neq f(a_1',a_2')$. Write $(v_1,v_2) = (a_1',a_2')-(a_1,a_2)$, and let $\\gamma(t) = (a_1,a_2)+t(v_1,v_2)$, $t \\in [0,1]$, be the path between $(a_1,a_2)$ and $(a_1',a_2')$. Define a real-valued function $g$ by $g(t) = (v_1,v_2) \\cdot f(\\gamma(t))$.\nBy the Chain Rule, \n\\[\nf'(\\gamma(t)) = \\left( \\begin{matrix} \\partial f_1/\\partial x_1 & \\partial f_1/\\partial x_2 \\\\ \\partial f_2/\\partial x_1 & \\partial f_2/\\partial x_2 \\end{matrix} \\right) \\left(\n\\begin{matrix} v_1 \\\\ v_2 \\end{matrix} \\right). \n\\]\nAbbreviate $\\partial f_i/\\partial x_j$ by $f_{ij}$; then\n\\begin{align*}\ng'(t) &= \\left( \\begin{matrix} v_1 & v_2 \\end{matrix} \\right) \\left( \\begin{matrix} f_{11} & f_{12} \\\\ f_{21} & f_{22} \\end{matrix} \\right) \\left( \\begin{matrix} v_1 \\\\ v_2 \\end{matrix} \\right) \\\\\n&= f_{11} v_1^2 + (f_{12}+f_{21})v_1v_2+f_{22} v_2^2 \\\\\n&= f_{11} \\left(v_1+\\frac{f_{12}+f_{21}}{2f_{11}} v_2 \\right)^2 + \\frac{4f_{11}f_{22}-(f_{12}+f_{21})^2}{4f_{11}} v_2^2 \\\\\n& \\geq 0\n\\end{align*}\nsince $f_{11}$ and $f_{11}f_{22}-(f_{12}+f_{21})^2/4$ are positive by assumption. Since the only way that equality could hold is if $v_1$ and $v_2$ are both $0$, we in fact have $g'(t)>0$ for all $t$. But if $f(a_1,a_2) = f(a_1',a_2')$, then $g(0) = g(1)$, a contradiction.\n\n\\noindent\n\\textbf{Remark.}\nA similar argument shows more generally that $f:\\thinspace \\mathbb{R}^n \\to \\mathbb{R}^n$ is injective if at all points in $\\mathbb{R}^n$, the Jacobian matrix $Df$ satisfies the following property: the quadratic form associated to the bilinear form with matrix $Df$ (or the symmetrized bilinear form with matrix $(Df+(Df)^T)/2$) is positive definite. In the setting of the problem, the symmetrized matrix is\n\\[\n\\left( \\begin{matrix} f_{11} & (f_{12}+f_{21})/2 \\\\ (f_{12}+f_{21})/2 & f_{22} \\end{matrix} \\right),\n\\]\nand this is positive definite if and only if $f_{11}$ and the determinant of the matrix are both positive\n(Sylvester's criterion). Note that the assumptions that $f_{12},f_{21}>0$ are unnecessary for the argument;\nit is also easy to see that the hypotheses $f_{11}, f_{12} > 0$ are also superfluous.\n(The assumption $f_{11}f_{22}-(f_{12}+f_{21})^2 > 0$ implies $f_{11} f_{22} > 0$, so both are nonzero and of the same sign; by continuity, this common sign must be constant over all of $\\mathbb{R}^2$. If it is negative, then\napply the same logic to $(-f_1, -f_2)$.)"
  },
  {
    "year": 2018,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $S$ be the set of sequences of length $2018$ whose terms  are in the set $\\{1,2,3,4,5,6,10\\}$ and sum to $3860$.\nProve that the cardinality of $S$ is at most\n\\[\n2^{3860} \\cdot \\left( \\frac{2018}{2048} \\right)^{2018}.\n\\]\n\n\\end{itemize}\n\n\\end{document}",
    "solution": "(by Manjul Bhargava)\nLet $a(k,n)$ denote the number of sequences of length $k$ taken from the set $\\{1,2,3,4,5,6,10\\}$ and having sum $n$.\nWe prove that \n\\[\na(k,n) < 2^n \\left( \\frac{2018}{2048} \\right)^k\n\\]\nby double induction on $n+k$ and $n-k$.  The claim is clearly true when $n-k \\leq 0$ and in particular when $n=k=1$, the smallest case for $n+k$.\n\nWe categorize the sequences counted by $a(k,n)$ by whether they end in $1,2,3,4,5,6,10$; removing the last\nterm of such a sequence yields a sequence counted by $a(k-1,n-1), a(k-1,n-2), a(k-1,n-3), a(k-1,n-4), a(k-1,n-5), a(k-1,n-6), a(k-1,n-10)$, respectively.  Therefore,\n\\begin{align*}\na(k,n) &= a(k-1,n-1) + \\cdots \\\\\n&\\quad + a(k-1,n-6) + a(k-1,n-10) \\\\\n&< (  2^{n-1} + \\cdots +   2^{n-6}  +  2^{n-10} ) \\left( \\frac{2018}{2048} \\right)^{k-1} \\\\\n&= 2^n \\left( \\frac{1}{2} + \\cdots + \\frac{1}{64} + \\frac{1}{1024} \\right) \\left( \\frac{2018}{2048} \\right)^{k-1} \\\\\n&= 2^n \\left( \\frac{1009}{1024} \\right) \\left( \\frac{2018}{2048} \\right)^{k-1} \\\\\n&= 2^n \\left( \\frac{2018}{2048} \\right)^{k}\n\\end{align*}\nwhere we used directly the induction hypothesis to obtain the inequality on the second line.\nThe case $k=2018, n=3860$ yields the desired result.\n\n\\noindent\n\\textbf{Remark.}\nK. Soundararajan suggests the following reinterpretation of this argument. The quantity $a(k,n)$ can be interpreted as the coefficient of $x^n$ in $(x + x^2 + \\cdots + x^6 + x^{10})^k$. Since this polynomial has nonnegative coefficients, \nfor any $x$, we have\n\\[\na(k,n) x^n < (x + x^2 + \\cdots + x^6 + x^{10})^k.\n\\]\nSubstituting $x = \\frac{1}{2}$ yields the bound stated above.\n\nOn a related note, Alexander Givental suggests that the value $n=3860$ (which is otherwise irrelevant to the problem) may have been chosen for the following reason: as a function of $x$, the upper bound $x^{-n} (x+x^2 + \\cdots + x^6 + x^{10})^k$\nis minimized when\n\\[\n\\frac{x(1 + 2x + \\cdots + 6x^5 + x^9)}{x + x^2 + \\cdots + x^6 + x^{10}} = \\frac{n}{k}.\n\\]\nIn order for this to hold for $x = 1/2$, $k=2018$, one must take $n = 3860$.\n\n\\noindent\n\\textbf{Remark.}\nFor purposes of comparison, the stated bound is about $10^{1149}$, while the trivial upper bound\ngiven by counting all sequences of length 2018 of positive integers that sum to 3860 is\n\\[\n\\binom{3859}{2017} \\sim 10^{1158}.\n\\]\nThe latter can be easily derived by a ``stars and bars'' argument: visualize each sequence of this form by representing the value $n$ by $n$ stars and inserting a bar between adjacent terms of the sequence. The resulting string of symbols consists of one star at the beginning, 2017 bar-star combinations, and 3860-2018 more stars.\n\nUsing a computer, it is practical to compute the exact cardinality of $S$ by finding the coefficient of $x^{3860}$ in\n$(x + x^2 + \\cdots + x^6 + x^{10})^{2018}$. For example, this can be done in \\texttt{Sage} in a couple of seconds as follows. (The truncation is truncated modulo $x^{4000}$ for efficiency.)\n\n\\begin{verbatim}\nsage: P.<x> = PowerSeriesRing(ZZ, 4000)\nsage: f = (x + x^2 + x^3 + x^4 + \\\n....:      x^5 + x^6 + x^10)^2018\nsage: m = list(f)[3860]\nsage: N(m)\n8.04809122940636e1146\n\\end{verbatim}\n\nThis computation shows that the upper bound of the problem differs from the true value by a factor of about 150.\n\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2019,
    "label": "A1",
    "difficulty": "1",
    "problem": "Determine all possible values of the expression\n\\[\nA^3+B^3+C^3-3ABC\n\\]\nwhere $A, B$, and $C$ are nonnegative integers.",
    "solution": "The answer is all nonnegative integers not congruent to $3$ or $6 \\pmod{9}$. Let $X$ denote the given expression;\nwe first show that we can make $X$ equal to each of the claimed values. Write $B=A+b$ and $C=A+c$, so that\n\\[\nX = (b^2-bc+c^2)(3A+b+c).\n\\]\nBy taking $(b,c) = (0,1)$ or $(b,c) = (1,1)$, we obtain respectively $X = 3A+1$ and $X = 3A+2$; consequently, as $A$ varies, we achieve every nonnegative integer not divisible by 3. By taking $(b,c) = (1,2)$, we obtain $X = 9A+9$; consequently, as $A$ varies, we achieve every positive integer divisible by 9. We may also achieve $X=0$\nby taking $(b,c) = (0,0)$.\n\nIn the other direction, $X$ is always nonnegative: either apply the arithmetic mean-geometric mean inequality, or write $b^2-bc+c^2 = (b - c/2)^2 + 3c^2/4$ to see that it is nonnegative.\nIt thus only remains to show that if $X$ is a multiple of $3$, then it is a multiple of $9$. Note that\n$3A+b+c \\equiv b+c \\pmod{3}$ and $b^2-bc+c^2 \\equiv (b+c)^2 \\pmod{3}$; consequently, if $X$ is divisible by $3$,\nthen $b+c$ must be divisible by $3$, so each factor in $X = (b^2-bc+c^2)(3A+b+c)$ is divisible by $3$.\nThis proves the claim.\n\n\\noindent\n\\textbf{Remark.}\nThe factorization of $X$ used above can be written more symmetrically as\n\\[\nX = (A+B+C)(A^2+B^2+C^2-AB-BC-CA).\n\\]\nOne interpretation of the factorization is that $X$ is the determinant of the circulant matrix\n\\[\n\\begin{pmatrix}\nA & B & C \\\\\nC & A & B \\\\\nB & C & A\n\\end{pmatrix}\n\\]\nwhich has the vector $(1,1,1)$ as an eigenvector (on either side) with eigenvalue $A+B+C$. The other eigenvalues are $A + \\zeta B + \\zeta^2 C$ where $\\zeta$ is a primitive cube root of unity; in fact, $X$ is the norm form for the ring $\\ZZ[T]/(T^3 - 1)$, from which it follows directly that the image of $X$ is closed under multiplication. (This is similar to the fact that the image of $A^2+B^2$, which is the norm form for the ring $\\mathbb{Z}[i]$ of Gaussian integers, is closed under multiplication.)\n\nOne can also the unique factorization property of the ring $\\ZZ[\\zeta]$ of Eisenstein integers as follows.\nThe three factors of $X$ over $\\ZZ[\\zeta_3]$ are pairwise congruent modulo $1-\\zeta_3$; consequently,\nif $X$ is divisible by 3, then it is divisible by $(1-\\zeta_3)^3 = -3\\zeta_3(1-\\zeta_3)$ and hence \n(because it is a rational integer) by $3^2$."
  },
  {
    "year": 2019,
    "label": "A2",
    "difficulty": "2",
    "problem": "In the triangle $\\triangle ABC$, let $G$ be the centroid, and let $I$ be the center of the inscribed circle.\nLet $\\alpha$ and $\\beta$ be the angles at the vertices $A$ and $B$, respectively.\nSuppose that the segment $IG$ is parallel to $AB$ and that $\\beta = 2 \\tan^{-1} (1/3)$. Find $\\alpha$.",
    "solution": "\\noindent \\textbf{Solution 1.}\nLet $M$ and $D$ denote the midpoint of $AB$ and the foot of the altitude from $C$ to $AB$, respectively, and let $r$ be the inradius of $\\bigtriangleup ABC$. Since $C,G,M$ are collinear with $CM = 3GM$, the distance from $C$ to line $AB$ is $3$ times the distance from $G$ to $AB$, and the latter is $r$ since $IG \\parallel AB$; hence the altitude $CD$ has length $3r$. By the double angle formula for tangent, $\\frac{CD}{DB} = \\tan\\beta = \\frac{3}{4}$, and so $DB = 4r$. Let $E$ be the point where the incircle meets $AB$; then $EB = r/\\tan(\\frac{\\beta}{2}) = 3r$. It follows that $ED = r$, whence the incircle is tangent to the altitude $CD$. This implies that $D=A$, $ABC$ is a right triangle, and $\\alpha = \\frac{\\pi}{2}$.\n\n\\noindent\n\\textbf{Remark.}\nOne can obtain a similar solution by fixing a coordinate system with $B$ at the origin and $A$ on the positive \n$x$-axis. Since $\\tan \\frac{\\beta}{2} = \\frac{1}{3}$, we may assume without loss of generality that\n$I = (3,1)$. Then $C$ lies on the intersection of the line $y=3$ (because $CD = 3r$ as above) \nwith the line $y = \\frac{3}{4} x$ (because $\\tan \\beta = \\frac{3}{4}$ as above), forcing $C = (4,3)$ and so forth.\n\n\\noindent \\textbf{Solution 2.}\nLet $a,b,c$ be the lengths of $BC,CA,AB$, respectively.\nLet $r$, $s$, and $K$ denote the inradius, semiperimeter, and area of $\\triangle ABC$. \nBy Heron's Formula,\n\\[\nr^2s^2 = K^2 = s(s-a)(s-b)(s-c).\n\\]\n\nIf $IG$ is parallel to $AB$, then \n\\[\n\\frac{1}{2} rc = \n\\mathrm{area}(\\triangle ABI) = \\mathrm{area}(\\triangle ABG) = \\frac{1}{3} K = \\frac{1}{3} rs\n\\]\nand so $c = \\frac{a+b}{2}$. Since $s = \\frac{3(a+b)}{4}$ and $s-c = \\frac{a+b}{4}$, we have \n$3r^2 = (s-a)(s-b)$. Let $E$ be the point at which the incircle meets $AB$; then $s-b = EB = r/\\tan(\\frac{\\beta}{2})$ and $s-a = EA = r/\\tan(\\frac{\\alpha}{2})$. It follows that $\\tan(\\frac{\\alpha}{2})\\tan(\\frac{\\beta}{2}) = \\frac{1}{3}$ and so $\\tan(\\frac{\\alpha}{2}) = 1$. This implies that $\\alpha = \\frac{\\pi}{2}$.\n\n\\noindent\n\\textbf{Remark.}\nThe equality $c = \\frac{a+b}{2}$ can also be derived from the vector representations\n\\[\nG = \\frac{A+B+C}{3}, \\qquad I = \\frac{aA+bB+cC}{a+b+c}.\n\\]\n\n\n\\noindent\n\\textbf{Solution 3.}\n(by Catalin Zara)\nIt is straightforward to check that a right triangle with $AC = 3, AB = 4, BC = 5$ works. For example,\nin a coordinate system with $A = (0,0), B = (4,0), C = (0,3)$, we have\n\\[\nG = \\left(\\frac{4}{3}, 1 \\right), \\qquad \nI = (1, 1)\n\\]\nand for $D = (1,0)$, \n\\[\n\\tan \\frac{\\beta}{2} = \\frac{ID}{BD} = \\frac{1}{3}.\n\\]\nIt thus suffices to suggest that this example is unique up to similarity.\n\nLet $C'$ be the foot of the angle bisector at $C$. Then \n\\[\n\\frac{CI}{IC'} = \\frac{CA + CB}{AB}\n\\] \nand so $IG$ is parallel to $AB$ if and only if $CA + CB = 2AB$. We may assume without loss of generality that $A$ and $B$ are fixed, in which case this condition restricts $C$ to an ellipse with foci at $A$ and $B$.\nSince the angle $\\beta$ is also fixed, up to symmetry \n$C$ is further restricted to a half-line starting at $B$; this intersects the ellipse in a unique point.\n\n\\noindent \n\\textbf{Remark.}\nGiven that $CA + CB = 2AB$, one can also recover the ratio of side lengths using the law of cosines."
  },
  {
    "year": 2019,
    "label": "A3",
    "difficulty": "3",
    "problem": "Given real numbers $b_0, b_1, \\dots, b_{2019}$ with $b_{2019} \\neq 0$, let $z_1,z_2,\\dots,z_{2019}$ be \nthe roots in the complex plane of the polynomial \n\\[\nP(z) = \\sum_{k=0}^{2019} b_k z^k.\n\\]\nLet $\\mu = (|z_1| + \\cdots + |z_{2019}|)/2019$ be the average of the distances from $z_1,z_2,\\dots,z_{2019}$ to the origin. Determine the largest constant $M$ such that $\\mu \\geq M$ for all choices of $b_0,b_1,\\dots, b_{2019}$ that satisfy\n\\[\n1 \\leq b_0 < b_1 < b_2 < \\cdots < b_{2019} \\leq 2019.\n\\]",
    "solution": "The answer is $M = 2019^{-1/2019}$. For any choices of $b_0,\\ldots,b_{2019}$ as specified, AM-GM gives\n\\[\n\\mu \\geq |z_1\\cdots z_{2019}|^{1/2019} = |b_0/b_{2019}|^{1/2019} \\geq 2019^{-1/2019}.\n\\]\nTo see that this is best possible, consider $b_0,\\ldots,b_{2019}$ given by $b_k = 2019^{k/2019}$ for all $k$. Then \n\\[\nP(z/2019^{1/2019}) = \\sum_{k=0}^{2019} z^k = \\frac{z^{2020}-1}{z-1}\n\\]\nhas all of its roots on the unit circle. It follows that all of the roots of $P(z)$ have modulus $2019^{-1/2019}$, and so $\\mu = 2019^{-1/2019}$ in this case."
  },
  {
    "year": 2019,
    "label": "A4",
    "difficulty": "4",
    "problem": "Let $f$ be a continuous real-valued function on $\\mathbb{R}^3$. Suppose that for every sphere $S$ of radius 1,\nthe integral of $f(x,y,z)$ over the surface of $S$ equals 0. Must $f(x,y,z)$ be identically 0?",
    "solution": "The answer is no. Let $g :\\thinspace \\mathbb{R} \\to \\mathbb{R}$ be any continuous function with $g(t+2) = g(t)$ for all $t$ and $\\int_0^2 g(t)\\,dt = 0$ (for instance, $g(t) = \\sin(\\pi t)$). Define $f(x,y,z) = g(z)$. We claim that for any sphere $S$ of radius $1$, $\\iint_S f\\,dS = 0$.\n\n\nIndeed, let $S$ be the unit sphere centered at $(x_0,y_0,z_0)$. We can parametrize $S$ by $S(\\phi,\\theta) = (x_0,y_0,z_0)+(\\sin\\phi\\cos\\theta,\n\\sin\\phi\\sin\\theta,\\cos\\phi)$ for $\\phi \\in [0,\\pi]$ and $\\theta \\in [0,2\\pi]$. Then we have\n\n\\begin{align*}\n\\iint_S f(x,y,z)\\,dS &= \\int_0^\\pi \\int_0^{2\\pi} f(S(\\phi,\\theta))\\left\\|\\frac{\\partial S}{\\partial \\phi} \\times \\frac{\\partial S}{\\partial \\theta}\\right\\|\\,d\\theta\\,d\\phi \\\\\n&=  \\int_0^\\pi \\int_0^{2\\pi} g(z_0+\\cos\\phi) \\sin\\phi\\,d\\theta\\,d\\phi \\\\\n&= 2\\pi \\int_{-1}^1 g(z_0+t)\\,dt,\n\\end{align*}\n\nwhere we have used the substitution $t = \\cos\\phi$; but this last integral is $0$ for any $z_0$ by construction.\n\n\\noindent\n\\textbf{Remark.}\nThe solution recovers the famous observation of Archimedes that the surface area of a spherical cap is linear in the height of the cap. In place of spherical coordinates, one may also compute $\\iint_S f(x,y,z)\\,dS$ by computing the integral over a ball of radius $r$, then computing the derivative with respect to $r$ and evaluating at $r=1$.\n\nNoam Elkies points out that a similar result holds in $\\mathbb{R}^n$ for any $n$. Also, there exist nonzero continuous functions on $\\mathbb{R}^n$ whose integral over any unit ball vanishes; this implies certain negative results about image reconstruction."
  },
  {
    "year": 2019,
    "label": "A5",
    "difficulty": "5",
    "problem": "Let $p$ be an odd prime number, and let $\\mathbb{F}_p$ denote the field of integers modulo $p$. Let $\\mathbb{F}_p[x]$ be the ring of polynomials over $\\mathbb{F}_p$, and let $q(x) \\in \\mathbb{F}_p[x]$ be given by \n\\[\nq(x) = \\sum_{k=1}^{p-1} a_k x^k,\n\\]\nwhere\n\\[\na_k = k^{(p-1)/2} \\mod{p}. \n\\]\nFind the greatest nonnegative integer $n$ such that $(x-1)^n$ divides $q(x)$ in $\\mathbb{F}_p[x]$.",
    "solution": "The answer is $\\frac{p-1}{2}$. \nDefine the operator $D = x \\frac{d}{dx}$, where $\\frac{d}{dx}$ indicates formal differentiation of polynomials.\nFor $n$ as in the problem statement, we have $q(x) = (x-1)^n r(x)$ for some polynomial $r(x)$ in $\\mathbb{F}_p$ not divisible by $x-1$. For $m=0,\\dots,n$, by the product rule we have\n\\[\n(D^m q)(x) \\equiv n^m x^m (x-1)^{n-m} r(x) \\pmod{(x-1)^{n-m+1}}.\n\\]\nSince $r(1) \\neq 0$ and $n \\not\\equiv 0 \\pmod{p}$ (because $n \\leq \\deg(q) = p-1$), we may identify $n$ as the smallest nonnegative integer for which $(D^n q)(1) \\neq 0$.\n\nNow note that $q = D^{(p-1)/2} s$ for\n\\[\ns(x) = 1 + x + \\cdots + x^{p-1} = \\frac{x^p-1}{x-1} = (x-1)^{p-1}\n\\]\nsince $(x-1)^p = x^p-1$ in $\\mathbb{F}_p[x]$.\nBy the same logic as above, $(D^n s)(1) = 0$ for $n=0,\\dots,p-2$ but not for $n=p-1$.\nThis implies the claimed result.\n\n\\noindent\n\\textbf{Remark.}\nOne may also finish by checking directly that \nfor any positive integer $m$,\n\\[\n\\sum_{k=1}^{p-1} k^m \\equiv \\begin{cases} -1 \\pmod{p} & \\mbox{if $(p-1)|m$} \\\\\n0 \\pmod{p} & \\mbox{otherwise.}\n\\end{cases}\n\\]\nIf $(p-1) | m$, then $k^m \\equiv 1 \\pmod{p}$ by the little Fermat theorem, and so the sum is congruent\nto $p-1 \\equiv -1 \\pmod{p}$. Otherwise, for any primitive root $\\ell$ mod $p$, multiplying the sum by $\\ell^m$ permutes the terms modulo $p$ and hence does not change the sum modulo $p$; since $\\ell^n \\not\\equiv 1 \\pmod{p}$, this is only possible if the sum is zero modulo $p$."
  },
  {
    "year": 2019,
    "label": "A6",
    "difficulty": "6",
    "problem": "Let $g$ be a real-valued function that is continuous on the closed interval $[0,1]$ and twice differentiable on \nthe open interval $(0,1)$. Suppose that for some real number $r>1$, \n\\[\n\\lim_{x \\to 0^+} \\frac{g(x)}{x^r} = 0.\n\\]\nProve that either\n\\[\n\\lim_{x \\to 0^+} g'(x) = 0 \\qquad \\mbox{or} \\qquad \\limsup_{x \\to 0^+} x^r |g''(x)| = \\infty.\n\\]",
    "solution": "\\textbf{Solution 1.}\n(by Harm Derksen)\nWe assume that $\\limsup_{x \\to 0^+} x^r |g''(x)| < \\infty$\nand deduce that $\\lim_{x \\to 0^+} g'(x) = 0$.\nNote that\n\\[\n\\limsup_{x \\to 0^+} x^r \\sup\\{| g''(\\xi)|: \\xi \\in [x/2, x]\\}\n< \\infty.\n\\]\nSuppose for the moment that there exists a function $h$ on $(0,1)$ which is positive, nondecreasing, and satisfies\n\\[\n\\lim_{x \\to 0^+} \\frac{g(x)}{h(x)} = \\lim_{x \\to 0^+} \\frac{h(x)}{x^r} = 0.\n\\]\nFor some $c>0$, $h(x) < x^r < x$ for $x \\in (0,c)$. By Taylor's theorem with remainder, we can find a function $\\xi$ on $(0,c)$ such that\n$\\xi(x) \\in [x-h(x),x]$ and\n\\[\ng(x-h(x)) = g(x) - g'(x) h(x) + \\frac{1}{2} g''(\\xi(x)) h(x)^2.\n\\]\nWe can thus express $g'(x)$ as\n\\[\n\\frac{g(x)}{h(x)} + \\frac{1}{2} x^r g''(\\xi(x)) \\frac{h(x)}{x^r}\n-  \\frac{g(x-h(x))}{h(x-h(x))} \\frac{h(x-h(x))}{h(x)}.\n\\]\nAs $x \\to 0^+$, $g(x)/h(x)$, $g(x-h(x))/h(x-h(x))$, and\n$h(x)/x^r$ tend to 0, while $x^r g''(\\xi(x))$ remains bounded\n(because $\\xi(x) \\geq x-h(x) \\geq x - x^r \\geq x/2$ for $x$ small)\nand $h(x-h(x))/h(x)$ is bounded in $(0,1]$.\nHence $\\lim_{x \\to 0^+} g'(x) = 0$ as desired.\n\nIt thus only remains to produce a function $h$ with the desired properties; this amounts to ``inserting'' a function between $g(x)$ and $x^r$ while taking care to ensure the positive and nondecreasing properties.\nOne of many options is $h(x) = x^r \\sqrt{f(x)}$ where\n\\[\nf(x) = \\sup\\{|z^{-r} g(z)|: z \\in (0,x)\\},\n\\]\nso that\n\\[\n\\frac{h(x)}{x^r} = \\sqrt{f(x)}, \\qquad \\frac{g(x)}{h(x)} = \\sqrt{f(x)} x^{-r} g(x).\n\\]\n\n\\noindent\n\\textbf{Solution 2.}\nWe argue by contradiction. Assume that $\\limsup_{x\\to 0^+} x^r|g''(x)|<\\infty$, so that there is an $M$ such that $|g''(x)| < M x^{-r}$ for all $x$; and that $\\lim_{x\\to 0^+} g'(x) \\neq 0$, so that there is an $\\epsilon_0>0$ and a sequence $x_n\\to 0$ with $|g'(x_n)| > \\epsilon_0$ for all $n$.\n\nNow let $\\epsilon>0$ be arbitrary. Since $\\lim_{x\\to 0^+} g(x) x^{-r} = 0$, there is a $\\delta>0$ for which $|g(x)|<\\epsilon x^r$ for all $x<\\delta$.\nChoose $n$ sufficiently large that $\\frac{\\epsilon_0 x_n^r}{2M}<x_n$ and $x_n < \\delta/2$; then $x_n+\\frac{\\epsilon_0 x_n^r}{2M} < 2 x_n < \\delta$. In addition,\nwe have $|g'(x)| > \\epsilon_0/2$ for all $x\\in [x_n,x_n+\\frac{\\epsilon_0 x_n^r}{2M}]$ since $|g'(x_n)| > \\epsilon_0$ and $|g''(x)| < Mx^{-r} \\leq M x_n^{-r}$ in this range. It follows that\n\\begin{align*}\n\\frac{\\epsilon_0^2}{2} \\frac{x_n^r}{2M} &<\n|g(x_n+\\frac{\\epsilon_0 x_n^r}{2M}) - g(x_n)| \\\\\n&\\leq |g(x_n+\\frac{\\epsilon_0 x_n^r}{2M})|+|g(x_n)| \\\\\n&< \\epsilon \\left((x_n+\\frac{\\epsilon_0 x_n^r}{2M})^r+x_n^r\\right) \\\\\n&< \\epsilon(1+2^r)x_n^r,\n\\end{align*}\nwhence $4M(1+2^r)\\epsilon > \\epsilon_0^2$. Since $\\epsilon>0$ is arbitrary and $M,r,\\epsilon_0$ are fixed, this gives the desired contradiction.\n\n\n\\noindent\n\\textbf{Remark.}\nHarm Derksen points out that the ``or'' in the problem need not be exclusive. For example, take\n\\[\ng(x) = \\begin{cases} x^5\\sin(x^{-3}) & x \\in (0,1] \\\\\n0 & x = 0.\n\\end{cases}\n\\]\nThen for $x \\in (0,1)$,\n\\begin{align*}\ng'(x) &= 5x^4\\sin(x^{-3})-3x\\cos(x^{-3}) \\\\\ng''(x) &=(20x^3-9x^{-3})\\sin(x^{-3})-18\\cos(x^{-3}).\n\\end{align*}\nFor $r=2$, $\\lim_{x\\to 0^+}x^{-r}g(x)=\\lim_{x\\to 0^+}x^3\\sin(x^{-3})=0$, $\\lim_{x\\to 0^+}g'(x)=0$ and\n$x^rg''(x)=(20x^5-9x^{-1})\\sin(x^{-3})-18x^2\\cos(x^{-3})$ is unbounded as $x\\to 0^+$.\n(Note that $g'(x)$ is not differentiable at $x=0$.)"
  },
  {
    "year": 2019,
    "label": "B1",
    "difficulty": "1",
    "problem": "Denote by $\\mathbb{Z}^2$ the set of all points $(x,y)$ in the plane with integer coordinates. For each integer $n \\geq 0$, let $P_n$ be the subset of $\\mathbb{Z}^2$ consisting of the point $(0,0)$ together with all points $(x,y)$ such that $x^2 + y^2 = 2^k$ for some integer $k \\leq n$. Determine, as a function of $n$, the number of four-point subsets of $P_n$ whose elements are the vertices of a square.",
    "solution": "The answer is $5n+1$.\n\nWe first determine the set $P_n$. Let $Q_n$ be the set of points in $\\mathbb{Z}^2$ of the form $(0, \\pm 2^k)$ or $(\\pm 2^k, 0)$ for some $k \\leq n$. Let $R_n$ be the set of points in $\\mathbb{Z}^2$ of the form $(\\pm 2^k, \\pm 2^k)$ for some $k \\leq n$ (the two signs being chosen independently). \nWe prove by induction on $n$ that\n\\[\nP_n = \\{(0,0)\\} \\cup Q_{\\lfloor n/2 \\rfloor} \\cup R_{\\lfloor (n-1)/2 \\rfloor}.\n\\]\nWe take as base cases the straightforward computations\n\\begin{align*}\nP_0 &= \\{(0,0), (\\pm 1, 0), (0, \\pm 1)\\} \\\\\nP_1 &= P_0 \\cup \\{(\\pm 1, \\pm 1)\\}.\n\\end{align*}\nFor $n \\geq 2$, it is clear that $\\{(0,0)\\} \\cup Q_{\\lfloor n/2 \\rfloor} \\cup R_{\\lfloor (n-1)/2 \\rfloor} \\subseteq P_n$, so it remains to prove the reverse inclusion. For $(x,y) \\in P_n$, note that $x^2 + y^2 \\equiv 0 \\pmod{4}$;\nsince every perfect square is congruent to either 0 or 1 modulo 4, $x$ and $y$ must both be even. Consequently,\n$(x/2, y/2) \\in P_{n-2}$, so we may appeal to the induction hypothesis to conclude.\n\nWe next identify all of the squares with vertices in $P_n$. In the following discussion, let $(a,b)$\nand $(c,d)$ be two opposite vertices of a square, so that the other two vertices are\n\\[\n\\left( \\frac{a-b+c+d}{2}, \\frac{a+b-c+d}{2} \\right)\n\\]\nand \n\\[\n\\left( \\frac{a+b+c-d}{2}, \\frac{-a+b+c+d}{2} \\right).\n\\]\n\\begin{itemize}\n\\item\nSuppose that $(a,b) = (0,0)$. Then $(c,d)$ may be any element of $P_n$ not contained in $P_0$.\nThe number of such squares is $4n$.\n\n\\item\nSuppose that $(a,b), (c,d) \\in Q_k$ for some $k$. \nThere is one such square with vertices \n\\[\n\\{(0, 2^k), (0, 2^{-k}), (2^k, 0), (2^{-k}, 0)\\}\n\\]\nfor $k = 0,\\dots,\\lfloor \\frac{n}{2} \\rfloor$, for a total of $\\lfloor \\frac{n}{2} \\rfloor + 1$.\nTo show that there are no others, by symmetry it suffices to rule out the existence of a square with\nopposite vertices $(a,0)$ and $(c,0)$ where $a > \\left| c \\right|$. \nThe other two vertices of this square would be $((a+c)/2, (a-c)/2)$ and $((a+c)/2, (-a+c)/2)$.\nThese cannot belong to any $Q_k$, or be equal to $(0,0)$,\nbecause $|a+c|, |a-c| \\geq a - |c| > 0$ by the triangle inequality.\nThese also cannot belong to any $R_k$ because $(a + |c|)/2 > (a - |c|)/2$. \n(One can also phrase this argument in geometric terms.)\n\n\\item\nSuppose that $(a,b), (c,d) \\in R_k$ for some $k$.\nThere is one such square with vertices\n\\[\n\\{(2^k, 2^k), (2^k, -2^k), (-2^k, 2^k), (-2^k, -2^k)\\}\n\\]\nfor $k=0,\\dots, \\lfloor \\frac{n-1}{2} \\rfloor$, for a total of $\\lfloor \\frac{n+1}{2} \\rfloor$.\nTo show that there are no others, we may reduce to the previous case: rotating by an angle of $\\frac{\\pi}{4}$ and then rescaling by a factor of $\\sqrt{2}$ would yield a square with two opposite vertices in some $Q_k$ not centered at $(0,0)$, which we have already ruled out.\n\n\\item\nIt remains to show that we cannot have $(a,b) \\in Q_k$ and $(c,d) \\in R_k$ for some $k$.\nBy symmetry, we may reduce to the case where $(a,b) = (0, 2^k)$ and $(c,d) = (2^\\ell, \\pm 2^\\ell)$.\nIf $d>0$, then the third vertex $(2^{k-1}, 2^{k-1} + 2^\\ell)$ is impossible.\nIf $d<0$, then the third vertex $(-2^{k-1}, 2^{k-1} - 2^\\ell)$ is impossible.\n\n\\end{itemize}\n\nSumming up, we obtain\n\\[\n4n + \\left\\lfloor \\frac{n}{2} \\right\\rfloor + 1 + \\left\\lfloor \\frac{n+1}{2} \\right\\rfloor = 5n+1\n\\]\nsquares, proving the claim.\n\n\\noindent\n\\textbf{Remark.}\nGiven the computation of $P_n$, we can alternatively show that the number of squares with vertices in $P_n$ is $5n+1$ as follows. Since this is clearly true for $n=1$, it suffices to show that for $n \\geq 2$, there are exactly $5$ squares with vertices in $P_n$, at least one of which is not in $P_{n-1}$. Note that the convex hull of $P_n$ is a square $S$ whose four vertices are the four points in $P_n \\setminus P_{n-1}$. If $v$ is one of these points, then a square with a vertex at $v$ can only lie in $S$ if its two sides containing $v$ are in line with the two sides of $S$ containing $v$. It follows that there are exactly two squares with a vertex at $v$ and all vertices in $P_n$: the square corresponding to $S$ itself, and a square whose vertex diagonally opposite to $v$ is the origin. Taking the union over the four points in $P_n \\setminus P_{n-1}$ gives a total of $5$ squares, as desired."
  },
  {
    "year": 2019,
    "label": "B2",
    "difficulty": "2",
    "problem": "For all $n \\geq 1$, let\n\\[\na_n = \\sum_{k=1}^{n-1} \\frac{\\sin \\left( \\frac{(2k-1)\\pi}{2n} \\right)}{\\cos^2 \\left( \\frac{(k-1)\\pi}{2n} \\right) \\cos^2 \\left( \\frac{k\\pi}{2n} \\right)}.\n\\]\nDetermine\n\\[\n\\lim_{n \\to \\infty} \\frac{a_n}{n^3}.\n\\]",
    "solution": "The answer is $\\frac{8}{\\pi^3}$.\n\n\\noindent\n\\textbf{Solution 1.}\nBy the double angle and sum-product identities for cosine, we have\n\\begin{align*}\n2\\cos^2\\left(\\frac{(k-1)\\pi}{2n}\\right) - 2\\cos^2 \\left(\\frac{k\\pi}{2n}\\right) &= \\cos\\left(\\frac{(k-1)\\pi}{n}\\right) - \\cos\\left(\\frac{k\\pi}{n}\\right) \\\\\n&= 2\\sin\\left(\\frac{(2k-1)\\pi}{2n}\\right) \\sin\\left(\\frac{\\pi}{2n}\\right),\n\\end{align*}\nand it follows that the summand in $a_n$ can be written as\n\\[\n\\frac{1}{\\sin\\left(\\frac{\\pi}{2n}\\right)} \\left(-\\frac{1}{\\cos^2\\left(\\frac{(k-1)\\pi}{2n}\\right)}+\\frac{1}{\\cos^2\\left(\\frac{k\\pi}{2n}\\right)}\\right).\n\\]\nThus the sum telescopes and we find that\n\\[\na_n = \\frac{1}{\\sin\\left(\\frac{\\pi}{2n}\\right)} \\left(-1+\\frac{1}{\\cos^2\\left(\\frac{(n-1)\\pi}{2n}\\right)}\\right) =\n- \\frac{1}{\\sin\\left(\\frac{\\pi}{2n}\\right)}+ \\frac{1}{\\sin^3\\left(\\frac{\\pi}{2n}\\right)}.\n\\]\nFinally, since $\\lim_{x\\to 0} \\frac{\\sin x}{x} = 1$, we have $\\lim_{n\\to\\infty} \\left( n\\sin\\frac{\\pi}{2n} \\right) = \\frac{\\pi}{2}$, and thus\n$\\lim_{n\\to\\infty} \\frac{a_n}{n^3} = \\frac{8}{\\pi^3}$.\n\n\\noindent\n\\textbf{Solution 2.}\nWe first substitute $n-k$ for $k$ to obtain\n\\[\na_n=\\sum_{k=1}^{n-1} \\frac{\\sin\\left(\\frac{(2k+1)\\pi}{2n}\\right)}{\\sin^2\\left(\\frac{(k+1)\\pi}{2n}\\right)\\sin^2\\left(\\frac{k\\pi}{2n}\\right)}.\n\\]\nWe then use the estimate\n\\[\n\\frac{\\sin x}{x} = 1 + O(x^2) \\qquad (x \\in [0, \\pi])\n\\]\nto rewrite the summand as\n\\[\n\\frac{\\left( \\frac{(2k-1)\\pi}{2n} \\right)}{\\left(\\frac{(k+1)\\pi}{2n}\\right)^2 \\left(\\frac{k\\pi}{2n}\\right)^2} \\left(1 + O\\left( \\frac{k^2}{n^2} \\right) \\right)\n\\]\nwhich simplifies to\n\\[\n\\frac{8 (2k-1) n^3}{k^2 (k+1)^2 \\pi^3} + O\\left( \\frac{n}{k} \\right).\n\\]\nConsequently,\n\\begin{align*}\n\\frac{a_n}{n^3} &= \\sum_{k=1}^{n-1} \\left( \\frac{8 (2k-1)}{k^2 (k+1)^2 \\pi^3} + O\\left( \\frac{1}{kn^2} \\right) \\right) \\\\\n&= \\frac{8}{\\pi^3} \\sum_{k=1}^{n-1} \\frac{(2k-1)}{k^2 (k+1)^2} \n+ O \\left( \\frac{\\log n}{n^2} \\right). \n\\end{align*}\nFinally, note that\n\\[\n\\sum_{k=1}^{n-1} \\frac{(2k-1)}{k^2 (k+1)^2} = \n\\sum_{k=1}^{n-1} \\left( \\frac{1}{k^2} - \\frac{1}{(k+1)^2}\\right) = 1 - \\frac{1}{n^2}\n\\]\nconverges to 1, and so $\\lim_{n \\to \\infty} \\frac{a_n}{n^3} = \\frac{8}{\\pi^3}$."
  },
  {
    "year": 2019,
    "label": "B3",
    "difficulty": "3",
    "problem": "Let $Q$ be an $n$-by-$n$ real orthogonal matrix, and let $u \\in \\mathbb{R}^n$ be a unit column vector (that is,\n$u^T u = 1$). Let $P = I - 2uu^T$, where $I$ is the $n$-by-$n$ identity matrix. Show that if $1$ is not an eigenvalue of $Q$, then $1$ is an eigenvalue of $PQ$.",
    "solution": "\\noindent\n\\textbf{Solution 1.}\nWe first note that $P$ corresponds to the linear transformation on $\\mathbb{R}^n$ given by reflection in the hyperplane perpendicular to $u$: $P(u) = -u$, and for any $v$ with $\\langle u,v\\rangle = 0$, $P(v) = v$. In particular, $P$ is an orthogonal matrix of determinant $-1$.\n\nWe next claim that if $Q$ is an $n\\times n$ orthogonal matrix that does not have $1$ as an eigenvalue, then $\\det Q = (-1)^n$. To see this, recall that the roots of the characteristic polynomial $p(t) = \\det(tI-Q)$ all lie on the unit circle in $\\mathbb{C}$, and all non-real roots occur in conjugate pairs ($p(t)$ has real coefficients, and orthogonality implies that $p(t) = \\pm t^n p(t^{-1})$). The product of each conjugate pair of roots is $1$; thus $\\det Q = (-1)^k$ where $k$ is the multiplicity of $-1$ as a root of $p(t)$. Since $1$ is not a root and all other roots appear in conjugate pairs, $k$ and $n$ have the same parity, and so $\\det Q = (-1)^n$.\n\nFinally, if neither of the orthogonal matrices $Q$ nor $PQ$ has $1$ as an eigenvalue, then $\\det Q = \\det(PQ) = (-1)^n$, contradicting the fact that $\\det P = -1$. The result follows.\n\n\\noindent\n\\textbf{Remark.}\nIt can be shown that any $n \\times n$ orthogonal matrix $Q$ can be written as a product of at most $n$ hyperplane reflections (Householder matrices). If equality occurs, then $\\det(Q) = (-1)^n$;\nif equality does not occur, then $Q$ has $1$ as an eigenvalue.\nConsequently, equality fails for one of $Q$ and $PQ$, and that matrix has $1$ as an eigenvalue.\n\nSucharit Sarkar suggests the following topological interpretation: an orthogonal matrix without 1 as an eigenvalue\ninduces a fixed-point-free map from the $(n-1)$-sphere to itself, and the degree of such a map must be $(-1)^n$.\n\n\\noindent\n\\textbf{Solution 2.}\nThis solution uses the (reverse) \\emph{Cayley transform}: if $Q$ is an orthogonal matrix not having 1 as an eigenvalue, then\n\\[\nA = (I-Q)(I+Q)^{-1}\n\\]\nis a skew-symmetric matrix (that is, $A^T = -A$).\n\nSuppose then that $Q$ does not have $1$ as an eigenvalue.\nLet $V$ be the orthogonal complement of $u$ in $\\mathbb{R}^n$. On one hand, for $v \\in V$,\n\\[\n(I-Q)^{-1} (I - QP) v = (I-Q)^{-1} (I-Q)v = v.\n\\]\nOn the other hand,\n\\[\n(I-Q)^{-1} (I - QP) u = (I-Q)^{-1} (I+Q)u = Au\n\\]\nand $\\langle u, Au \\rangle = \\langle A^T u, u \\rangle\n= \\langle -Au, u \\rangle$, so $Au \\in V$.\nPut $w = (1-A)u$; then $(1-QP)w = 0$, so $QP$ has 1 as an eigenvalue, and the same for $PQ$ because $PQ$ and $QP$ have the same characteristic polynomial.\n\n\\noindent\n\\textbf{Remark.}\nThe \\emph{Cayley transform} is the following construction: if $A$ is a skew-symmetric matrix,\nthen $I+A$ is invertible and\n\\[\nQ = (I-A)(I+A)^{-1}\n\\]\nis an orthogonal matrix.\n\n\\noindent\n\\textbf{Remark.}\n(by Steven Klee)\nA related argument is to compute $\\det(PQ-I)$ using the \\emph{matrix determinant lemma}:\nif $A$ is an invertible $n \\times n$ matrix and $v, w$ are $1 \\times n$ column vectors, then\n\\[\n\\det(A + vw^T) = \\det(A) (1 + w^T A^{-1} v).\n\\]\nThis reduces to the case $A = I$, in which case it again comes down to the fact that the product of two square matrices (in this case, obtained from $v$ and $w$ by padding with zeroes) retains the same characteristic polynomial when the factors are reversed."
  },
  {
    "year": 2019,
    "label": "B4",
    "difficulty": "4",
    "problem": "Let $\\mathcal{F}$ be the set of functions $f(x,y)$ that are twice continuously differentiable for $x \\geq 1$, $y \\geq 1$ and that satisfy the following two equations (where subscripts denote partial derivatives):\n\\begin{gather*}\nxf_x + yf_y = xy \\ln(xy), \\\\\nx^2 f_{xx} + y^2 f_{yy} = xy.\n\\end{gather*}\nFor each $f \\in \\mathcal{F}$, let\n\\[\nm(f) = \\min_{s \\geq 1} \\left(f(s+1,s+1) - f(s+1,s) - f(s,s+1) + f(s,s) \\right).\n\\]\nDetermine $m(f)$, and show that it is independent of the choice of $f$.",
    "solution": "\\noindent\n\\textbf{Solution 1.}\nWe compute that $m(f) = 2 \\ln 2 - \\frac{1}{2}$.\nLabel the given differential equations by (1) and (2). If we write, e.g., $x\\frac{\\partial}{\\partial x}(1)$ for the result of differentiating (1) by $x$ and multiplying the resulting equation by $x$, then the combination\n$x\\frac{\\partial}{\\partial x}(1)+y\\frac{\\partial}{\\partial y}(1)-(1)-(2)$ gives the equation\n$2xyf_{xy} = xy\\ln(xy)+xy$, whence $f_{xy} = \\frac{1}{2} (\\ln(x)+\\ln(y)+1)$.\n\nNow we observe that\n\\begin{align*}\n\\lefteqn{f(s+1,s+1)-f(s+1,s)-f(s,s+1)+f(s,s)} \\\\\n &= \\int_s^{s+1} \\int_s^{s+1} f_{xy}\\,dy\\,dx \\\\\n&= \\frac{1}{2} \\int_s^{s+1} \\int_s^{s+1} (\\ln(x)+\\ln(y)+1)\\,dy\\,dx \\\\\n&= \\frac{1}{2} + \\int_s^{s+1} \\ln(x)\\,dx.\n\\end{align*}\n\nSince $\\ln(x)$ is increasing, $\\int_s^{s+1} \\ln(x)\\,dx$ is an increasing function of $s$, and so it is minimized over $s \\in [1,\\infty)$ when $s=1$. We conclude that\n\\[\nm(f) = \\frac{1}{2} + \\int_1^2 \\ln(x)\\,dx = 2 \\ln 2-\\frac{1}{2}\n\\]\nindependent of $f$.\n\n\\noindent\n\\textbf{Remark.}\nThe phrasing of the question suggests that solvers were not expected to prove that $\\mathcal{F}$ is nonempty,\neven though this is necessary to make the definition of $m(f)$ logically meaningful. Existence will be explicitly established in the next solution.\n\n\\noindent\n\\textbf{Solution 2.}\nWe first verify that \n\\[\nf(x,y) = \\frac{1}{2}(xy\\ln(xy)-xy)\n\\]\nis an element of $\\mathcal{F}$, by computing that\n\\begin{gather*}\nxf_x = yf_y = \\frac{1}{2} xy \\ln(xy) \\\\\nx^2 f_{xx} = y^2 f_{yy} = xy.\n\\end{gather*}\n(See the following remark for motivation for this guess.)\n\nWe next show that the only elements of $\\mathcal{F}$ are $f+a \\ln(x/y) + b$ where $a,b$ are constants.\nSuppose that $f+g$ is a second element of $\\mathcal{F}$. As in the first solution, we deduce that $g_{xy} = 0$; this implies that\n$g(x,y) = u(x) + v(y)$ for some twice continuously differentiable functions $u$ and $v$. We also have\n$xg_x + yg_y = 0$, which now asserts that $xg_x = - yg_y$ is equal to some constant $a$. This yields that\n$g = a \\ln(x/y) + b$ as desired.\n\nWe next observe that \n\\[\ng(s+1,s+1)-g(s+1,s)-g(s,s+1)+g(s,s) = 0,\n\\]\nso $m(f) = m(f+g)$. It thus remains to compute $m(f)$. To do this, we verify that\n\\[\nf(s+1,s+1)-f(s+1,s)-f(s,s+1)+f(s,s)\n\\]\nis nondecreasing in $s$ by computing its derivative to be $\\ln (s+1) - \\ln(s)$\n(either directly or using the integral representation from the first solution).\nWe thus minimize by taking $s=1$ as in the first solution.\n\n\\noindent\n\\textbf{Remark.}\nOne way to make a correct guess for $f$ is to notice that the given equations are both symmetric in $x$ and $y$\nand posit that $f$ should also be symmetric. Any symmetric function of $x$ and $y$ can be written in terms of the variables $u = x+y$ and $v = xy$, so in principle we could translate the equations into those variables and solve. However, before trying this, we observe that $xy$ appears explicitly in the equations, so it is reasonable to make a first guess of the form $f(x,y) = h(xy)$. \nFor such a choice, we have\n\\[\nx f_x + y f_y = 2xy h' = xy \\ln(xy)\n\\]\nwhich forces us to set $h(t)  = \\frac{1}{2}(t \\ln(t) - t)$."
  },
  {
    "year": 2019,
    "label": "B5",
    "difficulty": "5",
    "problem": "Let $F_m$ be the $m$th Fibonacci number, defined by $F_1 = F_2 = 1$ and $F_m = F_{m-1} + F_{m-2}$ for all $m \\geq 3$.\nLet $p(x)$ be the polynomial of degree $1008$ such that $p(2n+1) = F_{2n+1}$ for $n=0,1,2,\\dots,1008$. Find integers $j$ and $k$ such that $p(2019) = F_j - F_k$.",
    "solution": "\\noindent\n\\textbf{Solution 1.}\nWe prove that $(j,k) = (2019, 1010)$ is a valid solution.\nMore generally, let $p(x)$ be the polynomial of degree $N$ such that $p(2n+1) = F_{2n+1}$ for $0 \\leq n \\leq N$. We will show that $p(2N+3) = F_{2N+3}-F_{N+2}$. \n\nDefine a sequence of polynomials $p_0(x),\\ldots,p_N(x)$ by $p_0(x) = p(x)$ and $p_k(x) = p_{k-1}(x)-p_{k-1}(x+2)$ for $k \\geq 1$. Then by induction on $k$, it is the case that $p_k(2n+1) = F_{2n+1+k}$ for $0 \\leq n \\leq N-k$, and also that $p_k$ has degree (at most) $N-k$ for $k \\geq 1$. Thus $p_N(x) = F_{N+1}$ since $p_N(1) = F_{N+1}$ and $p_N$ is constant.\n\n\nWe now claim that for $0\\leq k\\leq N$, $p_{N-k}(2k+3) = \\sum_{j=0}^k F_{N+1+j}$. We prove this again by induction on $k$: for the induction step, we have\n\\begin{align*}\np_{N-k}(2k+3) &= p_{N-k}(2k+1)+p_{N-k+1}(2k+1) \\\\\n&= F_{N+1+k}+\\sum_{j=0}^{k-1} F_{N+1+j}.\n\\end{align*}\nThus we have $p(2N+3) = p_0(2N+3) = \\sum_{j=0}^N F_{N+1+j}$. \n\nNow one final induction shows that $\\sum_{j=1}^m F_j = F_{m+2}-1$, and so $p(2N+3) = F_{2N+3}-F_{N+2}$, as claimed. In the case $N=1008$, we thus have $p(2019) = F_{2019} - F_{1010}$.\n\n\\noindent\n\\textbf{Solution 2.}\nThis solution uses the \\emph{Lagrange interpolation formula}: given $x_0,\\dots,x_n$ and $y_0,\\dots,y_n$, the unique polynomial $P$ of degree at most $n$ satisfying $P(x_i) = y_i$ for $i=0,\\dots,n$ is\n\\[\n\\sum_{i=0}^n P(x_i) \\prod_{j \\neq i} \\frac{x-x_j}{x_i-x_j} =\n\\]\nWrite \n\\[\nF_n = \\frac{1}{\\sqrt{5}}(\\alpha^n - \\beta^{-n}), \\qquad \\alpha = \\frac{1+\\sqrt{5}}{2}, \\beta = \\frac{1-\\sqrt{5}}{2}.\n\\]\nFor $\\gamma \\in \\mathbb{R}$, let $p_\\gamma(x)$ be the unique polynomial of degree at most 1008 satisfying\n\\[\np_1(2n+1) = \\gamma^{2n+1}, p_2(2n+1) = \\gamma^{2n+1} \\, (n=0,\\dots,1008);\n\\]\nthen $p(x) = \\frac{1}{\\sqrt{5}}(p_\\alpha(x) - p_\\beta(x))$.\n\nBy Lagrange interpolation,\n\\begin{align*}\np_\\gamma(2019) &= \\sum_{n=0}^{1008} \\gamma^{2n+1} \\prod_{0 \\leq j \\leq 1008, j \\neq n} \\frac{2019-(2j+1)}{(2n+1)-(2j+1)}\\\\\n&= \\sum_{n=0}^{1008} \\gamma^{2n+1} \\prod_{0 \\leq j \\leq 1008, j \\neq n} \\frac{1009-j}{n-j}\\\\\n&= \\sum_{n=0}^{1008} \\gamma^{2n+1} (-1)^{1008-n} \\binom{1009}{n} \\\\\n&= -\\gamma ((\\gamma^2-1)^{1009} - (\\gamma^2)^{1009}).\n\\end{align*}\nFor $\\gamma \\in \\{\\alpha, \\beta\\}$ we have $\\gamma^2 = \\gamma + 1$ and so\n\\[\np_\\gamma(2019) = \\gamma^{2019} - \\gamma^{1010}.\n\\]\nWe thus deduce that $p(x) = F_{2019} - F_{1010}$ as claimed.\n\n\\noindent\n\\textbf{Remark.}\nKarl Mahlburg suggests the following variant of this. As above, use Lagrange interpolation to write\n\\[\np(2019) = \\sum_{j=0}^{1008} \\binom{1009}{j} F_j;\n\\]\nit will thus suffice to verify (by substiting $j \\mapsto 1009-j$) that\n\\[\n\\sum_{j=0}^{1009} \\binom{1009}{j} F_{j+1} = F_{2019}.\n\\]\nThis identity has the following combinatorial interpretation. Recall that $F_{n+1}$ counts the number of ways to tile a $1 \\times n$ rectangle with $1 \\times 1$ squares and $1 \\times 2$ dominoes (see below). In any such tiling with $n = 2018$, let $j$ be the number of squares among the first 1009 tiles.\nThese can be ordered in $\\binom{1009}{j}$ ways, and the remaining $2018 - j - 2(1009-j) = j$ squares can be\ntiled in $F_{j+1}$ ways.\n\nAs an aside, this interpretation of $F_{n+1}$ is the oldest known interpretation of the Fibonacci sequence,\nlong predating Fibonacci himself. In ancient Sanskrit, syllables were classified as long or short, and a long syllable was considered to be twice as long as a short syllable; consequently, the number of syllable patterns of total length $n$ equals $F_{n+1}$.\n\n\\noindent\n\\textbf{Remark.}\nIt is not difficult to show that the solution $(j,k) = (2019, 2010)$ is unique (in positive integers). \nFirst, note that to have $F_j - F_k > 0$, we must have $k < j$.\nIf $j < 2019$, then\n\\[\nF_{2019} - F_{1010} = F_{2018} + F_{2017} - F_{1010} > F_{j} > F_j - F_k.\n\\]\nIf $j > 2020$, then  \n\\[\nF_j - F_k \\geq F_j - F_{j-1} = F_{j-2} \\geq F_{2019} > F_{2019} - F_{1010}.\n\\]\nSince $j = 2019$ obviously forces $k = 1010$, the only other possible solution would be with $j = 2020$.\nBut then\n\\[\n(F_j - F_k) - (F_{2019} - F_{1010})\n= (F_{2018} - F_k) + F_{1010} \n\\]\nwhich is negative for $k=2019$ (it equals $F_{1010} - F_{2017}$)\nand positive for $k \\leq 2018$."
  },
  {
    "year": 2019,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $\\mathbb{Z}^n$ be the integer lattice in $\\mathbb{R}^n$. Two points in $\\mathbb{Z}^n$ are called \n\\emph{neighbors} if they differ by exactly $1$ in one coordinate and are equal in all other coordinates. \nFor which integers $n \\geq 1$ does there exist a set of points $S \\subset \\mathbb{Z}^n$ satisfying the following two conditions?\n\\begin{enumerate}",
    "solution": "Such a set exists for every $n$. To construct an example, define the function $f: \\mathbb{Z}^n \\to \\mathbb{Z}/(2n+1) \\mathbb{Z}$ by\n\\[\nf(x_1,\\dots,x_n) = x_1 + 2x_2 + \\cdots + nx_n \\pmod{2n+1},\n\\]\nthen let $S$ be the preimage of 0.\n\nTo check condition (1), note that if $p \\in S$ and $q$ is a neighbor of $p$ differing only in coordinate $i$, then\n\\[\nf(q) = f(p) \\pm i \\equiv \\pm i \\pmod{2n+1}\n\\]\nand so $q \\notin S$.\n\nTo check condition (2), note that if $p \\in \\mathbb{Z}^n$ is not in $S$, then there exists a unique choice of $i \\in \\{1,\\dots,n\\}$ such that $f(p)$ is congruent to one of $+i$ or $-i$ modulo $2n+1$. The unique neighbor $q$ of $p$ in $S$ is then obtained by either subtracting $1$ from, or adding $1$ to, the $i$-th coordinate of $p$.\n\n\\noindent\n\\textbf{Remark.}\nAccording to Art of Problem Solving (thread c6h366290), this problem was a 1985 IMO submission from Czechoslovakia. For an application to steganography, see:\nJ. Fridrich and P. Lison\\v{e}k, Grid colorings in steganography,\n\\textit{IEEE Transactions on Information Theory} \\textbf{53} (2007), 1547--1549.\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2020,
    "label": "A1",
    "difficulty": "1",
    "problem": "How many positive integers $N$ satisfy all of the following three conditions?\n\\begin{enumerate}",
    "solution": "The values of $N$ that satisfy (ii) and (iii) are precisely the numbers of the form $N = (10^a-10^b)/9$ for $0\\leq b<a\\leq 2020$; this expression represents the integer with $a$ digits beginning with a string of $1$'s and ending with $b$ $0$'s. A value $N$ of this form is divisible by $2020 = 2^2 \\cdot 5 \\cdot 101$ if and only if $10^b(10^{a-b}-1)$ is divisible by each of $3^2$, $2^2\\cdot 5$, and $101$. Divisibility by $3^2$ is a trivial condition since $10 \\equiv 1 \\pmod{9}$. Since $10^{a-b}-1$ is odd, divisibility by $2^2\\cdot 5$ occurs if and only if $b \\geq 2$. Finally, since $10^2 \\equiv -1 \\pmod{101}$, we see that $10^{a-b}$ is congruent to $10$, $-1$, $-10$, or $1 \\pmod{101}$ depending on whether $a-b$ is congruent to $1$, $2$, $3$, or $0 \\pmod{4}$; thus $10^{a-b}-1$ is divisible by $101$ if and only if $a-b$ is divisible by $4$.\n\nIt follows that we need to count the number of $(a,b)$ with $2\\leq b<a\\leq 2020$ with $4\\,|\\,a-b$. For given $b$, there are $\\lfloor \\frac{2020-b}{4} \\rfloor$ possible values of $a$. Thus the answer is\n\\begin{align*}\n& 504+504+504+503+503+503+503+\\cdots+1+1+1+1  \\\\\n&\\quad = 4(504+503+\\cdots+1)-504 = 504\\cdot 1009 = 508536.\n\\end{align*}"
  },
  {
    "year": 2020,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $k$ be a nonnegative integer. Evaluate\n\\[\n\\sum_{j=0}^k 2^{k-j} \\binom{k+j}{j}.\n\\]",
    "solution": "The answer is $4^k$. \n\n\\noindent\n\\textbf{First solution.}\nLet $S_k$ denote the given sum. Then, with the convention that ${n\\choose{-1}} = 0$ for any $n\\geq 0$, we have for $k\\geq 1$,\n\\begin{align*}\nS_k &= \\sum_{j=0}^k 2^{k-j} \\left[ {{k-1+j}\\choose {j}} + {{k-1+j}\\choose {j-1}} \\right] \\\\\n&= 2\\sum_{j=0}^{k-1} 2^{k-1-j} {{k-1+j}\\choose j}+{{2k-1}\\choose k} + \\sum_{j=1}^k 2^{k-j}{{k-1+j}\\choose{j-1}} \\\\\n&= 2S_{k-1} + {{2k-1}\\choose{k}} + \\sum_{j=0}^{k-1} 2^{k-j-1}{{k+j}\\choose j} \\\\\n&= 2S_{k-1}+S_k/2\n\\end{align*}\nand so $S_k = 4S_{k-1}$. Since $S_0 = 1$, it follows that $S_k = 4^k$ for all $k$.\n\n\\noindent\n\\textbf{Second solution.}\nConsider a sequence of fair coin flips $a_1, a_2, \\dots$ and define the random variable $X$ to be the index of the $(k+1)$-st occurrence of heads.\nThen\n\\[\nP[X = n] = \\binom{n-1}{k} 2^{-n};\n\\]\nwriting $n = k+j+1$, we may thus rewrite the given sum as\n\\[\n2^{2k+1} P[X \\leq 2k+1].\n\\]\nIt now suffices to observe that $P[X \\leq 2k+1] = \\frac{1}{2}$:\nwe have $X \\leq 2k+1$ if and only if there are at least $k+1$ heads among the first $2k+1$ flips,\nand there are exactly as many outcomes with at most $k$ heads.\n\n\\noindent\n\\textbf{Third solution.}\n(by Pankaj Sinha)\nThe sum in question in the coefficient of $x^k$ in the formal power series\n\\begin{align*}\n\\sum_{j=0}^k 2^{k-j} (1+x)^{k+j} &= 2^k (1+x)^k \\sum_{j=0}^k 2^{-j} (1+x)^j \\\\\n&= 2^k (1+x)^k \\frac{1 - (1+x)^{k+1}/2^{k+1}}{1 - (1+x)/2} \\\\\n&= \\frac{2^{k+1}(1+x)^k - (1+x)^{2k+1}}{1-x} \\\\\n&= (2^{k+1}(1+x)^k - (1+x)^{2k+1})(1+x+\\cdots).\n\\end{align*}\nThis evidently equals\n\\begin{align*}\n2^{k+1} \\sum_{j=0}^k \\binom{k}{j} - \\sum_{j=0}^k \\binom{2k+1}{j} &= 2^{k+1} (2^k) - \\frac{1}{2} 2^{2k+1}  \\\\\n&= 2^{2k+1} - 2^{2k} = 2^{2k} = 4^k.\n\\end{align*}\n\n\\noindent\n\\textbf{Remark.}\nThis sum belongs to a general class that can be evaluated mechanically using the \\emph{WZ method}. See for example the book \\textit{$A=B$}\nby Petvoksek--Wilf--Zeilberger."
  },
  {
    "year": 2020,
    "label": "A3",
    "difficulty": "3",
    "problem": "Let $a_0 = \\pi/2$, and let $a_n = \\sin(a_{n-1})$ for $n \\geq 1$. Determine whether\n\\[\n\\sum_{n=1}^\\infty a_n^2\n\\]\nconverges.",
    "solution": "The series diverges. First note that since $\\sin (x)<x$ for all $x>0$, the sequence $\\{a_n\\}$ is positive and decreasing, with $a_1=1$. Next, we observe that for $x \\in [0,1]$, $\\sin(x) \\geq x-x^3/6$: this follows from Taylor's theorem with remainder, since $\\sin(x) = x- x^3/6+(\\sin c)x^4/24$ for some $c$ between $0$ and $x$.\n\nWe now claim that $a_n \\geq 1/\\sqrt{n}$ for all $n \\geq 1$; it follows that $\\sum a_n^2$ diverges since $\\sum 1/n$ diverges. To prove the claim, we induct on $n$, with $n=1$ being trivial. Suppose that $a_n \\geq 1/\\sqrt{n}$. To prove $\\sin(a_n) \\geq 1/\\sqrt{n+1}$, note that since $\\sin(a_n) \\geq \\sin(1/\\sqrt{n})$, it suffices to prove that $x-x^3/6 \\geq (n+1)^{-1/2}$ where $x=1/\\sqrt{n}$. Squaring both sides and clearing denominators, we find that this is equivalent to $(n+1)(6n-1)^2 \\geq 36n^3$, or $24n^2-11n+1 \\geq 0$. But this last inequality is true since $24n^2-11n+1 = (3n-1)(8n-1)$, and the induction is complete."
  },
  {
    "year": 2020,
    "label": "A4",
    "difficulty": "4",
    "problem": "Consider a horizontal strip of $N+2$ squares in which the first and the last square are black and the remaining $N$ squares are all white. Choose a white square uniformly at random, choose one of its two neighbors with equal probability,\nand color this neighboring square black if it is not already black. Repeat this process until all the remaining white squares have only black neighbors. Let $w(N)$ be the expected number of white squares remaining. Find\n\\[\n\\lim_{N \\to \\infty} \\frac{w(N)}{N}.\n\\]",
    "solution": "The answer is $1/e$. We first establish a recurrence for $w(N)$. Number the squares $1$ to $N+2$ from left to right. There are $2(N-1)$ equally likely events leading to the first new square being colored black: either we choose one of squares $3,\\ldots,N+1$ and color the square to its left, or we choose one of squares $2,\\ldots,N$ and color the square to its right. Thus the probability of square $i$ being the first new square colored black is $\\frac{1}{2(N-1)}$ if $i=2$ or $i=N+1$ and $\\frac{1}{N-1}$ if $3\\leq i\\leq N$. Once we have changed the first square $i$ from white to black, then the strip divides into two separate systems, squares $1$ through $i$ and squares $i$ through $N+2$, each with first and last square black and the rest white, and we can view the remaining process as continuing independently for each system. Thus if square $i$ is the first square to change color, the expected number of white squares at the end of the process is $w(i-2)+w(N+1-i)$. It follows that\n\\begin{align*}\nw(N) &= \\frac{1}{2(N-1)}(w(0)+w(N-1))+\\\\\n&\\quad \\frac{1}{N-1}\\left(\\sum_{i=3}^N (w(i-2)+w(N+1-i))\\right) \\\\\n&\\quad + \\frac{1}{2(N-1)}(w(N-1)+w(0))\n\\end{align*}\nand so \n\\[\n(N-1)w(N) = 2(w(1)+\\cdots+w(N-2))+w(N-1). \n\\]\nIf we replace $N$ by $N-1$ in this equation and subtract from the original equation, then we obtain the recurrence\n\\[\nw(N) = w(N-1)+\\frac{w(N-2)}{N-1}.\n\\]\n\nWe now claim that $w(N) = (N+1) \\sum_{k=0}^{N+1} \\frac{(-1)^k}{k!}$ for $N\\geq 0$. To prove this, we induct on $N$. The formula holds for $N=0$ and $N=1$ by inspection: $w(0)=0$ and $w(1)=1$. Now suppose that $N\\geq 2$ and $w(N-1) = N\\sum_{k=0}^N \\frac{(-1)^k}{k!}$, $w(N-2)=(N-1)\\sum_{k=0}^{N-1} \\frac{(-1)^k}{k!}$. Then\n\\begin{align*}\nw(N) &= w(N-1)+\\frac{w(N-2)}{N-1} \\\\\n&= N \\sum_{k=0}^N \\frac{(-1)^k}{k!} + \\sum_{k=0}^{N-1} \\frac{(-1)^k}{k!} \\\\\n& = (N+1) \\sum_{k=0}^{N-1} \\frac{(-1)^k}{k!}+\\frac{N(-1)^N}{N!}\\\\\n&= (N+1) \\sum_{k=0}^{N+1} \\frac{(-1)^k}{k!}\n\\end{align*}\nand the induction is complete.\n\nFinally, we compute that \n\\begin{align*}\n\\lim_{N\\to\\infty} \\frac{w(N)}{N} &= \\lim_{N\\to\\infty} \\frac{w(N)}{N+1} \\\\\n&= \\sum_{k=0}^\\infty \\frac{(-1)^k}{k!} = \\frac{1}{e}.\n\\end{align*}\n\n\\noindent\n\\textbf{Remark.}\nAoPS user pieater314159 suggests the following alternate description of $w(N)$. Consider the numbers $\\{1,\\dots,N+1\\}$ all originally colored white.\nChoose a permutation $\\pi \\in S_{N+1}$ uniformly at random. For $i=1,\\dots,N+1$ in succession, color $\\pi(i)$ black in case $\\pi(i+1)$ is currently white (regarding $i+1$ modulo $N+1$). After this, the expected number of white squares remaining is $w(N)$.\n\n\\noindent\n\\textbf{Remark.}\nAndrew Bernoff reports that this problem was inspired by a similar question of Jordan Ellenberg (disseminated via Twitter), which in turn was inspired by the final question of the 2017 MATHCOUNTS competition. See\n\\url{http://bit-player.org/2017/counting-your-chickens-before-theyre-pecked} for more discussion."
  },
  {
    "year": 2020,
    "label": "A5",
    "difficulty": "5",
    "problem": "Let $a_n$ be the number of sets $S$ of positive integers for which\n\\[\n\\sum_{k \\in S} F_k = n,\n\\]\nwhere the Fibonacci sequence $(F_k)_{k \\geq 1}$ satisfies $F_{k+2} = F_{k+1} + F_k$ and begins $F_1 = 1, F_2 = 1, F_3 = 2, F_4 = 3$. Find the largest integer $n$ such that $a_n = 2020$.",
    "solution": "The answer is $n=F_{4040}-1$. In both solutions, we use freely the identity\n\\begin{equation} \\label{eq:2020A5eq1}\nF_1+F_2+\\cdots+F_{m-2} = F_m-1\n\\end{equation}\nwhich follows by a straightforward induction on $m$.\nWe also use the directly computed values\n\\begin{equation} \\label{eq:2020A5eq2}\na_1 = a_2 = 2, a_3 = a_4 = 3.\n\\end{equation}\n\n\\noindent\n\\textbf{First solution.} (by George Gilbert)\n\nWe extend the definition of $a_n$ by setting $a_0 = 1$.\n\n\\setcounter{lemma}{0}\n\\begin{lemma}\nFor $m>0$ and $F_m \\leq n < F_{m+1}$, \n\\begin{equation} \\label{eq:2020A5eq3}\na_n = a_{n-F_m} + a_{F_{m+1}-n-1}.\n\\end{equation}\n\\end{lemma}\n\\begin{proof}\nConsider a set $S$ for which $\\sum_{k \\in S} F_k = n$.\nIf $m \\in S$ then $S \\setminus \\{m\\}$ gives a representation of $n-F_m$, and this construction is reversible because $n-F_m < F_{m-1} \\leq F_m$.\nIf $m \\notin S$, then $\\{1,\\dots,m-1\\} \\setminus S$ gives a representation of $F_{m+1} - n - 1$, and this construction is also reversible.\nThis implies the desired equality.\n\\end{proof}\n\n\\begin{lemma}\nFor $m \\geq 2$,\n\\[\na_{F_m} = a_{F_{m+1}-1} = \\left\\lfloor \\frac{m+2}{2} \\right\\rfloor.\n\\]\n\\end{lemma}\n\\begin{proof}\nBy \\eqref{eq:2020A5eq2}, this holds for $m=2,3,4$. We now proceed by induction; for $m \\geq 5$, given all preceding cases,\nwe have by Lemma 1 that\n\\begin{align*}\na_{F_m} &= a_0 + a_{F_{m-1}-1} = 1 + \\left\\lfloor \\frac{m}{2} \\right\\rfloor =  \\left\\lfloor \\frac{m+2}{2} \\right\\rfloor \\\\\na_{F_{m+1}-1} &= a_{F_{m-1}-1} + a_0 = a_{F_m}. \\qedhere\n\\end{align*}\n\\end{proof}\n\nUsing Lemma 2, we see that $a_n = 2020$ for $n = F_{4040}-1$.\n\n\\begin{lemma}\nFor $F_m \\leq n < F_{m+1}$, $a_n \\geq a_{F_m}$.\n\\end{lemma}\n\\begin{proof}\nWe again induct on $m$.\nBy Lemma 2, we may assume that \n\\begin{equation} \\label{eq:2020A5eq4}\n1 \\leq n -F_m \\leq (F_{m+1}-2) - F_m = F_{m-1} - 2.\n\\end{equation}\nBy \\eqref{eq:2020A5eq2}, we may also assume $n \\geq 6$, so that $m \\geq 5$. We apply Lemma 1, keeping in mind that\n\\[\n(n-F_m) + (F_{m+1}-n-1) = F_{m-1}-1.\n\\]\nIf $\\max\\{n-F_m, F_{m+1}-n-1\\} \\geq F_{m-2}$, then one of the summands in \\eqref{eq:2020A5eq3} \nis at least $a_{F_{m-2}}$ (by the induction hypothesis) and the other is at least 2 (by \\eqref{eq:2020A5eq4} and the induction hypothesis),\nso \n\\[\na_n \\geq a_{F_{m-2}}+2 = \\left\\lfloor \\frac{m+4}{2} \\right\\rfloor. \n\\]\nOtherwise,\n$\\min\\{n-F_m, F_{m+1}-n-1\\} \\geq F_{m-3}$ and so by the induction hypothesis again,\n\\[\na_n \\geq 2a_{F_{m-3}} = 2 \\left\\lfloor \\frac{m-1}{2} \\right\\rfloor \\geq 2 \\frac{m-2}{2} \\geq \\left\\lfloor \\frac{m+2}{2} \\right\\rfloor. \\qedhere\n\\]\n\\end{proof}\n\nCombining Lemma 2 and Lemma 3, we deduce that for $n > F_{4040}-1$, we have $a_n \\geq a_{F_{4040}} = 2021$. This completes the proof.\n\n\\noindent\n\\textbf{Second solution.}\nWe again start with a computation of some special values of $a_n$.\n\n\\setcounter{lemma}{0}\n\\begin{lemma}\nFor all $m \\geq 1$,\n\\[\na_{F_m-1} = \\left\\lfloor \\frac{m+1}2 \\right\\rfloor\n\\]\n\\end{lemma}\n\\begin{proof}\nWe proceed by induction on $m$. The result holds for $m=1$ and $m=2$ by \\eqref{eq:2020A5eq2}. For $m>2$, among the sets $S$ counted by $a_{F_m-1}$,\nby \\eqref{eq:2020A5eq1} the only one not containing $m-1$ is $S=\\{1,2,\\ldots,m-2\\}$,\nand there are $a_{F_m-F_{m-1}-1}$ others. Therefore, \n\\begin{align*}\na_{F_m-1} &= a_{F_m-F_{m-1}-1} + 1\\\\\n& = a_{F_{m-2}-1}+1 = \\left\\lfloor \\frac{m-1}2 \\right\\rfloor+1 = \\left\\lfloor \\frac{m+1}2 \\right\\rfloor. \\qedhere\n\\end{align*}\n\\end{proof}\n\nGiven an arbitrary positive integer $n$,\ndefine the set $S_0$ as follows:\nstart with the largest $k_1$ for which $F_{k_1} \\leq n$, then add the largest $k_2$ for which $F_{k_1} + F_{k_2} \\leq n$, and so on,\nstopping once $\\sum_{k \\in S_0} F_k = n$.\nThen form the bitstring \n\\[\ns_n = \\cdots e_1 e_0, \\qquad e_k = \\begin{cases} 1 & k \\in S_0 \\\\\n0 & k \\notin S_0;\n\\end{cases}\n\\]\nnote that no two 1s in this string are consecutive. We can thus divide $s_n$ into segments\n\\[\nt_{k_1,\\ell_1} \\cdots t_{k_r, \\ell_r} \\qquad (k_i, \\ell_i \\geq 1)\n\\]\nwhere the bitstring $t_{k,\\ell}$ is given by\n\\[\nt_{k,\\ell} = (10)^k (0)^\\ell\n\\]\n(that is, $k$ repetitions of $10$ followed by $\\ell$ repetitions of 0).\nNote that $\\ell_r \\geq 1$ because $e_1 = e_0 = 0$.\n\nFor $a = 1,\\dots,k$ and $b = 0,\\dots,\\lfloor (\\ell-1)/2 \\rfloor$, we can replace $t_{k,\\ell}$ with the string\nof the same length\n\\[\n(10)^{k-a} (0) (1)^{2a-1} (01)^b 1 0^{\\ell -2b}\n\\]\nto obtain a new bitstring corresponding to a set $S$ with $\\sum_{k \\in S} F_k = n$. Consequently,\n\\begin{equation} \\label{eq:2020A5eq3}\na_n \\geq \\prod_{i=1}^r \\left( 1 + k_i \\left\\lfloor \\frac{\\ell_i+1}{2} \\right\\rfloor \\right).\n\\end{equation}\n\nFor integers $k,\\ell \\geq 1$, we have\n\\[\n1 + k \\left \\lfloor \\frac{\\ell+1}{2} \\right\\rfloor\n\\geq k + \\left \\lfloor \\frac{\\ell+1}{2} \\right\\rfloor \\geq 2.\n\\]\nCombining this with repeated use of the inequality\n\\[\nxy \\geq x+y \\qquad (x,y \\geq 2),\n\\]\nwe deduce that\n\\[\na_n \\geq \\sum_{i=1}^r \\left( k_i + \\left\\lfloor \\frac{\\ell_i+1}{2} \\right\\rfloor \\right)\n\\geq \\left\\lfloor \\frac{1 + \\sum_{i=1}^r (2k_i + \\ell_i)}{2} \\right\\rfloor.\n\\]\nIn particular, for any even $m \\geq 2$, we have $a_n > \\frac{m}2$ for all $n \\geq F_m$.\nTaking $m = 4040$ yields the desired result.\n\n\\noindent\n\\textbf{Remark.}\nIt can be shown with a bit more work that the set $S_0$ gives the unique representation of $n$ as a sum of distinct Virahanka--Fibonacci numbers, no two consecutive; this is commonly called the\n\\emph{Zeckendorf representation} of $n$, but was first described by Lekkerkerker.\nUsing this property, one can show that the lower bound in \\eqref{eq:2020A5eq3} is sharp."
  },
  {
    "year": 2020,
    "label": "A6",
    "difficulty": "6",
    "problem": "For a positive integer $N$, let $f_N$\\footnote{Corrected from $F_N$ in the source.} be the function defined by \n\\[\nf_N(x) = \\sum_{n=0}^N \\frac{N+1/2-n}{(N+1)(2n+1)} \\sin((2n+1)x).\n\\]\nDetermine the smallest constant $M$ such that $f_N(x) \\leq M$ for all $N$ and all real $x$.",
    "solution": "The smallest constant $M$ is $\\pi/4$.\n\nWe start from the expression\n\\begin{equation} \\label{2020A6eq1}\nf_N(x) = \\sum_{n=0}^N \\frac{1}{2} \\left( \\frac{2}{2n+1} - \\frac{1}{N+1} \\right) \\sin((2n+1)x).\n\\end{equation}\nNote that if $\\sin(x) > 0$, then\n\\begin{align*}\n\\sum_{n=0}^N \\sin((2n+1)x) &= \\frac{1}{2i} \\sum_{n=0}^N (e^{i(2n+1)x} - e^{-i(2n+1)x}) \\\\\n&= \\frac{1}{2i} \\left( \\frac{e^{i(2N+3)x} - e^{ix}}{e^{2ix} - 1}  -\n\\frac{e^{-i(2N+3)x} - e^{-ix}}{e^{-2ix} - 1} \\right) \\\\\n&=\\frac{1}{2i} \\left( \\frac{e^{i(2N+2)x} - 1}{e^{ix} - e^{-ix}}  -\n\\frac{e^{-i(2N+2)x} - 1}{e^{-ix} - e^{ix}} \\right) \\\\\n&=\\frac{1}{2i} \\frac{e^{i(2N+2)x}+ e^{-i(2N+2)x} - 2}{e^{ix} - e^{-ix}} \\\\\n&= \\frac{2 \\cos ((2N+2)x) - 2}{2i(2i \\sin(x))} \\\\\n&= \\frac{1 - \\cos ((2N+2)x)}{2\\sin(x)} \\geq 0.\n\\end{align*}\nWe use this to compare the expressions of $f_N(x)$ and $f_{N+1}(x)$ given by \\eqref{2020A6eq1}.\nFor $x \\in (0, \\pi)$ with $\\sin((2N+3)x) \\geq 0$, we may omit the summand $n=N+1$ from $f_{N+1}(x)$ to obtain\n\\begin{align*}\n& f_{N+1}(x) - f_N(x) \\\\\n&\\geq \\frac{1}{2}  \\left( \\frac{1}{N+1} - \\frac{1}{N+2} \\right) \\sum_{n=0}^N \\sin((2n+1)x) \\geq 0.\n\\end{align*}\nFor $x \\in (0, \\pi)$ with $\\sin((2N+3)x) \\leq 0$, we may insert the summand $n=N+1$ into $f_{N+1}(x)$ to obtain\n\\begin{align*}\n&f_{N+1}(x) - f_N(x) \\\\\n&\\geq \\frac{1}{2}  \\left( \\frac{1}{N+1} - \\frac{1}{N+2} \\right) \\sum_{n=0}^{N+1} \\sin((2n+1)x) \\geq 0.\n\\end{align*}\nIn either case, we deduce that for $x \\in (0, \\pi)$, the sequence $\\{f_N(x)\\}_N$ is nondecreasing.\n\nNow rewrite \\eqref{2020A6eq1} as \n\\begin{equation} \\label{2020A6eq2}\nf_N(x) = \\sum_{n=0}^N \\frac{ \\sin((2n+1)x) }{2n+1}- \\frac{1-\\cos((2N+2)x)}{4(N+1) \\sin(x)}\n\\end{equation}\nand note that the last term tends to 0 as $N \\to \\infty$.\nConsequently, $\\lim_{N \\to \\infty} f_N(x)$ equals the sum of the series\n\\[\n\\sum_{n=0}^\\infty \\frac{1}{2n+1} \\sin((2n+1)x),\n\\]\nwhich is the Fourier series for the ``square wave'' function defined on $(-\\pi, \\pi]$ by\n\\[\nx \\mapsto \\begin{cases} -\\frac{\\pi}{4} & x \\in (-\\pi, 0) \\\\\n\\frac{\\pi}{4} & x \\in (0, \\pi) \\\\\n0 & x = 0, \\pi\n\\end{cases}\n\\]\nand extended periodically. Since this function is continuous on $(0, \\pi)$, we deduce that the Fourier series converges to the value of the function; that is,\n\\[\n\\lim_{N \\to \\infty} f_N(x) = \\frac{\\pi}{4} \\qquad (x \\in (0, \\pi)).\n\\]\nThis is enough to deduce the desired result as follows. \nSince\n\\[\nf_N(x+2\\pi) = f_N(x), \\qquad f_N(-x) = -f_N(x),\n\\]\nit suffices to check the bound $f_N(x) \\leq \\pi$ for $x \\in (-\\pi, \\pi]$.\nFor $x = 0, \\pi$ we have $f_N(x) = 0$ for all $N$.\nFor $x \\in (-\\pi, 0)$, the previous arguments imply that\n\\[\n0 \\geq f_0(x) \\geq f_1(x) \\geq \\cdots\n\\]\nFor $x \\in (0, \\pi)$, the previous arguments imply that\n\\[\n0 \\leq f_0(x) \\leq f_1(x) \\leq \\cdots \\leq \\frac{\\pi}{4}\n\\]\nand the limit is equal to $\\pi/4$. We conclude that $f_N(x) \\leq M$ holds for $M = \\pi/4$ but not for any smaller $M$, as desired.\n\n\\noindent\n\\textbf{Remark.}\nIt is also possible to replace the use of the convergence of the Fourier series with a more direct argument; it is sufficient to do this for $x$ in a dense subset of $(0, \\pi)$, such as the rational multiples of $\\pi$.\n\nAnother alternative (described at \\url{https://how-did-i-get-here.com/2020-putnam-a6/})\nis to deduce from \\eqref{2020A6eq2} and a second geometric series computation (omitted here) that\n\\begin{align*}\nf'_N(x) &= \\sum_{n=0}^N \\cos((2n+1)x) - \\frac{d}{dx} \\left( \\frac{1-\\cos((2N+2)x)}{4(N+1) \\sin(x)} \\right) \\\\\n&=\\frac{\\sin((2N+2)x)}{2\\sin(x)} \\\\\n&\\qquad - \\frac{(2N+2)\\sin((2N+2)x) - \\cos(x) (1-\\cos((N+2)x)}{4(N+1)\\sin(x)^2} \\\\\n&= \\frac{\\cos(x) (1-\\cos((N+2)x)}{4(N+1)\\sin(x)^2},\n\\end{align*}\nwhich is nonnegative for $x \\in (0, \\pi/2]$ and nonpositive for $x \\in [\\pi/2, \\pi)$.\nThis implies that $f_N(x)$ always has a global maximum at $x = \\pi/2$, so it suffices to check the\nconvergence of the Fourier series for the square wave at that point. This reduces to the Madhava--Gregory--Newton series evaluation\n\\[\n1 - \\frac{1}{3} + \\frac{1}{5} - \\frac{1}{7} + \\cdots = \\arctan(1) = \\frac{\\pi}{4}.\n\\]"
  },
  {
    "year": 2020,
    "label": "B1",
    "difficulty": "1",
    "problem": "For a positive integer $n$, define $d(n)$ to be the sum of the digits of $n$ when written in binary (for example, $d(13) = 1+1+0+1=3)$. Let\n\\[\nS = \\sum_{k=1}^{2020} (-1)^{d(k)} k^3.\n\\]\nDetermine $S$ modulo 2020.",
    "solution": "Note that\n$$\n(1-x)(1-x^2)(1-x^4)\\cdots(1-x^{1024})=\\sum_{k=0}^{2047}(-1)^{d(k)}x^k\n$$\nand\n$$\nx^{2016}(1-x)(1-x^2)\\cdots(1-x^{16})=\\sum_{k=2016}^{2047}(-1)^{d(k)}x^k.\n$$\nApplying $x\\frac{d}{dx}$ to both sides of each of these two equations three times, and then setting $x=1$, shows that\n$$\n\\sum_{k=0}^{2047}(-1)^{d(k)}k^3 = \\sum_{k=2016}^{2047}(-1)^{d(k)}k^3 = 0,\n$$\nand therefore\n$$\n\\sum_{k=1}^{2015}(-1)^{d(k)}k^3 = 0.\n$$\nHence we may write\n\\begin{align*}\nS &=\\sum_{k=2016}^{2020}(-1)^{d(k)}k^3 \\\\\n &= \\sum_{k=0}^4 (-1)^{d(k)} (k+2016)^3 \\\\\n&\\equiv (-4)^3 + (-1)(-3)^3+(-1)(-2)^3+(1)(-1)^3 \\\\\n&= -64+27+8-1 \\\\\n&\\equiv -30\\equiv 1990\\pmod{2020}.\n\\end{align*}\n\n\\noindent\n\\textbf{Remark.} The function $d(n)$ appears in the OEIS as sequence A000120."
  },
  {
    "year": 2020,
    "label": "B2",
    "difficulty": "2",
    "problem": "Let $k$ and $n$ be integers with $1 \\leq k < n$. Alice and Bob play a game with $k$ pegs in a line of $n$ holes. At the beginning of the game, the pegs occupy the $k$ leftmost holes. A legal move consists of moving a single peg\nto any vacant hole that is further to the right. The players alternate moves, with Alice playing first. The game ends when the pegs are in the $k$ rightmost holes, so whoever is next to play cannot move and therefore loses. For what values\nof $n$ and $k$ does Alice have a winning strategy?",
    "solution": "We refer to this two-player game, with $n$ holes and $k$ pegs, as the \\emph{$(n,k)$-game}.\nWe will show that Alice has a winning strategy for the $(n,k)$-game if and only if at least one of $n$ and $k$ is odd; otherwise Bob has a winning strategy.\n\nWe reduce the first claim to the second as follows. If $n$ and $k$ are both odd, then Alice can move the $k$-th peg to the last hole; this renders the last hole, and the peg in it, totally out of play, thus reducing the $(n,k)$-game to the $(n-1,k-1)$-game, for which Alice now has a winning strategy by the second claim. Similarly, if $n$ is odd but $k$ is even, then Alice may move the first peg to the $(k+1)$-st hole, removing the first hole from play and reducing the $(n,k)$-game to the $(n-1,k)$ game. Finally, if $n$ is even but $k$ is odd, then Alice can move the first peg to the last hole, taking the first and last holes, and the peg in the last hole, out of play, and reducing the $(n,k)$-game to the $(n-2,k-1)$-game.\n\nWe now assume $n$ and $k$ are both even and describe a winning strategy for the $(n,k)$-game for Bob.\nSubdivide the $n$ holes into $n/2$ disjoint pairs of adjacent holes. Call a configuration of $k$ pegs \\textit{good} if for each pair of holes, both or neither is occupied by pegs, and note that the starting position is good. Bob can ensure that after each of his moves, he leaves Alice with a good configuration: presented with a good configuration, Alice must move a peg from a pair of occupied holes to a hole in an unoccupied pair; then Bob can move the other peg from the first pair to the remaining hole in the second pair, resulting in another good configuration. In particular, this ensures that Bob always has a move to make. Since the game must terminate, this is a winning strategy for Bob."
  },
  {
    "year": 2020,
    "label": "B3",
    "difficulty": "3",
    "problem": "Let $x_0 = 1$, and let $\\delta$ be some constant satisfying $0 < \\delta < 1$. Iteratively, for $n=0,1,2,\\dots$, a point $x_{n+1}$ is chosen uniformly from the interval $[0, x_n]$. Let $Z$ be the smallest value of $n$ for which $x_n < \\delta$.\nFind the expected value of $Z$, as a function of $\\delta$.",
    "solution": "Let $f(\\delta)$ denote the desired expected value of $Z$ as a function of $\\delta$.\nWe prove that $f(\\delta) = 1-\\log(\\delta)$, where $\\log$ denotes natural logarithm.\n\nFor $c \\in [0,1]$, let $g(\\delta,c)$ denote the expected value of $Z$ given that $x_1=c$, and note that $f(\\delta) = \\int_0^1 g(\\delta,c)\\,dc$. Clearly $g(\\delta,c) = 1$ if $c<\\delta$. On the other hand, if $c\\geq\\delta$, then $g(\\delta,c)$ is $1$ more than the expected value of $Z$ would be if we used the initial condition $x_0=c$ rather than $x_0=1$. By rescaling the interval $[0,c]$ linearly to $[0,1]$ and noting that this sends $\\delta$ to $\\delta/c$, we see that this latter expected value is equal to $f(\\delta/c)$. That is, for $c\\geq\\delta$, $g(\\delta,c) = 1+f(\\delta/c)$. It follows that we have\n\\begin{align*}\nf(\\delta) &= \\int_0^1 g(\\delta,c)\\,dc  \\\\\n&= \\delta + \\int_\\delta^1 (1+f(\\delta/c))\\,dc = 1+\\int_\\delta^1 f(\\delta/c)\\,dc.\n\\end{align*}\nNow define $h :\\thinspace [1,\\infty) \\to \\mathbb{R}$ by $h(x) = f(1/x)$; then we have\n\\[\nh(x) = 1+\\int_{1/x}^1 h(cx)\\,dc = 1+\\frac{1}{x}\\int_1^x h(c)\\,dc.\n\\]\nRewriting this as $xh(x)-x = \\int_1^x h(c)\\,dc$ and differentiating with respect to $x$ gives\n$h(x)+xh'(x)-1 = h(x)$, whence $h'(x) = 1/x$ and so $h(x) = \\log(x)+C$ for some constant $C$. Since $h(1)=f(1)=1$, we conclude that $C=1$, $h(x) = 1+\\log(x)$, and finally\n$f(\\delta) = 1-\\log(\\delta)$. This gives the claimed answer."
  },
  {
    "year": 2020,
    "label": "B4",
    "difficulty": "4",
    "problem": "Let $n$ be a positive integer, and let $V_n$ be the set of integer $(2n+1)$-tuples $\\mathbf{v} = (s_0, s_1, \\cdots, s_{2n-1}, s_{2n})$ for which $s_0 = s_{2n} = 0$ and $|s_j - s_{j-1}| = 1$ for $j=1,2,\\cdots,2n$. Define\n\\[\nq(\\mathbf{v}) = 1 + \\sum_{j=1}^{2n-1} 3^{s_j},\n\\]\nand let $M(n)$ be the average of $\\frac{1}{q(\\mathbf{v})}$ over all $\\mathbf{v} \\in V_n$. Evaluate $M(2020)$.",
    "solution": "The answer is $\\frac{1}{4040}$. We will show the following more general fact. Let $a$ be any nonzero number and define $q(\\mathbf{v}) = 1+\\sum_{j=1}^{2n-1} a^{s_j}$; then the average of $\\frac{1}{q(\\mathbf{v})}$ over all $\\mathbf{v} \\in V_n$ is equal to $\\frac{1}{2n}$, independent of $a$.\n\nLet $W_n$ denote the set of $(2n)$-tuples $\\mathbf{w} = (w_1,\\ldots,w_{2n})$ such that $n$ of the $w_i$'s are equal to $+1$ and the other $n$ are equal to $-1$. Define a map $\\phi :\\thinspace W_n \\to W_n$ by $\\phi(w_1,w_2,\\ldots,w_{2n}) = (w_2,\\ldots,w_{2n},w_1)$; that is, $\\phi$ moves the first entry to the end. For $\\mathbf{w} \\in W_n$, define the \\textit{orbit} of $\\mathbf{w}$ to be the collection of elements of $W_n$ of the form $\\phi^k(\\mathbf{w})$, $k \\geq 1$, where $\\phi^k$ denotes the $k$-th iterate of $\\phi$, and note that $\\phi^{2n}(\\mathbf{w}) = \\mathbf{w}$. Then $W_n$ is a disjoint union of orbits. For a given $\\mathbf{w} \\in W_n$, the orbit of $\\mathbf{w}$ consists of $\\mathbf{w},\\phi(\\mathbf{w}),\\ldots,\\phi^{m-1}(\\mathbf{w})$, where $m$ is the smallest positive integer with $\\phi^m(\\mathbf{w}) = \\mathbf{w}$; the list $\\phi(\\mathbf{w}),\\ldots,\\phi^{2n}(\\mathbf{w})$ runs through the orbit of $\\mathbf{w}$ completely $2n/m$ times, with each element of the orbit appearing the same number of times.\n\nNow define the map $f :\\thinspace W_n \\to V_n$ by $f(\\mathbf{w}) = \\mathbf{v} = (s_0,\\ldots,s_{2n})$ with $s_j = \\sum_{i=1}^j w_i$; this is a one-to-one correspondence between $W_n$ and $V_n$, with the inverse map given by $w_j = s_j-s_{j-1}$ for $j=1,\\ldots,2n$. We claim that for any $\\mathbf{w} \\in W_n$, the average of $\\frac{1}{q(\\mathbf{v})}$, where $\\mathbf{v}$ runs over vectors in the image of the orbit of $\\mathbf{w}$ under $f$, is equal to $\\frac{1}{2n}$. Since $W_n$ is a disjoint union of orbits, $V_n$ is a disjoint union of the images of these orbits under $f$, and it then follows that the overall average of $\\frac{1}{q(\\mathbf{v})}$ over $\\mathbf{v} \\in V_n$ is $\\frac{1}{2n}$.\n\nTo prove the claim, we compute the average of $\\frac{1}{q(f(\\phi^k(\\mathbf{w})))}$ over $k=1,\\ldots,2n$; since $\\phi^k(\\mathbf{w})$ for $k=1,\\ldots,2n$ runs over the orbit of $\\mathbf{w}$ with each element in the orbit appearing equally, this is equal to the desired average. Now if we adopt the convention that the indices in $w_i$ are considered mod $2n$, so that $w_{2n+i} = w_i$ for all $i$, then the $i$-th entry of $\\phi^k(\\mathbf{w})$ is $w_{i+k}$; we can then define $s_j = \\sum_{i=1}^j w_i$ for all $j\\geq 1$, and $s_{2n+i}=s_i$ for all $i$ since $\\sum_{i=1}^{2n} w_i = 0$. We now have\n\\[\nq(f(\\phi^k(\\mathbf{w}))) = \\sum_{j=1}^{2n} a^{\\sum_{i=1}^j w_{i+k}} = \\sum_{j=1}^{2n} a^{s_{j+k}-s_k} = a^{-s_k} \\sum_{j=1}^{2n} a^{s_j}.\n\\]\n\nThus\n\\[\n\\sum_{k=1}^{2n} \\frac{1}{q(f(\\phi^k(\\mathbf{w})))} = \\sum_{k=1}^{2n} \\frac{a^{s_k}}{\\sum_{j=1}^{2n} a^{s_j}} = 1,\n\\]\nand the average of $\\frac{1}{q(f(\\phi^k(\\mathbf{w})))}$ over $k=1,\\ldots,2n$ is $\\frac{1}{2n}$, as desired."
  },
  {
    "year": 2020,
    "label": "B5",
    "difficulty": "5",
    "problem": "For $j \\in \\{1, 2, 3, 4\\}$, let $z_j$ be a complex number with $|z_j| = 1$ and $z_j \\neq 1$. Prove that\n\\[\n3 - z_1 - z_2 - z_3 - z_4 + z_1 z_2 z_3 z_4 \\neq 0.\n\\]",
    "solution": "\\noindent\n\\textbf{First solution.} (by Mitja Mastnak)\nIt will suffice to show that for any $z_1, z_2, z_3, z_4 \\in \\CC$ of modulus 1 such that $|3-z_1-z_2-z_3-z_4| = |z_1z_2z_3z_4|$, at least one of $z_1, z_2, z_3$ is equal to 1.\n\nTo this end, let $z_1=e^{\\alpha i}, z_2=e^{\\beta i}, z_3=e^{\\gamma i}$ and \n\\[\nf(\\alpha, \\beta, \\gamma)=|3-z_1-z_2-z_3|^2-|1-z_1z_2z_3|^2.\n\\]\\\n A routine calculation shows that \n\\begin{align*}\nf(\\alpha, \\beta, \\gamma)&=\n10 - 6\\cos(\\alpha) - 6\\cos(\\beta) - 6\\cos(\\gamma) \\\\\n&\\quad + 2\\cos(\\alpha + \\beta + \\gamma) + 2\\cos(\\alpha - \\beta) \\\\\n&\\quad + 2\\cos(\\beta - \\gamma) + 2\\cos(\\gamma - \\alpha).\n\\end{align*}\nSince the function $f$ is continuously differentiable, and periodic in each variable, $f$ has a maximum and a minimum and it attains these values only at points where $\\nabla f=(0,0,0)$.  A routine calculation now shows that \n\\begin{align*}\n\\frac{\\partial f}{\\partial \\alpha} + \\frac{\\partial f}{\\partial \\beta} + \\frac{\\partial f}{\\partial \\gamma} &=\n6(\\sin(\\alpha) +\\sin(\\beta)+\\sin(\\gamma)-  \\sin(\\alpha + \\beta + \\gamma)) \\\\\n&=\n24\\sin\\left(\\frac{\\alpha+\\beta}{2}\\right) \\sin\\left(\\frac{\\beta+\\gamma}{2}\\right)\n\\sin\\left(\\frac{\\gamma+\\alpha}{2}\\right).\n\\end{align*}\nHence every critical point of $f$ must satisfy one of $z_1z_2=1$, $z_2z_3=1$, or $z_3z_1=1$. By symmetry, let us assume that $z_1z_2=1$. Then \n\\[\nf = |3-2\\mathrm{Re}(z_1)-z_3|^2-|1-z_3|^2;\n\\]\nsince $3-2\\mathrm{Re}(z_1)\\ge 1$, $f$ is nonnegative and can be zero only if the real part of $z_1$, and hence also $z_1$ itself, is equal to $1$. \n\n\\noindent\n\\textbf{Remark.}\nIf $z_1 = 1$, we may then apply the same logic to deduce that one of $z_2,z_3,z_4$ is equal to 1. If $z_1 = z_2 = 1$, we may factor the expression\n\\[\n3 - z_1 - z_2 - z_3 - z_4 + z_1 z_2 z_3 z_4\n\\]\nas $(1 - z_3)(1-z_4)$ to deduce that at least three of $z_1, \\dots, z_4$ are equal to $1$.\n\n\\noindent\n\\textbf{Second solution.}\nWe begin with an ``unsmoothing'' construction.\n\\setcounter{lemma}{0}\n\\begin{lemma}\nLet $z_1,z_2,z_3$ be three distinct complex numbers with $|z_j|= 1$ and $z_1 + z_2 + z_3 \\in [0, +\\infty)$. Then there exist another three complex numbers $z'_1, z'_2, z'_3$, not all distinct, with\n$|z'_j| = 1$ and\n\\[\nz'_1 + z'_2 + z'_3 \\in (z_1+ z_2 + z_3, +\\infty), \\quad z_1 z_2 z_3 = z'_1 z'_2 z'_3.\n\\]\n\\end{lemma}\n\\begin{proof}\nWrite $z_j = e^{i \\theta_j}$ for $j=1,2,3$. \nWe are then trying to maximize the target function\n\\[\n\\cos \\theta_1 + \\cos \\theta_2 + \\cos \\theta_3\n\\]\ngiven the constraints\n\\begin{align*}\n0 &= \\sin \\theta_1 + \\sin \\theta_2 + \\sin \\theta_3\\\\\n* &= \\theta_1 + \\theta_2 + \\theta_3\n\\end{align*}\nSince $z_1, z_2, z_3$ run over a compact region without boundary, the maximum must be achieved at a point where the matrix\n\\[\n\\begin{pmatrix}\n\\sin \\theta_1 & \\sin \\theta_2 & \\sin \\theta_3 \\\\\n\\cos \\theta_1 & \\cos \\theta_2 & \\cos \\theta_3 \\\\\n1 & 1 & 1\n\\end{pmatrix}\n\\]\nis singular. Since the determinant of this matrix computes (up to a sign and a factor of 2) the area of the triangle with vertices $z_1, z_2, z_3$,\nit cannot vanish unless some two of $z_1, z_2, z_3$ are equal. This proves the claim.\n\\end{proof}\n\nFor $n$ a positive integer, let $H_n$ be the \\emph{hypocycloid curve} in $\\CC$ given by\n\\[\nH_n = \\{(n-1) z + z^{-n+1}: z \\in \\CC, |z| = 1\\}.\n\\]\nIn geometric terms, $H_n$ is the curve traced out by a marked point on a circle of radius 1 rolling one full circuit along the interior of a circle of radius 1, starting from the point $z=1$.\nNote that the interior of $H_n$ is not convex, but it is \\emph{star-shaped}: it is closed under multiplication by any number in $[0,1]$.\n\n\\begin{lemma}\nFor $n$ a positive integer, let $S_n$ be the set of complex numbers of the form $w_1 + \\cdots + w_n$ for some $w_1,\\dots,w_n \\in \\CC$ with\n$|w_j| = 1$ and $w_1 \\cdots w_n = 1$. Then for $n \\leq 4$, $S_n$ is the closed interior of $H_n$ (i.e., including the boundary).\n\\end{lemma}\n\\begin{proof}\nBy considering $n$-tuples of the form $(z,\\dots,z,z^{-n+1})$, we see that $H_n \\subseteq S_n$.\nIt thus remains to check that $S_n$ lies in the closed interior of $H_n$.\nWe ignore the easy cases $n=1$ (where $H_1 = S_1 = \\{1\\}$) and $n=2$ (where $H_2 = S_2 = [-2,2]$)\nand assume hereafter that $n \\geq 3$.\n\nBy Lemma 1, for each ray emanating from the the origin, the extreme intersection point of $S_n$ with this ray (which exists because $S_n$ is compact) is achieved by some tuple $(w_1,\\dots,w_n)$ with at most two distinct values.\nFor $n=3$, this immediately implies that this point lies on $H_n$. For $n=4$, we must also consider tuples consisting of two pairs of equal values; however, these only give rise to points in $[-4, 4]$, which are indeed contained in $H_4$.\n\\end{proof}\n\nTurning to the original problem, consider $z_1,\\dots,z_4 \\in \\CC$ with $|z_j| = 1$ and \n\\[\n3 - z_1 - z_2 - z_3 - z_4 + z_1 z_2 z_3 z_4 = 0;\n\\]\nwe must prove that at least one $z_j$ is equal to 1.\nLet $z$ be any fourth root of $z_1 z_2 z_3 z_4$,\nput $w_j = z_j/z$, and put $s = w_1 + \\cdots + w_4$. In this notation, we have\n\\[\ns = z^3 + 3z^{-1},\n\\]\nwhere $s \\in S_4$ and $z^3 + 3z^{-1} \\in H_4$. That is, $s$ is a boundary point of $S_4$, so in particular it is the extremal point of $S_4$ on the ray emanating from the origin through $s$.\nBy Lemma 1, this implies that $w_1,\\dots,w_4$ take at most two distinct values. As in the proof of Lemma 2, we distinguish two cases.\n\\begin{itemize}\n\\item\nIf $w_1 = w_2 = w_3$, then\n\\[\nw_1^{-3} + 3w_1 = z^3 + 3z^{-1}.\n\\]\nFrom the geometric description of $H_n$, we see that this forces $w_1^{-1} = z$ and hence $z_1 = 1$.\n\n\\item\nIf $w_1 = w_2$ and $w_3 = w_4$, then $s \\in [-4, 4]$ and hence $s = \\pm 4$. This can only be achieved by taking $w_1 = \\cdots = w_4 = \\pm 1$;\nsince $s = z^3 + 3z^{-1}$ we must also have $z = \\pm 1$, yielding $z_1 = \\cdots = z_4 = 1$.\n\\end{itemize}\n\n\\noindent\n\\textbf{Remark.}\nWith slightly more work, one can show that Lemma 2 remains true for all positive integers $n$.\nThe missing extra step is to check that for $m=1,\\dots,n-1$, the hypocycloid curve\n\\[\n\\{m z^{n-m} + (n-m) z^{-m}: z \\in \\CC, |z| = 1\\}\n\\]\nis contained in the filled interior of $H_n$. In fact, this curve only touches $H_n$ at points where they both touch the unit circle (i.e., at $d$-th roots of unity for $d = \\gcd(m,n)$);\nthis can be used to formulate a corresponding version of the original problem, which we leave to the reader."
  },
  {
    "year": 2020,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $n$ be a positive integer. Prove that\n\\[\n\\sum_{k=1}^n (-1)^{\\lfloor k(\\sqrt{2}-1) \\rfloor} \\geq 0.\n\\]\n(As usual, $\\lfloor x \\rfloor$ denotes the greatest integer less than or equal to $x$.)\n\n\\end{itemize}\n\n\\end{document}",
    "solution": "\\noindent\n\\textbf{First solution.}\nDefine the sequence $\\{a_k\\}_{k=0}^\\infty$ by $a_k = \\lfloor k(\\sqrt{2}-1)\\rfloor$. The first few terms of the sequence $\\{(-1)^{a_k}\\}$ are\n\\[\n1,1,1,-1,-1,1,1,1,-1,-1,1,1,1,\\ldots.\n\\]\nDefine a new sequence $\\{c_i\\}_{i=0}^\\infty$ given by $3,2,3,2,3,\\ldots$, whose members alternately are the lengths of the clusters of consecutive $1$'s and the lengths of the clusters of consecutive $-1$'s in the sequence $\\{(-1)^{a_k}\\}$. Then for any $i$, $c_0+\\cdots+c_i$ is the number of nonnegative integers $k$ such that $\\lfloor k(\\sqrt{2}-1) \\rfloor$ is strictly less than $i+1$, i.e., such that $k(\\sqrt{2}-1)<i+1$. This last condition is equivalent to $k<(i+1)(\\sqrt{2}+1)$, and we conclude that \\begin{align*}\nc_0+\\cdots+c_i &= \\lfloor (i+1)(\\sqrt{2}+1)\\rfloor  + 1 \\\\\n&= 2i+3+\\lfloor (i+1)(\\sqrt{2}-1)\\rfloor.\n\\end{align*}\nThus for $i>0$,\n\\begin{equation} \\label{eq:2020B6eq1}\nc_i =2+\\lfloor (i+1)(\\sqrt{2}-1)\\rfloor-\\lfloor i(\\sqrt{2}-1) \\rfloor.\n\\end{equation}\nNow note that $\\lfloor (i+1)(\\sqrt{2}-1)\\rfloor-\\lfloor i(\\sqrt{2}-1) \\rfloor$ is either $1$ or $0$ depending on whether or not there is an integer $j$ between $i(\\sqrt{2}-1)$ and $(i+1)(\\sqrt{2}-1)$: this condition is equivalent to $i<j(\\sqrt{2}+1)<i+1$. That is, for $i>0$,\n\\begin{equation} \\label{eq:2020B6eq3}\nc_i = \\begin{cases} 3 & \\text{if } i=\\lfloor j(\\sqrt{2}+1)\\rfloor \\text{ for some integer }j, \\\\\n2 &\\text{otherwise};\n\\end{cases}\n\\end{equation}\nby inspection, this also holds for $i=0$.\n\nNow we are asked to prove that\n\\begin{equation}\\label{eq:2020B6eq2}\n\\sum_{k=0}^n (-1)^{a_k} \\geq 1\n\\end{equation}\nfor all $n\\geq 1$. We will prove that if \\eqref{eq:2020B6eq2} holds for all $n\\leq N$, then \\eqref{eq:2020B6eq2} holds for all $n\\leq 4N$; since \\eqref{eq:2020B6eq2} clearly holds for $n=1$, this will imply the desired result.\n\nSuppose that \\eqref{eq:2020B6eq2} holds for $n\\leq N$. To prove that \\eqref{eq:2020B6eq2} holds for $n\\leq 4N$, it suffices to show that the partial sums\n\\[\n\\sum_{i=0}^m (-1)^i c_i\n\\]\nof the sequence $\\{(-1)^{a_k}\\}$ are positive for all $m$ such that $c_0+\\cdots+c_{m-1}<4N+3$, since these partial sums cover all clusters through $a_{4N}$. Now if $c_0+\\cdots+c_{m-1}<4N+3$, then since each $c_i$ is at least $2$, we must have $m<2N+2$. From \\eqref{eq:2020B6eq3}, we see that if $m$ is odd, then\n\\begin{align*}\n\\sum_{i=0}^m (-1)^i c_i &= \\sum_{i=0}^m (-1)^i (c_i-2) \\\\\n&= \\sum_j (-1)^{\\lfloor j(\\sqrt{2}+1)\\rfloor} = \\sum_j (-1)^{a_j}\n\\end{align*}\nwhere the sum in $j$ is over nonnegative integers $j$ with $j(\\sqrt{2}+1) < m$, i.e., $j <m(\\sqrt{2}-1)$; since $m(\\sqrt{2}-1)<m/2<N+1$,\n$\\sum_j (-1)^{a_j}$ is positive by the induction hypothesis. Similarly, if $m$ is even, then $\\sum_{i=0}^m (-1)^i c_i = c_m+ \\sum_j (-1)^{a_j}$ and this is again positive by the induction hypothesis. This concludes the induction step and the proof.\n\n\\noindent\n\\textbf{Remark.}\nMore generally, using the same proof we can establish the result with $\\sqrt{2}-1$ replaced by $\\sqrt{n^2+1}-n$ for any positive integer $n$.\n\n\n\\noindent\n\\textbf{Second solution.}\nFor $n \\geq 0$, define the function \n\\[\nf(n) = \\sum_{k=1}^n (-1)^{\\lfloor k (\\sqrt{2}-1) \\rfloor}\n\\]\nwith the convention that $f(0) = 0$.\n\nDefine the sequence $q_0, q_1, \\dots$ by the initial conditions\n\\[\nq_0 = 0, q_1 = 1\n\\]\nand the recurrence relation\n\\[\n\\qquad q_j = 2q_{j-1} + q_{j-2}.\n\\]\nThis is OEIS sequence A000129; its first few terms are\n\\[\n0,1,2,5,12,29,70,\\dots.\n\\]\nNote that $q_j \\equiv j \\pmod{2}$.\n\nWe now observe that the fractions $q_{j-1}/q_j$ are the \\emph{convergents} of the continued fraction expansion of $\\sqrt{2}-1$.\nThis implies the following additional properties of the sequence.\n\\begin{itemize}\n\\item\nFor all $j \\geq 0$, \n\\[\n\\frac{q_{2j}}{q_{2j+1}} < \\sqrt{2}-1 < \\frac{q_{2j+1}}{q_{2j+2}}.\n\\]\n\\item\nThere is no fraction $r/s$ with $s < q_j + q_{j+1}$ such that\n$\\frac{r}{s}$ separates $\\sqrt{2}-1$ from $q_j/q_{j-1}$. In particular, for $k < q_j + q_{j+1}$,\n\\[\n\\lfloor k (\\sqrt{2}-1) \\rfloor = \\left\\lfloor \\frac{kq_{j-1}}{q_j} \\right\\rfloor\n\\]\nexcept when $j$ is even and $k \\in \\{q_j, 2q_j\\}$, in which case they differ by 1.\n\\end{itemize}\n\nWe use this to deduce a ``self-similarity'' property of $f(n)$.\n\\setcounter{lemma}{0}\n\\begin{lemma}\nLet $n,j$ be nonnegative integers with $q_j \\leq n < q_j + q_{j+1}$.\n\\begin{itemize}"
  },
  {
    "year": 2021,
    "label": "A1",
    "difficulty": "1",
    "problem": "A grasshopper starts at the origin in the coordinate plane and makes a sequence of hops.\nEach hop has length $5$, and after each hop the grasshopper is at a point whose coordinates are both integers; thus, there are $12$ possible locations for the grasshopper after the first hop.\nWhat is the smallest number of hops needed for the grasshopper to reach the point $(2021, 2021)$?",
    "solution": "The answer is $578$. \n\nEach hop corresponds to adding one of the $12$ vectors $(0,\\pm 5)$, $(\\pm 5,0)$, $(\\pm 3,\\pm 4)$, $(\\pm 4,\\pm 3)$ to the position of the grasshopper. Since $(2021,2021) = 288(3,4)+288(4,3)+(0,5)+(5,0)$, the grasshopper can reach $(2021,2021)$ in $288+288+1+1=578$ hops.\n\nOn the other hand, let $z=x+y$ denote the sum of the $x$ and $y$ coordinates of the grasshopper, so that it starts at $z=0$ and ends at $z=4042$. Each hop changes the sum of the $x$ and $y$ coordinates of the grasshopper by at most $7$, and $4042 > 577 \\times 7$; it follows immediately that the grasshopper must take more than $577$ hops to get from $(0,0)$ to $(2021,2021)$.\n\n\\noindent\n\\textbf{Remark.}\nThis solution implicitly uses the distance function \n\\[\nd((x_1, y_1), (x_2, y_2)) = |x_1 - x_2| + |y_1 - y_2|\n\\]\non the plane, variously called the \\emph{taxicab metric}, the \\emph{Manhattan metric}, or the \\emph{$L^1$-norm} (or $\\ell_1$-norm)."
  },
  {
    "year": 2021,
    "label": "A2",
    "difficulty": "2",
    "problem": "For every positive real number $x$, let\n\\[\ng(x) = \\lim_{r \\to 0} ((x+1)^{r+1} - x^{r+1})^{\\frac{1}{r}}.\n\\]\nFind $\\lim_{x \\to \\infty} \\frac{g(x)}{x}$.",
    "solution": "The limit is $e$.\n\n\\noindent\n\\textbf{First solution.}\nBy l'H\\^opital's Rule, we have\n\\begin{align*}\n&\\lim_{r\\to 0} \\frac{\\log((x+1)^{r+1}-x^{r+1})}{r} \\\\\n&\\quad = \\lim_{r\\to 0} \\frac{d}{dr} \\log((x+1)^{r+1}-x^{r+1}) \\\\\n&\\quad = \\lim_{r\\to 0} \\frac{(x+1)^{r+1}\\log(x+1)-x^{r+1}\\log x}{(x+1)^{r+1}-x^{r+1}} \\\\\n&\\quad = (x+1)\\log(x+1)-x\\log x,\n\\end{align*}\nwhere $\\log$ denotes natural logarithm. It follows that $g(x) = e^{(x+1)\\log(x+1)-x\\log x} = \\frac{(x+1)^{x+1}}{x^x}$. Thus\n\\[\n\\lim_{x\\to\\infty} \\frac{g(x)}{x} = \\left(\\lim_{x\\to\\infty}\\frac{x+1}{x}\\right) \\cdot \\left(\\lim_{x\\to\\infty} \\left(1+\\frac{1}{x}\\right)^x\\right) = 1\\cdot e = e.\n\\]\n\n\\noindent\n\\textbf{Second solution.}\nWe first write \n\\begin{align*}\n\\lim_{x \\to \\infty} \\frac{g(x)}{x} &= \\lim_{x \\to \\infty} \\lim_{r \\to 0} \\frac{((x+1)^{r+1} - x^{r+1})^{1/r}}{x} \\\\\n&= \\lim_{x \\to \\infty} \\lim_{r \\to 0} \\frac{((r+1) x^r + O(x^{r-1}))^{1/r}}{x}.\n\\end{align*}\nWe would like to interchange the order of the limits, but this requires some justification.\nUsing Taylor's theorem with remainder, for $x \\geq 1$, $r \\leq 1$\nwe can bound the error term $O(x^{r-1})$ in absolute value by $(r+1) r x^{r-1}$. This\nmeans that if we continue to rewrite the orginial limit as\n\\[\n\\lim_{r\\to 0} \\lim_{x\\to\\infty} (r+1+O(x^{-1}))^{1/r},\n\\]\nthe error term $O(x^{-1})$ is bounded in absolute value by $(r+1) r/x$.\nFor $x \\geq 1$, $r \\leq 1$ this quantity is bounded in absolute value by $(r+1)r$, \\emph{independently of $x$}. This allows us to continue by interchanging the order of the limits,\nobtaining \n\\begin{align*}\n&\\lim_{r\\to 0} \\lim_{x\\to\\infty} (r+1+O(x^{-1}))^{1/r} \\\\\n&\\quad = \\lim_{r\\to 0} (r+1)^{1/r} \\\\\n&\\quad = \\lim_{s\\to \\infty} (1+1/s)^{s} = e,\n\\end{align*}\nwhere in the last step we take $s = 1/r$.\n\n\\noindent\n\\textbf{Third solution.} (by Clayton Lungstrum)\nWe first observe that\n\\begin{align*}\n((x+1)^{r+1} - x^{r+1})^{1/r}\n&= \\left( \\int_x^{x+1} (r+1)u^r\\,du \\right)^{1/r} \\\\\n&= (r+1)^{1/r} \\left( \\int_x^{x+1} u^r\\,du \\right)^{1/r}.\n\\end{align*}\nSince $\\lim_{r \\to 0} (r+1)^{1/r} = e$, we deduce that\n\\[\ng(x) = e \\lim_{r \\to 0} \\left( \\int_x^{x+1} u^r\\,du \\right)^{1/r}.\n\\]\nFor $r > 0$, $u^r$ is increasing for $x \\leq u \\leq x+1$, so\n\\[\nx^r \\leq \\int_x^{x+1} u^r\\,du \\leq (x+1)^r;\n\\]\nfor $r < 0$, $u^r$ is decreasing for $x \\leq u \\leq x+1$, so\n\\[\nx^r \\geq \\int_x^{x+1} u^r\\,du \\geq (x+1)^r.\n\\]\nIn both cases, we deduce that\n\\[\nx \\leq \\left( \\int_x^{x+1} u^r\\,du \\right)^{1/r} \\leq x+1;\n\\]\napplying the squeeze theorem to the resulting inequality\n $e \\leq \\frac{g(x)}{x} \\leq e\\left( 1 + \\frac{1}{x} \\right)$\n yields the claimed limit."
  },
  {
    "year": 2021,
    "label": "A3",
    "difficulty": "3",
    "problem": "Determine all positive integers $N$ for which the sphere\n\\[\nx^2 + y^2 + z^2 = N\n\\]\nhas an inscribed regular tetrahedron whose vertices have integer coordinates.",
    "solution": "The integers $N$ with this property are those of the form $3m^2$ for some positive integer $m$.\n\nIn one direction, for $N = 3m^2$, the points\n\\[\n(m,m,m), (m,-m,-m), (-m,m,-m), (-m,-m,m)\n\\]\nform the vertices of a regular tetrahedron inscribed in the sphere $x^2 + y^2 + z^2 = N$.\n\nConversely, suppose that $P_i = (x_i, y_i, z_i)$ for $i=1,\\dots,4$ are the vertices of an inscribed regular \ntetrahedron. Then the center of this tetrahedron must equal the center of the sphere, namely $(0,0,0)$. Consequently, these four vertices together with $Q_i = (-x_i, -y_i, -z_i)$ for $i=1,\\dots,4$ form the vertices of an inscribed cube in the sphere.\nThe side length of this cube is $(N/3)^{1/2}$, so its volume is $(N/3)^{3/2}$;\non the other hand, this volume also equals the determinant of the matrix\nwith row vectors $Q_2-Q_1, Q_3-Q_1, Q_4-Q_1$, which is an integer. Hence $(N/3)^3$ is a perfect square, as then is $N/3$."
  },
  {
    "year": 2021,
    "label": "A4",
    "difficulty": "4",
    "problem": "Let\n\\[\nI(R) = \\iint_{x^2+y^2 \\leq R^2} \\left( \\frac{1+2x^2}{1+x^4+6x^2y^2+y^4} - \\frac{1+y^2}{2+x^4+y^4} \\right)\\,dx\\,dy.\n\\]\nFind\n\\[\n\\lim_{R \\to \\infty} I(R),\n\\]\nor show that this limit does not exist.",
    "solution": "The limit exists and equals $\\frac{\\sqrt{2}}{2} \\pi \\log 2$.\n\nWe first note that we can interchange $x$ and $y$ to obtain\n\\[\nI(R) = \\iint_{x^2+y^2 \\leq R^2} \\left( \\frac{1+2y^2}{1+x^4+6x^2y^2+y^4} - \\frac{1+x^2}{2+x^4+y^4} \\right)\\,dx\\,dy.\n\\]\nAveraging the two expressions for $I(R)$ yields\n\\[\nI(R) = \\iint_{x^2+y^2 \\leq R^2} (f(x,y) - g(x,y))\\,dx\\,dy\n\\]\nwhere\n\\begin{align*}\nf(x,y) &= \\frac{1+x^2+y^2}{1 + x^4 + 6x^2y^2 + y^4} \\\\\ng(x,y) &= \\frac{1+x^2/2+y^2/2}{2 + x^4 + y^4}.\n\\end{align*}\nNow note that\n\\[f(x,y) = 2 g(x+y, x-y).\n\\]\nWe can thus write\n\\[\nI(R) = \\iint_{R^2 \\leq x^2 +y^2 \\leq 2R^2} g(x,y)\\,dx\\,dy.\n\\]\nTo compute this integral, we switch to polar coordinates:\n\\begin{align*}\nI(R) &= \\int_R^{R\\sqrt{2}} \\int_0^{2\\pi} g(r\\cos \\theta, r \\sin \\theta)r\\,dr\\,d\\theta \\\\\n&=  \\int_R^{R\\sqrt{2}} \\int_0^{2\\pi} \\frac{1 + r^2/2}{2 + r^4(1 - (\\sin^2 2\\theta)/2)} r\\,dr\\,d\\theta.\n\\end{align*}\nWe rescale $r$ to remove the factor of $R$ from the limits of integration:\n\\begin{align*}\nI(R) & =  \\int_1^{\\sqrt{2}} \\int_0^{2\\pi} \\frac{1 + R^2 r^2/2}{2 + R^4 r^4(1 - (\\sin^2 2\\theta)/2)} R^2 r\\,dr\\,d\\theta.\n\\end{align*}\n\nSince the integrand is uniformly bounded for $R \\gg 0$, we may take the limit over $R$ through the integrals to obtain\n\\begin{align*}\n\\lim_{R \\to \\infty} I(R) &= \\int_1^{\\sqrt{2}} \\int_0^{2\\pi} \\frac{r^2/2}{r^4(1 - (\\sin^2 2\\theta)/2)} r\\,dr\\,d\\theta \\\\\n&= \\int_1^{\\sqrt{2}} \\frac{dr}{r} \\int_0^{2\\pi} \\frac{1}{2- \\sin^2 2\\theta} d\\theta \\\\\n&= \\log \\sqrt{2} \\int_0^{2\\pi} \\frac{1}{1 + \\cos^2 2\\theta} d\\theta \\\\\n&= \\frac{1}{2} \\log 2 \\int_0^{2\\pi} \\frac{2}{3 + \\cos 4\\theta} d\\theta.\n\\end{align*}\nIt thus remains to evaluate \n\\[\n\\int_0^{2\\pi} \\frac{2}{3 + \\cos 4\\theta} d\\theta = \n2 \\int_0^{\\pi} \\frac{2}{3 + \\cos \\theta} d\\theta.\n\\]\nOne option for this is to use the half-angle substitution $t = \\tan (\\theta/2)$ to get\n\\begin{align*}\n\\int_{-\\infty}^\\infty \\frac{4}{3(1+t^2) + (1-t^2)}\\,dt\n&= \\int_{-\\infty}^\\infty \\frac{2}{2+t^2}\\,dt \\\\\n&= \\sqrt{2} \\arctan \\left( \\frac{x}{\\sqrt{2}} \\right)^{\\infty}_{-\\infty} \\\\\n&= \\sqrt{2} \\pi.\n\\end{align*}\nPutting this together yields the claimed result."
  },
  {
    "year": 2021,
    "label": "A5",
    "difficulty": "5",
    "problem": "Let $A$ be the set of all integers $n$ such that $1 \\leq n \\leq 2021$ and $\\gcd(n, 2021) = 1$.\nFor every nonnegative integer $j$, let\n\\[\nS(j) = \\sum_{n \\in A} n^j.\n\\]\nDetermine all values of $j$ such that $S(j)$ is a multiple of 2021.",
    "solution": "The values of $j$ in question are those not divisible by either $42$ or $46$.\n\nWe first check that for $p$ prime,\n\\[\n\\sum_{n=1}^{p-1} n^j \\equiv 0 \\pmod{p} \\Leftrightarrow j \\not\\equiv 0 \\pmod{p-1}.\n\\]\nIf $j \\equiv 0 \\pmod{p-1}$, then $n^j \\equiv 1 \\pmod{p}$ for each $n$, so $\\sum_{n=1}^{p-1} n^j \\equiv p-1 \\pmod{p}$. If $j \\not\\equiv 0 \\pmod{p-1}$, we can pick a primitive root $m$ modulo $p$,\nobserve that $m^j \\not\\equiv 1 \\pmod{p}$, and then note that\n\\[\n\\sum_{n=1}^{p-1} n^j \\equiv \\sum_{n=1}^{p-1} (mn)^j = m^j \\sum_{n=1}^{p-1} n^j \\pmod{p},\n\\]\nwhich is only possible if $\\sum_{n=1}^{p-1} n^j \\equiv 0 \\pmod{p}$.\n\nWe now note that the prime factorization of 2021 is $43 \\times 47$,\nso it suffices to determine when $S(j)$ is divisible by each of 43 and 47.\nWe have\n\\begin{align*}\nS(j) &\\equiv 46 \\sum_{n=1}^{42} n^j \\pmod{43} \\\\\nS(j) &\\equiv 42 \\sum_{n=1}^{46} n^j \\pmod{47}.\n\\end{align*}\nSince 46 and 42 are coprime to 43 and 47, respectively, \nwe have \n\\begin{gather*}\nS(j) \\equiv 0 \\pmod{43} \\Leftrightarrow j \\not\\equiv 0 \\pmod{42} \\\\\nS(j) \\equiv 0 \\pmod{47} \\Leftrightarrow j \\not\\equiv 0 \\pmod{46}.\n\\end{gather*}\nThis yields the claimed result."
  },
  {
    "year": 2021,
    "label": "A6",
    "difficulty": "6",
    "problem": "Let $P(x)$ be a polynomial whose coefficients are all either $0$ or $1$.\nSuppose that $P(x)$ can be written as a product of two nonconstant polynomials with integer coefficients. Does it follow that $P(2)$ is a composite integer?",
    "solution": "Yes, it follows that $P(2)$ is a composite integer. (Note: 1 is neither prime nor composite.)\n\nWrite $P(x) = a_0 + a_1 x + \\cdots + a_n x^n$ with $a_i \\in \\{0,1\\}$ and $a_n = 1$.\nLet $\\alpha$ be an arbitrary root of $P$. Since $P(\\alpha) = 0$, $\\alpha$ cannot be a positive real number.\n%In addition, if $\\alpha \\neq 0$ then\n%\\begin{align*}\n%1 &< |a_{n-1} \\alpha^{-1} + \\cdots + a_0 \\alpha^{-n}| \\\\\n%&\\leq |\\alpha|^{-1} + \\cdots + |\\alpha|^{-n}\n%\\end{align*}\n%and so $|\\alpha| < 2$.\n%\nIn addition, if $\\alpha \\neq 0$ then\n\\begin{align*}\n|1 + a_{n-1} \\alpha^{-1}| &= |a_{n-2} \\alpha^{-2} + \\cdots + a_0 \\alpha^{-n}| \\\\\n&\\leq |\\alpha|^{-2} + \\cdots + |\\alpha|^{-n}.\n\\end{align*}\nIf $\\alpha \\neq 0$ and $\\mathrm{Re}(\\alpha) \\geq 0$, then $\\mathrm{Re}(1 + a_{n-1} \\alpha^{-1}) \\geq 1$\nand \n\\[\n1 \\leq |\\alpha|^{-2} + \\cdots + |\\alpha|^{-n} < \\frac{|\\alpha|^{-2}}{1 - |\\alpha|^{-1}};\n\\]\nthis yields $|\\alpha| < (1 + \\sqrt{5})/2$.\n\nBy the same token, if $\\alpha \\neq 0$ then\n\\[\n|1 + a_{n-1} \\alpha^{-1} + a_{n-2} \\alpha^{-2}| \\leq |\\alpha|^{-3} + \\cdots + |\\alpha|^{-n}.\n\\]\nWe deduce from this that $\\mathrm{Re}(\\alpha) \\leq 3/2$ as follows.\n\\begin{itemize}\n\\item\nThere is nothing to check if $\\mathrm{Re}(\\alpha) \\leq 0$.\n\\item\nIf the argument of $\\alpha$ belongs to $[-\\pi/4, \\pi/4]$, then $\\mathrm{Re}(\\alpha^{-1}), \\mathrm{Re}(\\alpha^{-2}) \\geq 0$, so\n\\[\n1 \\leq |\\alpha|^{-3} + \\cdots + |\\alpha|^{-n} < \\frac{|\\alpha|^{-3}}{1 - |\\alpha|^{-1}}.\n\\]\nHence $|\\alpha|^{-1}$ is greater than the unique positive root of $x^3 + x - 1$, which \nis greater than $2/3$. \n\\item\nOtherwise, $\\alpha$ has argument in $(-\\pi/2,\\pi/4) \\cup (\\pi/4,\\pi/2)$,\nso the bound $|\\alpha| < (1 + \\sqrt{5})/2$ implies that $\\mathrm{Re}(\\alpha) < (1 + \\sqrt{5})/(2 \\sqrt{2}) < 3/2$.\n\\end{itemize}\n\nBy hypothesis, there exists a factorization $P(x) = Q(x)R(x)$ into two nonconstant integer polynomials, which we may assume are monic.\n$Q(x + 3/2)$ is a product of polynomials, each of the form $x - \\alpha$ where $\\alpha$ is a real root of $P$\nor of the form\n\\begin{align*}\n&\\left( x + \\frac{3}{2} - \\alpha\\right) \\left(x + \\frac{3}{2} - \\overline{\\alpha} \\right) \\\\\n&\\quad = x^2 + 2 \\mathrm{Re}\\left(\\frac{3}{2} - \\alpha\\right) x + \\left|\\frac{3}{2} - \\alpha \\right|^2\n\\end{align*}\nwhere $\\alpha$ is a nonreal root of $P$. It follows that $Q(x+3/2)$ has positive coefficients;\ncomparing its values at $x=1/2$ and $x=-1/2$ yields $Q(2) > Q(1)$. We cannot have $Q(1) \\leq 0$, as otherwise the intermediate value theorem would imply that $Q$ has a real root in $[1, \\infty)$; hence $Q(1)  \\geq 1$ and so $Q(2) \\geq 2$.\nSimilarly $R(2) \\geq 2$, so $P(2) = Q(2) R(2)$ is composite.\n\n\\noindent\n\\textbf{Remark.}\nA theorem of Brillhart, Filaseta, and Odlyzko from 1981 states that if a prime $p$ is written as $\\sum_i a_i b^i$ in any base $b \\geq 2$, the polynomial $\\sum_i a_i x^i$ is irreducible.\n(The case $b=10$ is an older result of Cohn.) \nThe solution given above is taken from: Ram Murty, Prime numbers and irreducible polynomials, \\textit{Amer. Math. Monthly} \\textbf{109} (2002), 452--458). The final step is due to P\\'olya and Szeg\\H{o}."
  },
  {
    "year": 2021,
    "label": "B1",
    "difficulty": "1",
    "problem": "Suppose that the plane is tiled with an infinite checkerboard of unit squares. If another unit square is dropped on the plane at random with position and orientation independent of the checkerboard tiling, what is the probability that it does not cover any of the corners of the squares of the checkerboard?",
    "solution": "The probability is $2 - \\frac{6}{\\pi}$.\n\nSet coordinates so that the original tiling includes the (filled) square \n$S = \\{(x,y): 0 \\leq x,y \\leq 1 \\}$. It is then equivalent to choose the second square by first choosing a point uniformly at random in $S$ to be the center of the square, then choosing an angle of rotation uniformly at random from the interval $[0, \\pi/2]$.\n\nFor each $\\theta \\in [0, \\pi/2]$, circumscribe a square $S_\\theta$ around $S$ with angle of rotation $\\theta$ relative to $S$; this square has side length $\\sin \\theta + \\cos \\theta$. Inside $S_\\theta$, draw the smaller square $S_\\theta'$ consisting of points at distance greater than $1/2$ from each side of $S_\\theta$; this square has side length $\\sin \\theta + \\cos \\theta - 1$. \n\nWe now verify that a unit square with angle of rotation $\\theta$ fails to cover any corners of $S$ if and only if its center lies in the interior of $S_\\theta'$. In one direction, if one of the corners of $S$ is covered, then that corner lies on a side of $S_\\theta$ which meets the dropped square, so the center of the dropped square is at distance less than $1/2$ from that side of $S_\\theta$.\nTo check the converse, note that\nthere are two ways to dissect the square $S_\\theta$ into the square $S_\\theta'$ plus four $\\sin \\theta \\times \\cos \\theta$ rectangles. If $\\theta \\neq 0, \\pi/4$, then one of these dissections\nhas the property that each corner $P$ of $S$ appears as an interior point of a side (not a corner) of one of the rectangles $R$. \nIt will suffice to check that if the center of the dropped square is in $R$, then the dropped square covers $P$; this follows from the fact that $\\sin \\theta$ and $\\cos \\theta$ are both at most 1.\n\nIt follows that the conditional probability, given that the angle of rotation is chosen to be $\\theta$, that the dropped square does not cover any corners of $S$ is $(\\sin \\theta + \\cos \\theta - 1)^2$. We then compute the original probability as the integral\n\\begin{align*}\n&\\frac{2}{\\pi} \\int_0^{\\pi/2} (\\sin \\theta + \\cos \\theta - 1)^2\\,d\\theta \\\\\n&\\quad =\n\\frac{2}{\\pi} \\int_0^{\\pi/2} (2 + \\sin 2\\theta - 2\\sin \\theta - 2 \\cos \\theta)\\,d\\theta\\\\\n&\\quad = \\frac{2}{\\pi} \\left( 2 \\theta - \\frac{1}{2} \\cos 2\\theta + 2 \\cos \\theta - 2 \\sin \\theta \\right)_0^{\\pi/2} \\\\\n&\\quad = \\frac{2}{\\pi} \\left( \\pi + 1 - 2 - 2 \\right) = 2 - \\frac{6}{\\pi}.\n\\end{align*}\n\n\\noindent\n\\textbf{Remark:} Noam Elkies has some pictures illustrating this problem:\n\\href{https://abel.math.harvard.edu/~elkies/putnam_b1a.pdf}{image 1},\n\\href{https://abel.math.harvard.edu/~elkies/putnam_b1.pdf}{image 2}."
  },
  {
    "year": 2021,
    "label": "B2",
    "difficulty": "2",
    "problem": "Determine the maximum value of the sum\n\\[\nS = \\sum_{n=1}^\\infty \\frac{n}{2^n} (a_1 a_2 \\cdots a_n)^{1/n}\n\\]\nover all sequences $a_1, a_2, a_3, \\cdots$ of nonnegative real numbers satisfying\n\\[\n\\sum_{k=1}^\\infty a_k = 1.\n\\]",
    "solution": "The answer is $2/3$. \n\nBy AM-GM, we have\n\\begin{align*}\n2^{n+1}(a_1\\cdots a_n)^{1/n} &= \\left((4a_1)(4^2a_2)\\cdots (4^na_n)\\right)^{1/n}\\\\\n& \\leq \\frac{\\sum_{k=1}^n (4^k a_k)}{n}.\n\\end{align*}\nThus\n\\begin{align*}\n2S &\\leq \\sum_{n=1}^\\infty \\frac{\\sum_{k=1}^n (4^k a_k)}{4^n} \\\\\n&= \\sum_{n=1}^\\infty \\sum_{k=1}^n (4^{k-n}a_k) = \\sum_{k=1}^\\infty \\sum_{n=k}^\\infty (4^{k-n}a_k) \\\\\n&= \\sum_{k=1}^\\infty \\frac{4a_k}{3}  = \\frac{4}{3}\n\\end{align*}\nand $S \\leq 2/3$. Equality is achieved when $a_k=\\frac{3}{4^k}$ for all $k$, since in this case $4a_1=4^2a_2=\\cdots=4^na_n$ for all $n$."
  },
  {
    "year": 2021,
    "label": "B3",
    "difficulty": "3",
    "problem": "Let $h(x,y)$ be a real-valued function that is twice continuously differentiable throughout $\\mathbb{R}^2$, and define\n\\[\n\\rho(x,y) = yh_x - xh_y.\n\\]\nProve or disprove: For any positive constants $d$ and $r$ with $d>r$, there is a circle $\\mathcal{S}$ of radius $r$ whose center is a distance $d$ away from the origin such that the integral of $\\rho$ over the interior of $\\mathcal{S}$ is zero.",
    "solution": "We prove the given statement.\n\nFor any circle $\\mathcal{S}$ of radius $r$ whose center is at distance $d$ from the origin, express the integral in polar coordinates $s,\\theta$:\n\\[\n\\iint_{\\mathcal{S}} \\rho = \\int_{s_1}^{s_2} \\int_{\\theta_1(s)}^{\\theta_2(s)} (yh_x - xh_y)(s \\sin \\theta, s \\cos \\theta) s\\,d\\theta\\,ds.\n\\]\nFor fixed $s$, the integral over $\\theta$ is a line integral of $\\mathrm{grad} \\, h$, which evaluates to $h(P_2) - h(P_1)$\nwhere $P_1, P_2$ are the endpoints of the endpoints of the arc of the circle of radius $s$ centered at the origin lying within $\\mathcal{S}$. If we now fix $r$ and $d$ and integrate $\\iint_{\\mathcal{S}} \\rho$ over all choices of $\\mathcal{S}$ (this amounts to a single integral over an angle in the range $[0, 2\\pi]$), we may interchange the order of integration to first integrate over $\\theta$,\nthen over the choice of $\\mathcal{S}$, and at this point we get 0 for every $s$.\nWe conclude that the integral of $\\iint_{\\mathcal{S}}$ over all choices of $\\mathcal{S}$ vanishes; since the given integral varies continuously in $\\mathcal{S}$, by the intermediate value theorem there must be some $\\mathcal{S}$  where the given integral is 0."
  },
  {
    "year": 2021,
    "label": "B4",
    "difficulty": "4",
    "problem": "Let $F_0, F_1, \\dots$ be the sequence of Fibonacci numbers, with $F_0 = 0$, $F_1 = 1$, and $F_n = F_{n-1} + F_{n-2}$ for $n \\geq 2$. For $m > 2$, let $R_m$ be the remainder when the product $\\prod_{k=1}^{F_m-1} k^k$ is divided by $F_m$. Prove that $R_m$ is also a Fibonacci number.",
    "solution": "We can check directly that $R_3=R_4=1$ are Virahanka--Fibonacci numbers; henceforth we will assume $m \\geq 5$.\n\nDenote the product $\\prod_{k=1}^{F_m-1} k^k$ by $A$. Note that if $F_m$ is composite, say $F_m = ab$ for $a,b>1$ integers, then $A$ is divisible by $a^a b^b$ and thus by $F_m=ab$; it follows that $R_m=0=F_0$ when $F_m$ is composite.\n\nNow suppose that $F_m$ is prime. Since $F_{2n} = F_n(F_{n+1}+F_{n-1})$ for all $n$, $F_m$ is composite if $m>4$ is even; thus we must have that $m$ is odd. Write $p=F_m$, and use $\\equiv$ to denote congruence $\\pmod p$. Then we have\n\\[\nA = \\prod_{k=1}^{p-1} (p-k)^{p-k} \\equiv \\prod_{k=1}^{p-1} (-k)^{p-k} = (-1)^{p(p-1)/2} \\prod_{k=1}^{p-1} k^{p-k}\n\\]\nand consequently\n\\begin{align*}\nA^2 &\\equiv (-1)^{p(p-1)/2} \\prod_{k=1}^{p-1} (k^k k^{p-k}) \\\\\n&= (-1)^{p(p-1)/2}((p-1)!)^p \\\\\n&\\equiv (-1)^{p(p+1)/2},\n\\end{align*}\nwhere the final congruence follows from Wilson's Theorem. Now observe that when $m$ is odd, $p=F_m$ must be congruent to either $1$ or $2 \\pmod{4}$: this follows from inspection of the Virahanka--Fibonacci sequence mod $4$, which has period $6$: $1,1,2,3,1,0,1,1,\\ldots$. It follows that $A^2 \\equiv (-1)^{p(p+1)/2} = -1$.\n\nOn the other hand, by the Kepler--Cassini identity\n\\[\nF_n^2 = (-1)^{n+1} + F_{n-1}F_{n+1}\n\\]\nwith $n=m-1$, we have $F_{m-1}^2 \\equiv (-1)^m = -1$. Thus we have\n$0 \\equiv A^2 - F_{m-1}^2 \\equiv (A-F_{m-1})(A-F_{m-2})$. Since $p$ is prime, it must be the case that either $A=F_{m-1}$ or $A=F_{m-2}$, and we are done.\n\n\\noindent\n\\textbf{Remark.}\nThe Kepler--Cassini identity first appears in a letter of Kepler from 1608.\nNoam Elkies has scanned the \\href{https://people.math.harvard.edu/~elkies/Kepler_XVI_p157.jpg}{relevant page of Kepler's collected works} (slightly NSFW if your boss can read Latin)."
  },
  {
    "year": 2021,
    "label": "B5",
    "difficulty": "5",
    "problem": "Say that an $n$-by-$n$ matrix $A = (a_{ij})_{1 \\leq i,j \\leq n}$ with integer entries is \\emph{very odd} if, for every nonempty subset $S$ of $\\{1,2,\\dots,n\\}$, the $|S|$-by-$|S|$ submatrix $(a_{ij})_{i,j \\in S}$ has odd determinant. Prove that if $A$ is very odd, then $A^k$ is very odd for every $k \\geq 1$.",
    "solution": "For convenience, throughout we work with matrices over the field of 2 elements. In this language, if there exists a permutation matrix $P$ such that $P^{-1} A P$ is unipotent (i.e., has 1s on the main diagonal and 0s below it), then $A$ is very odd: any principal submatrix of $A$ is conjugate to a principal submatrix of $P^{-1} A P$, which is again unipotent and in particular nonsingular.\nWe will solve the problem by showing that conversely, for any very odd matrix $A$, there exists a permutation matrix $P$ such that $P^{-1} A P$ is unipotent. Since the latter condition is preserved by taking powers, this will prove the desired result.\n\nTo begin, we may take $S = \\{i\\}$ to see that $a_{ii} = 1$. We next form a (loopless) directed graph on the vertex set $\\{1,\\dots,n\\}$ with an edge from $i$ to $j$ whenever $a_{ij} = 1$, and claim that this graph has no cycles.\nTo see this, suppose the contrary,\nchoose a cycle of minimal length $m \\geq 2$, and let $i_1,\\dots,i_m$ be the vertices in order.\nThe minimality of the cycle implies that\n\\[\na_{i_j i_k} = \\begin{cases} 1 & \\mbox{if } k - j \\equiv 0 \\mbox{ or } 1 \\pmod{m} \\\\\n0 & \\mbox{otherwise}.\n\\end{cases}\n\\]\nThe submatrix corresponding to $S = \\{i_1,\\dots,i_m\\}$ has row sum 0 and hence is singular, a contradiction.\n\nWe now proceed by induction on $n$.\nSince the directed graph has no cycles, there must be some vertex which is not the starting point of any edge\n(e.g., the endpoint of any path of maximal length).\nWe may conjugate by a permutation matrix so that this vertex becomes 1. We now apply the induction hypothesis to the submatrix corresponding to $S = \\{2,\\dots,n\\}$ to conclude.\n\n\\noindent\n\\textbf{Remark.}\nA directed graph without cycles, as in our solution, is commonly called a \\emph{DAG (directed acyclic graph)}. It is a standard fact that a directed graph is a TAG if and only if there is a linear ordering of its vertices consistent with all edge directions.\nSee for example \\url{https://en.wikipedia.org/wiki/Directed_acyclic_graph}.\n\n\\noindent\n\\textbf{Remark.}\nAn $n \\times n$ matrix $A = (a_{ij})$ for which the value of $a_{ij}$ depends only on $i-j \\pmod{n}$ is called a \\emph{circulant matrix}.\nThe circulant matrix with first row $(1,1,0,\\dots,0)$ is an example of an $n \\times n$ matrix whose determinant is even, but whose other principal minors are all odd."
  },
  {
    "year": 2021,
    "label": "B6",
    "difficulty": "6",
    "problem": "Given an ordered list of $3N$ real numbers, we can \\emph{trim} it to form a list of $N$ numbers as follows: We divide the list into $N$ groups of $3$ consecutive numbers, and within each group, discard the highest and lowest numbers, keeping only the median.\n\nConsider generating a random number $X$ by the following procedure: Start with a list of $3^{2021}$ numbers, drawn independently and uniformly at random between 0 and 1. Then trim this list as defined above, leaving a list of $3^{2020}$ numbers. Then trim again repeatedly until just one number remains; let $X$ be this number. Let $\\mu$ be the expected value of $|X - \\frac{1}{2}|$. Show that\n\\[\n\\mu \\geq \\frac{1}{4} \\left( \\frac{2}{3} \\right)^{2021}.\n\\]\n\n\\end{itemize}\n\n\\end{document}",
    "solution": "\\noindent\n\\textbf{First solution.}\n(based on a suggestion of Noam Elkies)\nLet $f_k(x)$ be the probability distribution of $X_k$, the last number remaining when one repeatedly trims a list of $3^k$ random variables chosen with respect to the uniform distribution on $[0,1]$; note that $f_0(x) = 1$ for $x \\in [0,1]$.\nLet $F_k(x)=\\int_0^x f_k(t)\\,dt$ be the cumulative distribution function; by symmetry,\n$F_k(\\frac{1}{2}) = \\frac{1}{2}$.\nLet $\\mu_k$ be the expected value of $X_k - \\frac{1}{2}$; then $\\mu_0 = \\frac{1}{4}$, so it will suffice to prove that $\\mu_{k} \\geq \\frac{2}{3} \\mu_{k-1}$ for $k > 0$.\n\nBy integration by parts and symmetry, we have\n\\[\n\\mu_k = 2 \\int_0^{1/2} \\left( \\frac{1}{2} - x \\right) f_k(x)\\,dx  = 2 \\int_0^{1/2} F_k(x)\\,dx;\n\\]\nthat is, $\\mu_k$ computes twice the area under the curve $y = F_k(x)$ for $0 \\leq x \\leq\\frac{1}{2}$. Since $F_k$ is a monotone function from $[0, \\frac{1}{2}]$ \nwith $F_k(0) = 0$ and $F_k(\\frac{1}{2}) = \\frac{1}{2}$, we may transpose the axes to obtain\n\\begin{equation} \\label{eq:2021B6 eq4}\n\\mu_k = 2 \\int_0^{1/2} \\left( \\frac{1}{2} - F_k^{-1}(y) \\right)\\,dy.\n\\end{equation}\n\nSince $f_k(x)$ is the probability distribution of the median of three random variables chosen with respect to the distribution $f_{k-1}(x)$,\n\\begin{equation} \\label{eq:2021B6 eq1}\nf_k(x) = 6 f_{k-1}(x) F_{k-1}(x) ( 1-F_{k-1}(x) )\n\\end{equation}\nor equivalently\n\\begin{equation} \\label{eq:2021B6 eq2}\nF_k(x) = 3 F_{k-1}(x)^2 - 2 F_{k-1}(x)^3.\n\\end{equation}\nBy induction, $F_k$ is the $k$-th iterate of $F_1(x) = 3x^2 -2x^3$, so\n\\begin{equation} \\label{eq:2021B6 eq5}\nF_k(x) = F_{k-1}(F_1(x)).\n\\end{equation}\nSince $f_1(t) = 6t(1-t) \\leq \\frac{3}{2}$ for $t \\in [0,\\frac{1}{2}]$,\n\\[\n\\frac{1}{2} - F_1(x) = \\int_x^{1/2} 6t(1-t)\\,dt \\leq \\frac{3}{2}\\left(\\frac{1}{2}-x\\right);\n\\]\nfor $y \\in [0, \\frac{1}{2}]$, we may take $x = F_{k}^{-1}(y)$ to obtain\n\\begin{equation} \\label{eq:2021B6 eq3}\n\\frac{1}{2} - F_k^{-1}(y) \\geq \\frac{2}{3} \\left( \\frac{1}{2} - F_{k-1}^{-1}(y) \\right).\n\\end{equation}\nUsing \\eqref{eq:2021B6 eq5} and \\eqref{eq:2021B6 eq3}, we obtain\n\\begin{align*}\n\\mu_k &= 2 \\int_0^{1/2} \\left( \\frac{1}{2} - F_k^{-1}(y) \\right) \\,dy \\\\\n&\\geq \\frac{4}{3} \\int_0^{1/2} \\left( \\frac{1}{2} - F_{k-1}^{-1}(y) \\right) \\,dy = \\frac{2}{3}\\mu_{k-1}\n\\end{align*}\nas desired.\n\n\\noindent\n\\textbf{Second solution.}\nRetain notation as in the first solution. Again $F_k(\\frac{1}{2}) = \\frac{1}{2}$, so \\eqref{eq:2021B6 eq1} implies\n\\[\nf_k\\left( \\frac{1}{2} \\right) = 6 f_{k-1} \\left( \\frac{1}{2} \\right) \\times \\frac{1}{2} \\times \\frac{1}{2}.\n\\]\nBy induction on $k$, we deduce that %$f_k(x)$ is a polynomial in $x$,\n$f_k(\\frac{1}{2}) = (\\frac{3}{2})^k$\nand $f_k(x)$ is nondecreasing on $[0,\\frac{1}{2}]$.\n(More precisely, besides \\eqref{eq:2021B6 eq1}, the second assertion uses that $F_{k-1}(x)$ increases from $0$ to $1/2$\nand $y \\mapsto y - y^2$ is nondecreasing on $[0, 1/2]$.)\n\nThe expected value of $|X_k-\\frac{1}{2}|$ equals\n\\begin{align*}\n\\mu_k &= 2 \\int_0^{1/2} \\left( \\frac{1}{2} - x \\right) f_k(x)\\,dx \\\\\n&= 2 \\int_0^{1/2} x f_k\\left( \\frac{1}{2} - x \\right)\\,dx.% \\\\\n%&= \\int_0^{1/2} \\left( \\frac{1}{2} - F_k\\left( \\frac{1}{2} - x \\right)\\right)\\,dx \\\\\n\\end{align*}\n%where the last step is integration by parts. Define the function\nDefine the function\n\\[\ng_k(x) = \\begin{cases} \\left( \\frac{3}{2} \\right)^k & x \\in \\left[ 0, \\frac{1}{2} \\left( \\frac{2}{3} \\right)^k \\right] \\\\ 0 & \\mbox{otherwise}.\n\\end{cases}\n\\]\nNote that for $x \\in [0, 1/2]$ we have\n\\[\n\\int_0^x (g_k(t) - f_k(1/2-t))\\,dt \\geq 0\n\\]\nwith equality at $x=0$ or $x=1/2$. (On the interval $[0, (1/2)(2/3)^k]$ the integrand is nonnegative, so the function increases from 0; on the interval $[(1/2)(2/3)^k, 1/2]$ the integrand is nonpositive, so the function decreases to 0.)\nHence by integration by parts,\n\\begin{align*}\n&\\mu_k - 2 \\int_0^{1/2} x g_k(x) \\,dx \\\\\n&\\quad = \\int_0^{1/2} 2x (f_k\\left( \\frac{1}{2} - x \\right) - g_k(x)) \\,dx \\\\\n&\\quad = \\int_0^{1/2} x^2 \\left( \\int_0^x g_k(t) - \\int_0^x f_k\\left( \\frac{1}{2} - t \\right)\\,dt \\,dt \\right)\\,dx \\geq 0. \n\\end{align*}\n(This can also be interpreted as an instance of the \\emph{rearrangement inequality}.)\n\nWe now see that\n\\begin{align*}\n\\mu_k &\\geq 2\\int_0^{1/2} x g_k(x)\\,dx \\\\\n&\\quad \\geq 2 \\left( \\frac{3}{2} \\right)^k \\int_0^{(1/2)(2/3)^k} x\\,dx\\\\\n&\\quad = 2 \\left( \\frac{3}{2} \\right)^k \\left. \\frac{1}{2} x^2 \\right|_0^{(1/2)(2/3)^k} \\\\\n&\\quad = 2 \\left( \\frac{3}{2} \\right)^k \\frac{1}{8} \\left( \\frac{2}{3} \\right)^{2k}  = \\frac{1}{4} \\left( \\frac{2}{3} \\right)^k\n\\end{align*}\nas desired.\n\n\n\n\\noindent\n\\textbf{Remark.}\nFor comparison, if we instead take the median of a list of $n$ numbers, the probability distribution is given by\n\\[\nP_{2n+1}(x) = \\frac{(2n+1)!}{n!n!} x^n (1-x)^n.\n\\]\nThe expected value of the absolute difference between $1/2$ and the median is \n\\[\n2 \\int_0^{1/2} (1/2 - x) P_{2n+1}(x) dx = 2^{-2n-2}{{2n+1}\\choose n}.\n\\]\nFor $n = 3^{2021}$, using Stirling's approximation this can be estimated as\n$1.13 (0.577)^{2021} < 0.25 (0.667)^{2021}$. This shows that the trimming procedure produces a quantity that is on average further away from 1/2 than the median.\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2022,
    "label": "A1",
    "difficulty": "1",
    "problem": "Determine all ordered pairs of real numbers $(a,b)$ such that the line $y = ax+b$ intersects the curve $y = \\ln(1+x^2)$ in exactly one point.",
    "solution": "Write $f(x) = \\ln(1+x^2)$.\nWe show that $y=ax+b$ intersects $y=f(x)$ in exactly one point if and only if $(a,b)$ lies in one of the following groups:\n\\begin{itemize}\n\\item\n$a=b=0$\n\\item\n$|a| \\geq 1$, arbitrary $b$\n\\item\n$0 < |a| < 1$, and $b<\\ln(1-r_-)^2-|a|r_-$ or $b>\\ln(1-r_+)^2-|a|r_+$, where \n\\[\nr_\\pm = \\frac{1\\pm\\sqrt{1-a^2}}{a}.\n\\]\n\\end{itemize}\n\n Since the graph of $y=f(x)$ is symmetric under reflection in the $y$-axis, it suffices to consider the case $a \\geq 0$: $y=ax+b$ and $y=-ax+b$ intersect $y=f(x)$ the same number of times. For $a=0$, by the symmetry of $y=f(x)$ and the fact that $f(x)> 0$ for all $x\\neq 0$ implies that the only line $y=b$ that intersects $y=f(x)$ exactly once is the line $y=0$.\n\nWe next observe that on $[0,\\infty)$, $f'(x) = \\frac{2x}{1+x^2}$ increases on $[0,1]$ from $f'(0)=0$ to a maximum at $f'(1)=1$, and then decreases on $[1,\\infty)$ with $\\lim_{x\\to\\infty} f'(x)=0$. In particular, $f'(x) \\leq 1$ for all $x$ (including $x<0$ since then $f'(x)<0$) and $f'(x)$ achieves each value in $(0,1)$ exactly twice on $[0,\\infty)$.\n\nFor $a \\geq 1$, we claim that any line $y=ax+b$ intersects $y=f(x)$ exactly once. They must intersect at least once by the intermediate value theorem: for $x\\ll 0$, $ax+b<0<f(x)$, while for $x \\gg 0$, $ax+b>f(x)$ since $\\lim_{x\\to\\infty} \\frac{\\ln(1+x^2)}{x} = 0$. On the other hand, they cannot intersect more than once: for $a>1$, this follows from the mean value theorem, since $f'(x)<a$ for all $x$. For $a=1$, suppose that they intersect at two points $(x_0,y_0)$ and $(x_1,y_1)$. Then\n\\[\n1 = \\frac{y_1-y_0}{x_1-x_0} = \\frac{\\int_{x_0}^{x_1} f'(x)\\,dx}{x_1-x_0} < 1\n\\]\nsince $f'(x)$ is continuous and $f'(x) \\leq 1$ with equality only at one point.\n\nFinally we consider $0<a<1$. The equation $f'(x) = a$ has exactly two solutions, at $x=r_-$ and $x=r_+$ for $r_{\\pm}$ as defined above.\nIf we define $g(x) = f(x)-ax$, then $g'(r_\\pm)=0$; $g'$ is strictly decreasing on $(-\\infty,r_-)$, strictly increasing on $(r_-,r_+)$, and strictly decreasing on $(r_+,\\infty)$; and $\\lim_{x\\to-\\infty} g(x) = \\infty$ while $\\lim_{x\\to\\infty} g(x) = -\\infty$. It follows that $g(x)=b$ has exactly one solution for $b<g(r_-)$ or $b>g(r_+)$, exactly three solutions for $g(r_-)<b<g(r_+)$, and exactly two solutions for $b = g(r_\\pm)$. That is, $y=ax+b$ intersects $y=f(x)$ in exactly one point if and only if $b<g(r_-)$ or $b>g(r_+)$."
  },
  {
    "year": 2022,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $n$ be an integer with $n \\geq 2$. Over all real polynomials $p(x)$ of degree $n$, what is the largest possible number of negative coefficients of $p(x)^2$?",
    "solution": "The answer is $2n-2$. Write $p(x) = a_nx^n+\\cdots+a_1x+a_0$ and $p(x)^2 = b_{2n}x^{2n}+\\cdots+b_1x+b_0$. Note that $b_0 = a_0^2$ and $b_{2n} = a_n^2$. We claim that not all of the remaining $2n-1$ coefficients $b_1,\\ldots,b_{2n-1}$ can be negative, whence the largest possible number of negative coefficients is $\\leq 2n-2$. Indeed, suppose $b_i <0$ for $1\\leq i\\leq 2n-1$. Since $b_1 = 2a_0a_1$, we have $a_0 \\neq 0$. Assume $a_0>0$ (or else replace $p(x)$ by $-p(x)$). We claim by induction on $i$ that $a_i < 0$ for $1\\leq i\\leq n$. For $i=1$, this follows from $2a_0a_1 = b_1<0$. If $a_i<0$ for $1\\leq i\\leq k-1$, then\n\\[\n2a_0a_k = b_k - \\sum_{i=1}^{k-1} a_i a_{k-i} < b_k < 0\n\\]\nand thus $a_k<0$, completing the induction step. But now $b_{2n-1} = 2a_{n-1}a_n > 0$, contradiction.\n\nIt remains to show that there is a polynomial $p(x)$ such that $p(x)^2$ has $2n-2$ negative coefficients. For example, we may take\n\\[\np(x) = n(x^n+1) - 2(x^{n-1} + \\cdots + x),\n\\]\nso that\n\\begin{align*}\np(x)^2 &= n^2(x^{2n} + x^n + 1) - 2n(x^n+1)(x^{n-1}+\\cdots+x)\\\\\n&\\qquad \n+ (x^{n-1} + \\cdots + x)^2.\n\\end{align*}\nFor $i\\in \\{1,\\dots,n-1,n+1,\\dots,n-1\\}$, the coefficient of $x^i$ in $p(x)^2$ is at most $-2n$ (coming from the cross term)\nplus $-2n+2$ (from expanding $(x^{n-1} + \\cdots + x)^2$), and hence negative."
  },
  {
    "year": 2022,
    "label": "A3",
    "difficulty": "3",
    "problem": "Let $p$ be a prime number greater than 5. Let $f(p)$ denote the number of infinite sequences $a_1, a_2, a_3, \\dots$ such that\n$a_n \\in \\{1, 2, \\dots, p-1\\}$ and $a_n a_{n+2} \\equiv 1 + a_{n+1} \\pmod{p}$ for all $n \\geq 1$. Prove that $f(p)$ is congruent to 0 or 2 $\\pmod{5}$.",
    "solution": "\\textbf{First solution.}\nWe view the sequence $a_1,a_2,\\ldots$ as lying in $\\mathbb{F}_p^\\times \\subset \\mathbb{F}_p$.  Then the sequence is determined by the values of $a_1$ and $a_2$, via the recurrence $a_{n+2}=(1+a_{n+1})/a_n$.  Using this recurrence, we compute\n\\begin{gather*}\na_3=\\frac{1 + a_2}{a_1}, \\, a_4 = \\frac{1 + a_1 + a_2}{a_1 a_2}, \\\\\na_5=\\frac{1 + a_1}{a_2}, \\, a_6 = a_1, \\, a_7 = a_2 \n\\end{gather*}\nand thus the sequence is periodic with period 5.  The values for $a_1$ and $a_2$ may thus be any values in $\\mathbb{F}_p^\\times$ provided that $a_1\\neq p-1$, $a_2\\neq p-1$, and $a_1+a_2\\neq p-1$.  The number of choices for $a_1,a_2\\in\\{1,\\ldots,p-2\\}$ such that $a_1+a_2\\neq p-1$ is thus $(p-2)^2 - (p-2)= (p-2)(p-3)$.\n\nSince $p$ is not a multiple of 5, $(p-2)(p-3)$ is a product of two consecutive integers $a,a+1$, where $a\\not\\equiv 2 \\pmod{5}$. Now $0\\cdot 1\\equiv 0$, $1\\cdot 2 \\equiv 2$, $3\\cdot 4\\equiv 2$, and $4\\cdot 0 \\equiv 0$ (mod 5).  Thus the number of possible sequences $a_1,a_2,\\ldots$ is 0 or 2 (mod 5), as desired. \n\n\\noindent\n\\textbf{Second solution.}\nSay that a sequence is \\textit{admissible} if it satisfies the given conditions. As in the first solution, any admissible sequence is 5-periodic.\n\nNow consider the collection $S$ of possible $5$-tuples of numbers mod $p$ given by $(a_1,a_2,a_3,a_4,a_5)$ for admissible sequences $\\{a_n\\}$. Each of these $5$-tuples in $S$ comes from a unique admissible sequence, and there is a $5$-periodic action on $S$ given by cyclic permutation: $(a,b,c,d,e) \\rightarrow (b,c,d,e,a)$. This action divides $S$ into finitely many orbits, and each orbit either consists of $5$ distinct tuples (if $a,b,c,d,e$ are not all the same) or $1$ tuple $(a,a,a,a,a)$. It follows that the number of admissible sequences is a multiple of $5$ plus the number of constant admissible sequences.\n\nConstant admissible sequences correspond to nonzero numbers $a \\pmod{p}$ such that $a^2 \\equiv 1+a \\pmod{p}$.\nSince the quadratic $x^2-x-1$ has discriminant 5, for $p > 5$ it has either 2 roots (if the discriminant is a quadratic residue mod $p$) or 0 roots mod $p$."
  },
  {
    "year": 2022,
    "label": "A4",
    "difficulty": "4",
    "problem": "Suppose that $X_1, X_2, \\dots$ are real numbers between 0 and 1 that are chosen independently and uniformly at random. Let $S = \\sum_{i=1}^k X_i/2^i$, where $k$ is the least positive integer such that $X_k < X_{k+1}$, or $k = \\infty$ if there is no such integer. Find the expected value of $S$.",
    "solution": "The expected value is $2e^{1/2}-3$.\n\nExtend $S$ to an infinite sum by including zero summands for $i> k$. We may then compute the expected value as the sum of the expected value of the $i$-th summand over all $i$. This summand\noccurs if and only if $X_1,\\dots,X_{i-1} \\in [X_i, 1]$\nand $X_1,\\dots,X_{i-1}$ occur in nonincreasing order. These two events are independent and occur with respective probabilities $(1-X_i)^{i-1}$ and $\\frac{1}{(i-1)!}$; the expectation of this summand is therefore\n\\begin{align*}\n&\\frac{1}{2^i(i-1)!} \\int_0^1 t (1-t)^{i-1}\\,dt \\\\\n&\\qquad = \\frac{1}{2^i(i-1)!} \\int_0^1 ((1-t)^{i-1} - (1-t)^i)\\,dt \\\\\n&\\qquad = \\frac{1}{2^i(i-1)!} \\left( \\frac{1}{i} - \\frac{1}{i+1} \\right) = \\frac{1}{2^i (i+1)!}.\n\\end{align*}\nSumming over $i$, we obtain\n\\[\n\\sum_{i=1}^\\infty \\frac{1}{2^i (i+1)!}\n= 2 \\sum_{i=2}^\\infty \\frac{1}{2^i i!}\n= 2\\left(e^{1/2}-1-\\frac{1}{2} \\right).\n\\]"
  },
  {
    "year": 2022,
    "label": "A5",
    "difficulty": "5",
    "problem": "Alice and Bob play a game on a board consisting of one row of 2022 consecutive squares. They take turns placing tiles that cover two adjacent squares, with Alice going first. By rule, a tile must not cover a square that is already covered by another tile. The game ends when no tile can be placed according to this rule. Alice's goal is to maximize the number of uncovered squares when the game ends; Bob's goal is to minimize it. What is the greatest number of uncovered squares that Alice can ensure at the end of the game, no matter how Bob plays?",
    "solution": "We show that the number in question equals 290. More generally,\nlet $a(n)$ (resp.\\ $b(n)$) be the optimal final score for Alice (resp.\\ Bob) moving first in a position with $n$ consecutive squares. We show that\n\\begin{align*}\na(n) &= \\left\\lfloor \\frac{n}{7} \\right\\rfloor + a\\left(n - 7\\left\\lfloor \\frac{n}{7} \\right\\rfloor \\right), \\\\\nb(n) &= \\left\\lfloor \\frac{n}{7} \\right\\rfloor + b\\left(n - 7\\left\\lfloor \\frac{n}{7} \\right\\rfloor \\right),\n\\end{align*}\nand that the values for $n \\leq 6$ are as follows:\n\\[\n\\begin{array}{c|cccccccccc}\nn & 0 & 1 & 2 & 3 & 4 & 5 & 6 \\\\\n\\hline\na(n) & 0 & 1 & 0 & 1 & 2 & 1 & 2  \\\\\nb(n) & 0 & 1 & 0 & 1 & 0 & 1 & 0 \n\\end{array}\n\\]\nSince $2022 \\equiv 6 \\pmod{7}$, this will yield\n$a(2022) = 2 + \\lfloor \\frac{2022}{7} \\rfloor = 290$.\n\nWe proceed by induction, starting with the base cases $n \\leq 6$.\nSince the number of odd intervals never decreases, we have $a(n), b(n) \\geq n - 2 \\lfloor \\frac{n}{2} \\rfloor$; by looking at the possible final positions, we see that equality holds for $n=0,1,2,3,5$. For $n=4,6$, Alice moving first can split the original interval into two odd intervals, guaranteeing at least two odd intervals in the final position; whereas Bob can move to leave behind one or two intervals of length 2, guaranteeing no odd intervals in the final position.\n\nWe now proceed to the induction step. Suppose that $n \\geq 7$\nand the claim is known for all $m < n$. In particular, this means that $a(m) \\geq b(m)$; consequently, it does not change the analysis to allow a player to pass their turn after the first move, as both players will still have an optimal strategy which involves never passing.\n\nIt will suffice to check that\n\\[\na(n) = a(n-7) + 1, \\qquad b(n) = b(n-7) + 1.\n\\]\nMoving first, Alice can leave behind two intervals of length 1 and $n-3$. This shows that\n\\[\na(n) \\geq 1 + b(n-3) = a(n-7) + 1.\n\\]\nOn the other hand, if Alice leaves behind intervals of length $i$ and $n-2-i$, Bob can choose to play in either one of these intervals and then follow Alice's lead thereafter (exercising the pass option if Alice makes the last legal move in one of the intervals). \nThis shows that\n\\begin{align*}\na(n) &\\leq \\max\\{\\min\\{a(i) + b(n-2-i), \\\\\n& \\qquad b(i)+a(n-2-i)\\}: i =0,1,\\dots,n-2\\} \\\\\n&= a(n-7)+1.\n\\end{align*}\n\nMoving first, Bob can leave behind two intervals of lengths 2 and $n-4$. This shows that\n\\[\nb(n) \\leq a(n-4) = b(n-7) + 1.\n\\]\nOn the other hand, if Bob leaves behind intervals of length $i$ and $n-2-i$, Alice can choose to play in either one of these intervals and then follow Bob's lead thereafter (again passing as needed). This shows that\n\\begin{align*}\nb(n) &\\geq \\min\\{\\max\\{a(i) + b(n-2-i), \\\\\n& \\qquad b(i)+a(n-2-i)\\}: i =0,1,\\dots,n-2\\} \\\\\n&= b(n-7)+1.\n\\end{align*}\nThis completes the induction."
  },
  {
    "year": 2022,
    "label": "A6",
    "difficulty": "6",
    "problem": "Let $n$ be a positive integer. Determine, in terms of $n$, the largest integer $m$ with the following property: There exist real numbers $x_1,\\dots,x_{2n}$ with $-1 < x_1 < x_2 < \\cdots < x_{2n} < 1$ such that the sum of the lengths of the $n$ intervals\n\\[\n[x_1^{2k-1}, x_2^{2k-1}], [x_3^{2k-1},x_4^{2k-1}], \\dots, [x_{2n-1}^{2k-1}, x_{2n}^{2k-1}]\n\\]\nis equal to 1 for all integers $k$ with $1 \\leq k \\leq m$.",
    "solution": "\\textbf{First solution.}\nThe largest such $m$ is $n$.\nTo show that $m \\geq n$,\nwe take\n\\[\nx_j = \\cos \\frac{(2n+1-j)\\pi}{2n+1} \\qquad (j=1,\\dots,2n).\n\\]\nIt is apparent that $-1 < x_1 < \\cdots < x_{2n} < 1$.\nThe sum of the lengths of the intervals can be interpreted as\n\\begin{align*}\n& -\\sum_{j=1}^{2n} ((-1)^{2n+1-j} x_j)^{2k-1} \\\\\n&= -\\sum_{j=1}^{2n} \\left(\\cos (2n+1-j)\\left(\\pi + \\frac{\\pi}{2n+1} \\right)\\right)^{2k-1} \\\\\n&= -\\sum_{j=1}^{2n} \\left(\\cos \\frac{2\\pi(n+1)j}{2n+1}\\right)^{2k-1}.\n\\end{align*}\nFor $\\zeta = e^{2 \\pi i (n+1)/(2n+1)}$, this becomes\n\\begin{align*}\n&= -\\sum_{j=1}^{2n} \\left( \\frac{\\zeta^j + \\zeta^{-j}}{2} \\right)^{2k-1} \\\\\n&= -\\frac{1}{2^{2k-1}}\\sum_{j=1}^{2n} \\sum_{l=0}^{2k-1} \n\\binom{2k-1}{l} \\zeta^{j(2k-1-2l)} \\\\\n&= -\\frac{1}{2^{2k-1}} \\sum_{l=0}^{2k-1} \\binom{2k-1}{l}\n\\sum_{j=1}^{2n}\n\\zeta^{j(2k-1-2l)}  \\\\\n&= -\\frac{1}{2^{2k-1}} \\sum_{l=0}^{2k-1} \\binom{2k-1}{l}\n(-1) = 1,\n\\end{align*}\nusing the fact that $\\zeta^{2k-1-2l}$ is a \\emph{nontrivial} root of unity of order dividing $2n+1$.\n\nTo show that $m \\leq n$, we use the following lemma.\nWe say that a multiset $\\{x_1,\\dots,x_m\\}$ of complex numbers is \\emph{inverse-free} if there are no two indices $1 \\leq i \\leq j \\leq m$ such that $x_i + x_j = 0$; this implies in particular that 0 does not occur.\n\\begin{lemma*}\nLet $\\{x_1,\\dots,x_m\\},\\{y_1,\\dots,y_n\\}$ be two inverse-free multisets of complex numbers such that\n\\[\n\\sum_{i=1}^m x_i^{2k-1} = \\sum_{i=1}^n y_i^{2k-1} \\qquad (k=1,\\dots,\\max\\{m,n\\}).\n\\]\nThen these two multisets are equal.\n\\end{lemma*}\n\\begin{proof}\nWe may assume without loss of generality that $m \\leq n$.\nForm the rational functions\n\\[\nf(z) = \\sum_{i=1}^m \\frac{x_i z}{1 - x_i^2 z^2}, \\quad\ng(z) = \\sum_{i=1}^n \\frac{y_i z}{1 - y_i^2 z^2};\n\\]\nboth $f(z)$ and $g(z)$ have total pole order at most $2n$.\nMeanwhile, by expanding in power series around $z=0$, we see that $f(z)-g(z)$ is divisible by $z^{2n+1}$.\nConsequently, the two series are equal. \n\nHowever, we can uniquely recover the multiset $\\{x_1,\\dots,x_m\\}$ from $f(z)$: $f$ has poles at $\\{1/x_1^2,\\dots,1/x_m^2\\}$\nand the residue of the pole at $z = 1/x_i^2$ uniquely determines both $x_i$ (i.e., its sign) and its multiplicity.\nSimilarly, we may recover $\\{y_1,\\dots,y_n\\}$ from $g(z)$, so the two multisets must coincide.\n\\end{proof}\n\nNow suppose by way of contradiction that we have an example showing that $m \\geq n+1$. We then have\n\\[\n1^{2k-1} + \\sum_{i=1}^n x_{2i-1}^{2k-1} = \\sum_{i=1}^n x_{2i}^{2k-1} \\qquad (k=1,\\dots,n+1).\n\\]\nBy the lemma, this means that the multisets $\\{1,x_1,x_3,\\dots,x_{2n-1}\\}$ and $\\{x_2,x_4,\\dots,x_{2n}\\}$ become equal after removing pairs of inverses until this becomes impossible. However, of the resulting two multisets, the first contains 1 and the second does not, yielding the desired contradiction.\n\n\\noindent\n\\textbf{Remark.}\nOne can also prove the lemma using the invertibility of the Vandermonde matrix\n\\[\n(x_i^j)_{i=0,\\dots,n; j=0,\\dots,n}\n\\]\nfor $x_0,\\dots,x_n$ pairwise distinct (this matrix has determinant $\\prod_{0 \\leq i < j \\leq n}(x_i - x_j) \\neq 0$). For a similar argument, see\nProposition 22 of: M. Bhargava, Galois groups of random integer polynomials and van der Waerden's conjecture, arXiv:2111.06507.\n\n\\noindent\n\\textbf{Remark.}\nThe solution for $m=n$ given above is not unique (see below).\nHowever, it does become unique if we add the assumption that $x_i = -x_{2n+1-i}$ for $i=1,\\dots,2n$ (i.e., the set of intervals is symmetric around 0).\n\n\\noindent\n\\textbf{Second solution.} (by Evan Dummit)\nDefine the polynomial\n\\[\np(x) = (x-x_1)(x+x_2) \\cdots (x-x_{2n-1})(x+x_{2n})(x+1);\n\\]\nby hypothesis, $p(x)$ has $2n+1$ distinct real roots in the interval $[-1, 1)$. Let $s_k$ denote the $k$-th power sum of $p(x)$; then for any given $m$, the desired condition is that\n$s_{2k-1} = 0$ for $k=1,\\dots,m$.\nLet $e_k$ denote the $k$-th elementary symmetric function of the roots of $p(x)$; that is,\n\\[\np(x) = x^{2n+1} + \\sum_{i=k}^{2n+1} (-1)^k e_k x^{2n+1-k}.\n\\]\nBy the Girard--Newton identities,\n\\[\n(2k-1) e_{2k-1} = s_1 e_{2k-2} - s_2 e_{2k-2} + \\cdots - s_{2k} e_1;\n\\]\nhence the desired condition implies that $e_{2k-1} = 0$ for $k=1,\\dots,m$.\n\nIf we had a solution with $m=n+1$, then the vanishing of $e_1,\\dots,e_{2k+1}$ would imply that $p(x)$ is an odd polynomial (that is, $p(x) = -p(x)$ for all $x$), which in turn would imply that $x=1$ is also a root of $p$. Since we have already identified $2n+1$ other roots of $p$, this yields a contradiction.\n\nBy the same token, a solution with $m=n$ corresponds to a polynomial $p(x)$ of the form $xq(x^2) + a$ for some polynomial $q(x)$ of degree $n$ and some real number $a$ (necessarily equal to $q(1)$). It will thus suffice to choose $q(x)$ so that the resulting polynomial $p(x)$ has roots consisting of $-1$ plus $2n$ distinct values in $(-1,1)$. To do this, start with any polynomial $r(x)$ of degree $n$ with $n$ distinct positive roots (e.g., $r(x) = (x-1)\\cdots(x-n)$). \nThe polynomial $x r(x^2)$ then has $2n+1$ distinct real roots;\nconsequently, for $\\epsilon > 0$ sufficiently small, $xr(x^2) + \\epsilon$ also has $2n+1$ distinct real roots. Let $-\\alpha$ be the smallest of these roots (so that $\\alpha > 0$); we then take $q(x) = r(x\\sqrt{\\alpha})$ to achieve the desired result.\n\n\\noindent\n\\textbf{Remark.}\nBrian Lawrence points out that one can also produce solutions for $m=n$ by starting with the degenerate solution\n\\[\n-a_{n-1}, \\ldots, -a_1, 0, a_1, \\ldots, a_{n-1}, 1\n\\]\n(where $0 < a_1 < \\cdots < a_{n-1} < 1$ but no other conditions are imposed) and deforming it using the implicit function theorem. More\nprecisely, there exists a differentiable parametric solution $x_1(t),\\dots,x_{2n}(t)$ with $x_i(t) = x_{2n-i}(t)$ for $i=1,\\dots,n-1$ specializing to the previous solution at $t=0$,\nsuch that $x_i'(0) \\neq 0$ for $i=n,\\dots,2n$; this is because the Jacobian matrix\n\\[\nJ = ((2k-1) x_i(0)^{2k-2})_{i=n,\\dots,2n; k=1,\\dots,n}\n\\]\n(interpreting $0^0$ as $1$) has the property that every maximal minor is nonzero (these being scaled Vandermonde matrices).\nIn particular we may normalize so that $x_{2n}'(0) < 0$, and then evaluating at a small positive value of $t$ gives the desired example.\n\nIn the proof that $m=n+1$ cannot occur, one can similarly use the implicit function theorem (with some care) to reduce to the case where $\\{|x_1|,\\dots,|x_{2n}|\\}$ has cardinality $n+1$. This can be extended to a complete solution, but the details are rather involved."
  },
  {
    "year": 2022,
    "label": "B1",
    "difficulty": "1",
    "problem": "Suppose that $P(x) = a_1 x + a_2 x^2 + \\cdots + a_n x^n$ is a polynomial with integer coefficients, with $a_1$ odd. Suppose that $e^{P(x)} = b_0 + b_1 x + b_2 x^2 + \\cdots$ for all $x$. Prove that $b_k$ is nonzero for all $k \\geq 0$.",
    "solution": "We prove that $b_k k!$ is an odd integer for all $k \\geq 0$.\n\n\\textbf{First solution.}\nSince $e^{P(x)} = \\sum_{n=0}^\\infty \\frac{(P(x))^n}{n!}$, the number $k!\\,b_k$ is the coefficient of $x^k$ in\n\\[\n(P(x))^k + \\sum_{n=0}^{k-1} \\frac{k!}{n!}(P(x))^n.\n\\]\nIn particular, $b_0=1$ and $b_1=a_1$ are both odd. \n\nNow suppose $k \\geq 2$; we want to show that $b_k$ is odd. The coefficient of $x^k$ in $(P(x))^k$ is $a_1^k$. It suffices to show that the coefficient of $x^k$ in $\\frac{k!}{n!}(P(x))^n$ is an even integer for any $n<k$. For $k$ even or $n \\leq k-2$, this follows immediately from the fact that $\\frac{k!}{n!}$ is an even integer. For $k$ odd and $n=k-1$, we have\n\\begin{align*}\n\\frac{k!}{(k-1)!}(P(x))^{k-1} &= k(a_1x+a_2x^2+\\cdots)^{k-1} \\\\\n&= k(a_1^{k-1}x^{k-1}+(k-1)a_1^{k-2}a_2x^k+\\cdots)\n\\end{align*}\nand the coefficient of $x^k$ is $k(k-1)a_1^{k-2}a_2$, which is again an even integer.\n\n\\noindent\n\\textbf{Second solution.}\nLet $G$ be the set of power series of the form $\\sum_{n=0}^\\infty c_n \\frac{x_n}{n!}$ with $c_0 = 1, c_n \\in \\mathbb{Z}$; then $G$ forms a group under formal series multiplication because\n\\[\n\\left( \\sum_{n=0}^\\infty c_n \\frac{x^n}{n!} \\right)\n\\left( \\sum_{n=0}^\\infty d_n \\frac{x^n}{n!} \\right)\n= \\sum_{n=0}^\\infty e_n \\frac{x^n}{n!} \n\\]\nwith\n\\[\ne_n = \\sum_{m=0}^n \\binom{n}{m} c_m d_{n-m}.\n\\]\nBy the same calculation, the subset $H$ of series with $c_n \\in 2\\mathbb{Z}$ for all $n \\geq 1$ is a subgroup of $G$.\n\nWe have $e^{2x} \\in H$ because $\\frac{2^n}{n!} \\in 2\\mathbb{Z}$ for all $n \\geq 1$: the exponent of 2 in the prime factorization of $n!$ is\n\\[\n\\sum_{i=1}^\\infty \\left\\lfloor \\frac{n}{2^i} \\right\\rfloor\n< \\sum_{i=1}^\\infty \\frac{n}{2^i} = n.\n\\]\nFor any integer $k \\geq 2$, we have $e^{x^k} \\in H$ because $\\frac{(nk)!}{n!} \\in 2\\mathbb{Z}$ for all $n \\geq 1$: this is clear if $k=2,n=1$, and in all other cases the ratio is divisible by $(n+1)(n+2)$. \n\nWe deduce that $e^{P(x)-x} \\in H$.\nBy writing $e^{P(x)}$ as $e^x = \\sum_{n=0}^\\infty \\frac{x^n}{n!}$\ntimes an element of $H$, we deduce that $k! b_k$ is odd for all $k \\geq 0$.\n\n\\noindent\n\\textbf{Third solution.}\n(by David Feldman)\nWe interpret $e^{P(x)}$ using the exponential formula for generating functions.\nFor each $j$, choose a set $S_j$ consisting of $|a_j|$ colors.\nThen $b_k$ is a weighted count over set partitions of $\\{1,\\dots,k\\}$, with each part of size $j$ assigned a color in $S_j$, and the weight being $(-1)^i$ where $i$ is the number of parts of any size $j$ for which $a_j < 0$.\n\nSince we are only looking for the parity of $b_k$, we may dispense with the signs; that is, we may assume $a_j \\geq 0$ for all $j$\nand forget about the weights.\n\nChoose an involution on each $S_j$ with at most one fixed point; this induces an involution on the partitions, so to find the parity of $b_k$ we may instead count fixed points of the involution. That is, we may assume that $a_j \\in \\{0,1\\}$.\n\nLet $T_k$ be the set of set partitions in question with the all-singletons partition removed; it now suffices to exhibit a fixed-point-free involution of $T_k$. To wit, for each partition in $T_k$, there is a smallest index $i \\in \\{1,\\dots,k-1\\}$ for which $i$ and $i+1$ are not both singletons; we define an involution by swapping the positions of $i$ and $i+1$."
  },
  {
    "year": 2022,
    "label": "B2",
    "difficulty": "2",
    "problem": "Let $\\times$ represent the cross product in $\\mathbb{R}^3$. For what positive integers $n$ does there exist a set $S \\subset \\mathbb{R}^3$ with exactly $n$ elements such that \n\\[\nS = \\{v \\times w: v, w \\in S\\}?\n\\]",
    "solution": "The possible values of $n$ are 1 and 7.\n\nClearly the set $S = \\{0\\}$ works. Suppose that $S \\neq \\{0\\}$ is a finite set satisfying the given condition; in particular, $S$ does not consist of a collection of collinear vectors, since otherwise $\\{v \\times w: v,w \\in S\\} = \\{0\\}$. We claim that $S$ cannot contain any nonzero vector $v$ with $\\|v\\| \\neq 1$. Suppose otherwise, and let $w \\in S$ be a vector not collinear with $v$. Then $S$ must contain the nonzero vector $u_1 = v\\times w$, as well as the sequence of vectors $u_n$ defined inductively by $u_n = v \\times u_{n-1}$. Since each $u_n$ is orthogonal to $v$ by construction, we have $\\|u_n\\| = \\|v\\| \\|u_{n-1}\\|$ and so $\\|u_n\\| = \\|v\\|^{n-1} \\|u_1\\|$. The sequence $\\|u_n\\|$ consists of all distinct numbers and thus $S$ is infinite, a contradiction. This proves the claim, and so every nonzero vector in $S$ is a unit vector.\n\nNext note that any pair of vectors $v,w \\in S$ must either be collinear or orthogonal: by the claim, $v,w$ are both unit vectors, and if $v,w$ are not collinear then $v\\times w \\in S$ must be a unit vector, whence $v\\perp w$. Now choose any pair of non-collinear vectors $v_1,v_2 \\in S$, and write $v_3 = v_1 \\times v_2$. Then $\\{v_1,v_2,v_3\\}$ is an orthonormal basis of $\\mathbb{R}^3$, and it follows that all of these vectors are in $S$: $0$, $v_1$, $v_2$, $v_3$, $-v_1 = v_3 \\times v_2$, $-v_2 = v_1 \\times v_3$, and $-v_3 = v_2 \\times v_1$. On the other hand, $S$ cannot contain any vector besides these seven, since any other vector $w$ in $S$ would have to be simultaneously orthogonal to all of $v_1,v_2,v_3$.\n\nThus any set $S \\neq \\{0\\}$ satisfying the given condition must be of the form $\\{0,\\pm v_1,\\pm v_2,\\pm v_3\\}$ where $\\{v_1,v_2,v_3\\}$ is an orthonormal basis of $\\mathbb{R}^3$. It is clear that any set of this form does satisfy the given condition. We conclude that the answer is $n=1$ or $n=7$."
  },
  {
    "year": 2022,
    "label": "B3",
    "difficulty": "3",
    "problem": "Assign to each positive real number a color, either red or blue. Let $D$ be the set of all distances $d > 0$ such that there are two points of the same color at distance $d$ apart. Recolor the positive reals so that the numbers in $D$ are red and the numbers not in $D$ are blue. If we iterate this recoloring process, will we always end up with all the numbers red after a finite number of steps?\n\n\\smallskip",
    "solution": "The answer is yes. Let $R_0,B_0 \\subset \\mathbb{R}^+$ be the set of red and blue numbers at the start of the process, and let $R_n,B_n$ be the set of red and blue numbers after $n$ steps. We claim that $R_2 = \\mathbb{R}^+$.\n\nWe first note that if $y \\in B_1$, then $y/2 \\in R_1$. Namely, the numbers $y$ and $2y$ must be of opposite colors in the original coloring, and then $3y/2$ must be of the same color as one of $y$ or $2y$. \n\nNow suppose by way of contradiction that $x \\in B_2$. Then of the four numbers $x,2x,3x,4x$, every other number must be in $R_1$ and the other two must be in $B_1$. By the previous observation, $2x$ and $4x$ cannot both be in $B_1$; it follows that $2x,4x \\in R_1$ and $x,3x \\in B_1$. By the previous observation again, $x/2$ and $3x/2$ must both be in $R_1$, but then $x = 3x/2-x/2$ is in $R_2$, contradiction. We conclude that $R_2 = \\mathbb{R}^+$, as desired."
  },
  {
    "year": 2022,
    "label": "B4",
    "difficulty": "4",
    "problem": "Find all integers $n$ with $n \\geq 4$ for which there exists a sequence of distinct real numbers $x_1,\\dots,x_n$ such that each of the sets\n\\begin{gather*}\n\\{x_1,x_2,x_3\\}, \\{x_2,x_3,x_4\\}, \\dots, \\\\\n\\{x_{n-2},x_{n-1},x_n\\}, \\{x_{n-1},x_n, x_1\\}, \\mbox{ and } \\{x_n, x_1, x_2\\}\n\\end{gather*}\nforms a 3-term arithmetic progression when arranged in increasing order.",
    "solution": "The values of $n$ in question are the multiples of 3 starting with 9. Note that we interpret ``distinct'' in the problem statement to mean ``pairwise distinct'' (i.e., no two equal). See the remark below.\n\nWe first show that such a sequence can only occur when $n$ is divisible by 3.\nIf $d_1$ and $d_2$ are the common differences of the arithmetic progressions $\\{x_m, x_{m+1}, x_{m+2}\\}$ and $\\{x_{m+1}, x_{m+2}, x_{m+3}\\}$ for some $m$, then $d_2 \\in \\{d_1, 2d_1, d_1/2\\}$. \nBy scaling we may assume that the smallest common difference that occurs is 1; in this case, all of the common differences are integers. By shifting, we may assume that the $x_i$ are themselves all integers. We now observe that any three consecutive terms in the sequence have pairwise distinct residues modulo 3, \nforcing $n$ to be divisible by 3.\n\nWe then observe that for any $m \\geq 2$, \nwe obtain a sequence of the desired form of length $3m+3 = (2m-1)+1+(m+1)+2$ by\nconcatenating the arithmetic progressions\n\\begin{gather*}\n(1, 3, \\dots, 4m-3, 4m-1), \\\\\n4m-2, (4m, 4m-4, \\dots, 4, 0), 2.\n\\end{gather*}\nWe see that no terms are repeated by noting that the first parenthesized sequence consists of odd numbers; the second sequence consists of multiples of 4; and the remaining numbers $2$ and $4m-2$ are distinct (because $m \\geq 2$) but both congruent to 2 mod 4.\n\nIt remains to show that no such sequence occurs with $n=6$.\nWe may assume without loss of generality that the smallest common difference among the arithmetic progressions is 1 and occurs for $\\{x_1, x_2, x_3\\}$; by rescaling, shifting, and reversing the sequence as needed, we may assume that\n$x_1 = 0$ and $(x_2, x_3) \\in \\{(1,2), (2,1)\\}$.\nWe then have $x_4 = 3$ and\n\\[\n(x_5, x_6) \\in \\{(4,5), (-1, -5), (-1, 7), (5, 4), (5, 7)\\}.\n\\]\nIn none of these cases does $\\{x_5, x_6, 0\\}$ form an arithmetic progression.\n\n\\noindent\n\\textbf{Remark.}\nIf one interprets ``distinct'' in the problem statement to mean ``not all equal'', then the problem becomes simpler:\nthe same argument as above shows that $n$ must be a multiple of 3, in which case a suitable repetition of the sequence $-1,0,1$ works."
  },
  {
    "year": 2022,
    "label": "B5",
    "difficulty": "5",
    "problem": "For $0 \\leq p \\leq 1/2$, let $X_1, X_2, \\dots$ be independent random variables such that\n\\[\nX_i = \\begin{cases} 1 & \\mbox{with probability $p$,} \\\\\n-1 & \\mbox{with probability $p$,} \\\\\n0 & \\mbox{with probability $1-2p$,}\n\\end{cases}\n\\]\nfor all $i \\geq 1$. Given a positive integer $n$ and integers $b, a_1, \\dots, a_n$, let $P(b, a_1, \\dots, a_n)$ denote the probability that $a_1 X_1 + \\cdots + a_n X_n = b$. For which values of $p$ is it the case that\n\\[\nP(0, a_1, \\dots, a_n) \\geq P(b, a_1, \\dots, a_n)\n\\]\nfor all positive integers $n$ and all integers $b, a_1, \\dots, a_n$?",
    "solution": "\\textbf{First solution.}\nThe answer is $p \\leq 1/4$. We first show that $p >1/4$ does not satisfy the desired condition. For $p>1/3$, $P(0,1) = 1-2p < p = P(1,1)$. For $p=1/3$, it is easily calculated (or follows from the next calculation) that $P(0,1,2) = 1/9 < 2/9 = P(1,1,2)$. Now suppose $1/4 < p < 1/3$, and consider $(b,a_1,a_2,a_3,\\ldots,a_n) = (1,1,2,4,\\ldots,2^{n-1})$.  The only solution to\n\\[\nX_1+2X_2+\\cdots+2^{n-1}X_n = 0\n\\]\nwith $X_j \\in \\{0,\\pm 1\\}$ is $X_1=\\cdots=X_n=0$; thus $P(0,1,2,\\ldots,2^{2n-1}) = (1-2p)^n$. On the other hand, the solutions to\n\\[\nX_1+2X_2+\\cdots+2^{n-1}X_n = 1\n\\]\nwith $X_j \\in \\{0,\\pm 1\\}$ are \n\\begin{gather*}\n(X_1,X_2,\\ldots,X_n) = (1,0,\\ldots,0),(-1,1,0,\\ldots,0), \\\\\n(-1,-1,1,0,\\ldots,0), \\ldots, (-1,-1,\\ldots,-1,1),\n\\end{gather*}\nand so\n\\begin{align*}\n&P(1,1,2,\\ldots,2^{n-1}) \\\\\n& = p(1-2p)^{n-1}+p^2(1-2p)^{n-2}+\\cdots+p^n \\\\\n&= p\\frac{(1-2p)^{n}-p^{n}}{1-3p}.\n\\end{align*}\nIt follows that the inequality\n$P(0,1,2,\\ldots,2^{n-1}) \\geq P(1,1,2,\\ldots,2^{n-1})$ is equivalent to \n\\[\np^{n+1} \\geq (4p-1)(1-2p)^n,\n\\]\nbut this is false for sufficiently large $n$ since $4p-1>0$ and $p<1-2p$.\n\nNow suppose $p \\leq 1/4$; we want to show that for arbitrary $a_1,\\ldots,a_n$ and $b \\neq 0$, $P(0,a_1,\\ldots,a_n) \\geq P(b,a_1,\\ldots,a_n)$. Define the polynomial\n\\[\nf(x) = px+px^{-1}+1-2p, \n\\]\nand observe that $P(b,a_1,\\ldots,a_n)$ is the coefficient of $x^b$ in\n$f(x^{a_1})f(x^{a_2})\\cdots f(x^{a_n})$. We can write\n\\[\nf(x^{a_1})f(x^{a_2})\\cdots f(x^{a_n}) = g(x)g(x^{-1})\n\\]\nfor some real polynomial $g$: indeed, if we define $\\alpha = \\frac{1-2p+\\sqrt{1-4p}}{2p} > 0$, then $f(x) = \\frac{p}{\\alpha}(x+\\alpha)(x^{-1}+\\alpha)$, and so we can use\n\\[\ng(x) = \\left(\\frac{p}{\\alpha}\\right)^{n/2} (x^{a_1}+\\alpha)\\cdots(x^{a_n}+\\alpha).\n\\]\n\nIt now suffices to show that in $g(x)g(x^{-1})$, the coefficient of $x^0$ is at least as large as the coefficient of $x^b$ for any $b \\neq 0$. Since $g(x)g(x^{-1})$ is symmetric upon inverting $x$, we may assume that $b > 0$. If we write $g(x) = c_0 x^0 + \\cdots + c_m x^m$, then the coefficients of $x^0$ and $x^b$ in $g(x)g(x^{-1})$ are $c_0^2+c_1^2+\\cdots+c_m^2$ and $c_0c_b+c_1c_{b+1}+\\cdots+c_{m-b}c_m$, respectively. But\n\\begin{align*}\n&2(c_0c_b+c_1c_{b+1}+\\cdots+c_{m-b}c_m)\\\\\n&\\leq (c_0^2+c_b^2)+(c_1^2+c_{b+1}^2)+\\cdots+(c_{m-b}^2+c_m^2) \\\\\n& \\leq\n2(c_0^2+\\cdots+c_m^2),\n\\end{align*}\nand the result follows.\n\n\\noindent\n\\textbf{Second solution.} (by Yuval Peres)\nWe check that $p \\leq 1/4$ is necessary as in the first solution. To check that it is sufficient, we introduce the following concept: for $X$ a random variable taking finitely many integer values, define the \\emph{characteristic function}\n\\[\n\\varphi_X(\\theta) = \\sum_{\\ell \\in \\mathbb{Z}} P(X = \\ell) e^{i \\ell \\theta}\n\\]\n(i.e., the expected value of $e^{i X\\theta}$, or \nthe Fourier transform of the probability measure corresponding to $X$). We use two evident properties of these functions:\n\\begin{itemize}\n\\item\nIf $X$ and $Y$ are independent, then $\\varphi_{X+Y}(\\theta) = \\varphi_X(\\theta) + \\varphi_Y(\\theta)$.\n\\item\nFor any $b \\in \\mathbb{Z}$,\n\\[\nP(X = b) = \\frac{1}{2} \\int_0^{2\\pi} e^{-ib\\theta} \\varphi_X(\\theta)\\,d\\theta.\n\\]\nIn particular, if $\\varphi_X(\\theta) \\geq 0$ for all $\\theta$, then\n$P(X=b) \\leq P(X = 0)$.\n\\end{itemize}\n\nFor $p \\leq 1/4$, we have\n\\[\n\\varphi_{X_k}(\\theta) = (1-2p) + 2p \\cos (\\theta) \\geq 0.\n\\]\nHence for $a_1,\\dots,a_n \\in \\mathbb{Z}$, the random variable $S = a_1 X_1 + \\cdots + a_n X_n$ satisfies\n\\[\n\\varphi_S(\\theta) = \\prod_{k=1}^n \\varphi_{a_kX_k}(\\theta)\n= \\prod_{k=1}^n \\varphi_{X_k}(a_k\\theta) \\geq 0.\n\\]\nWe may thus conclude that $P(S=b) \\leq P(S=0)$ for any $b \\in \\mathbb{Z}$, as desired."
  },
  {
    "year": 2022,
    "label": "B6",
    "difficulty": "6",
    "problem": "Find all continuous functions $f: \\mathbb{R}^+ \\to \\mathbb{R}^+$ such that\n\\[\nf(xf(y)) + f(yf(x)) = 1 + f(x+y)\n\\]\nfor all $x,y > 0$.\n\\end{itemize}\n\n\\end{document}",
    "solution": "The only such functions are the functions $f(x) = \\frac{1}{1+cx}$\nfor some $c \\geq 0$ (the case $c=0$ giving the constant function $f(x) = 1$). \nNote that we interpret $\\mathbb{R}^+$ in the problem statement to mean the set of positive real numbers, excluding 0.\n\nFor convenience, we reproduce here the given equation:\n\\begin{equation} \\label{eq:B61}\nf(xf(y)) + f(yf(x)) = 1 + f(x+y)\n\\end{equation}\n\nWe first prove that\n\\begin{equation} \\label{eq:B62}\n\\lim_{x \\to 0^+} f(x) = 1.\n\\end{equation}\nSet\n\\[\nL_- = \\liminf_{x \\to 0^+} f(x),\n\\quad\nL_+ = \\limsup_{x \\to 0^+} f(x).\n\\]\nFor any fixed $y$, we have by \\eqref{eq:B61}\n\\begin{align*}\nL_+ &= \\limsup_{x \\to 0^+} f(xf(y)) \\\\\n&\\leq \\limsup_{x \\to0^+} (1+f(x+y))\n= 1+f(y) < \\infty.\n\\end{align*}\nConsequently, $xf(x) \\to 0$ as $x \\to 0^+$.\nBy \\eqref{eq:B62} with $y=x$,\n\\begin{align*}\n2L_+ &= \\limsup_{x \\to 0^+} 2f(xf(x)) \\\\\n&= \\limsup_{x \\to 0^+} (1 + f(2x)) = 1 + L_+ \\\\\n2L_- &= \\liminf_{x \\to 0^+} 2f(xf(x)) \\\\\n&= \\liminf_{x \\to 0^+} (1 + f(2x)) = 1 + L_-\n\\end{align*}\nand so $L_- = L_+ = 1$, confirming \\eqref{eq:B62}.\n\nWe next confirm that\n\\begin{equation} \\label{eq:B63}\nf(x) \\geq 1 \\mbox{ for all } x>0 \\Longrightarrow f(x) = 1 \\mbox{ for all } x>0.\n\\end{equation}\nSuppose that $f(x) \\geq 1$ for all $x > 0$.\nFor $0 < c \\leq \\infty$, put $S_c = \\sup\\{f(x): 0 < x \\leq c\\}$;\nfor $c < \\infty$, \\eqref{eq:B62} implies that $S_c < \\infty$.\nIf there exists $y>0$ with $f(y) > 1$, then from \\eqref{eq:B61} we have $f(x+y) - f(xf(y)) = f(yf(x)) - 1 \\geq 0$;\nhence\n\\[\nS_c = S_{(c-y)f(y)} \\qquad \\left(c \\geq c_0 = \\frac{yf(y)}{f(y)-1}\\right)\n\\]\nand (since $(c-y)f(y) - c_0 = f(y)(c-c_0)$) iterating this construction shows that $S_\\infty = S_c$ for any $c > c_0$.\nIn any case, we deduce that \n\\begin{equation} \\label{eq:B64}\nf(x) \\geq 1 \\mbox{ for all } x>0 \\Longrightarrow S_\\infty < \\infty.\n\\end{equation}\nStill assuming that $f(x) \\geq 1$ for all $x>0$,\nnote that from \\eqref{eq:B61} with $x=y$,\n\\[\nf(xf(x)) = \\frac{1}{2}(1 + f(2x)).\n\\]\nSince $xf(x) \\to 0$ as $x \\to 0^+$ by \\eqref{eq:B62} and $xf(x) \\to \\infty$ as $x \\to \\infty$, $xf(x)$ takes all positive real values by the intermediate value theorem. We deduce that $2S_\\infty \\leq 1 + S_\\infty$ and hence $S_\\infty = 1$; \nthis proves \\eqref{eq:B63}.\n\nWe may thus assume hereafter that $f(x) < 1$ for some $x > 0$.\nWe next check that\n\\begin{equation} \\label{eq:B65}\n\\lim_{x \\to \\infty} f(x) = 0.\n\\end{equation}\nPut $I = \\inf\\{f(x): x > 0\\} < 1$, choose $\\epsilon \\in (0, (1-I)/2)$, and choose $y>0$ such that $f(y) < I+\\epsilon$. We then must have $xf(x) \\neq y$ for all $x$, or else\n\\[\n1 + I \\leq 1 + f(2x) = 2f(y) < 2I + 2\\epsilon,\n\\]\ncontradiction. Since $xf(x) \\to 0$ as $x \\to 0^+$ by \\eqref{eq:B62}, we have $\\sup\\{xf(x): x > 0\\} < \\infty$ by the intermediate value theorem, yielding \\eqref{eq:B65}.\n\nBy \\eqref{eq:B62} plus \\eqref{eq:B65},\n$f^{-1}(1/2)$ is nonempty and compact.\nWe can now simplify by noting that if $f(x)$ satisfies the original equation, then so does $f(cx)$ for any $c>0$; we may thus assume\nthat the least element of $f^{-1}(1/2)$ is 1,\nin which case we must show that $f(x) = \\frac{1}{1+x}$.\n\nWe next show that\n\\begin{equation}  \\label{eq:B68}\n\\lim_{x \\to \\infty} xf(x) = 1.\n\\end{equation}\nFor all $x > 0$,\nby \\eqref{eq:B61} with $y=x$,\n\\begin{equation} \\label{eq:B68a}\nf(xf(x)) = \\frac{1}{2}(1 + f(2x)) > \\frac{1}{2} = f(1),\n\\end{equation}\nso in particular $xf(x) \\neq 1$.\nAs in the proof of \\eqref{eq:B65}, this implies that $xf(x) < 1$ for all $x > 0$.\nHowever, by \\eqref{eq:B65} and \\eqref{eq:B68a}\nwe have $f(xf(x)) \\to \\frac{1}{2}$ as $x \\to \\infty$,\nyielding \\eqref{eq:B68}.\n\nBy substituting $y \\mapsto xy$ in \\eqref{eq:B61},\n\\[\nf(xf(xy)) + f(xyf(x)) = 1 + f(x+xy).\n\\]\nTaking the limit as $x \\to \\infty$ and applying \\eqref{eq:B68} yields\n\\begin{equation} \\label{eq:B69}\nf(1/y) + f(y) = 1.\n\\end{equation}\nCombining  \\eqref{eq:B61} with \\eqref{eq:B69} yields\n\\[\nf(xf(y))=f(x+y)+f \\left( \\frac{1}{yf(x)} \\right).\n\\]\nMultiply both sides by $xf(y)$, then take the limit as $x \\to \\infty$ to obtain\n\\begin{align*}\n1 &= \\lim_{x \\to \\infty} xf(y) f(x+y) + \\lim_{x \\to \\infty} xf(y) \nf\\left( \\frac{1}{yf(x)} \\right) \\\\\n&= f(y) + \\lim_{x \\to \\infty} xf(y) yf(x) \\\\\n&= f(y) + yf(y)\n\\end{align*}\nand solving for $f(y)$ now yields $f(y) = \\frac{1}{1+y}$, as desired.\n\n\\noindent\n\\textbf{Remark.}\nSome variants of the above approach are possible. For example,\nonce we have \\eqref{eq:B65}, we can establish that $f$ is monotone decreasing as follows. We first check that\n\\begin{equation} \\label{eq:B66}\nf(x) < 1 \\mbox{ for all } x > 0.\n\\end{equation}\nSuppose by way of contradiction that $f(x) = 1$ for some $x$.\nBy \\eqref{eq:B61},\n\\[\nf(2x) + 1 = 2f(xf(x)) = 2f(x) = 2\n\\]\nand so $f(2x) = 1$. It follows that $f^{-1}(1)$ is infinite, contradicting \\eqref{eq:B65}.\n\n\nWe next check that\n\\begin{equation} \\label{eq:B67}\nx<y \\Longrightarrow f(x) > f(y).\n\\end{equation}\nFor $x < y$, by substituting $x \\mapsto y-x$ in \\eqref{eq:B61} we obtain\n\\begin{align*}\n1+f(y) &= f(xf(y-x)) + f((y-x)f(x)) \\\\\n&< 1 + f((y-x)f(x)),\n\\end{align*}\nwhence $f((y-x)f(x))> f(y)$. Because $(y-x)f(x) \\to 0$ as $x \\to y^-$ and $(y-x)f(x) \\to y$ as $x \\to 0^+$, $(y-x)f(x)$ takes all values in $(0,y)$ as $x$ varies over $(0,y)$; this proves \\eqref{eq:B67}.\n\n\n\\end{itemize}\n\\end{document}"
  },
  {
    "year": 2023,
    "label": "A1",
    "difficulty": "1",
    "problem": "For a positive integer $n$, let $f_n(x) = \\cos(x) \\cos(2x) \\cos(3x) \\cdots \\cos(nx)$. Find the smallest $n$ such that $|f_n''(0)| > 2023$.",
    "solution": "If we use the product rule to calculate $f_n''(x)$, the result is a sum of terms of two types: terms where two distinct factors $\\cos(m_1x)$ and $\\cos(m_2x)$ have each been differentiated once, and terms where a single factor $\\cos(mx)$ has been differentiated twice. When we evaluate at $x=0$, all terms of the first type vanish since $\\sin(0)=0$, while the term of the second type involving $(\\cos(mx))''$ becomes $-m^2$. Thus \n\\[\n|f_n''(0)| = \\left|-\\sum_{m=1}^n m^2\\right| = \\frac{n(n+1)(2n+1)}{6}.\n\\]\nThe function $g(n) = \\frac{n(n+1)(2n+1)}{6}$ is increasing for $n\\in\\mathbb{N}$ and satisfies $g(17)=1785$ and $g(18)=2109$. It follows that the answer is $n=18$."
  },
  {
    "year": 2023,
    "label": "A2",
    "difficulty": "2",
    "problem": "Let $n$ be an even positive integer. Let $p$ be a monic, real polynomial of degree $2n$; that is to say, $p(x) = x^{2n} + a_{2n-1} x^{2n-1} + \\cdots + a_1 x + a_0$ for some real coefficients $a_0, \\dots, a_{2n-1}$. Suppose that $p(1/k) = k^2$ for all integers $k$ such that $1 \\leq |k| \\leq n$. Find all other real numbers $x$ for which $p(1/x) = x^2$.",
    "solution": "The only other real numbers with this property are $\\pm 1/n!$.\n(Note that these are indeed \\emph{other} values than $\\pm 1, \\dots, \\pm n$ because $n>1$.)\n\nDefine the polynomial $q(x) = x^{2n+2}-x^{2n}p(1/x) = x^{2n+2}-(a_0x^{2n}+\\cdots+a_{2n-1}x+1)$. The statement that $p(1/x)=x^2$ is equivalent (for $x\\neq 0$) to the statement that $x$ is a root of $q(x)$. Thus we know that $\\pm 1,\\pm 2,\\ldots,\\pm n$ are roots of $q(x)$, and we can write\n\\[\nq(x) = (x^2+ax+b)(x^2-1)(x^2-4)\\cdots (x^2-n^2)\n\\]\nfor some monic quadratic polynomial $x^2+ax+b$. Equating the coefficients of $x^{2n+1}$ and $x^0$ on both sides gives $0=a$ and $-1=(-1)^n(n!)^2 b$, respectively. Since $n$ is even, we have $x^2+ax+b = x^2-(n!)^{-2}$. We conclude that there are precisely two other real numbers $x$ such that $p(1/x)=x^2$, and they are $\\pm 1/n!$."
  },
  {
    "year": 2023,
    "label": "A3",
    "difficulty": "3",
    "problem": "Determine the smallest positive real number $r$ such that there exist differentiable functions $f\\colon \\mathbb{R} \\to \\mathbb{R}$ and\n$g\\colon \\mathbb{R} \\to \\mathbb{R}$ satisfying\n\\begin{enumerate}",
    "solution": "The answer is $r=\\frac{\\pi}{2}$, which manifestly is achieved by setting $f(x)=\\cos x$ and $g(x)=\\sin x$.\n\n\\noindent\n\\textbf{First solution.}\nSuppose by way of contradiction that there exist some $f,g$ satisfying the stated conditions for some $0 < r<\\frac{\\pi}{2}$. We first note that we can assume that $f(x) \\neq 0$ for $x\\in [0,r)$. Indeed, by continuity, $\\{x\\,|\\,x\\geq 0 \\text{ and } f(x)=0\\}$ is a closed subset of $[0,\\infty)$ and thus has a minimum element $r'$ with $0<r'\\leq r$. After replacing $r$ by $r'$, we now have $f(x)\\neq 0$ for $x\\in [0,r)$.\n\nNext we note that $f(r)=0$ implies $g(r) \\neq 0$. Indeed, define the function $k :\\thinspace \\mathbb{R} \\to \\mathbb{R}$ by $k(x) = f(x)^2+g(x)^2$. Then $|k'(x)| = 2|f(x)f'(x)+g(x)g'(x))| \\leq 4|f(x)g(x)| \\leq 2k(x)$, where the last inequality follows from the AM-GM inequality. It follows that $\\left|\\frac{d}{dx} (\\log k(x))\\right| \\leq 2$ for $x \\in [0,r)$; since $k(x)$ is continuous at $x=r$, we conclude that $k(r) \\neq 0$.\n\nNow define the function $h\\colon [0,r) \\to (-\\pi/2,\\pi/2)$ by $h(x) = \\tan^{-1}(g(x)/f(x))$. We compute that\n\\[\nh'(x) = \\frac{f(x)g'(x)-g(x)f'(x)}{f(x)^2+g(x)^2}\n\\]\nand thus\n\\[\n|h'(x)| \\leq \\frac{|f(x)||g'(x)|+|g(x)||f'(x)|}{f(x)^2+g(x)^2} \\leq \\frac{|f(x)|^2+|g(x)|^2}{f(x)^2+g(x)^2} = 1.\n\\]\nSince $h(0) = 0$, we have $|h(x)| \\leq x<r$ for all $x\\in [0,r)$. Since $r<\\pi/2$ and $\\tan^{-1}$ is increasing on $(-r,r)$, we conclude that $|g(x)/f(x)|$ is uniformly bounded above by $\\tan r$ for all $x\\in [0,r)$. But this contradicts the fact that $f(r)=0$ and $g(r) \\neq 0$, since $\\lim_{x\\to r^-} g(x)/f(x) = \\infty$. This contradiction shows that $r<\\pi/2$ cannot be achieved.\n\n\\noindent\n\\textbf{Second solution.}\n(by Victor Lie)\nAs in the first solution, we may assume $f(x) > 0$ \nfor $x \\in [0,r)$.\nCombining our hypothesis with the fundamental theorem of calculus, for $x > 0$ we obtain\n\\begin{align*}\n|f'(x)| &\\leq |g(x)| \\leq \\left| \\int_0^x g'(t)\\,dt \\right|  \\\\\n& \\leq \\int_0^x |g'(t)| \\,dt \\leq \\int_0^x |f(t)|\\,dt.\n\\end{align*}\nDefine $F(x) = \\int_0^x f(t)\\,dt$; we then have\n\\[\nf'(x) + F(x) \\geq 0 \\qquad (x \\in [0,r]).\n\\]\nNow suppose by way of contradiction that $r < \\frac{\\pi}{2}$.\nThen $\\cos x > 0$ for $x \\in [0,r]$, so \n\\[\nf'(x) \\cos x + F(x) \\cos x \\geq 0 \\qquad (x \\in [0,r]).\n\\]\nThe left-hand side is the derivative of $f(x) \\cos x + F(x) \\sin x $. Integrating from $x=y$ to $x=r$, we obtain\n\\[\nF(r) \\sin r \\geq f(y) \\cos y + F(y) \\sin y \\qquad (y \\in [0,r]).\n\\]\nWe may rearrange to obtain\n\\[\nF(r)\\sin r \\sec^2 y \\geq f(y) \\sec y + F(y) \\sin y \\sec^2 y \\quad (y \\in [0,r]).\n\\]\nThe two sides are the derivatives of $F(r) \\sin r \\tan y$ and $F(y) \\sec y$, respectively.\nIntegrating from $y=0$ to $y=r$ and multiplying by $\\cos^2 r$, we obtain\n\\[\nF(r) \\sin^2 r \\geq F(r)\n\\]\nwhich is impossible because $F(r) > 0$ and $0 < \\sin r < 1$."
  },
  {
    "year": 2023,
    "label": "A4",
    "difficulty": "4",
    "problem": "Let $v_1, \\dots, v_{12}$ be unit vectors in $\\mathbb{R}^3$ from the origin to the vertices of a regular icosahedron. Show that for every vector $v \\in \\mathbb{R}^3$ and every $\\varepsilon > 0$, there exist integers $a_1,\\dots,a_{12}$ such that $\\| a_1 v_1 + \\cdots + a_{12} v_{12} - v \\| < \\varepsilon$.",
    "solution": "The assumption that all vertices of the icosahedron correspond to vectors of the same length forces the center of the icosahedron to lie at the origin, since the icosahedron is inscribed in a unique sphere.\nSince scaling the icosahedron does not change whether or not the stated conclusion is true, we may choose coordinates so that the vertices are the cyclic permutations of the vectors $(\\pm \\frac{1}{2}, \\pm \\frac{1}{2} \\phi, 0)$ where\n$\\phi = \\frac{1+\\sqrt{5}}{2}$ is the golden ratio. The subgroup of $\\RR^3$ generated by these vectors contains $G \\times G \\times G$ where $G$ is the subgroup of $\\RR$ generated by 1 and $\\phi$. Since $\\phi$ is irrational, it generates a dense subgroup of $\\RR/\\ZZ$; hence $G$ is dense in $\\RR$, and so $G \\times G \\times G$ is dense in $\\RR^3$,\nproving the claim."
  },
  {
    "year": 2023,
    "label": "A5",
    "difficulty": "5",
    "problem": "For a nonnegative integer $k$, let $f(k)$ be the number of ones in the base 3 representation of $k$. Find all complex numbers $z$ such that\n\\[\n\\sum_{k=0}^{3^{1010}-1} (-2)^{f(k)} (z+k)^{2023} = 0.\n\\]",
    "solution": "The complex numbers $z$ with this property are\n\\[\n-\\frac{3^{1010}-1}{2} \\text{ and } -\\frac{3^{1010}-1}{2}\\pm\\frac{\\sqrt{9^{1010}-1}}{4}\\,i.\n\\]\n\nWe begin by noting that for $n \\geq 1$, we have the following equality of polynomials in a parameter $x$:\n\\[\n\\sum_{k=0}^{3^n-1} (-2)^{f(k)} x^k = \\prod_{j=0}^{n-1} (x^{2\\cdot 3^j}-2x^{3^j}+1).\n\\]\nThis is readily shown by induction on $n$, using the fact that for $0\\leq k\\leq 3^{n-1}-1$, $f(3^{n-1}+k)=f(k)+1$ and $f(2\\cdot 3^{n-1}+k)=f(k)$.\n\nNow define a ``shift'' operator $S$ on polynomials in $z$ by $S(p(z))=p(z+1)$; then we can define $S^m$ for all $m\\in\\mathbb{Z}$ by $S^m(p(z))$, and in particular $S^0=I$ is the identity map. Write\n\\[\np_n(z) := \\sum_{k=0}^{3^n-1}(-2)^{f(k)}(z+k)^{2n+3}\n\\]\nfor $n \\geq 1$; it follows that \n\\begin{align*}\np_n(z) &= \\prod_{j=0}^{n-1}(S^{2\\cdot 3^j}-2S^{3^j}+I) z^{2n+3}\n\\\\\n&= S^{(3^n-1)/2} \\prod_{j=0}^{n-1}(S^{3^j}-2I+S^{-3^j}) z^{2n+3}.\n\\end{align*}\nNext observe that for any $\\ell$, the operator $S^\\ell-2I+S^{-\\ell}$ acts on polynomials in $z$ in a way that decreases degree by $2$. More precisely, for $m\\geq 0$, we have\n\\begin{align*}\n(S^\\ell-2I+S^{-\\ell})z^m &= (z+\\ell)^m-2z^m+(z-\\ell)^m \\\\\n&= 2{m\\choose 2}\\ell^2z^{m-2}+2{m\\choose 4}\\ell^4z^{m-4}+O(z^{m-6}).\n\\end{align*}\nWe use this general calculation to establish the following: for any $1\\leq i\\leq n$, there is a nonzero constant $C_i$ (depending on $n$ and $i$ but not $z$) such that\n\\begin{gather}\n\\nonumber\n\\prod_{j=1}^{i} (S^{3^{n-j}}-2I+S^{-3^{n-j}}) z^{2n+3} \\\\\n\\nonumber\n= C_i\\left(z^{2n+3-2i}+\\textstyle{\\frac{(2n+3-2i)(n+1-i)}{6}}(\\sum_{j=1}^i 9^{n-j})z^{2n+1-2i}\\right) \\\\\n+O(z^{2n-1-2i}).\n\\label{eq:product}\n\\end{gather}\nProving \\eqref{eq:product} is a straightforward induction on $i$: the induction step applies $S^{3^{n-i-1}}-2I+S^{-3^{n-i-1}}$ to the right hand side of \\eqref{eq:product}, using the general formula for $(S^\\ell-2I+S^{-\\ell})z^m$.\n\nNow setting $i=n$ in \\eqref{eq:product}, we find that for some $C_n$,\n\\[\n\\prod_{j=0}^{n-1}(S^{3^j}-2I+S^{-3^j}) z^{2n+3} = C_n\\left(z^3+\\frac{9^n-1}{16}z\\right).\n\\]\nThe roots of this polynomial are $0$ and $\\pm \\frac{\\sqrt{9^n-1}}{4} i$, and it follows that the roots of $p_n(z)$ are these three numbers minus $\\frac{3^n-1}{2}$. In particular, when $n=1010$, we find that the roots of $p_{1010}(z)$ are as indicated above."
  },
  {
    "year": 2023,
    "label": "A6",
    "difficulty": "6",
    "problem": "Alice and Bob play a game in which they take turns choosing integers from $1$ to $n$. Before any integers are chosen, Bob selects a goal of ``odd'' or ``even''. On the first turn, Alice chooses one of the $n$ integers. On the second turn, Bob chooses one of the remaining integers. They continue alternately choosing one of the integers that has not yet been chosen, until the $n$th turn, which is forced and ends the game. Bob wins if the parity of $\\{k\\colon \\mbox{the number $k$ was chosen on the $k$th turn}\\}$ matches his goal. For which values of $n$ does Bob have a winning strategy?",
    "solution": "(Communicated by Kai Wang)\nFor all $n$, Bob has a winning strategy. Note that we can interpret the game play as building a permutation of $\\{1,\\dots,n\\}$, and the number of times an integer $k$ is chosen on the $k$-th turn is exactly the number of fixed points of this permutation.\n\nFor $n$ even, Bob selects the goal ``even''. Divide $\\{1,\\dots,n\\}$ into the pairs $\\{1,2\\},\\{3,4\\},\\dots$; each time Alice chooses an integer, Bob follows suit with the other integer in the same pair. For each pair $\\{2k-1,2k\\}$, we see that $2k-1$ is a fixed point if and only if $2k$ is, so the number of fixed points is even.\n\nFor $n$ odd, Bob selects the goal ``odd''. On the first turn, if Alice chooses 1 or 2, then Bob chooses the other one to transpose into the strategy for $n-2$ (with no moves made). We may thus assume hereafter that Alice's first move is some $k > 2$, which Bob counters with 2; at this point there is exactly one fixed point. \n\nThereafter, as long as Alice chooses $j$ on the $j$-th turn (for $j \\geq 3$ odd), either $j+1 < k$, in which case Bob can choose $j+1$\nto keep the number of fixed points odd; or $j+1=k$, in which case $k$ is even and Bob can choose 1 to transpose into the strategy for  $n-k$ (with no moves made).\n\nOtherwise, at some odd turn $j$, Alice does not choose $j$. At this point, the number of fixed points is odd, and on each subsequent turn Bob can ensure that neither his own move nor Alice's next move does not create a fixed point: on any turn $j$ for Bob, if $j+1$ is available Bob chooses it; otherwise, Bob has at least two choices available, so he can choose a value other than $j$."
  },
  {
    "year": 2023,
    "label": "B1",
    "difficulty": "1",
    "problem": "Consider an $m$-by-$n$ grid of unit squares, indexed by $(i,j)$ with $1 \\leq i \\leq m$ and $1 \\leq j \\leq n$. There are $(m-1)(n-1)$ coins, which are initially placed in the squares $(i,j)$ with $1 \\leq i \\leq m-1$ and $1 \\leq j \\leq n-1$. If a coin occupies the square $(i,j)$ with $i \\leq m-1$ and $j \\leq n-1$ and the squares $(i+1,j), (i,j+1)$, and $(i+1,j+1)$ are unoccupied, then a legal move is to slide the coin from $(i,j)$ to $(i+1,j+1)$. How many distinct configurations of coins can be reached starting from the initial configuration by a (possibly empty) sequence of legal moves?",
    "solution": "The number of such configurations is $\\binom{m+n-2}{m-1}$.\n\nInitially the unoccupied squares form a path from $(1,n)$ to $(m,1)$ consisting of $m-1$ horizontal steps and $n-1$ vertical steps,\nand every move preserves this property. This yields an injective map from the set of reachable configurations to the set of paths of this form.\n\nSince the number of such paths is evidently $\\binom{m+n-2}{m-1}$ (as one can arrange the horizontal and vertical steps in any order),\nit will suffice to show that the map we just wrote down is also surjective; that is, that one can reach any path of this form by a sequence of moves. \n\nThis is easiest to see by working backwards. Ending at a given path, if this path is not the initial path, then it contains at least one sequence of squares of the form $(i,j) \\to (i,j-1) \\to (i+1,j-1)$.\nIn this case the square $(i+1,j)$ must be occupied, so we can undo a move by replacing this sequence with \n$(i,j) \\to (i+1,j) \\to (i+1,j-1)$."
  },
  {
    "year": 2023,
    "label": "B2",
    "difficulty": "2",
    "problem": "For each positive integer $n$, let $k(n)$ be the number of ones in the binary representation of $2023 \\cdot n$. What is the minimum value of $k(n)$?",
    "solution": "The minimum is $3$. \n\n\\noindent\n\\textbf{First solution.}\n\nWe record the factorization $2023 = 7\\cdot 17^2$. We first rule out $k(n)=1$ and $k(n)=2$. If $k(n)=1$, then $2023n = 2^a$ for some $a$, which clearly cannot happen. If $k(n)=2$, then $2023n=2^a+2^b=2^b(1+2^{a-b})$ for some $a>b$. Then $1+2^{a-b} \\equiv 0\\pmod{7}$; but $-1$ is not a power of $2$ mod $7$ since every power of $2$ is congruent to either $1$, $2$, or $4 \\pmod{7}$.\n\nWe now show that there is an $n$ such that $k(n)=3$. It suffices to find $a>b>0$ such that $2023$ divides $2^a+2^b+1$. First note that $2^2+2^1+1=7$ and $2^3 \\equiv 1 \\pmod{7}$; thus if $a \\equiv 2\\pmod{3}$ and $b\\equiv 1\\pmod{3}$ then $7$ divides $2^a+2^b+1$. Next, $2^8+2^5+1 = 17^2$ and $2^{16\\cdot 17} \\equiv 1 \\pmod{17^2}$ by Euler's Theorem; thus if $a \\equiv 8 \\pmod{16\\cdot 17}$ and $b\\equiv 5 \\pmod{16\\cdot 17}$ then $17^2$ divides $2^a+2^b+1$.\n\nWe have reduced the problem to finding $a,b$ such that $a\\equiv 2\\pmod{3}$, $a\\equiv 8\\pmod{16\\cdot 17}$, $b\\equiv 1\\pmod{3}$, $b\\equiv 5\\pmod{16\\cdot 17}$. But by the Chinese Remainder Theorem, integers $a$ and $b$ solving these equations exist and are unique mod $3\\cdot 16\\cdot 17$. Thus we can find $a,b$ satisfying these congruences; by adding appropriate multiples of $3\\cdot 16\\cdot 17$, we can also ensure that $a>b>1$.\n\n\\noindent\n\\textbf{Second solution.}\nWe rule out $k(n) \\leq 2$ as in the first solution.\nTo force $k(n) = 3$, we first note that $2^4 \\equiv -1 \\pmod{17}$\nand deduce that $2^{68} \\equiv -1 \\pmod{17^2}$.\n(By writing $2^{68} = ((2^4+1) - 1)^{17}$ and expanding the binomial, we obtain $-1$ plus some terms each of which is divisible by 17.) Since $(2^8-1)^2$ is divisible by $17^2$,\n\\begin{align*}\n0 &\\equiv 2^{16} - 2\\cdot 2^8 + 1 \\equiv 2^{16} + 2\\cdot 2^{68}\\cdot 2^8 + 1 \\\\\n&= 2^{77} + 2^{16} + 1 \\pmod{17^2}.\n\\end{align*}\nOn the other hand, since $2^3 \\equiv -1 \\pmod{7}$, \n\\[\n2^{77} + 2^{16} + 1 \\equiv 2^2 + 2^1 + 1 \\equiv 0 \\pmod{7}.\n\\]\nHence $n = (2^{77}+2^{16}+1)/2023$ is an integer with $k(n) = 3$.\n\n\\noindent\n\\textbf{Remark.} \nA short computer calculation shows that the value of $n$ with $k(n)=3$ found in the second solution is the smallest possible.\nFor example, in SageMath, this reduces to a single command:\n\\begin{verbatim}\nassert all((2^a+2^b+1) % 2023 != 0\n    for a in range(1,77) for b in range(1,a))\n\\end{verbatim}"
  },
  {
    "year": 2023,
    "label": "B3",
    "difficulty": "3",
    "problem": "A sequence $y_1,y_2,\\dots,y_k$ of real numbers is called \\emph{zigzag} if $k=1$, or if $y_2-y_1, y_3-y_2, \\dots, y_k-y_{k-1}$ are nonzero and alternate in sign. Let $X_1,X_2,\\dots,X_n$ be chosen independently from the uniform distribution on $[0,1]$. Let $a(X_1,X_2,\\dots,X_n)$ be the largest value of $k$ for which there exists an increasing sequence of integers $i_1,i_2,\\dots,i_k$ such that $X_{i_1},X_{i_2},\\dots,X_{i_k}$ is zigzag. Find the expected value of $a(X_1,X_2,\\dots,X_n)$ for $n \\geq 2$.",
    "solution": "The expected value is $\\frac{2n+2}{3}$.\n\nDivide the sequence $X_1,\\dots,X_n$ into alternating increasing and decreasing segments, with $N$ segments in all. Note that removing one term cannot increase $N$: if the removed term is interior to some segment then the number remains unchanged, whereas if it separates two segments then one of those decreases in length by 1 (and possibly disappears). From this it follows that $a(X_1,\\dots,X_n) = N+1$: in one direction, the endpoints of the segments form a zigzag of length $N+1$; in the other, for any zigzag $X_{i_1},\\dots, X_{i_m}$, we can view it as a sequence obtained from $X_1,\\dots,X_n$ by removing terms, so its number of segments (which is manifestly $m-1$) cannot exceed $N$.\n\nFor $n \\geq 3$, $a(X_1,\\dots,X_n) - a(X_2,\\dots,X_{n})$\nis 0 if $X_1, X_2, X_3$ form a monotone sequence and 1 otherwise. Since the six possible orderings of $X_1,X_2,X_3$ are equally likely,\n\\[\n\\mathbf{E}(a(X_1,\\dots,X_n) - a(X_1,\\dots,X_{n-1})) = \\frac{2}{3}.\n\\]\nMoreover, we always have $a(X_1, X_2) = 2$ because any sequence of two distinct elements is a zigzag. By linearity of expectation plus induction on $n$, we obtain $\\mathbf{E}(a(X_1,\\dots,X_n)) = \\frac{2n+2}{3}$ as claimed."
  },
  {
    "year": 2023,
    "label": "B4",
    "difficulty": "4",
    "problem": "For a nonnegative integer $n$ and a strictly increasing sequence of real numbers $t_0,t_1,\\dots,t_n$, let $f(t)$ be the corresponding real-valued function defined for $t \\geq t_0$ by the following properties:\n\\begin{enumerate}",
    "solution": "The minimum value of $T$ is 29.\n\nWrite $t_{n+1} = t_0+T$ and define $s_k = t_k-t_{k-1}$ for $1\\leq k\\leq n+1$. On $[t_{k-1},t_k]$, we have $f'(t) = k(t-t_{k-1})$ and so $f(t_k)-f(t_{k-1}) = \\frac{k}{2} s_k^2$. Thus if we define\n\\[\ng(s_1,\\ldots,s_{n+1}) = \\sum_{k=1}^{n+1} ks_k^2,\n\\]\nthen we want to minimize $\\sum_{k=1}^{n+1} s_k = T$ (for all possible values of $n$) subject to the constraints that $g(s_1,\\ldots,s_{n+1}) = 4045$ and $s_k \\geq 1$ for $k \\leq n$.\n\nWe first note that a minimum value for $T$ is indeed achieved. To see this, note that the constraints $g(s_1,\\ldots,s_{n+1}) = 4045$ and $s_k \\geq 1$ place an upper bound on $n$. For fixed $n$, the constraint $g(s_1,\\ldots,s_{n+1}) = 4045$ places an upper bound on each $s_k$, whence the set of $(s_1,\\ldots,s_{n+1})$ on which we want to minimize $\\sum s_k$ is a compact subset of $\\mathbb{R}^{n+1}$.\n\nNow say that $T_0$ is the minimum value of $\\sum_{k=1}^{n+1} s_k$ (over all $n$ and $s_1,\\ldots,s_{n+1}$), achieved by $(s_1,\\ldots,s_{n+1}) = (s_1^0,\\ldots,s_{n+1}^0)$. Observe that there cannot be another $(s_1,\\ldots,s_{n'+1})$ with the same sum, $\\sum_{k=1}^{n'+1} s_k = T_0$, satisfying $g(s_1,\\ldots,s_{n'+1}) > 4045$; otherwise, the function $f$ for $(s_1,\\ldots,s_{n'+1})$ would satisfy $f(t_0+T_0) > 4045$ and there would be some $T<T_0$ such that $f(t_0+T) = 4045$ by the intermediate value theorem.\n\nWe claim that $s_{n+1}^0 \\geq 1$ and $s_k^0 = 1$ for $1\\leq k\\leq n$. If $s_{n+1}^0<1$ then\n\\begin{align*}\n& g(s_1^0,\\ldots,s_{n-1}^0,s_n^0+s_{n+1}^0)-g(s_1^0,\\ldots,s_{n-1}^0,s_n^0,s_{n+1}^0) \\\\\n&\\quad = s_{n+1}^0(2ns_n^0-s_{n+1}^0) > 0,\n\\end{align*}\ncontradicting our observation from the previous paragraph. Thus $s_{n+1}^0 \\geq 1$. If $s_k^0>1$ for some $1\\leq k\\leq n$ then replacing $(s_k^0,s_{n+1}^0)$ by $(1,s_{n+1}^0+s_k^0-1)$ increases $g$:\n\\begin{align*}\n&g(s_1^0,\\ldots,1,\\ldots,s_{n+1}^0+s_k^0-1)-g(s_1^0,\\ldots,s_k^0,\\ldots,s_{n+1}^0) \\\\\n&\\quad= (s_k^0-1)((n+1-k)(s_k^0+1)+2(n+1)(s_{n+1}^0-1)) > 0,\n\\end{align*}\nagain contradicting the observation. This establishes the claim.\n\nGiven that $s_k^0 = 1$ for $1 \\leq k \\leq n$, we have\n$T = s_{n+1}^0 + n$ and\n\\[\ng(s_1^0,\\dots,s_{n+1}^0) = \\frac{n(n+1)}{2} + (n+1)(T-n)^2.\n\\]\nSetting this equal to 4045 and solving for $T$ yields\n\\[\nT = n+\\sqrt{\\frac{4045}{n+1} - \\frac{n}{2}}.\n\\]\nFor $n=9$ this yields $T = 29$; it thus suffices to show that for all $n$, \n\\[\nn+\\sqrt{\\frac{4045}{n+1} - \\frac{n}{2}} \\geq 29.\n\\]\nThis is evident for $n \\geq 30$. For $n \\leq 29$, rewrite the claim as\n\\[\n\\sqrt{\\frac{4045}{n+1} - \\frac{n}{2}} \\geq 29-n;\n\\]\nwe then obtain an equivalent inequality by squaring both sides:\n\\[\n\\frac{4045}{n+1} - \\frac{n}{2} \\geq n^2-58n+841.\n\\]\nClearing denominators, gathering all terms to one side, and factoring puts this in the form\n\\[\n(9-n)(n^2 - \\frac{95}{2} n + 356) \\geq 0.\n\\]\nThe quadratic factor $Q(n)$ has a minimum at $\\frac{95}{4} = 23.75$\nand satisfies $Q(8) = 40, Q(10) = -19$; it is thus positive for $n \\leq 8$ and negative for $10 \\leq n \\leq 29$."
  },
  {
    "year": 2023,
    "label": "B5",
    "difficulty": "5",
    "problem": "Determine which positive integers $n$ have the following property:\nFor all integers $m$ that are relatively prime to $n$, there exists a permutation $\\pi\\colon \\{1,2,\\dots,n\\} \\to \\{1,2,\\dots,n\\}$ such that $\\pi(\\pi(k)) \\equiv mk \\pmod{n}$ for all $k \\in \\{1,2,\\dots,n\\}$.",
    "solution": "The desired property holds if and only if $n = 1$ or $n \\equiv 2 \\pmod{4}$.\n\nLet $\\sigma_{n,m}$ be the permutation of $\\ZZ/n\\ZZ$ induced by multiplication by $m$; the original problem asks for which $n$ does $\\sigma_{n,m}$ always have a square root. For $n=1$, $\\sigma_{n,m}$ is the identity permutation and hence has a square root.\n\nWe next identify when a general permutation admits a square root.\n\n\\begin{lemma} \\label{lem:2023B5-2}\nA permutation $\\sigma$ in $S_n$ can be written as the square of another permutation if and only if for every even positive integer $m$, the number of cycles of length $m$ in $\\sigma$ is even.\n\\end{lemma}\n\\begin{proof}\nWe first check the ``only if'' direction. Suppose that $\\sigma = \\tau^2$. Then every cycle of $\\tau$ of length $m$ remains a cycle in $\\sigma$ if $m$ is odd, and splits into two cycles of length $m/2$ if $m$ is even.\n\nWe next check the ``if'' direction. We may partition the cycles of $\\sigma$ into individual cycles of odd length and pairs of cycles of the same even length; then we may argue as above to write each partition as the square of another permutation.\n\\end{proof}\n\nSuppose now that $n>1$ is odd. Write $n = p^e k$ where $p$ is an odd prime, $k$ is a positive integer, and $\\gcd(p,k) = 1$. \nBy the Chinese remainder theorem, we have a ring isomorphism \n\\[\n\\ZZ/n\\ZZ \\cong \\ZZ/p^e \\ZZ \\times \\ZZ/k \\ZZ.\n\\]\nRecall that the group $(\\ZZ/p^e \\ZZ)^\\times$ is cyclic; choose $m \\in \\ZZ$ reducing to a generator of $(\\ZZ/p^e \\ZZ)^\\times$ and to the identity in $(\\ZZ/k\\ZZ)^\\times$. Then $\\sigma_{n,m}$ consists of $k$ cycles (an odd number) of length $p^{e-1}(p-1)$ (an even number) plus some shorter cycles. By Lemma~\\ref{lem:2023B5-2}, $\\sigma_{n,m}$ does not have a square root.\n\nSuppose next that $n \\equiv 2 \\pmod{4}$. Write $n = 2k$ with $k$ odd, so that \n\\[\n\\ZZ/n\\ZZ \\cong \\ZZ/2\\ZZ \\times \\ZZ/k\\ZZ.\n\\]\nThen $\\sigma_{n,m}$ acts on $\\{0\\} \\times \\ZZ/k\\ZZ$ and $\\{1\\} \\times \\ZZ/k\\ZZ$ with the same cycle structure, so every cycle length occurs an even number of times. By Lemma~\\ref{lem:2023B5-2}, $\\sigma_{n,m}$ has a square root.\n\nFinally, suppose that $n$ is divisible by 4. For $m = -1$, $\\sigma_{n,m}$ consists of two fixed points ($0$ and $n/2$) together with $n/2-1$ cycles (an odd number) of length 2 (an even number). \nBy Lemma~\\ref{lem:2023B5-2}, $\\sigma_{n,m}$ does not have a square root."
  },
  {
    "year": 2023,
    "label": "B6",
    "difficulty": "6",
    "problem": "Let $n$ be a positive integer. For $i$ and $j$ in $\\{1,2,\\dots,n\\}$, let $s(i,j)$ be the number of pairs $(a,b)$ of nonnegative integers satisfying $ai +bj=n$. Let $S$ be the $n$-by-$n$ matrix whose $(i,j)$ entry is $s(i,j)$. For example, when $n=5$, we have\n$S = \\begin{bmatrix} 6 & 3 & 2 & 2 & 2 \\\\\n3 & 0 & 1 & 0 & 1 \\\\\n2 & 1 & 0 & 0 & 1 \\\\\n2 & 0 & 0 & 0 & 1 \\\\\n2 & 1 & 1 & 1 & 2\n\\end{bmatrix}$. \nCompute the determinant of $S$.\n\n\\end{itemize}\n\n\\end{document}",
    "solution": "The determinant equals $(-1)^{\\lceil n/2 \\rceil-1} 2 \\lceil \\frac{n}{2} \\rceil$.\n\nTo begin with, we read off the following features of $S$.\n\\begin{itemize}\n\\item\n$S$ is symmetric: $S_{ij} = S_{ji}$ for all $i,j$, corresponding to $(a,b) \\mapsto (b,a)$).\n\\item\n$S_{11} = n+1$, corresponding to $(a,b) = (0,n),(1,n-1),\\dots,(n,0)$.\n\\item\nIf $n = 2m$ is even, then $S_{mj} = 3$ for $j=1,m$, corresponding to $(a,b) = (2,0),(1,\\frac{n}{2j}),(0,\\frac{n}{j})$.\n\\item\nFor $\\frac{n}{2} < i \\leq n$, $S_{ij} = \\# (\\ZZ \\cap \\{\\frac{n-i}{j}, \\frac{n}{j}\\})$, corresponding to $(a,b) = (1, \\frac{n-i}{j}), (0, \\frac{n}{j})$.\n\\end{itemize}\n\nLet $T$ be the matrix obtained from $S$ by performing row and column operations as follows: for $d=2,\\dots,n-2$, \nsubtract $S_{nd}$ times row $n-1$ from row $d$ and subtract $S_{nd}$ times column $n-1$ from column $d$; then subtract \nrow $n-1$ from row $n$ and column $n-1$ from column $n$.\nEvidently $T$ is again symmetric and $\\det(T) = \\det(S)$.\n\nLet us examine row $i$ of $T$ for $\\frac{n}{2} < i < n-1$:\n\\begin{align*}\nT_{i1} &= S_{i1} - S_{in} S_{(n-1)1} = 2-1\\cdot 2 = 0 \\\\\nT_{ij} &= S_{ij} - S_{in} S_{(n-1)j} - S_{nj}S_{i(n-1)}\\\\\n& =\n\\begin{cases} 1 & \\mbox{if $j$ divides $n-i$} \\\\\n0 & \\mbox{otherwise}.\n\\end{cases} \\quad (1 < j < n-1) \\\\\nT_{i(n-1)} &= S_{i(n-1)} - S_{in} S_{(n-1)(n-1)} = 0-1\\cdot0 = 0 \\\\\nT_{in} &= S_{in} - S_{in} S_{(n-1)n} - S_{i(n-1)}\n = 1 - 1\\cdot1 - 0 = 0.\n\\end{align*}\nNow recall (e.g., from the expansion of a determinant in minors) \nif a matrix contains an entry equal to 1 which is the unique nonzero entry in either its row or its column, then we may strike out this entry (meaning striking out the row and column containing it) at the expense of multiplying the determinant by a sign. To simplify notation, we do \\emph{not} renumber rows and columns after performing this operation.\n\nWe next verify that for the matrix $T$, for $i=2,\\dots,\\lfloor \\frac{n}{2} \\rfloor$ in turn, it is valid to strike out\n$(i,n-i)$ and $(n-i, i)$ at the cost of multiplying the determinant by -1. Namely, when we reach the entry $(n-i,i)$, the only other nonzero entries in this row have the form $(n-i,j)$ where $j>1$ divides $n-i$, and those entries are in previously struck columns. \n\nWe thus compute $\\det(S) = \\det(T)$ as:\n\\begin{gather*}\n(-1)^{\\lfloor n/2 \\rfloor-1}\n\\det \\begin{pmatrix}\nn+1 & -1 & 0 \\\\\n-1 & 0 & 1 \\\\\n0 & 1  & 0\n\\end{pmatrix} \\mbox{for $n$ odd,} \\\\\n(-1)^{\\lfloor n/2 \\rfloor-1}\n \\det \\begin{pmatrix}\nn+1 & -1 & 2 & 0 \\\\\n-1 & -1 & 1 & -1 \\\\\n2 & 1 & 0 & 1 \\\\\n0 & -1 & 1 & 0\n\\end{pmatrix} \\mbox{for $n$ even.}\n\\end{gather*}\nIn the odd case, we can strike the last two rows and columns (creating another negation) and then conclude at once. In the even case, the rows and columns are labeled $1, \\frac{n}{2}, n-1, n$; by adding row/column $n-1$ to row/column $\\frac{n}{2}$, we produce\n\\[\n(-1)^{\\lfloor n/2 \\rfloor}\n \\det \\begin{pmatrix}\nn+1 & 1 & 2 & 0 \\\\\n1 & 1 & 1 & 0 \\\\\n2 & 1 & 0 & 1 \\\\\n0 & 0 & 1 & 0\n\\end{pmatrix}\n\\]\nand we can again strike the last two rows and columns (creating another negation) and then read off the result.\n\n\\noindent\n\\textbf{Remark.}\nOne can use a similar approach to compute some related determinants.\nFor example, let $J$ be the matrix with $J_{ij} = 1$ for all $i,j$.\nIn terms of an indeterminate $q$, define the matrix $T$ by \n\\[\nT_{ij} = q^{S_{ij}}.\n\\]\nWe then have\n\\[\n\\det(T-tJ) = (-1)^{\\lceil n/2 \\rceil-1} q^{2(\\tau(n)-1)} (q-1)^{n-1}f_n(q,t)\n\\]\nwhere $\\tau(n)$ denotes the number of divisors of $n$\nand\n\\[\nf_n(q,t) = \\begin{cases} q^{n-1}t+q^2-2t & \\mbox{for $n$ odd,} \\\\q^{n-1}t +q^2-qt-t & \\mbox{for $n$ even.}\n\\end{cases}\n\\]\nTaking $t=1$ and then dividing by $(q-1)^n$, this yields a \\emph{$q$-deformation} of the original matrix $S$.\n\n\\end{itemize}\n\\end{document}"
  }
]